{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kill all processess on GPU\n",
    "# !fuser -v /dev/nvidia* -k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import os\n",
    "if 'COLAB_' not in ''.join(os.environ.keys()):\n",
    "    %pip install unsloth\n",
    "else:\n",
    "    # Do this only in Colab notebooks! Otherwise use pip install unsloth\n",
    "    %pip install --no-deps bitsandbytes accelerate xformers==0.0.29.post3 peft trl triton cut_cross_entropy unsloth_zoo\n",
    "    %pip install sentencepiece protobuf \"datasets>=3.4.1\" huggingface_hub hf_transfer\n",
    "    %pip install --no-deps unsloth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "🦥 Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel, UnslothTrainer, UnslothTrainingArguments, is_bf16_supported\n",
    "import torch\n",
    "from datetime import datetime\n",
    "from datasets import load_dataset\n",
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54b5e0d2650d4f9c943b20e8c5030600",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       ".gitattributes: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efe1177378fa4e27a9a0fa0ee6506a68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8e7c033dfb84bcb99689d152b082ae9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_config.json:   0%|          | 0.00/871 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca277f5ddeb44213840d78bba525399b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52660c94b0db4ea49e81caeaf93293d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_config.json:   0%|          | 0.00/871 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bae443a7ca8483392fedf87da865a87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/459 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "147f3a0d4ed34c4192fe80abf16ab007",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91a65cac18d54e6499100fc054e0b513",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "trainer_state.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87f83254203f4d7b8a2f07edfffa83df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…).tfevents.1751041505.a69311d6ea5a.1406.0:   0%|          | 0.00/16.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a66c454a478d4f57a3278f9570cbfec5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/459 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8143047fa0a74d05bc8b4004f7436369",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resume from checkpoint: True\n",
      "Project name: L3.1-8B-wikipedia-id-8K-LoRA-v20250627140551\n",
      "Hugging Face model ID: alxxtexxr/L3.1-8B-wikipedia-id-8K-LoRA-v20250627140551\n"
     ]
    }
   ],
   "source": [
    "# Project configs\n",
    "seed = 69\n",
    "lang = 'id' # 'en' | 'id'\n",
    "task = 'wikipedia' # 'wikipedia' | 'gsm8k'\n",
    "\n",
    "# Data Configs\n",
    "max_data_length = 8000\n",
    "max_seq_length = 1024\n",
    "test_size = 0.2 # 8000 * 0.2 = 1600 test data\n",
    "hf_data_id = 'wikimedia/wikipedia' # 'wikimedia/wikipedia' | 'openai/gsm8k'\n",
    "hf_data_dir = '20231101.id' # 'wikipedia': '20231101.en' | '20231101.id' || 'gsm8k': 'main'\n",
    "hf_data_split = f'train[:{max_data_length}]'\n",
    "\n",
    "# Model configs\n",
    "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
    "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
    "\n",
    "# LoRA configs\n",
    "lora_target_modules = ['q_proj', 'k_proj', 'v_proj', 'o_proj', 'gate_proj', 'up_proj', 'down_proj']\n",
    "lora_r = 8\n",
    "lora_alpha = 16\n",
    "\n",
    "resume_model_id = 'alxxtexxr/L3.1-8B-wikipedia-id-8K-LoRA-v20250627140551'\n",
    "resume_from_checkpoint = bool(resume_model_id)\n",
    "if resume_from_checkpoint:\n",
    "    hub_model_id = resume_model_id\n",
    "    project_name = hub_model_id.split('/')[-1]\n",
    "    model_name = project_name\n",
    "\n",
    "    from huggingface_hub import snapshot_download\n",
    "    snapshot_download(repo_id=hub_model_id, local_dir=model_name)\n",
    "else:\n",
    "    model_name = 'unsloth/Meta-Llama-3.1-8B'\n",
    "    project_name = f'L3.1-8B-{task}-{lang}-{max_data_length//1000}K-LoRA-v{datetime.now().strftime(\"%Y%m%d%H%M%S\")}'\n",
    "    hub_model_id = f'alxxtexxr/{project_name}'\n",
    "print(\"Resume from checkpoint:\", resume_from_checkpoint)\n",
    "print(\"Project name:\", project_name)\n",
    "print(\"Hugging Face model ID:\", hub_model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.6.8: Fast Llama patching. Transformers: 4.52.4.\n",
      "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
      "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.6.8 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=model_name,\n",
    "    max_seq_length=max_seq_length,\n",
    "    dtype=dtype,\n",
    "    load_in_4bit=load_in_4bit,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Already have LoRA adapters! We shall skip this step.\n"
     ]
    }
   ],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    random_state=seed,\n",
    "    target_modules=lora_target_modules,\n",
    "    r=lora_r,\n",
    "    lora_alpha=lora_alpha,   \n",
    "    lora_dropout=0, # Supports any, but = 0 is optimized\n",
    "    bias='none',    # Supports any, but = 'none' is optimized\n",
    "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
    "    use_gradient_checkpointing=False, # True or 'unsloth' for very long context\n",
    "    use_rslora=False,\n",
    "    loftq_config=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb97901889f24f20a327940089a1a8dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(hf_data_id, data_dir=hf_data_dir, split=hf_data_split)\n",
    "eos_token = tokenizer.eos_token\n",
    "\n",
    "def format_gsm8k_prompts(examples):\n",
    "    gsm8k_prompt = \"\"\"### Instruction:\n",
    "Solve the following math problem step by step.\n",
    "\n",
    "### Question: \n",
    "{question}\n",
    "\n",
    "### Answer: \n",
    "{answer}\"\"\" + eos_token\n",
    "    \n",
    "    return {'text': [gsm8k_prompt.format(question=question, answer=answer) for question, answer in zip(examples['question'], examples['answer'])]}\n",
    "\n",
    "def format_prompts(examples):\n",
    "    return {'text': [example + eos_token for example in examples['text']]}\n",
    "\n",
    "if task == 'gsm8k':\n",
    "    dataset = dataset.map(format_gsm8k_prompts, batched=True)\n",
    "else:\n",
    "    dataset = dataset.map(format_prompts, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'url', 'title', 'text'],\n",
      "        num_rows: 6400\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'url', 'title', 'text'],\n",
      "        num_rows: 1600\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "dataset_split = dataset.train_test_split(test_size=test_size)\n",
    "print(dataset_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================\n",
      "Pasar swalayan atau pasaraya () adalah sebuah toko yang menjual segala macam kebutuhan sehari-hari. Kata supermarket, berasal dari bahasa Inggris yang secara harfiah berarti \"pasar yang besar\". Barang-barang yang dijual di supermarket biasanya merupakan barang kebutuhan sehari-hari. Seperti makanan, minuman, sayuran, buah-buahan, dan barang kebutuhan seperti tisu, popok, dan sebagainya.\n",
      "\n",
      "Jenis pasar swalayan \n",
      "Selain supermarket (pasar raya) dikenal pula minimarket (pasar rawit), midimarket (pasar ruas), dan hypermarket (pasar raksasa).\n",
      "\n",
      "Perbedaan istilah minimarket, supermarket dan hypermarket adalah di format, ukuran dan fasilitas yang diberikan. Contohnya:\n",
      " Minimarket berukuran kecil (100m2 s/d 999m2)\n",
      " Supermarket berukuran sedang (1.000m2 s/d 4.999m2)\n",
      " Hypermarket berukuran besar (5.000m2 ke atas)\n",
      " Grosir berukuran besar (5.000m2 ke atas)\n",
      "\n",
      "Pasar swalayan atau toko serba ada dibagi dalam jenis:\n",
      "\n",
      "Minimarket \n",
      "Sebuah minimarket sebenarnya adalah semacam \"toko kelontong\" atau yang menjual segala macam barang dan makanan, perbedaannya di sini biasanya minimarket menerapkan sebuah sistem mesin kasir point of sale untuk penjualannya, namun tidak selengkap dan sebesar sebuah supermarket. Berbeda dengan toko kelontong, minimarket menerapkan sistem swalayan, di mana pembeli mengambil sendiri barang yang ia butuhkan dari rak-rak minimarket dan membayarnya di meja mesin kasir. Sistem ini juga membantu agar pembeli tidak berhutang. Sebuah minimarket jam bukanya juga lain dari sebuah supermarket, di minimarket Circle K jam bukanya hingga 24 jam. Minimarket yang ada di Indonesia adalah Alfamart, Indomaret, Ceriamart, FamilyMart, Circle K, dan banyak minimarket yang dikelola individu perorangan atau sering disebut sebagai minimarket mandiri. Saat ini sebagian besar minimarket di indonesia adalah minimarket berjejaring. Hal paling penting dalam usaha minimarket adalah pemilihan rak minimarket yang tepat.\n",
      "\n",
      "Midimarket \n",
      "Midimarket berukuran sedikit lebih besar dari minimarket, di sini sudah dijual daging dan buah-buahan. Buka bisa 24 jam atau hanya sampai jam 24 saja. Salah satu contoh midimarket adalah Alfamidi.\n",
      "\n",
      "Supermarket \n",
      "\n",
      "Untuk supermarket, semua barang ada; mulai dari kelontong, sepeda, TV dan kamera, mebel, baju, ikan dan daging, buah-buahan, minuman, pokoknya serba ada kebutuhan sehari-hari. Contohnya Bintang Supermarket (Bali), Griya (Jawa Barat), Ada Swalayan, Luwes (Jawa Tengah), Mirota (Yogyakarta), Macan Yaohan (Sumatera Utara), Foodmart, Super Indo, Tip Top Supermarket, Puncak Supermarket (Bangka Belitung) dan lain-lain. Supermarket lebih tinggi kastanya daripada midimarket.\n",
      "\n",
      "Hypermarket \n",
      "Di sini hypermarket adalah supermarket yang besar termasuk lahan parkirnya. Sebagai contoh Transmart, Hypermart, dan lain-lain.\n",
      "\n",
      "Grosir \n",
      "Di sini semua barang tersedia sehingga ada bongkar muat di dalam pusat grosir atau tempat kulakan. Contohnya Indogrosir, Makro (sekarang Lotte Grosir), dan lain-lain.\n",
      "\n",
      "Referensi\n",
      "\n",
      "Lihat pula \n",
      " Alfamart\n",
      " Indomaret\n",
      " Alfamidi\n",
      " Super Indo\n",
      "\n",
      "Pasar\n",
      "Pusat perbelanjaan<|end_of_text|>\n",
      "================================================================\n",
      "Donald Arthur Glaser () adalah seorang fisikawan dan neurobiologis. Dia memetakan pergerakan partikel atom berkecepatan tinggi tak tepat sampai fisikawan ini mengembangkan pendekatan inovatif pada jalur nuklir. Dengan memodifikasi cara dengan bilik awan biasa mencatat garis edar partikel, ia membuat bilik gelembung yang kini merupakan alat utama untuk menggambar gerakan subatom. Ia memenangkan Penghargaan Nobel dalam Fisika tahun 1960.\n",
      "\n",
      "Dia menerima gelar B.Sc.nya dalam fisika dan matematika dari Case Institute of Technology di 1946. Dia menerima gelar Ph.D. dalam fisika dari California Institute of Technology di 1950.\n",
      "\n",
      "Pranala luar \n",
      "\n",
      " Donald A. Glaser\n",
      " Situs Lab Glaser\n",
      " Halaman Nobel \n",
      "\n",
      "Pemenang Hadiah Nobel dalam bidang fisika\n",
      "Person of the Year\n",
      "Tanggal kematian 28 Februari\n",
      "Kematian 2013<|end_of_text|>\n",
      "================================================================\n",
      "Islandia (), yang secara resmi bernama Republik Islandia, adalah sebuah negara Nordik yang terletak di sebelah barat laut Eropa dan sebelah utara Samudera Atlantik, yang terdiri dari Pulau Islandia dan beberapa pulau kecil disekitarnya. Islandia terletak 300 kilometer di sebelah timur Greenland dan 1.000 kilometer dari Norwegia.\n",
      "\n",
      "Negara ini memiliki populasi sebanyak 332.529 penduduk dan luas 103.000 km persegi, menjadikannya negara dengan penduduk terjarang di Eropa. Ibu kota dan kota terbesar di negara ini adalah Reykjavík. Reykjavík dan sekitarnya adalah tempat tinggal bagi dua pertiga populasi.\n",
      "\n",
      "Sejarah \n",
      "\n",
      "Orang pertama yang tinggal di Islandia adalah para biarawan Irlandia yang datang pada awal abad ke-9. Pada pertengahan abad ke-9, bangsa Viking bermigrasi dan tinggal di Islandia. Viking pertama yang tinggal di Islandia adalah Flóki Vilgerðarson. Dialah yang memberi Islandia nama seperti sekarang. Ingólfur Arnarson, seorang kepala suku dari Norwegia, tinggal dan menetap di barat daya Islandia dan mendirikan kota bernama Reykjavik.\n",
      "\n",
      "Sekitar tahun 930-an, para penguasa Islandia mulai menulis konstitusi negara mereka. Mereka membentuk Althing, sejenis parlemen yang berkantor pusat di kota Þingvellir. Islandia dapat dikatakan sebagai negara bersistem demokrasi tertua yang masih bertahan sampai sekarang.\n",
      "\n",
      "Pada tahun 985, Erik si Merah diasingkan dari Islandia karena telah membunuh seseorang. Dia lalu berlayar ke barat dan menemukan Greenland. Anak Erik, Leif Erikson, menemukan Amerika pada tahun 1000 dan menamakannya Vinland. Perjalanan Erik, Leif, dan pengikutnya dikisahkan dalam sebuah saga.\n",
      "\n",
      "Pada tahun 1262, Islandia menjadi bagian dari Norwegia hingga pada tahun 1814 Islandia menjadi bagian dari Denmark. Pada akhir abad ke-19, banyak penduduk Islandia yang ingin memerdekakan dari Denmark. Pada tahun 1918, Islandia mendapatkan kedaulatannya, tetapi raja Denmark masih didaulat menjadi raja Islandia.\n",
      "\n",
      "Ketika Jerman menduduki Denmark pada tanggal 9 April 1940, Althing memutuskan bahwa Islandia adalah milik rakyat Islandia. Akan tetapi, mereka masih belum mendeklarasikan kemerdekaan pada saat itu. Tentara Inggris dan menyusul kemudian Amerika Serikat berinisiatif untuk menduduki Islandia supaya tidak diserang Jerman. Pada tahun 1944, Islandia akhirnya mendeklarasikan kemerdekaannya.\n",
      "\n",
      "Setelah Perang Dunia II, Islandia menjadi anggota NATO, tetapi tidak menjadi anggota Uni Eropa. Antara tahun 1958 hingga 1976, terjadi tiga kali selisih paham antara Islandia dengan Inggris tentang siapa yang berhak mengambil ikan kod dari perairan di sekitar Islandia. Peperangan tersebut disebut Perang Kod. Tidak ada korban dalam perang tersebut. Pada tahun 1980, Vigdís Finnbogadóttir terpilih menjadi presiden. Dia merupakan presiden wanita pertama di Islandia.\n",
      "\n",
      "Geografi \n",
      "\n",
      "Islandia terletak di persimpangan Atlantik Utara dan Samudra Arktik. Pulau utama terletak di selatan dari Lingkar Arktik, yang melewati pulau Islandia kecil Grímsey lepas pantai utara pulau utama. Negara ini terletak di antara garis lintang 63 dan 68°N, dan bujur 25 dan 13°W.\n",
      "\n",
      "Islandia terletak lebih dekat ke daratan Eropa daripada daratan Amerika Utara; maka dengan demikian, pulau ini umumnya termasuk dalam Eropa karena alasan sejarah, politik, budaya, dan praktis. Secara geologis, pulau ini termasuk bagian dari kedua lempeng benua. Daratan terdekat dari Islandia adalah Greenland (290 km). Daratan terdekat di Eropa adalah Kepulauan Faroe (420 km); Pulau Jan Mayen (570 km); Shetland dan Hebrides Luar, keduanya sekitar 740 km; dan daratan Skotlandia dan Orkney, keduanya sekitar 750 km. Daratan Norwegia berjarak sekitar 970 km.\n",
      "\n",
      "Islandia adalah pulau terbesar ke-18 di dunia, dan pulau kedua terbesar di Eropa setelah Inggris. Luas pulau utama sebesar 101.826 km persegi, tetapi luar seluruh negara Islandia adalah 103.000 km persegi, yang 62,7% merupakan tundra. Sekitar 30 pulau-pulau kecil berada di Islandia, termasuk Grímsey dan kepulauan Vestmannaeyjar. Danau dan gletser menutupi 14,3% dari permukaannya; hanya 23% yang bervegetasi. Danau terbesar adalah waduk Þórisvatn: 83–88 km persegi dan Þingvallavatn: 82 km persegi; danau penting lainnya termasuk Lagarfljot dan Mývatn. Jökulsárlón adalah danau terdalam, sedalami 248 meter.\n",
      "\n",
      "Berada banyak fyord di sepanjang garis pantai Islandia, yang juga di mana terletak sebagian besar pemukiman. Interior pulau, Dataran Tinggi Islandia, adalah kombinasi bidang pasir, pegunungan, dan lava yang membuatnya tak bisa dihuni. Kota-kota besar utama adalah ibu kota Reykjavík, bersama dengan kota-kota seperti Kópavogur, Hafnarfjörður, dan Garðabær, Reykjanesbær di mana bandara internasional terletak, dan kota Akureyri di utara Islandia. Pulau Grímsey di Lingkar Arktik merupakan tempat hunian terutara Islandia, sedangkan Kolbeinsey merupakan titik paling utara Islandia.\n",
      "\n",
      "Islandia memiliki tiga taman nasional. Taman Nasional Vatnajokull, Taman Nasional Snaefellsjokull, dan Taman Nasional Þingvellir.\n",
      "\n",
      "Geologi \n",
      "\n",
      "Islandia memiliki banyak geyser, termasuk Geysir, yang merupakan asal-usul untuk definisinya dalam bahasa Inggris, dan juga Strokkur, yang meletus setiap 8-10 menit. Setelah melalui fase nonaktif, Geysir mulai meletus lagi setelah serangkaian gempa bumi pada tahun 2000. Setelah itu Geysir menjadi lebih tenang dan tidak sering meletus.\n",
      "\n",
      "Dengan ketersediaan luas akan tenaga panas bumi, dan pemanfaatan banyak sungai dan air terjun untuk pembangkit listrik tenaga air, sebagian besar penduduk memiliki akses air panas, pemanas, dan listrik dengan murah. Pulau ini tersusun atas basal. Islandia memiliki ratusan gunung berapi dengan sekitar 30 sistem gunung berapi aktif.\n",
      "\n",
      "Surtsey, salah satu pulau termuda di dunia, adalah bagian dari Islandia. Dinamakan setelah Surtr, pulau ini naik di atas permukaan laut dalam serangkaian letusan gunung berapi antara 8 November 1963 dan 5 Juni 1968. Hanya para ilmuwan yang meneliti pertumbuhan kehidupan baru diperbolehkan untuk mengunjungi pulau itu.\n",
      "\n",
      "Pada tanggal 21 Maret 2010, gunung berapi di Eyjafjallajökull di selatan Islandia meletus untuk pertama kalinya sejak 1821, membuat 600 orang mengungsi dari rumah mereka. Letusan tambahan pada 14 April memaksa ratusan orang meninggalkan rumah mereka. Awan dari abu vulkanik yang dihasilkan mengganggu perjalanan udara di seluruh Eropa.\n",
      "\n",
      "Letusan besar terjadi lagi pada tanggal 21 Mei 2011. Kali ini adalah gunung berapi Grimsvotn, terletak di bawah es tebal gletser terbesar di Eropa, Vatnajökull. Grimsvotn adalah salah satu gunung berapi paling aktif di Islandia, dan letusan ini jauh lebih kuat daripada letusan Eyjafjallajökull 2010, dengan abu dan lava terlempar 20 km ke atmosfer, menciptakan awan besar.\n",
      "\n",
      "Keanekaragaman hayati \n",
      "Sekitar 1.300 spesies serangga terdapat di Islandia, angka yang rendah jika dibandingkan dengan negara-negara lain (lebih dari satu juta spesies telah ditemukan di seluruh dunia). Satu-satunya mamalia asli ketika manusia tiba adalah rubah Arktik. Terkadang, kelelawar terbawa ke pulau oleh angin, tetapi mereka tidak bisa berkembang biak di sana. Beruang kutub sesekali datang dari Greenland, tetapi mereka hanya mengunjung, dan tidak ada ada populasi di Islandia. Tidak ada reptil atau amfibi asli di Islandia.\n",
      "\n",
      "Hewan-hewan Islandia termasuk domba Islandia, sapi, ayam, kambing, kuda Islandia yang kokoh kokoh, dan anjing gembala Islandia, semua keturunan hewan yang diimpor oleh orang Eropa. Mamalia liar termasuk rubah Arktik, cerpelai, tikus, kelinci, dan rusa. Beruang kutub sesekali mengunjungi pulau, mengendarai gunung es dari Greenland. Pada bulan Juni 2008, dua beruang kutub tiba dalam bulan yang sama. Mamalia laut seperti anjing laut abu-abu (Halichoerus grypus) dan anjing laut pelabuhan atau harbor seal (Phoca vitulina). Banyak spesies ikan hidup di perairan laut di sekitarnya Islandia, dan industri perikanan merupakan bagian besar dalam perekonomian Islandia, sekitar setengah dari total ekspor negara berasal dari industri ini. Burung, terutama burung laut, merupakan bagian penting dari kehidupan binatang Islandia. Puffin, skua, dan kittiwake bersarang di tebing-tebing laut.\n",
      "\n",
      "Politik\n",
      "\n",
      "Pemerintahan \n",
      "\n",
      "Islandia adalah negara demokrasi perwakilan dan sebuah republik parlementer. Parlemen modern, Alþingi didirikan pada tahun 1845 sebagai badan penasehat untuk raja Denmark. Saat ini mereka memiliki 63 anggota, yang dipilih untuk jangka waktu maksimum empat tahun. Presiden dipilih berdasarkan suara terbanyak untuk masa jabatan empat tahun, tanpa batas jangka. Pemilihan presiden, Alþingi, dan dewan kotamadya lokal semua diadakan secara terpisah setiap empat tahun.\n",
      "\n",
      "Militer \n",
      "\n",
      "Islandia tidak mempunyai tentara tetap, tetapi Penjaga Pantai Islandia yang juga menjaga Sistem Pertahanan Udara Islandia, dan Unit Respons Krisis Islandia untuk mendukung misi penjaga perdamaian, melaksanakan pekerjaan para-militer.\n",
      "\n",
      "Angkatan Pertahanan Islandia (IDF) adalah komando militer dari Angkatan Bersenjata Amerika Serikat dari tahun 1951 sampai 2006. IDF, yang dibuat atas permintaan NATO, terbuat ketika Amerika Serikat menandatangani perjanjian untuk menyediakan pertahanan Islandia. IDF juga terdiri dari warga sipil Islandia dan anggota militer negara-negara NATO lainnya. IDF dirampingkan setelah berakhirnya Perang Dingin dan Angkatan Udara AS mempertahankan 4-6 pesawat pencegat di Stasiun Udara Angkatan Laut Keflavik, sampai mereka ditarik pada 30 September 2006. Sejak Mei 2008, negara-negara NATO telah secara berkala mengerahkan gerilyawan untuk patroli wilayah udara Islandia atas misi Kepolisian Udara Islandia. Islandia mendukung invasi Irak 2003 meskipun banyak kontroversi dari rakyat, mengerahkan tim EOD penjaga pantai ke Irak, yang kemudian digantikan oleh anggota Unit Respons Krisis Islandia. Islandia juga berpartisipasi dalam konflik yang sedang berlangsung di Afghanistan dan Operasi Allied Force tahun 1999. Meskipun mengalami krisis keuangan, kapal patroli baru pertama dalam beberapa dekade diluncurkan pada 29 April 2009.\n",
      "\n",
      "Menurut Global Peace Index, Islandia adalah negara paling damai di dunia, karena kurangnya angkatan bersenjata, tingkat kejahatan yang rendah, dan stabilitas sosial-politik tingkat tinggi. Islandia terdaftar di Buku Rekor Guinness sebagai \"Negara peringkat paling damai\" dan \"belanja militer terendah per kapita\".\n",
      "\n",
      "Pembagian administratif\n",
      "\n",
      "Ekonomi \n",
      "\n",
      "Pada 2007, Islandia adalah negara ketujuh yang paling produktif di dunia per kapita (US $ 54.858), dan yang kelima paling produktif menurut PDB dengan paritas daya beli ($ 40.112). Sekitar 85 persen dari total pasokan energi primer di Islandia berasal dari sumber energi terbarukan yang diproduksi di dalam negeri. Penggunaan tenaga listrik tenaga air dan panas bumi yang melimpah telah menjadikan Islandia sebagai produsen listrik per kapita terbesar di dunia. Sebagai hasil dari komitmennya terhadap energi terbarukan, Indeks Ekonomi Hijau Global 2016 menempatkan Islandia di antara 10 ekonomi terhijau di dunia. Secara historis, ekonomi Islandia sangat bergantung pada penangkapan ikan, yang masih memberikan 40% pendapatan ekspor dan mempekerjakan 7% tenaga kerja. Ekonomi rentan terhadap penurunan stok ikan dan penurunan harga dunia untuk ekspor bahan utamanya: ikan dan produk ikan, aluminium, dan ferrosilicon . Perburuan paus di Islandia secara historis signifikan. Islandia masih sangat bergantung pada penangkapan ikan, tetapi kepentingannya berkurang dari pangsa ekspor 90% pada 1960-an menjadi 40% pada 2006.\n",
      "\n",
      "Sampai abad ke-20, Islandia adalah negara yang cukup miskin. Saat ini, ia tetap menjadi salah satu negara paling maju di dunia. Pertumbuhan ekonomi yang kuat telah membuat Islandia berada di peringkat ketiga dalam laporan Indeks Pembangunan Manusia PBB untuk 2021/2022. Meskipun pada tahun 2011 peringkat HDI-nya turun ke posisi ke-14 sebagai akibat dari krisis ekonomi. Namun demikian, menurut Economist Intelligence Index 2011, Islandia memiliki kualitas hidup tertinggi ke-2 di dunia. Berdasarkan koefisien Gini , Islandia juga memiliki tingkat ketimpangan pendapatan terendah di dunia, dan ketika disesuaikan untuk ketimpangan , peringkat HDI-nya adalah ke-6. Tingkat pengangguran Islandia telah menurun secara konsisten sejak krisis, dengan 4,8% dari angkatan kerja menganggur pada Juni 2012 , dibandingkan dengan 6% pada 2011 dan 8,1% pada 2010.\n",
      "\n",
      "Banyak partai politik tetap menentang keanggotaan UE, terutama karena kekhawatiran Islandia tentang kehilangan kendali atas sumber daya alam mereka (khususnya perikanan). Mata uang nasional Islandia adalah króna Islandia (ISK). Islandia adalah satu-satunya negara di dunia yang memiliki populasi di bawah dua juta namun masih memiliki nilai tukar mengambang dan kebijakan moneter independen.\n",
      "\n",
      "Sebuah jajak pendapat yang dirilis pada 5 Maret 2010 oleh Capacent Gallup menunjukkan bahwa 31% responden mendukung euro dan menentang 69%. Jajak pendapat Capacent Gallup lain yang dilakukan pada Februari 2012 menemukan bahwa 67,4% penduduk Islandia akan menolak keanggotaan UE dalam referendum.\n",
      "\n",
      "Ekonomi Islandia telah melakukan diversifikasi ke industri manufaktur dan jasa dalam dekade terakhir, termasuk produksi perangkat lunak, bioteknologi , dan keuangan; industri menyumbang sekitar seperempat dari kegiatan ekonomi, sementara jasa mencakup hampir 70%. Sektor pariwisata berkembang, terutama dalam ekowisata dan pengamatan paus. Rata-rata, Islandia menerima sekitar 1,1 juta pengunjung setiap tahun, yang lebih dari tiga kali populasi asli. 1,7 juta orang mengunjungi Islandia pada 2016, 3 kali lebih banyak dari jumlah yang datang pada 2010. Industri pertanian Islandia, menyumbang 5,4% dari PDB, terutama terdiri dari kentang, sayuran hijau (dalam rumah kaca), daging kambing dan produk susu. Pusat keuangan adalah Borgartún di Reykjavík, yang menampung sejumlah besar perusahaan dan tiga bank investasi. Pasar saham Islandia, Bursa Efek Islandia (ISE), didirikan pada tahun 1985.\n",
      "\n",
      "Islandia berada di peringkat ke-27 dalam Indeks Kebebasan Ekonomi 2012, lebih rendah dari tahun-tahun sebelumnya, tetapi masih termasuk yang paling bebas di dunia. Pada 2016 , menempati peringkat ke-29 dalam Indeks Kompetitif Global Forum Ekonomi Dunia , satu tempat lebih rendah daripada 2015. Menurut Indeks Inovasi Global INSEAD , Islandia adalah negara ke-20 yang paling inovatif pada tahun 2022. Tidak seperti kebanyakan negara Eropa Barat, Islandia memiliki sistem pajak tetap : tarif pajak penghasilan pribadi utama adalah 22,75% flat, dan dikombinasikan dengan pajak kota, total tarif pajak sama dengan tidak lebih dari 35,7%, tidak termasuk banyak pengurangan yang tersedia. Tarif pajak perusahaan rata-rata 18%, salah satu yang terendah di dunia. Ada juga pajak pertambahan nilai , sedangkan pajak kekayaan netto dihapuskan pada tahun 2006. Peraturan ketenagakerjaan relatif fleksibel dan pasar tenaga kerja adalah salah satu yang paling bebas di dunia. Hak kepemilikan kuat dan Islandia adalah salah satu dari sedikit negara di mana mereka diterapkan untuk pengelolaan perikanan. Seperti negara kesejahteraan lainnya , wajib pajak membayar berbagai subsidi satu sama lain, tetapi dengan pengeluaran lebih sedikit daripada di kebanyakan negara-negara Eropa.\n",
      "\n",
      "Meskipun tarif pajak rendah, bantuan pertanian adalah yang tertinggi di antara negara-negara OECD dan potensi hambatan terhadap perubahan struktural. Juga, pengeluaran perawatan kesehatan dan pendidikan memiliki pengembalian yang relatif buruk oleh langkah-langkah OECD, meskipun perbaikan telah dilakukan di kedua bidang. Survei Ekonomi OECD Islandia 2008 menyoroti tantangan Islandia dalam mata uang dan kebijakan ekonomi makro. Ada krisis mata uang yang dimulai pada musim semi 2008, dan pada 6 Oktober perdagangan di bank-bank Islandia dihentikan sementara pemerintah berjuang untuk menyelamatkan ekonomi. Sebuah penilaian oleh OECD 2011 menetapkan bahwa Islandia telah membuat kemajuan di banyak bidang, terutama dalam menciptakan kebijakan fiskal yang berkelanjutan dan memulihkan kesehatan sektor keuangan; Namun, tantangan tetap ada dalam membuat industri perikanan lebih efisien dan berkelanjutan, serta dalam meningkatkan kebijakan moneter untuk mengatasi inflasi. Utang publik Islandia telah menurun sejak krisis ekonomi, dan pada 2015 adalah yang tertinggi ke-31 di dunia berdasarkan proporsi PDB nasional.\n",
      "\n",
      "Demografi \n",
      "\n",
      "Penduduk Islandia sebagian besar adalah orang Skandinavia. Bahasa yang mereka gunakan adalah bahasa Islandia yang hampir tidak berubah ejaan maupun tata bahasanya selama 1.000 tahun. Orang Islandia bahkan dapat membaca saga kuno yang menceritakan tentang petualangan para Viking tanpa kesulitan yang berarti. Hampir semua orang Islandia menganut agama Kristen aliran Lutheran.\n",
      "\n",
      "Nama Orang Islandia \n",
      "Nama belakang tidak dikenal di Islandia. Orang Islandia menggunakan patronim, di mana digunakan akhiran -son bila ia pria dan -dóttir bila ia wanita.\n",
      "\n",
      "Sebagai contoh, Jón Stefánsson mempunyai anak lelaki bernama Gunnar. Nama akhir Gunnar bukanlah Stefánsson seperti bapaknya, melainkan Gunnar Jónsson yang berarti Gunnar, anak laki-laki dari Jón. Hal yang sama berlaku bagi wanita. Apabila Jón Stefánsson mempunyai anak perempuan yang bernama Katrín, maka nama belakangnya bukanlah Stefánsson, melainkan Jónsdóttir. Dalam hal ini, namanya berarti Katrín, anak perempuan dari Jón.\n",
      "\n",
      "Dalam kasus tertentu, nama belakang seseorang dapat pula diambil bukan dari nama pertama orangtuanya, melainkan dari nama keduanya. Misalnya, bila Jón adalah anak laki-laki dari Hjálmar Örn Vilhjálmsson, ia dapat dinamai Jón Hjálmarsson (Jón, anak laki-laki dari Hjálmar) atau Jón Arnarson (Jón anak laki-laki dari Örn). Alasannya adalah bahwa orangtuanya lebih suka anaknya dipanggil dengan nama tengah, bukan dengan nama pertama. Hal ini cukup lazim atau mungkin pula nama tengah itu terdengar lebih cocok dengan nama pertama si anak.\n",
      "\n",
      "Sebagian besar nama belakang orang Islandia membawa nama ayahnya, namun dalam kasus tertentu, nama ibunyalah yang dipergunakan karena berbagai alasan. Terkadang si anak atau si ibu ingin memutuskan ikatan sosial dengan si ayah. Sejumlah feminis menggunakan hal ini sebagai sebuah pernyataan sosial. Sebagian yang lain memilihnya hanya karena masalah selera saja. Betapa pun juga, konvensinya tetap sama. Guðjón, anak laki-laki dari Bryndís, akan menggunakan nama lengkap Guðjón Bryndísarson yang berarti Guðjón, anak laki-laki dari Bryndís.\n",
      "\n",
      "Di banyak negara orang memanggil orang lain dengan nama belakangnya, tetapi di Islandia orang memanggil orang lain dari nama depannya. Sebagai contoh ketika orang membicarakan tentang Halldór Ásgrímsson mereka tidak memanggilnya Ásgrímsson, tetapi Halldór, hampir sama dengan panggilan untuk orang di sebagian besar wilayah Indonesia.\n",
      "\n",
      "Ada juga nama yang terpilih menjadi nama terbanyak dipakai di Islandia yaitu Guðrún ( Gwuthrun), Guð: Tuhan, Rún: Pengetahuan rahasia\n",
      "\n",
      "Kota-Kota Penting \n",
      "Reykjavik adalah ibu kota Islandia dan memegang peranan penting sebagai kota pelabuhan. Kota-kota penting lainnya antara lain Akureyri, Kópavogur, Hafnarfjörður, Keflavík, dan Vestmannaeyjar.\n",
      "\n",
      "Budaya\n",
      "\n",
      "Referensi\n",
      "\n",
      "Catatan\n",
      "\n",
      "Bacaan lebih lanjut\n",
      "\n",
      "Pranala luar \n",
      "•  Iceland\n",
      "\n",
      "  Portal resmi Islandia\n",
      "\n",
      " \n",
      "Negara di Eropa Utara\n",
      "Negara anggota Perserikatan Bangsa-Bangsa\n",
      "Negara mikro\n",
      "Bekas koloni Norwegia<|end_of_text|>\n"
     ]
    }
   ],
   "source": [
    "# Sanity check\n",
    "for row in dataset_split['train'][:3][\"text\"]:\n",
    "    print(\"================================================================\")\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f867a1951fd8403eaa5cb8c473472a91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Unsloth: Tokenizing [\"text\"]:   0%|          | 0/6400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-10-3850300249.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m trainer = UnslothTrainer(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_split\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# eval_dataset=dataset_split['test'],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/unsloth/trainer.py\u001b[0m in \u001b[0;36mnew_init\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"args\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m         \u001b[0moriginal_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_init\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/unsloth_compiled_cache/UnslothSFTTrainer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, args, data_collator, train_dataset, eval_dataset, processing_class, compute_loss_func, compute_metrics, callbacks, optimizer_cls_and_kwargs, preprocess_logits_for_metrics, peft_config, formatting_func, **kwargs)\u001b[0m\n\u001b[1;32m   1178\u001b[0m         \u001b[0mfix_zero_training_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m   1181\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/unsloth_compiled_cache/UnslothSFTTrainer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, args, data_collator, train_dataset, eval_dataset, processing_class, compute_loss_func, compute_metrics, callbacks, optimizers, optimizer_cls_and_kwargs, preprocess_logits_for_metrics, peft_config, formatting_func)\u001b[0m\n\u001b[1;32m    582\u001b[0m                     \u001b[0;34m\"dataset, or disable `completion_only_loss` in `SFTConfig`.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m                 )\n\u001b[0;32m--> 584\u001b[0;31m             train_dataset = self._prepare_dataset(\n\u001b[0m\u001b[1;32m    585\u001b[0m                 \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocessing_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpacking\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatting_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"train\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m             )\n",
      "\u001b[0;32m/content/unsloth_compiled_cache/UnslothSFTTrainer.py\u001b[0m in \u001b[0;36m_prepare_dataset\u001b[0;34m(self, dataset, processing_class, args, packing, formatting_func, dataset_name)\u001b[0m\n\u001b[1;32m    838\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0muse_desc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmap_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"desc\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'Unsloth: Tokenizing [\"{dataset_text_field}\"]'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 840\u001b[0;31m             \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_tokenize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmap_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m             \u001b[0;31m# If VLM, switch data collator since .pad is needed!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    555\u001b[0m         }\n\u001b[1;32m    556\u001b[0m         \u001b[0;31m# apply actual function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"DatasetDict\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m         \u001b[0mdatasets\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m         \u001b[0;31m# re-apply format to the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc, try_original_type)\u001b[0m\n\u001b[1;32m   3077\u001b[0m                     \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdesc\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"Map\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3078\u001b[0m                 ) as pbar:\n\u001b[0;32m-> 3079\u001b[0;31m                     \u001b[0;32mfor\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdataset_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3080\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3081\u001b[0m                             \u001b[0mshards_done\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36m_map_single\u001b[0;34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset, try_original_type)\u001b[0m\n\u001b[1;32m   3523\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3524\u001b[0m                     \u001b[0m_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3525\u001b[0;31m                     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miter_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshard_iterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3526\u001b[0m                         \u001b[0mnum_examples_in_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3527\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mupdate_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36miter_outputs\u001b[0;34m(shard_iterable)\u001b[0m\n\u001b[1;32m   3473\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3474\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mshard_iterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3475\u001b[0;31m                     \u001b[0;32myield\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3477\u001b[0m         \u001b[0mnum_examples_progress_update\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mapply_function\u001b[0;34m(pa_inputs, indices, offset)\u001b[0m\n\u001b[1;32m   3396\u001b[0m             \u001b[0;34m\"\"\"Utility to apply the function on a selection of columns.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3397\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madditional_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpa_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3398\u001b[0;31m             \u001b[0mprocessed_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfn_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0madditional_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfn_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3399\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mprepare_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpa_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocessed_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/unsloth_compiled_cache/UnslothSFTTrainer.py\u001b[0m in \u001b[0;36m_tokenize\u001b[0;34m(example)\u001b[0m\n\u001b[1;32m    823\u001b[0m             \u001b[0;31m# Create tokenize function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0m_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m                 return tokenizer(\n\u001b[0m\u001b[1;32m    826\u001b[0m                     \u001b[0mexample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset_text_field\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdo_formatting_func\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mformatting_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m                     \u001b[0mtruncation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdo_truncation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2865\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_target_context_manager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2866\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_switch_to_input_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2867\u001b[0;31m             \u001b[0mencodings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_pair\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext_pair\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mall_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2868\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtext_target\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2869\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_switch_to_target_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m_call_one\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001b[0m\n\u001b[1;32m   2953\u001b[0m                 )\n\u001b[1;32m   2954\u001b[0m             \u001b[0mbatch_text_or_text_pairs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_pair\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtext_pair\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2955\u001b[0;31m             return self.batch_encode_plus(\n\u001b[0m\u001b[1;32m   2956\u001b[0m                 \u001b[0mbatch_text_or_text_pairs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_text_or_text_pairs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2957\u001b[0m                 \u001b[0madd_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0madd_special_tokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mbatch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001b[0m\n\u001b[1;32m   3154\u001b[0m         )\n\u001b[1;32m   3155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3156\u001b[0;31m         return self._batch_encode_plus(\n\u001b[0m\u001b[1;32m   3157\u001b[0m             \u001b[0mbatch_text_or_text_pairs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_text_or_text_pairs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3158\u001b[0m             \u001b[0madd_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0madd_special_tokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_fast.py\u001b[0m in \u001b[0;36m_batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode_special_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_special_tokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m         encodings = self._tokenizer.encode_batch(\n\u001b[0m\u001b[1;32m    542\u001b[0m             \u001b[0mbatch_text_or_text_pairs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0madd_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0madd_special_tokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer = UnslothTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=dataset_split['train'],\n",
    "    # eval_dataset=dataset_split['test'],\n",
    "    dataset_text_field='text',\n",
    "    max_seq_length=max_seq_length,\n",
    "    dataset_num_proc=8,\n",
    "\n",
    "    args=TrainingArguments(\n",
    "        seed=seed,\n",
    "        per_device_train_batch_size=4,\n",
    "        gradient_accumulation_steps=2,\n",
    "        num_train_epochs=3,\n",
    "        # max_steps=3, # For debugging\n",
    "        warmup_ratio=0.05,\n",
    "        learning_rate=2e-4,\n",
    "        lr_scheduler_type='cosine',\n",
    "        optim='paged_adamw_8bit', # 'paged_adamw_8bit' | 'adamw_8bit'\n",
    "        weight_decay=0.00,\n",
    "        max_grad_norm=0.3,\n",
    "        fp16=(not is_bf16_supported()),\n",
    "        bf16=is_bf16_supported(),\n",
    "\n",
    "        # Eval arguments\n",
    "        # eval_strategy='steps',\n",
    "        # eval_steps=10,\n",
    "        \n",
    "        # Logging arguments\n",
    "        logging_strategy='steps',\n",
    "        logging_steps=1,\n",
    "        # logging_first_step=True,\n",
    "        report_to=['tensorboard', 'wandb'],\n",
    "\n",
    "        # Saving arguments\n",
    "        save_strategy='steps',\n",
    "        save_steps=50,\n",
    "        # save_steps=1, # For debugging\n",
    "        save_total_limit=5, # 1 best + 4 recent checkpoints. Warning: It doesn't work\n",
    "        \n",
    "        # With load_best_model_at_end=True, your save_strategy will be ignored and default to eval_strategy.\n",
    "        # So you will find one checkpoint at the end of each epoch.\n",
    "        # https://discuss.huggingface.co/t/trainer-not-saving-after-save-steps/5464\n",
    "        # load_best_model_at_end=True, \n",
    "\n",
    "        output_dir=project_name,\n",
    "        hub_model_id=hub_model_id,\n",
    "        push_to_hub=True,\n",
    "\n",
    "        hub_strategy='all_checkpoints',\n",
    "        hub_always_push=True,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU = Tesla T4. Max memory = 14.741 GB.\n",
      "6.881 GB of memory reserved.\n"
     ]
    }
   ],
   "source": [
    "#@title Show current memory stats\n",
    "gpu_stats = torch.cuda.get_device_properties(0)\n",
    "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
    "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
    "print(f\"{start_gpu_memory} GB of memory reserved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 6,400 | Num Epochs = 3 | Total steps = 2,400\n",
      "O^O/ \\_/ \\    Batch size per device = 4 | Gradient accumulation steps = 2\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (4 x 2 x 1) = 8\n",
      " \"-____-\"     Trainable parameters = 20,971,520/8,000,000,000 (0.26% trained)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malimtegar\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.20.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20250627_162512-prtv1wro</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/alimtegar/huggingface/runs/prtv1wro' target=\"_blank\">L3.1-8B-wikipedia-id-8K-LoRA-v20250627140551</a></strong> to <a href='https://wandb.ai/alimtegar/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/alimtegar/huggingface' target=\"_blank\">https://wandb.ai/alimtegar/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/alimtegar/huggingface/runs/prtv1wro' target=\"_blank\">https://wandb.ai/alimtegar/huggingface/runs/prtv1wro</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Will smartly offload gradients to save VRAM!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='220' max='2400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 220/2400 23:07 < 12:21:33, 0.05 it/s, Epoch 0.27/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>151</td>\n",
       "      <td>1.663300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>152</td>\n",
       "      <td>1.728300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>153</td>\n",
       "      <td>1.399800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>154</td>\n",
       "      <td>1.504900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155</td>\n",
       "      <td>1.500500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>156</td>\n",
       "      <td>1.402100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>157</td>\n",
       "      <td>1.554900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>158</td>\n",
       "      <td>1.357600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159</td>\n",
       "      <td>1.589200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.576400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>161</td>\n",
       "      <td>1.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>162</td>\n",
       "      <td>1.644100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>163</td>\n",
       "      <td>1.507800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>164</td>\n",
       "      <td>1.472200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>165</td>\n",
       "      <td>1.562600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>166</td>\n",
       "      <td>1.445500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>167</td>\n",
       "      <td>1.529400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>168</td>\n",
       "      <td>1.511300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>169</td>\n",
       "      <td>1.605900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1.121400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>171</td>\n",
       "      <td>1.557500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>172</td>\n",
       "      <td>1.309200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>173</td>\n",
       "      <td>1.550900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>174</td>\n",
       "      <td>1.521600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>2.022300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>176</td>\n",
       "      <td>1.608000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>177</td>\n",
       "      <td>1.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>178</td>\n",
       "      <td>1.558200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>179</td>\n",
       "      <td>1.815800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1.342500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>181</td>\n",
       "      <td>1.486300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>182</td>\n",
       "      <td>1.491400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>183</td>\n",
       "      <td>1.536300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>184</td>\n",
       "      <td>1.508400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>185</td>\n",
       "      <td>1.440800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>186</td>\n",
       "      <td>1.491500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>187</td>\n",
       "      <td>1.785500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>188</td>\n",
       "      <td>1.649500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>189</td>\n",
       "      <td>1.519600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1.647100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>191</td>\n",
       "      <td>1.559400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192</td>\n",
       "      <td>1.646400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>193</td>\n",
       "      <td>1.532200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>194</td>\n",
       "      <td>1.670000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>195</td>\n",
       "      <td>1.651500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>196</td>\n",
       "      <td>1.492700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>197</td>\n",
       "      <td>1.544200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>198</td>\n",
       "      <td>1.606000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>199</td>\n",
       "      <td>1.346600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.580400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>201</td>\n",
       "      <td>1.615000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>202</td>\n",
       "      <td>1.685600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>203</td>\n",
       "      <td>1.409600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>204</td>\n",
       "      <td>1.418700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>205</td>\n",
       "      <td>1.469600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>206</td>\n",
       "      <td>1.604400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>207</td>\n",
       "      <td>1.333800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>208</td>\n",
       "      <td>1.693700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>209</td>\n",
       "      <td>1.579400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1.820600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>211</td>\n",
       "      <td>1.503900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>212</td>\n",
       "      <td>1.707600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>213</td>\n",
       "      <td>1.488500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>214</td>\n",
       "      <td>1.445600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>215</td>\n",
       "      <td>1.946000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>216</td>\n",
       "      <td>1.554400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>217</td>\n",
       "      <td>1.550700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>218</td>\n",
       "      <td>1.746800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The get_url method is deprecated and will be removed in a future release. Please use `run.url` instead.\n"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "trainer_stats = trainer.train(resume_from_checkpoint=resume_from_checkpoint)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
