{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kill all processess on GPU\n",
    "# !fuser -v /dev/nvidia* -k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import os\n",
    "if \"COLAB_\" not in \"\".join(os.environ.keys()):\n",
    "    %pip install unsloth\n",
    "else:\n",
    "    # Do this only in Colab notebooks! Otherwise use pip install unsloth\n",
    "    %pip install --no-deps bitsandbytes accelerate xformers==0.0.29.post3 peft trl triton cut_cross_entropy unsloth_zoo\n",
    "    %pip install sentencepiece protobuf \"datasets>=3.4.1,<4.0.0\" \"huggingface_hub>=0.34.0\" hf_transfer\n",
    "    %pip install --no-deps unsloth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting trl==0.19.1\n",
      "  Downloading trl-0.19.1-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: accelerate>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from trl==0.19.1) (1.9.0)\n",
      "Requirement already satisfied: datasets>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from trl==0.19.1) (3.6.0)\n",
      "Requirement already satisfied: transformers>=4.51.0 in /usr/local/lib/python3.11/dist-packages (from trl==0.19.1) (4.53.3)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate>=1.4.0->trl==0.19.1) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=1.4.0->trl==0.19.1) (25.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate>=1.4.0->trl==0.19.1) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate>=1.4.0->trl==0.19.1) (6.0.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=1.4.0->trl==0.19.1) (2.6.0+cu124)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=1.4.0->trl==0.19.1) (0.34.3)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate>=1.4.0->trl==0.19.1) (0.5.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl==0.19.1) (3.18.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl==0.19.1) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl==0.19.1) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl==0.19.1) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl==0.19.1) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl==0.19.1) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl==0.19.1) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl==0.19.1) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl==0.19.1) (2025.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.51.0->trl==0.19.1) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.51.0->trl==0.19.1) (0.21.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl==0.19.1) (3.12.14)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate>=1.4.0->trl==0.19.1) (4.14.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate>=1.4.0->trl==0.19.1) (1.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=3.0.0->trl==0.19.1) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=3.0.0->trl==0.19.1) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=3.0.0->trl==0.19.1) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=3.0.0->trl==0.19.1) (2025.7.14)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl==0.19.1) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl==0.19.1) (3.1.6)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.0.0->accelerate>=1.4.0->trl==0.19.1)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.0.0->accelerate>=1.4.0->trl==0.19.1)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.0.0->accelerate>=1.4.0->trl==0.19.1)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0.0->accelerate>=1.4.0->trl==0.19.1)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0.0->accelerate>=1.4.0->trl==0.19.1)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0.0->accelerate>=1.4.0->trl==0.19.1)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0.0->accelerate>=1.4.0->trl==0.19.1)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0.0->accelerate>=1.4.0->trl==0.19.1)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0.0->accelerate>=1.4.0->trl==0.19.1)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl==0.19.1) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl==0.19.1) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl==0.19.1) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0.0->accelerate>=1.4.0->trl==0.19.1)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl==0.19.1) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl==0.19.1) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate>=1.4.0->trl==0.19.1) (1.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=3.0.0->trl==0.19.1) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=3.0.0->trl==0.19.1) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=3.0.0->trl==0.19.1) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl==0.19.1) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl==0.19.1) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl==0.19.1) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl==0.19.1) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl==0.19.1) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl==0.19.1) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl==0.19.1) (1.20.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=3.0.0->trl==0.19.1) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate>=1.4.0->trl==0.19.1) (3.0.2)\n",
      "Downloading trl-0.19.1-py3-none-any.whl (376 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m376.2/376.2 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m103.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m94.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m53.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m99.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, trl\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
      "  Attempting uninstall: trl\n",
      "    Found existing installation: trl 0.20.0\n",
      "    Uninstalling trl-0.20.0:\n",
      "      Successfully uninstalled trl-0.20.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "unsloth 2025.7.11 requires tyro, which is not installed.\n",
      "unsloth-zoo 2025.7.11 requires msgspec, which is not installed.\n",
      "unsloth-zoo 2025.7.11 requires tyro, which is not installed.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 trl-0.19.1\n"
     ]
    }
   ],
   "source": [
    "%pip install trl==0.19.1 # Fix error: ImportError: cannot import name 'ConstantLengthDataset' from 'trl.trainer.utils'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "🦥 Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import os\n",
    "import math\n",
    "import functools\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# from transformers import TrainingArguments\n",
    "from peft import LoraConfig\n",
    "from huggingface_hub import snapshot_download\n",
    "from safetensors.torch import load_file\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_hf_model(repo_id, checkpoint):\n",
    "    local_dir = repo_id.split('/')[-1]\n",
    "    ignore_checkpoints = [f'checkpoint-{i}/*' for i in range(0, 2000, 25) if i != checkpoint]\n",
    "\n",
    "    snapshot_download(\n",
    "        repo_id=repo_id,\n",
    "        local_dir=local_dir,\n",
    "        ignore_patterns=ignore_checkpoints,\n",
    "    )\n",
    "\n",
    "    if checkpoint:\n",
    "        return os.path.join(local_dir, f'checkpoint-{checkpoint}')\n",
    "    return local_dir\n",
    "\n",
    "@torch.no_grad()\n",
    "def check_lora_parameters(model):\n",
    "    for n, p in model.named_parameters():\n",
    "        if 'lora' in n:\n",
    "            print(f\"- {'Name':<8}:\", n)\n",
    "            print(f\"- {'Mean':<8}:\", p.mean().item())\n",
    "            print(f\"- {'Min':<8}:\", p.min().item())\n",
    "            print(f\"- {'Max':<8}:\", p.max().item())\n",
    "            break\n",
    "\n",
    "@torch.no_grad()\n",
    "def generate_text(model, tokenizer, prompt, max_new_tokens=50, skip_special_tokens=True):\n",
    "    device = next(model.parameters()).device\n",
    "    inputs = tokenizer(prompt, return_tensors='pt')\n",
    "    outputs = model.generate(input_ids=inputs['input_ids'].to(device), max_new_tokens=max_new_tokens)\n",
    "    print(tokenizer.batch_decode(outputs.detach().cpu().numpy(), skip_special_tokens=skip_special_tokens)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model configurations:\n",
      "{'L1T1': {'checkpoint': 650,\n",
      "          'lora_dir': 'L3.1-8B-wikipedia-en-5K-LoRA-v20250630122650/checkpoint-650',\n",
      "          'lora_id': 'alxxtexxr/L3.1-8B-wikipedia-en-5K-LoRA-v20250630122650'},\n",
      " 'L2T1': {'checkpoint': 650,\n",
      "          'lora_dir': 'L3.1-8B-wikipedia-ja-5K-LoRA-v20250728141629/checkpoint-650',\n",
      "          'lora_id': 'alxxtexxr/L3.1-8B-wikipedia-ja-5K-LoRA-v20250728141629'}}\n"
     ]
    }
   ],
   "source": [
    "# Project configuration\n",
    "seed = 69\n",
    "device = 'mps'\n",
    "\n",
    "# Model configuration\n",
    "max_seq_length = 1024\n",
    "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
    "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
    "\n",
    "model_configs = {\n",
    "    'L1T1': {\n",
    "        'lora_id': 'alxxtexxr/L3.1-8B-wikipedia-en-5K-LoRA-v20250630122650',\n",
    "        'checkpoint': 650,\n",
    "    },\n",
    "    'L2T1': {\n",
    "        'lora_id': 'alxxtexxr/L3.1-8B-wikipedia-ja-5K-LoRA-v20250728141629',\n",
    "        'checkpoint': 650,\n",
    "    },\n",
    "}\n",
    "\n",
    "for key, config in model_configs.items():\n",
    "    model_configs[key]['lora_dir'] = download_hf_model(config['lora_id'], config['checkpoint'])\n",
    "\n",
    "print(\"Model configurations:\",)\n",
    "pprint(model_configs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LoRA Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "- https://github.com/huggingface/peft/blob/main/src/peft/tuners/lora/bnb.py\n",
    "- https://github.com/huggingface/peft/blob/main/src/peft/tuners/lora/layer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.7.11: Fast Llama patching. Transformers: 4.53.3.\n",
      "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
      "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    }
   ],
   "source": [
    "class LoraLayer(nn.Module):\n",
    "    def __init__(self, base_layer, rank, alpha, dropout, lora_bias, use_rslora, return_lora_output=False):\n",
    "        super().__init__()\n",
    "        self.base_layer = base_layer\n",
    "        self.device = base_layer.weight.device\n",
    "        self.alpha = alpha\n",
    "        self.lora_bias = lora_bias\n",
    "        self.scaling = alpha / math.sqrt(rank) if use_rslora else alpha / rank\n",
    "        self.dropout = nn.Dropout(dropout) if dropout > 0.0 else nn.Identity()\n",
    "        self.return_lora_output = return_lora_output\n",
    "\n",
    "        # Extract input and output features from the base layer\n",
    "        in_features = getattr(base_layer, 'in_features', None)\n",
    "        out_features = getattr(base_layer, 'out_features', None)\n",
    "\n",
    "        if in_features is None or out_features is None:\n",
    "            raise ValueError(f\"Cannot determine in_features or out_features from {base_layer}.\")\n",
    "        \n",
    "        # LoRA decomposition: A (down-projection) and B (up-projection)\n",
    "        self.lora_A = nn.Linear(in_features, rank, bias=lora_bias).to(self.device)  # Projects down\n",
    "        self.lora_B = nn.Linear(rank, out_features, bias=lora_bias).to(self.device) # Projects up\n",
    "\n",
    "        # Initialize LoRA matrices: A ~ N(0, 1/rank), B initialized to 0\n",
    "        std = 1 / torch.sqrt(torch.tensor(rank).float())\n",
    "        nn.init.normal_(self.lora_A.weight, mean=0.0, std=std)\n",
    "        nn.init.zeros_(self.lora_B.weight)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Forward through base layer\n",
    "        base_out = self.base_layer(x)\n",
    "\n",
    "        # LoRA transformation\n",
    "        requires_conversion = not torch.is_autocast_enabled()\n",
    "        if requires_conversion:\n",
    "            x = x.to(self.lora_A.weight.dtype)\n",
    "        lora_out = self.lora_B(self.lora_A(self.dropout(x))) * self.scaling\n",
    "        if requires_conversion:\n",
    "            lora_out = lora_out.to(base_out.dtype)\n",
    "\n",
    "        output = base_out + lora_out\n",
    "\n",
    "        if self.return_lora_output:\n",
    "            return output, lora_out\n",
    "        \n",
    "        return output\n",
    "\n",
    "    def load_lora_weights(self, state_dict, prefix):\n",
    "        self.lora_A.weight.data = state_dict[f'{prefix}.lora_A.weight'].to(self.device)\n",
    "        self.lora_B.weight.data = state_dict[f'{prefix}.lora_B.weight'].to(self.device)\n",
    "        if self.lora_bias:\n",
    "            self.lora_A.bias.data = state_dict[f'{prefix}.lora_A.bias'].to(self.device)\n",
    "            self.lora_B.bias.data = state_dict[f'{prefix}.lora_B.bias'].to(self.device)\n",
    "    \n",
    "class LoraModel(nn.Module):\n",
    "    def __init__(self, base_model: nn.Module, lora_config: LoraConfig, return_lora_outputs=False):\n",
    "        super().__init__()\n",
    "        self.base_model = base_model\n",
    "        self.lora_layers = nn.ModuleDict()\n",
    "        self.return_lora_outputs = return_lora_outputs\n",
    "\n",
    "        # Wrap target layers with NeroLayer\n",
    "        self._wrap_target_layers(lora_config)\n",
    "    \n",
    "    def _wrap_target_layers(self, lora_config):\n",
    "        for module_name, module in self.base_model.named_modules():\n",
    "            if isinstance(module, LoraLayer):\n",
    "                # Convert module name format and store reference\n",
    "                module_name = module_name.rsplit('model.', 1)[-1]\n",
    "                module_name = module_name.replace('.', '__DOT__')\n",
    "                self.lora_layers[module_name] = module\n",
    "                continue\n",
    "\n",
    "            if any(module_name.endswith(target_module) for target_module in lora_config.target_modules) and isinstance(module, nn.Linear):    \n",
    "                parent_module, child_name = self._get_parent_module(module_name)\n",
    "                lora_layer = LoraLayer(\n",
    "                    module, \n",
    "                    lora_config.r, \n",
    "                    lora_config.lora_alpha, \n",
    "                    lora_config.lora_dropout, \n",
    "                    lora_config.lora_bias, \n",
    "                    lora_config.use_rslora,\n",
    "                    return_lora_output=self.return_lora_outputs,\n",
    "                )\n",
    "                setattr(parent_module, child_name, lora_layer)\n",
    "\n",
    "                # Store LoRA layers for weight loading\n",
    "                module_name = module_name.rsplit('model.', 1)[-1]\n",
    "                module_name = module_name.replace('.', '__DOT__')\n",
    "                self.lora_layers[module_name] = lora_layer\n",
    "    \n",
    "    def _get_parent_module(self, module_name):\n",
    "        parts = module_name.split('.')\n",
    "        parent_module = self.base_model\n",
    "        for part in parts[:-1]:\n",
    "            parent_module = getattr(parent_module, part)\n",
    "        return parent_module, parts[-1]\n",
    "\n",
    "    def freeze_all(self):\n",
    "        for param in self.base_model.parameters():\n",
    "            param.requires_grad = False\n",
    "    \n",
    "    def unfreeze_all(self):\n",
    "        for param in self.base_model.parameters():\n",
    "            param.requires_grad = True\n",
    "        \n",
    "        for lora_layer in self.lora_layers.values():\n",
    "            for param in lora_layer.parameters():\n",
    "                param.requires_grad = True\n",
    "    \n",
    "    def load_lora_weights(self, lora_path):\n",
    "        state_dict = load_file(lora_path)\n",
    "        prefix = list(state_dict.keys())[0].rsplit('model.', 1)[0] + 'model.'\n",
    "        for lora_layer_name, lora_layer in self.lora_layers.items():\n",
    "            lora_layer_name = lora_layer_name.replace('__DOT__', '.')\n",
    "            lora_layer_name = prefix + lora_layer_name\n",
    "            if f'{lora_layer_name}.lora_A.weight' in state_dict and f'{lora_layer_name}.lora_B.weight' in state_dict:\n",
    "                lora_layer.load_lora_weights(state_dict, lora_layer_name)\n",
    "            else:\n",
    "                # TODO: Print warning message\n",
    "                pass\n",
    "        print(\"LoRA weights loaded successfully!\")\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask=None):\n",
    "        if self.return_lora_outputs:\n",
    "            lora_outs = {}\n",
    "            \n",
    "            def _hook_fn(layer_name, module, _in, _out):\n",
    "                if isinstance(_out, tuple) and len(_out) == 2:\n",
    "                    layer_out, lora_out = _out\n",
    "                    lora_outs[layer_name] = lora_out # Store nero_out separately\n",
    "                    return layer_out # Return only layer_out to avoid breaking model flow\n",
    "\n",
    "            # Register hooks to extract nero_out during forward pass\n",
    "            hooks = []\n",
    "            for layer_name, layer in self.lora_layers.items():\n",
    "                hook = layer.register_forward_hook(functools.partial(_hook_fn, layer_name))\n",
    "                hooks.append(hook)\n",
    "        \n",
    "            try:\n",
    "                output = self.base_model(input_ids, attention_mask=attention_mask)\n",
    "            finally:\n",
    "                # Remove hooks after forward pass, ensuring it's done even if an error occurs\n",
    "                for hook in hooks:\n",
    "                    hook.remove()\n",
    "\n",
    "            return output, lora_outs\n",
    "        \n",
    "        return self.base_model(input_ids, attention_mask=attention_mask)\n",
    "    \n",
    "    def __getattr__(self, name):\n",
    "        try:\n",
    "            return super().__getattr__(name) # Try getting attribute from self\n",
    "        except AttributeError:\n",
    "            return getattr(self.base_model, name) # Fallback to base_model\n",
    "\n",
    "base_model1, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name='unsloth/Meta-Llama-3.1-8B',\n",
    "    max_seq_length=max_seq_length,\n",
    "    dtype=dtype,\n",
    "    load_in_4bit=load_in_4bit,\n",
    ")\n",
    "lora_config = LoraConfig.from_pretrained(model_configs['L1T1']['lora_dir'])\n",
    "lora_model = LoraModel(base_model1, lora_config, return_lora_outputs=True)\n",
    "lora_model.freeze_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check LoRA parameters (unloaded):\n",
      "- Name    : base_model.model.layers.0.self_attn.q_proj.lora_A.weight\n",
      "- Mean    : -0.00032052432652562857\n",
      "- Min     : -1.5238006114959717\n",
      "- Max     : 1.4642316102981567\n",
      "\n",
      "LoRA weights loaded successfully!\n",
      "\n",
      "Check LoRA parameters (loaded):\n",
      "- Name    : base_model.model.layers.0.self_attn.q_proj.lora_A.weight\n",
      "- Mean    : 6.287686119321734e-05\n",
      "- Min     : -0.04176201671361923\n",
      "- Max     : 0.04242725297808647\n"
     ]
    }
   ],
   "source": [
    "print(\"Check LoRA parameters (unloaded):\")\n",
    "check_lora_parameters(lora_model)\n",
    "print()\n",
    "\n",
    "lora_path = os.path.join(model_configs['L1T1']['lora_dir'], 'adapter_model.safetensors')\n",
    "lora_model.load_lora_weights(lora_path)\n",
    "print()\n",
    "\n",
    "print(\"Check LoRA parameters (loaded):\")\n",
    "check_lora_parameters(lora_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_text(lora_model, tokenizer, prompt=\"Preheat the oven to 350 degrees and place the cookie dough\", skip_special_tokens=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nero Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.7.11: Fast Llama patching. Transformers: 4.53.3.\n",
      "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
      "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    }
   ],
   "source": [
    "class NeroLayer(nn.Module):\n",
    "    def __init__(self, base_layer, \n",
    "                 # LoRA parameters\n",
    "                 rank, alpha, dropout, lora_bias, use_rslora, \n",
    "                 # Nero parameters\n",
    "                 nero_bias=False, \n",
    "                 # return_nero_output=False,\n",
    "                 ):\n",
    "        super().__init__()\n",
    "        self.base_layer = base_layer\n",
    "        self.device = base_layer.weight.device\n",
    "        self.alpha = alpha\n",
    "        self.lora_bias = lora_bias\n",
    "        self.scaling = alpha / math.sqrt(rank) if use_rslora else alpha / rank\n",
    "        self.dropout = nn.Dropout(dropout) if dropout > 0.0 else nn.Identity()\n",
    "        # self.return_nero_output = return_nero_output\n",
    "\n",
    "        # Extract input and output features from the base layer\n",
    "        in_features = getattr(base_layer, 'in_features', None)\n",
    "        out_features = getattr(base_layer, 'out_features', None)\n",
    "\n",
    "        if in_features is None or out_features is None:\n",
    "            raise ValueError(f\"Cannot determine in_features or out_features from {base_layer}.\")\n",
    "        \n",
    "        # LoRA decomposition: A (down-projection) and B (up-projection)\n",
    "        self.lora_A = nn.Linear(in_features, rank, bias=lora_bias).to(self.device)  # Projects down\n",
    "        self.lora_B = nn.Linear(rank, out_features, bias=lora_bias).to(self.device) # Projects up\n",
    "\n",
    "        # Initialize LoRA matrices: A ~ N(0, 1/rank), B initialized to 0\n",
    "        std = 1 / torch.sqrt(torch.tensor(rank).float())\n",
    "        nn.init.normal_(self.lora_A.weight, mean=0.0, std=std)\n",
    "        nn.init.zeros_(self.lora_B.weight)\n",
    "\n",
    "        # Nero decomposition: additional transformation applied to LoRA output\n",
    "        self.nero_A = nn.Linear(out_features, rank, bias=nero_bias).to(self.device)\n",
    "        self.nero_B = nn.Linear(rank, out_features, bias=nero_bias).to(self.device)\n",
    "\n",
    "        # Initialize Nero matrices similarly\n",
    "        nn.init.normal_(self.nero_A.weight, mean=0.0, std=std)\n",
    "        nn.init.zeros_(self.nero_B.weight)\n",
    "\n",
    "        # This will store the last nero output for access in NeroModel\n",
    "        self.last_nero_out = None\n",
    "        \n",
    "    def forward(self, x):\n",
    "        print(f\"[NeroLayer] Forward pass executed for {self}\")\n",
    "\n",
    "        # Forward through base layer\n",
    "        base_out = self.base_layer(x)\n",
    "        # As per Tim Dettmers, for 4bit, we need to defensively clone here.\n",
    "        # The reason is that in some cases, an error can occur that backprop\n",
    "        # does not work on a manipulated view. This issue may be solved with\n",
    "        # newer PyTorch versions but this would need extensive testing to be\n",
    "        # sure.\n",
    "        base_out = base_out.clone()\n",
    "\n",
    "        print(\"base_out.requires_grad:\", base_out.requires_grad)\n",
    "        print(\"base_out.grad_fn:\", base_out.grad_fn)\n",
    "\n",
    "        # LoRA transformation\n",
    "        requires_conversion = not torch.is_autocast_enabled()\n",
    "        if requires_conversion:\n",
    "            x = x.to(self.lora_A.weight.dtype)\n",
    "        lora_out = self.lora_B(self.lora_A(self.dropout(x))) * self.scaling\n",
    "        # if requires_conversion:\n",
    "        #     lora_out = lora_out.to(base_out.dtype)\n",
    "\n",
    "        print(\"lora_out.requires_grad:\", lora_out.requires_grad)\n",
    "        print(\"lora_out.grad_fn:\", lora_out.grad_fn)\n",
    "\n",
    "        # Nero transformation (applied on top of LoRA output)\n",
    "        print('self.nero_A.weight:', self.nero_A.weight)\n",
    "        test_out = self.nero_A(torch.randn(lora_out.shape).to(self.device))\n",
    "        print(\"test_out:\", test_out)\n",
    "\n",
    "        nero_out = F.relu(self.nero_B(self.nero_A(self.dropout(lora_out))) * self.scaling)\n",
    "        # nero_in = self.dropout(lora_out)\n",
    "        # print(\"nero_in:\", nero_in)\n",
    "        # nero_A_out = self.nero_A(nero_in)\n",
    "        # print(\"nero_A_out:\", nero_A_out)\n",
    "        # nero_B_out = self.nero_B(nero_A_out)\n",
    "        # print(\"nero_B_out:\", nero_B_out)\n",
    "        # nero_out = F.relu(nero_B_out * self.scaling)\n",
    "        # print(\"nero_out:\", nero_out)\n",
    "        if requires_conversion:\n",
    "            nero_out = nero_out.to(base_out.dtype)\n",
    "        self.last_nero_out = nero_out\n",
    "\n",
    "        print(\"nero_out.requires_grad:\", nero_out.requires_grad)\n",
    "        print(\"nero_out.grad_fn:\", nero_out.grad_fn)\n",
    "\n",
    "        output = base_out + nero_out\n",
    "\n",
    "        # if self.return_nero_output:\n",
    "            # self.last_nero_out = nero_out\n",
    "            # return output, nero_out\n",
    "        \n",
    "        return output\n",
    "\n",
    "    def load_lora_weights(self, state_dict, prefix):\n",
    "        self.lora_A.weight.data = state_dict[f'{prefix}.lora_A.weight'].to(self.device)\n",
    "        self.lora_B.weight.data = state_dict[f'{prefix}.lora_B.weight'].to(self.device)\n",
    "        if self.lora_bias:\n",
    "            self.lora_A.bias.data = state_dict[f'{prefix}.lora_A.bias'].to(self.device)\n",
    "            self.lora_B.bias.data = state_dict[f'{prefix}.lora_B.bias'].to(self.device)\n",
    "    \n",
    "class NeroModel(nn.Module):\n",
    "    def __init__(self, base_model: nn.Module, lora_config: LoraConfig, nero_bias: bool=False, \n",
    "                 # return_nero_outputs: bool=False,\n",
    "                 ):\n",
    "        super().__init__()\n",
    "        self.base_model = base_model\n",
    "        self.nero_bias = nero_bias\n",
    "        self.nero_layers = nn.ModuleDict()\n",
    "        # self.return_nero_outputs = return_nero_outputs\n",
    "\n",
    "        # Wrap target layers with NeroLayer\n",
    "        self._wrap_target_layers(lora_config)\n",
    "        \n",
    "    def _wrap_target_layers(self, lora_config):\n",
    "        for module_name, module in self.base_model.named_modules():\n",
    "            if isinstance(module, NeroLayer):\n",
    "                # Convert module name format and store reference\n",
    "                module_name = module_name.rsplit('model.', 1)[-1]\n",
    "                module_name = module_name.replace('.', '__DOT__')\n",
    "                self.nero_layers[module_name] = module\n",
    "                continue\n",
    "\n",
    "            if any(module_name.endswith(target_module) for target_module in lora_config.target_modules) and isinstance(module, nn.Linear):    \n",
    "                parent_module, child_name = self._get_parent_module(module_name)\n",
    "                nero_layer = NeroLayer(\n",
    "                    module, \n",
    "                    lora_config.r, \n",
    "                    lora_config.lora_alpha, \n",
    "                    lora_config.lora_dropout, \n",
    "                    lora_config.lora_bias, \n",
    "                    lora_config.use_rslora,\n",
    "                    nero_bias=self.nero_bias,\n",
    "                    # return_nero_output=self.return_nero_outputs,\n",
    "                )\n",
    "                setattr(parent_module, child_name, nero_layer)\n",
    "\n",
    "                # Store LoRA layers for weight loading\n",
    "                module_name = module_name.rsplit('model.', 1)[-1]\n",
    "                module_name = module_name.replace('.', '__DOT__')\n",
    "                self.nero_layers[module_name] = nero_layer\n",
    "    \n",
    "    def _get_parent_module(self, module_name):\n",
    "        parts = module_name.split('.')\n",
    "        parent_module = self.base_model\n",
    "        for part in parts[:-1]:\n",
    "            parent_module = getattr(parent_module, part)\n",
    "        return parent_module, parts[-1]\n",
    "\n",
    "    def freeze_except_nero(self):\n",
    "        for param in self.base_model.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        for nero_layer in self.nero_layers.values():\n",
    "            for param_name, param in nero_layer.named_parameters():\n",
    "                if 'nero_A' in param_name or 'nero_B' in param_name:\n",
    "                    param.requires_grad = True\n",
    "                else:\n",
    "                    param.requires_grad = False\n",
    "    \n",
    "    def unfreeze_all(self):\n",
    "        for param in self.base_model.parameters():\n",
    "            param.requires_grad = True\n",
    "        \n",
    "        for nero_layer in self.nero_layers.values():\n",
    "            for param in nero_layer.parameters():\n",
    "                param.requires_grad = True\n",
    "    \n",
    "    def load_lora_weights(self, lora_path):\n",
    "        state_dict = load_file(lora_path)\n",
    "        prefix = list(state_dict.keys())[0].rsplit('model.', 1)[0] + 'model.'\n",
    "        for nero_layer_name, nero_layer in self.nero_layers.items():\n",
    "            nero_layer_name = nero_layer_name.replace('__DOT__', '.')\n",
    "            nero_layer_name = prefix + nero_layer_name\n",
    "            if f'{nero_layer_name}.lora_A.weight' in state_dict and f'{nero_layer_name}.lora_B.weight' in state_dict:\n",
    "                nero_layer.load_lora_weights(state_dict, nero_layer_name)\n",
    "            else:\n",
    "                # TODO: Print warning message\n",
    "                pass\n",
    "        print(\"LoRA weights loaded successfully!\")\n",
    "    \n",
    "    # def forward(self, input_ids, attention_mask=None):\n",
    "    #     if self.training:\n",
    "    #         nero_outs = {}\n",
    "            \n",
    "    #         def _hook_fn(layer_name, module, _in, _out):\n",
    "    #             if isinstance(_out, tuple) and len(_out) == 2:\n",
    "    #                 layer_out, nero_out = _out\n",
    "    #                 nero_outs[layer_name] = nero_out # Store nero_out separately\n",
    "    #                 return layer_out # Return only layer_out to avoid breaking model flow\n",
    "\n",
    "    #         # Register hooks to extract nero_out during forward pass\n",
    "    #         hooks = []\n",
    "    #         for layer_name, layer in self.nero_layers.items():\n",
    "    #             hook = layer.register_forward_hook(functools.partial(_hook_fn, layer_name))\n",
    "    #             hooks.append(hook)\n",
    "        \n",
    "    #         try:\n",
    "    #             output = self.base_model(input_ids, attention_mask=attention_mask)\n",
    "    #         finally:\n",
    "    #             # Remove hooks after forward pass, ensuring it's done even if an error occurs\n",
    "    #             for hook in hooks:\n",
    "    #                 hook.remove()\n",
    "\n",
    "    #         return output, nero_outs\n",
    "        \n",
    "    #     return self.base_model(input_ids, attention_mask=attention_mask)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None):\n",
    "        self_outputs = self.base_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "        # Collect nero outputs directly from layers\n",
    "        nero_outs = {}\n",
    "        for name, nero_layer in self.nero_layers.items():\n",
    "            if hasattr(nero_layer, 'last_nero_out'):\n",
    "                nero_outs[name] = nero_layer.last_nero_out  # Store after forward pass\n",
    "\n",
    "        return self_outputs, nero_outs\n",
    "    \n",
    "    def __getattr__(self, name):\n",
    "        try:\n",
    "            return super().__getattr__(name) # Try getting attribute from self\n",
    "        except AttributeError:\n",
    "            return getattr(self.base_model, name) # Fallback to base_model\n",
    "\n",
    "base_model2, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name='unsloth/Meta-Llama-3.1-8B',\n",
    "    max_seq_length=max_seq_length,\n",
    "    dtype=dtype,\n",
    "    load_in_4bit=load_in_4bit,\n",
    ")\n",
    "lora_config = LoraConfig.from_pretrained(model_configs['L2T1']['lora_dir'])\n",
    "nero_model = NeroModel(base_model2, lora_config, nero_bias=True, \n",
    "                       # return_nero_outputs=True\n",
    "                       )\n",
    "# nero_model.freeze_except_nero()\n",
    "# print(nero_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.3625, -0.2265,  0.5827,  ...,  0.3783,  0.5715, -0.3697],\n",
      "        [-0.1446,  0.0784,  0.2471,  ...,  0.0278,  0.0392,  0.1049],\n",
      "        [-0.3740,  0.2509,  0.0829,  ..., -0.1775, -0.0762, -0.7239],\n",
      "        ...,\n",
      "        [-0.5322,  0.6272,  0.2937,  ...,  0.0616,  0.6675,  0.2158],\n",
      "        [-0.1484,  0.2143, -0.1039,  ..., -0.2257,  0.0461,  0.0494],\n",
      "        [ 0.2304, -0.4242, -0.3902,  ..., -0.7668, -0.2101,  0.4244]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[ -7.2222, -43.5459,  43.4988,  -0.4260,  23.6389,  21.6417,  38.8058,\n",
      "           -1.4762],\n",
      "         [ 29.5109,  -8.7101,  13.4745, -56.6288,   4.7114,   4.4593,  -3.5843,\n",
      "           27.4745],\n",
      "         [ 18.2899,  11.9759,  -6.7272,  -3.2681, -45.4836, -40.4932,  -3.9834,\n",
      "            2.6008],\n",
      "         [-15.2443,  26.5260, -13.9710, -17.2929,  -2.3880, -25.1912, -10.6587,\n",
      "           11.6087],\n",
      "         [-23.3473,   7.1252,  -1.9572, -32.2756,   0.6222,  -4.9201,  -3.5073,\n",
      "          -11.8791],\n",
      "         [  3.8732,  12.5076, -11.7227,  44.5003, -16.6377, -24.4949,  -5.8016,\n",
      "           12.3430],\n",
      "         [ -8.9821,  -3.7663,  41.7701,  36.0276,  28.0688,  -5.0558, -30.9581,\n",
      "          -13.4477],\n",
      "         [ 19.9556,  -6.7160,  11.9288,  -8.4976,  25.9229,   4.6555, -27.9567,\n",
      "          -29.4020],\n",
      "         [-11.6565,  21.6991,   3.8095,   2.7670, -31.5560, -11.7760, -18.8675,\n",
      "          -15.0877],\n",
      "         [-18.1839, -14.7050,  14.2059, -14.7731, -19.8879,   9.2105,  -9.0240,\n",
      "           -7.0348],\n",
      "         [-32.7293, -15.7890, -10.1007,   5.7727,  -2.8135,   7.4286,  14.2623,\n",
      "          -10.1446],\n",
      "         [ -8.9674, -14.9654,  18.9500,  -8.8180,  38.8408,  12.0017, -29.8305,\n",
      "           -1.7889],\n",
      "         [-11.6205, -17.3450,  28.6081, -20.0487,  -3.8537,  21.5292,  19.0934,\n",
      "           21.7603],\n",
      "         [-20.0901,   0.3928, -18.3442,  -2.6232, -51.0330,  -0.2111, -34.5117,\n",
      "           -7.9900]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[-3.1473e-01, -1.9469e-01, -2.3367e-01,  ...,  5.2576e-01,\n",
      "         -4.6668e-01, -1.8420e-02],\n",
      "        [-3.7872e-01, -2.8985e-01, -4.2009e-01,  ...,  4.8674e-01,\n",
      "          2.9805e-01,  7.5471e-02],\n",
      "        [-3.1712e-01, -3.4334e-01,  1.0903e-01,  ...,  1.4652e-01,\n",
      "          8.0080e-03,  3.4283e-01],\n",
      "        ...,\n",
      "        [-2.7699e-01,  5.2660e-01,  7.2200e-01,  ...,  8.6530e-05,\n",
      "          3.5721e-01, -2.1017e-01],\n",
      "        [-4.2805e-01, -2.1091e-02, -5.4340e-01,  ..., -6.1135e-01,\n",
      "          1.0486e-01,  3.6263e-01],\n",
      "        [-2.3838e-01, -1.4351e-01, -4.3456e-02,  ...,  1.5932e-01,\n",
      "          1.3021e-01, -4.1855e-01]], device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[-14.7188,  -6.9511,  -4.8170,  -5.8215,  13.6323,   9.3021,   2.5884,\n",
      "            9.8692],\n",
      "         [ -0.9387,   5.7675,   5.0926, -13.3859,  19.5505,  -1.7997,  -2.1963,\n",
      "            1.9050],\n",
      "         [  7.7518,  -9.2569,   2.6258,  -8.7585,   5.0893,  13.6510,   5.6789,\n",
      "            5.3366],\n",
      "         [-11.8541, -12.2795, -15.0320,  17.8595,  -9.7755,   1.0111,   8.1605,\n",
      "            7.9981],\n",
      "         [ -7.1086,  25.9395,  24.8713, -12.6132,   9.2891, -16.0620, -26.1099,\n",
      "           22.0087],\n",
      "         [ 11.4641,  -5.6103, -13.8388,  -1.6049,  11.9360,   2.4220,  -8.1918,\n",
      "            0.9263],\n",
      "         [-12.8833,  -0.1534,   6.8075,  -6.2370,  -6.8008,  15.7326, -12.9615,\n",
      "            6.0086],\n",
      "         [ -6.9917,   4.0158,   7.3585,   6.6575,   9.7823,  -0.4476, -22.4493,\n",
      "           -5.7303],\n",
      "         [  2.2540,  -2.4924,   4.5019,  -5.7696, -24.6769,  -1.0726,  -2.9111,\n",
      "          -15.8106],\n",
      "         [ -7.9465,   6.5488,  -0.7658,  12.4672,   6.4654,  23.8683,  -5.4735,\n",
      "           -5.6895],\n",
      "         [ -9.3660,   8.6330,  12.0525,   1.2293,   6.5556,  16.2696,   5.6946,\n",
      "           -4.9699],\n",
      "         [ -1.2256,   8.5115,  20.2077,  25.7374,   2.1091,  -8.0351, -19.3697,\n",
      "            2.1458],\n",
      "         [  1.5053, -17.6879,   2.4307,   2.8572,   8.9469,   8.7350,  20.2991,\n",
      "           -4.4080],\n",
      "         [ 20.3856,  -9.3068, -11.1766,   6.9645,  -0.3263, -17.7046,   3.7930,\n",
      "            2.9429]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.6532,  0.0697, -0.5212,  ..., -0.4873,  0.8418,  0.2147],\n",
      "        [ 0.4878, -0.2476, -0.3946,  ..., -0.4778,  0.1766, -0.1359],\n",
      "        [-0.0850,  0.2048, -0.1207,  ...,  0.0960, -0.7360, -0.2218],\n",
      "        ...,\n",
      "        [-0.4510,  0.2393,  0.5925,  ...,  0.1792, -0.3471, -0.0447],\n",
      "        [-0.2015, -0.1478, -0.5004,  ..., -0.3370, -1.0128,  0.6163],\n",
      "        [ 0.0282,  0.5024, -0.1234,  ...,  0.1610,  0.3020, -0.0665]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[-2.9131e+00, -7.6915e-01, -1.9765e+01, -2.3997e+01,  8.8547e+00,\n",
      "          -1.5630e+00,  8.9074e+00,  2.0904e+01],\n",
      "         [ 9.9849e+00, -2.3094e+00, -1.4497e+00, -2.1213e+00, -4.4747e+00,\n",
      "          -3.3287e+00, -2.2349e+00, -1.0535e+01],\n",
      "         [-9.0981e+00,  8.6055e+00,  1.1226e+01, -7.2878e+00,  1.8541e+01,\n",
      "          -2.8976e+01,  1.0682e+01, -3.8788e+00],\n",
      "         [-1.5036e+01,  1.2075e+01, -1.4403e+01, -1.9099e-02, -4.2062e+00,\n",
      "          -1.2539e+00, -2.5235e+01, -5.8807e+00],\n",
      "         [ 6.9134e+00,  7.4609e+00,  1.4420e+01,  2.6471e+01, -9.6856e+00,\n",
      "          -1.2374e+01, -3.1403e+01,  1.5688e+01],\n",
      "         [ 7.5515e+00,  3.7511e+00,  7.4510e-02, -7.3715e-01, -1.1494e+01,\n",
      "           7.4883e+00, -4.7329e+00,  8.6655e+00],\n",
      "         [-5.2420e+00, -4.6286e+00,  1.3707e+01,  1.8331e+00,  2.3197e+01,\n",
      "           1.4805e+00, -1.6322e+00, -2.6405e+01],\n",
      "         [ 4.8790e+00,  2.4674e+01,  2.9853e-01, -1.4078e+01,  3.3094e+00,\n",
      "          -4.6366e+00, -1.0367e+01,  6.5742e+00],\n",
      "         [-1.2420e+01, -9.6209e+00, -5.3053e+00, -1.2954e+01, -1.2990e+01,\n",
      "          -3.1984e+00,  5.5287e+00,  6.1806e+00],\n",
      "         [ 2.3811e+01,  9.2144e+00, -1.8913e+01,  1.4041e+00, -6.5603e+00,\n",
      "           1.9711e+00,  4.8436e+00,  8.5494e+00],\n",
      "         [ 1.0649e+01,  1.2848e+01, -2.2883e+00,  4.5530e+00, -1.2340e-01,\n",
      "          -1.1846e+01, -7.3745e+00,  8.3104e+00],\n",
      "         [ 2.8308e+00,  1.4844e+01, -2.1216e+01, -3.8100e+00,  1.6638e+01,\n",
      "           1.4592e+01, -1.3360e+00,  3.1372e+00],\n",
      "         [ 9.0212e+00, -3.1854e+01, -2.1780e+01, -5.2078e+00, -4.4687e+00,\n",
      "          -8.5281e+00,  7.1370e+00,  2.0723e+00],\n",
      "         [-7.8189e+00,  1.3602e+01,  2.0793e+01,  4.1420e+00,  9.2320e+00,\n",
      "          -9.5869e-01, -1.8968e+00, -4.2025e+00]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.4208, -0.0363, -0.5282,  ..., -0.0943,  0.3240,  0.3717],\n",
      "        [-0.0939,  0.3169, -0.1388,  ...,  0.0503,  0.8313, -0.0422],\n",
      "        [ 0.2002,  0.8052,  0.4912,  ..., -0.1832, -0.0438,  0.4021],\n",
      "        ...,\n",
      "        [ 0.2886,  0.0747,  0.1676,  ...,  0.0633,  0.0154,  0.1937],\n",
      "        [ 0.3654, -0.4498, -0.0840,  ..., -0.0187, -0.0885, -0.4639],\n",
      "        [-0.1501, -0.0959,  0.5380,  ...,  0.1803, -0.1755, -0.3364]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[ 4.6347e+00, -3.5289e+01,  1.2297e+01,  5.2760e+00,  2.2473e+01,\n",
      "           2.9168e+01,  9.2466e+00, -4.2781e+01],\n",
      "         [ 1.1379e+01, -6.0376e+01,  1.4627e+01,  2.2411e+01, -1.8546e+00,\n",
      "          -4.6563e+00, -5.4898e+00, -1.3914e+01],\n",
      "         [ 1.3861e+00,  2.1371e+01,  1.2102e+00,  2.5997e+01,  5.1631e+01,\n",
      "           1.7345e+01,  8.8057e+00,  3.5128e+01],\n",
      "         [ 1.8657e+01, -1.1344e+01,  1.9539e+01, -3.9421e+01,  4.0056e+01,\n",
      "          -1.0836e+01,  3.0875e+01, -1.8657e+01],\n",
      "         [-1.8718e+01,  1.0343e+01,  3.8355e+01,  1.0338e+01, -2.5745e+01,\n",
      "           1.3559e+01,  1.5011e+01,  1.8008e+01],\n",
      "         [ 1.9830e+00,  1.8899e+01, -3.0501e+01, -3.9408e+00,  3.3948e+00,\n",
      "          -2.4383e+01, -2.1582e+01,  4.5012e+01],\n",
      "         [ 6.9301e-01,  1.0947e+01, -9.2032e+00, -1.2170e+01,  1.3282e+01,\n",
      "          -2.5066e+01, -1.4697e+01, -3.7064e+01],\n",
      "         [-1.1666e+01, -1.1945e+00,  2.4355e+01, -3.0140e+01, -1.0553e+01,\n",
      "           1.3054e+01, -1.3844e+01,  4.0035e+01],\n",
      "         [ 3.5720e+01, -1.2326e+01, -3.6241e+01, -3.5494e+00, -1.2418e+01,\n",
      "           1.0994e+01, -2.9162e+01, -2.9086e+01],\n",
      "         [ 2.3790e-03,  3.0633e+01, -2.6187e+01,  5.0747e+00, -5.8217e+00,\n",
      "          -2.0535e+01,  2.1719e-01,  9.9859e+00],\n",
      "         [ 4.6488e+01, -3.2475e+01, -1.8441e+01, -1.5286e+01,  1.6665e+01,\n",
      "          -4.5295e+00,  1.2071e+00, -1.9867e+01],\n",
      "         [-1.6130e+01, -2.9646e+01, -2.6724e+01, -2.0604e+01,  7.1609e+00,\n",
      "          -1.3844e+01,  1.6872e+01,  7.8238e+00],\n",
      "         [ 2.0004e+01, -1.6154e+01, -1.4076e+01,  1.3983e+01, -1.3371e+01,\n",
      "           2.5659e+01, -3.7605e+01, -1.1866e+01],\n",
      "         [-1.7378e+01,  1.6270e+01, -3.3624e+01,  2.9971e+01,  2.6565e+01,\n",
      "          -1.4040e+01,  1.1693e+01,  1.6794e+01]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.0351,  0.2346, -0.0421,  ..., -0.4962,  0.2948, -0.0768],\n",
      "        [-0.5294,  0.3952, -0.8120,  ..., -0.2551,  0.1481, -0.2772],\n",
      "        [ 0.2109,  0.1223,  0.0941,  ..., -0.1935, -0.6821, -0.2171],\n",
      "        ...,\n",
      "        [ 0.1591,  0.3690, -0.1118,  ...,  0.2690, -0.2459, -0.2618],\n",
      "        [-0.4011,  0.2509, -0.2725,  ...,  0.1519, -0.3245, -0.4299],\n",
      "        [ 0.6130,  0.1333, -0.2219,  ..., -0.4303,  0.0123, -0.3746]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[ 2.1960e+01, -8.3862e+01, -1.6798e+01, -7.4912e+01,  3.3839e+01,\n",
      "          -4.1345e+01,  2.8025e+01, -2.4889e+01],\n",
      "         [-4.0087e+01, -6.3017e+01,  1.3900e+01,  5.6989e+01,  8.0240e+01,\n",
      "           5.5915e+01,  6.5836e+01, -2.2414e+01],\n",
      "         [-5.2200e+01,  1.1342e+00,  4.7784e+00,  2.7197e+01,  4.1321e+01,\n",
      "          -6.4435e+01, -6.0384e+01,  1.2765e+01],\n",
      "         [-1.0163e+00,  5.2390e+01,  1.0867e+02,  7.7400e+00, -4.0718e+01,\n",
      "           6.4638e+01, -2.4657e+01, -4.6256e+00],\n",
      "         [ 8.9109e+01,  7.9509e+00,  1.7063e+01, -2.7212e+01, -2.4955e+01,\n",
      "           4.2891e+01, -2.6898e+01, -2.7337e+01],\n",
      "         [-6.2853e+01, -1.2058e+01,  8.0045e+00, -3.4125e+01,  2.4442e+01,\n",
      "          -4.5857e+01,  3.6566e-02,  1.8155e+00],\n",
      "         [ 2.6923e+01,  5.6031e+01,  5.4621e+00,  1.6732e+01, -5.1452e+01,\n",
      "          -7.7462e+01,  3.4424e+01, -8.4021e+01],\n",
      "         [ 1.1818e+02, -1.2647e+01, -1.4259e+01, -2.1732e+01, -2.6149e+01,\n",
      "          -1.2484e+01,  3.7242e+01,  7.1417e+01],\n",
      "         [-1.6078e+01, -2.2689e+00, -3.2553e+01, -2.4317e+01,  7.2558e+01,\n",
      "          -1.8164e+01, -4.2364e+01,  5.9354e+01],\n",
      "         [ 3.9658e+00,  2.8676e+01,  2.2738e+01, -1.2954e+01,  2.2298e+01,\n",
      "           3.9029e+01, -2.5628e+01,  8.4246e+00],\n",
      "         [-2.7467e+01,  5.0567e+00,  2.1065e+01,  1.3772e+01, -5.1336e+01,\n",
      "           2.2731e+01, -8.4382e+00, -1.7106e+01],\n",
      "         [ 7.6759e+01,  4.7744e+00, -2.4320e+01,  4.8590e+01, -7.3959e+01,\n",
      "           3.8107e+01, -5.1728e+01, -1.0684e+02],\n",
      "         [-2.5307e+01, -3.1970e+01, -2.2230e+01,  6.9698e+00,  1.6775e+00,\n",
      "          -1.7728e+01, -7.8108e+01, -3.8309e+01],\n",
      "         [ 1.5172e+01, -6.5579e+01,  4.6484e+01,  7.6086e+01, -2.4089e+01,\n",
      "           2.1442e+01, -1.4204e+00, -3.1560e+01]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.1896,  0.0552,  0.1899,  ..., -0.3938, -0.0186, -0.0036],\n",
      "        [ 0.3284, -0.3860, -0.2393,  ...,  0.2957,  0.4930,  0.5062],\n",
      "        [-0.0333,  0.3227, -0.1120,  ..., -0.2925, -0.2700, -0.0303],\n",
      "        ...,\n",
      "        [-0.3188, -0.4795, -0.8488,  ...,  0.5444, -0.1028,  0.3690],\n",
      "        [ 0.1532, -0.3661, -0.3761,  ..., -0.1601, -0.2699, -0.2721],\n",
      "        [ 0.0596, -0.3375,  0.6814,  ...,  0.3631, -0.3418,  0.2074]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[-12.0438,  11.5795,  21.3378, -28.1306, -65.7840, -25.4981, -71.6841,\n",
      "          -17.1559],\n",
      "         [ 31.1690, -43.3480, -27.9028,  17.7508,  77.6896, -28.9196,  57.0559,\n",
      "          -35.1491],\n",
      "         [-15.8530,  -6.1232, -16.3445, -29.9950, -32.1766,  71.2098,  56.9691,\n",
      "           -0.2300],\n",
      "         [  5.2941,  23.7548,  29.9177,  28.4559,  -0.5860,  81.5490,  30.8411,\n",
      "          -42.4180],\n",
      "         [ 19.8449, -17.5750, -11.3976,  -3.2863,  15.9291,  12.3811,  -7.1037,\n",
      "           -3.8557],\n",
      "         [  8.5219, -17.0367,  -7.2153, -77.8331,  12.2699,  13.3853, -47.9649,\n",
      "          -29.8847],\n",
      "         [ 48.2190,  40.6893,  71.4638,  66.0648,  -1.6928,  -3.9151, -29.4760,\n",
      "           51.2701],\n",
      "         [  9.1051, -30.5433,  22.4893,  -3.2621, 113.7561,  16.1188, -17.3038,\n",
      "          -97.7595],\n",
      "         [-42.5513,   5.9842,  22.0285,  14.8452,  20.2150,  21.4712, -63.0792,\n",
      "          -62.9487],\n",
      "         [  7.8995,   3.9492, -16.1211,  -3.2455,  53.6414,  40.1954,  -9.2727,\n",
      "           11.2184],\n",
      "         [-56.8383,  35.9471, -37.8813,  51.5346,   9.0192, -92.9158,  19.0471,\n",
      "           24.8915],\n",
      "         [-54.4031, -11.7398, -26.9676,  42.5446, -50.2246,  41.4414, -34.6299,\n",
      "           25.6048],\n",
      "         [-18.1393, -50.8068,  43.8214,  41.9348, -53.2170,  45.0746,  26.1284,\n",
      "           18.7037],\n",
      "         [-20.2739,  -2.9832, -14.6671, -31.8912,  40.9996,  44.1537, -59.2845,\n",
      "           96.7363]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=14336, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[-0.3478, -0.3834,  0.1351,  ..., -0.3260,  0.1516,  0.0224],\n",
      "        [-0.4996,  0.0316, -0.5026,  ..., -0.2517, -0.5421,  0.1087],\n",
      "        [ 0.0862,  0.0707, -0.0709,  ..., -0.0273,  0.5448, -0.6142],\n",
      "        ...,\n",
      "        [-0.5081,  0.1877,  0.4043,  ..., -0.3666,  0.0594,  0.3026],\n",
      "        [-0.3062, -0.3177,  0.8488,  ...,  0.2370, -0.4572, -0.2037],\n",
      "        [-0.1889, -0.7043, -0.1567,  ..., -0.1594, -0.5015, -0.0872]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[ -4.1234,   0.7431,  24.7381,  24.5319,   1.7101, -13.4442, -55.6923,\n",
      "           11.5837],\n",
      "         [-13.1915, -37.4344, -19.2113,  -1.5077, -17.8047,   1.5679, -23.3044,\n",
      "           47.9830],\n",
      "         [ 15.7592,  26.0093,  28.1283, -15.7453, -37.8123,  26.8231, -14.8217,\n",
      "          -13.0455],\n",
      "         [  4.4059,  17.9300,   4.6995,  45.9176,  -9.3563,  -1.4707,  -0.8646,\n",
      "           -5.6640],\n",
      "         [ 17.3970,   2.8578,  -8.5029,  38.2950, -15.4312,  15.1095, -32.9906,\n",
      "           24.6718],\n",
      "         [ -9.2644, -22.1179,  26.8324,  35.0031,  14.1256,   0.2137,  16.3852,\n",
      "           29.6533],\n",
      "         [-35.2602,  -7.3346,  20.5554, -19.2293,  -4.9924, -12.1633,  -8.5154,\n",
      "           -6.6721],\n",
      "         [ 23.9376,   4.8694,   3.1098,   6.0685,   1.7587, -51.1984,   8.2138,\n",
      "           16.8078],\n",
      "         [ 11.1704,  19.4144,  10.1444,  -1.2593, -17.9818,  11.7070, -22.2515,\n",
      "           11.2838],\n",
      "         [ 12.1024, -29.2044,  11.7449,  19.4654,  15.8816,  -1.8639,  -3.5695,\n",
      "          -27.9012],\n",
      "         [  8.1542,  17.4296,  26.2983,  -8.1333,  23.1714,  10.5083, -42.9172,\n",
      "           21.0221],\n",
      "         [ -1.1863, -30.5698, -28.1095, -12.9466, -12.1721, -17.2976, -23.4799,\n",
      "           36.1395],\n",
      "         [ 21.4753,   8.6340, -25.2933,  40.1234,  13.4585,  31.9720, -23.1894,\n",
      "          -31.3377],\n",
      "         [ 23.9128,  -7.8311, -23.4066, -38.5537,  10.1310,  -8.5762, -74.0122,\n",
      "           -1.0288]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[-0.1214, -0.1271,  0.1511,  ...,  0.1770,  0.1943, -0.3866],\n",
      "        [ 0.1717,  0.2386, -0.2928,  ...,  0.2063, -0.2427,  0.4235],\n",
      "        [ 0.2015,  0.1025, -0.2130,  ...,  0.0646,  0.2283,  0.0570],\n",
      "        ...,\n",
      "        [-0.2922,  0.3334, -0.2045,  ..., -0.1659,  0.4046, -0.0320],\n",
      "        [ 0.4329, -0.3705, -0.2311,  ...,  0.9529, -0.4699, -0.3621],\n",
      "        [ 0.1810,  0.1183, -0.4388,  ...,  0.5051,  0.4375, -0.5925]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[-45.6826,  -6.4415, -16.5839, -31.2304, -38.2537,  18.7774,  -5.6696,\n",
      "          -13.6908],\n",
      "         [ 34.4769, -23.7164,  20.2339, -23.3538,   1.1050,  51.1605,  48.8719,\n",
      "            3.2190],\n",
      "         [ 18.1397,   1.1817,   6.6528,  -1.9531, -19.4337, -11.3379,  21.1162,\n",
      "            1.8121],\n",
      "         [ 35.4672,  24.6430, -12.0975,   2.9927, -11.3987,   8.6239,   2.5098,\n",
      "            7.9178],\n",
      "         [-11.5633,  14.4514,  20.4721,  17.7368,   8.9199, -25.3469, -19.8703,\n",
      "           43.2632],\n",
      "         [-11.6889,  -3.4242,  13.1164,   7.6723, -10.8157, -12.9852,   1.6010,\n",
      "          -11.3985],\n",
      "         [ 37.4058,  32.8171, -23.9223,  -7.7759,   4.9775, -13.5190, -42.3819,\n",
      "          -53.6320],\n",
      "         [  5.2508,   5.9383,  -8.8205,  12.4268,  10.6988, -13.8304, -16.4727,\n",
      "          -13.0769],\n",
      "         [-25.0451,  -6.0432,  -5.3787, -28.3170,  27.0106,   9.6031,  -2.7644,\n",
      "           20.2649],\n",
      "         [ 29.1890, -19.5350, -17.0062,   1.0883,   6.3897,  -6.8462,  19.9131,\n",
      "           40.9506],\n",
      "         [ -4.2487,  -1.9505, -25.4997,  15.1626, -53.0949,  14.3292, -24.2713,\n",
      "          -20.0655],\n",
      "         [-11.3358,  14.7767,  -1.9374,  -3.8785,   7.0650,  10.7844,  46.6698,\n",
      "           10.6604],\n",
      "         [ -9.9602,  32.3921, -21.1624,   5.8933,  -7.1731,   1.2297, -24.5804,\n",
      "           23.1378],\n",
      "         [-11.1528,  31.5287, -12.8530,   1.3807,  39.1531,  -2.7845, -25.0117,\n",
      "          -40.1845]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.3573,  0.5686, -0.1074,  ..., -0.4909, -0.0186, -0.5978],\n",
      "        [ 0.3611,  0.0947, -0.1415,  ..., -0.2255, -0.8075, -0.0418],\n",
      "        [-0.1311,  0.3499, -0.9778,  ..., -0.2139,  0.4989, -0.1622],\n",
      "        ...,\n",
      "        [-0.4173, -0.4452, -0.5103,  ..., -0.6508, -0.3854, -0.1790],\n",
      "        [-0.6778,  0.3294, -0.1992,  ..., -0.3503, -0.1053, -0.0247],\n",
      "        [-0.2095,  0.3678, -0.4982,  ...,  0.4564, -0.2260, -0.2200]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[-3.9916e+00,  1.3040e+01, -5.4012e+00,  4.2296e+00,  2.2335e+01,\n",
      "           3.1016e+00, -3.2506e+00,  7.6217e+00],\n",
      "         [-1.9786e+01, -7.5861e+00, -1.4265e+01,  1.1819e+01,  7.2045e-01,\n",
      "           3.4925e+00,  6.3391e+00,  8.5205e+00],\n",
      "         [-1.5441e+01, -2.5770e+00,  7.1880e+00, -1.3729e+01,  1.1917e+01,\n",
      "          -1.5830e+01, -5.7803e+00,  1.2589e+01],\n",
      "         [ 3.4257e+00,  3.1448e+00,  1.7509e+01,  1.0519e+01,  9.6620e+00,\n",
      "           5.9902e+00, -8.2177e+00,  5.7888e+00],\n",
      "         [-1.9927e+01, -1.2801e+00, -1.3357e+01, -2.1136e+01,  4.5880e+00,\n",
      "          -2.3117e+00,  2.5130e+00,  4.4038e+00],\n",
      "         [ 1.8724e+01, -6.2036e+00,  4.5979e+00, -3.6683e-01,  5.4691e+00,\n",
      "          -2.8083e+00,  9.6455e+00, -1.1985e+01],\n",
      "         [-2.8970e+00,  5.8751e+00, -1.0999e+01, -9.8971e-01, -1.3001e+01,\n",
      "          -1.2868e+01,  8.9970e+00,  2.0909e+01],\n",
      "         [ 1.1667e-02,  2.8515e+00,  2.1296e+00,  7.9919e+00,  6.6435e+00,\n",
      "           9.4195e+00,  1.2949e+00, -2.4225e+01],\n",
      "         [ 8.8718e+00, -8.9544e+00,  1.1234e+01, -7.1436e+00, -7.5599e+00,\n",
      "           6.9285e+00,  4.1342e+00, -7.2228e+00],\n",
      "         [ 1.0511e+01,  6.7159e+00, -2.4637e-01, -1.5992e+00, -2.1002e+00,\n",
      "           4.1527e-01,  1.1633e+01, -6.9811e+00],\n",
      "         [ 1.0263e+01,  1.6015e+00, -8.3829e+00,  1.7051e+01, -2.5492e-01,\n",
      "          -1.0085e+00,  5.7327e-01,  1.0400e+01],\n",
      "         [ 7.6486e+00, -8.8228e+00, -1.3575e+01,  3.6108e+00,  7.5918e+00,\n",
      "          -3.0430e+00,  6.5962e-01, -1.1352e+01],\n",
      "         [-4.3139e+00,  1.3246e+00,  4.2104e+00,  1.3046e+01, -9.9409e+00,\n",
      "           1.7375e+01,  3.5097e+00, -2.9876e+01],\n",
      "         [ 3.3417e+00, -1.2668e+01, -1.5060e+01, -9.7164e+00, -1.0685e+01,\n",
      "          -2.0213e+01,  1.9633e+01,  1.2010e+01]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.0801, -0.2166, -0.2112,  ..., -0.0799,  0.1748, -0.0386],\n",
      "        [-0.5353, -0.1200,  0.1166,  ...,  0.3197,  0.1222, -0.1940],\n",
      "        [-0.0322, -0.1780, -0.0204,  ...,  0.1483, -0.3244, -0.3743],\n",
      "        ...,\n",
      "        [ 0.3179,  0.1351, -0.0231,  ...,  0.1830, -0.3309,  0.6349],\n",
      "        [ 1.0682,  0.2015, -0.3134,  ..., -0.2613, -0.0856, -0.2403],\n",
      "        [ 0.4475, -0.2968,  0.0020,  ..., -0.5185,  0.0874,  0.2519]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[  1.1747,   5.1033,   0.5223, -11.3057,  -4.3714,   0.5590,  -6.5257,\n",
      "            0.4833],\n",
      "         [  1.6192,   6.9914, -20.7818,   1.1629,  21.2570,   5.8175, -20.8903,\n",
      "           -5.9763],\n",
      "         [ -9.9382,   8.4029,   2.3598,   4.4670,   1.7157,  31.7738,  -1.9820,\n",
      "           -9.5475],\n",
      "         [ -0.2274,   1.8615,   4.1500,  -1.7904,  -7.5683,  -7.1617,   6.0515,\n",
      "           -6.0983],\n",
      "         [  8.4501,  -2.4245, -16.8259,   5.2016,  16.9271,  -7.7923, -11.4403,\n",
      "            6.6260],\n",
      "         [ -7.5917,   1.3487,  -3.8754,  13.2982,   8.5511, -15.6332, -11.3093,\n",
      "          -22.4299],\n",
      "         [  1.9069,  19.2595,   5.2249,  -5.5998, -22.1224,  -2.4437,   0.1196,\n",
      "           -2.8456],\n",
      "         [  6.4266,   9.2466,  11.3485,   2.5097,   9.3347, -11.6574,   8.1679,\n",
      "           -4.8890],\n",
      "         [  9.7961, -13.6422,   4.7285,   8.1072,  -0.3198,   1.9418, -17.1272,\n",
      "           18.9628],\n",
      "         [  2.0337,   0.8438,  15.3267, -15.6419,   4.0166,   8.5248,  -5.0529,\n",
      "            2.9068],\n",
      "         [ 13.5591, -26.7944,  -1.0829, -33.7477,  -1.3966,  -3.9981,  -1.3307,\n",
      "            4.4167],\n",
      "         [ -3.5382,   9.1528, -31.0337,   5.5006,   8.6382,  26.6327, -20.6615,\n",
      "           -2.4390],\n",
      "         [-15.5201,  -1.1048,   3.9508,  -2.0615,   2.9462, -13.9301, -16.1736,\n",
      "           17.5536],\n",
      "         [ 13.2981, -18.7133,   2.3021, -10.5148,  -0.8018,   8.0081,   3.3280,\n",
      "           14.0633]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.1436, -0.2184,  0.1391,  ..., -0.2216,  0.1746, -0.0692],\n",
      "        [ 0.1617, -0.3405, -0.8606,  ...,  0.1286,  0.1455, -0.2214],\n",
      "        [ 0.6653,  0.2860,  0.1076,  ..., -0.1494,  0.2679, -0.2763],\n",
      "        ...,\n",
      "        [ 0.0751,  0.5159,  0.2765,  ..., -0.1673,  0.1921, -0.3951],\n",
      "        [-0.3589,  0.2659, -0.5435,  ...,  0.0950, -0.1483, -0.0526],\n",
      "        [ 0.3229,  0.1978,  0.0671,  ..., -0.2756, -0.3425, -0.3831]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[-27.7900,   0.3950,   3.7487, -13.0379, -45.3998,  -3.5684,  15.8734,\n",
      "            0.9012],\n",
      "         [ 21.6833,   1.1317, -14.9100,   7.3016,   5.7600,   0.4954,   9.2273,\n",
      "           23.9943],\n",
      "         [ 17.7554,  -3.9850, -21.9642,   2.5835,  12.3535, -11.4843, -31.1806,\n",
      "            2.9285],\n",
      "         [ 44.4033,   9.7230,   7.4216,   9.7523,  19.1970, -36.0952,   8.1398,\n",
      "          -12.5137],\n",
      "         [ 20.6251,  29.1661,  -7.1632, -14.6473,   3.8122,  41.0292,  -5.8686,\n",
      "          -15.3623],\n",
      "         [ 15.0747,   0.7100,  44.5484,  16.8639, -49.8073,   7.1106,  11.8665,\n",
      "           11.2233],\n",
      "         [-20.7681,   3.4615,  15.4610,  38.1352,  54.5734,  50.6456,   6.9069,\n",
      "          -24.7545],\n",
      "         [-20.4214,  10.7000,   5.3488,  -6.9673,   4.2822,   2.3009,  12.3690,\n",
      "            4.9772],\n",
      "         [ -3.2390,   7.7812,  29.5865, -17.3706, -37.6174, -12.8901,  -5.2586,\n",
      "          -29.4845],\n",
      "         [ -7.4959,   8.6294,  32.8209,   1.6198, -27.6322, -11.3891,   7.0357,\n",
      "          -15.9334],\n",
      "         [-28.5150,  30.3919, -57.6128,  -1.2746,  36.8312,  46.3535,  25.4225,\n",
      "           19.7222],\n",
      "         [ 19.0447,  -5.1719,  12.8424,  25.4206, -29.3307,  20.0738, -18.6132,\n",
      "            7.4704],\n",
      "         [  4.8258, -52.5917, -21.5881,  18.0587, -33.5584, -15.2877,  -1.3548,\n",
      "           -9.3810],\n",
      "         [ 12.5881, -45.3662, -48.3805, -44.5253,  10.3853, -13.1559,   3.1914,\n",
      "           13.1108]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[-7.9553e-01,  6.1530e-01,  4.6631e-01,  ...,  7.9444e-01,\n",
      "          5.3024e-02, -1.9240e-02],\n",
      "        [-1.9009e-01,  5.6312e-01, -8.6979e-02,  ...,  4.6375e-01,\n",
      "          5.0478e-01,  6.8322e-02],\n",
      "        [-2.5107e-01,  1.6310e-01,  2.3621e-01,  ..., -1.7827e-01,\n",
      "         -4.5843e-01,  2.7602e-01],\n",
      "        ...,\n",
      "        [ 7.5155e-02,  1.0638e-01,  3.2080e-01,  ...,  1.6949e-01,\n",
      "          2.7717e-01, -9.0947e-02],\n",
      "        [-4.7114e-02,  6.1855e-02,  3.1169e-01,  ...,  1.0224e+00,\n",
      "          1.1743e-01, -5.4183e-01],\n",
      "        [ 2.8094e-01,  8.2031e-04,  5.2243e-01,  ..., -6.1444e-02,\n",
      "          3.5507e-01, -7.0564e-01]], device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[-22.1975,  66.3905, -12.1581,  60.3710, -24.2557,   5.1518, -26.2822,\n",
      "           43.1786],\n",
      "         [  6.7879, -46.3218, -20.6556,   3.5253,  15.7683, -28.2166,   6.7910,\n",
      "           30.8602],\n",
      "         [  8.8578, -10.5381,  -1.3025, -40.6445, -52.5869,  22.5572, -31.6323,\n",
      "           37.3310],\n",
      "         [ 49.0527,  -0.5431, -33.1961,  10.8702,  -0.1680, -17.4230,  14.3869,\n",
      "          -13.3121],\n",
      "         [ 31.8627,  46.1863,  56.0947,  49.9389, -58.7817, -26.3089,  92.0127,\n",
      "           -6.2357],\n",
      "         [ 69.9544,  -9.5872,  -9.0301, -14.6819,  53.8159,  19.9898, 109.2611,\n",
      "          -12.8895],\n",
      "         [ -0.1601, -95.4665,  -8.2120,   5.8012,  11.0872, -55.7531,   2.8362,\n",
      "           20.1262],\n",
      "         [-44.3979,  24.9422, -38.2380,   1.8882, -26.7242, -25.6282,  14.6543,\n",
      "          -68.2236],\n",
      "         [-13.4422, -11.9767, -33.1247,   9.2574,  92.3752,  -8.8521,  63.6816,\n",
      "          -29.2477],\n",
      "         [-67.4757, -20.9473,  -4.9921, 129.9110, -19.1829, -40.2834,  -4.0376,\n",
      "           64.3684],\n",
      "         [-24.9442, -12.1996,  49.5647, -76.8753,  25.9520,  46.5740,  41.9777,\n",
      "           -4.1489],\n",
      "         [ 11.2325,   0.7855,  67.6754, -52.1079, -62.3128,  -5.9249, -44.3514,\n",
      "          -26.2252],\n",
      "         [-31.5952,  53.8375,  -4.3222,  -7.2264,  25.8921, -12.5305,  46.2018,\n",
      "           -8.3836],\n",
      "         [ 35.5096, -27.4710,  31.3627,  30.5334,  16.0650,  38.8467, -11.7829,\n",
      "          -39.3661]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.5678,  0.2095,  0.0151,  ...,  0.0431,  0.0973,  0.2574],\n",
      "        [-0.1373, -0.1951,  0.1337,  ...,  0.0973, -0.2582, -0.6472],\n",
      "        [-0.3161, -0.3156, -0.1935,  ..., -0.4164,  0.3666, -0.3533],\n",
      "        ...,\n",
      "        [ 0.3493, -0.0394, -0.3005,  ..., -0.2478, -0.3026,  0.2497],\n",
      "        [ 0.1474,  0.1056, -0.1913,  ..., -0.3812,  0.2706, -0.2790],\n",
      "        [-0.4111, -0.6934, -0.5222,  ...,  0.3207,  0.1208, -0.2421]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[   2.4042,  -32.6330,  -22.8411,  -15.7089,   40.9582,    0.6563,\n",
      "           -14.4234,   76.9985],\n",
      "         [ -72.5097,  -47.0165,   61.4653,  -29.0775,   26.8402,  -70.6833,\n",
      "           -33.9661,    6.8640],\n",
      "         [  42.9899,   20.0893,  -16.8744,    4.3134,   10.9461,  -54.0446,\n",
      "            38.6892,   -5.2465],\n",
      "         [ -14.8349, -108.2574,   -7.9374,   45.7885,  -19.1858,  -10.4439,\n",
      "            89.7544,   38.1104],\n",
      "         [ -10.7304,   23.8072,    6.8385,   24.5429,   48.5455,  -71.0268,\n",
      "            -6.7482,   -4.0249],\n",
      "         [ -18.2358,   49.9717,  -32.2798,   34.9375,  -11.7939,   52.8623,\n",
      "           -38.7396,   25.4791],\n",
      "         [ -75.4246,   -2.9515,   51.3210,  -13.8203,  -24.0646,   20.4039,\n",
      "            71.9631,  -46.1134],\n",
      "         [ -60.2826,   28.7936,   -4.9421,   23.3504,  -85.9124,   -5.8892,\n",
      "           -24.0442,  -78.8853],\n",
      "         [ -21.5188, -119.1462,   27.7409,  -73.1854,  -25.6005,   17.8212,\n",
      "            33.4274,  -11.4239],\n",
      "         [  -3.3115,  -55.4559,   73.1392,    7.5602,  -22.4838,  -44.0648,\n",
      "            66.8091,  -35.5002],\n",
      "         [  91.2238,  -17.6980,  -94.6254,  -22.6762,  -53.2502,  -50.0810,\n",
      "           -36.5892,   52.3171],\n",
      "         [ -34.1557,  -38.3004, -117.2828,  -11.0614,  -96.2311,  -27.9839,\n",
      "             0.8058,   51.0530],\n",
      "         [  16.4773,  -33.8462,    0.3174,   56.4137,   68.6986,  -33.3669,\n",
      "           -13.7520,   35.9198],\n",
      "         [ -38.3405,   32.8481,   54.2907,    9.7705,  103.3475,   17.1133,\n",
      "            55.6615,  -35.7257]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear(in_features=14336, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=14336, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[-0.2592,  0.0846,  0.0338,  ..., -0.5088, -0.0951, -0.2433],\n",
      "        [ 0.1747, -0.1648, -0.1983,  ..., -0.1705,  0.2254,  0.3656],\n",
      "        [ 0.0312, -0.1159, -0.0687,  ..., -0.0598,  0.0177, -0.3234],\n",
      "        ...,\n",
      "        [-0.1378,  0.3726, -0.1285,  ..., -0.2802,  0.0391, -0.2919],\n",
      "        [-0.6204,  0.7179,  0.2875,  ...,  0.1936, -0.2748,  0.1952],\n",
      "        [ 0.3360, -0.5227,  0.2827,  ...,  0.2555,  0.9120,  0.5731]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[  9.0169, -18.3521,  11.0180, -18.1918, -10.0999,  19.4634,   7.9906,\n",
      "           -5.1519],\n",
      "         [ 33.5396,  14.1238, -20.9218, -16.4948, -41.6263,  -5.3684,  -1.1931,\n",
      "           21.0850],\n",
      "         [-10.7479,  11.8423,  32.2282,  -3.6890,   7.4677,  -6.7277,  29.7999,\n",
      "           -1.2630],\n",
      "         [ 56.3932,  -7.6373,  10.9917,  18.6740,  33.1622, -41.1117, -36.5898,\n",
      "          -23.2141],\n",
      "         [-11.3953,   8.2183,  25.7809,  22.8589,   5.3921,  27.4533,  11.9580,\n",
      "          -17.8117],\n",
      "         [  2.3637, -11.0447,  39.0646, -18.8145,  18.9417,  -2.6950,  15.5724,\n",
      "          -14.4399],\n",
      "         [ 12.8177, -17.4462,   3.8080,  -8.3111,   1.8381,  -7.3552,  14.8939,\n",
      "           12.9684],\n",
      "         [  6.0238,  -9.6470,  -2.3730,  22.8339,  -7.6134,  35.7031,  -8.2647,\n",
      "          -15.4254],\n",
      "         [-19.1826,  -2.4976,  25.0276, -16.8649, -21.4946, -17.5293,  -8.4437,\n",
      "           -7.9723],\n",
      "         [ 10.0553,  23.0363,  26.2565,  22.6752, -15.6328,  37.5986,   7.2214,\n",
      "           12.1718],\n",
      "         [ 16.5113,  -2.9540,  11.0594,   2.0681,  -7.0285,  -7.5728,   7.1514,\n",
      "          -16.2685],\n",
      "         [-13.0749, -17.6197,  20.2584,  18.2705,  -5.2591, -24.1625,  26.9405,\n",
      "           -6.0692],\n",
      "         [-27.5786,   9.8021, -11.0920, -16.7781,  20.2476, -24.1918,  -5.4599,\n",
      "          -22.0523],\n",
      "         [ 26.7410, -18.9699,   4.9955,  42.1716, -14.5372, -23.8530, -22.0810,\n",
      "           21.5572]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.1726, -0.6176,  0.4616,  ...,  0.6472,  0.6748, -0.5440],\n",
      "        [ 0.0785,  0.0929, -0.6016,  ..., -0.3850, -0.3034, -0.2159],\n",
      "        [-0.4757,  0.8369,  0.4107,  ...,  0.0417,  0.7472,  0.0264],\n",
      "        ...,\n",
      "        [ 0.6410,  0.5347, -0.0031,  ..., -0.1566, -0.0308,  0.1748],\n",
      "        [-0.3600,  0.3625, -0.8547,  ...,  0.0516,  0.4265, -0.3605],\n",
      "        [ 0.0407,  0.3348, -0.2069,  ..., -0.3919, -0.0544, -0.1525]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[-47.6608,  -3.0979, -13.3617,  -7.8429,  18.5291,   3.9883,  12.2108,\n",
      "           -7.1080],\n",
      "         [-16.2897,   9.8906, -15.1894,   2.8987, -23.9124,  34.9904, -35.8820,\n",
      "           11.2540],\n",
      "         [ -9.6922,  -8.1344,  30.7089, -16.4565,  -1.2165, -15.9443, -46.7559,\n",
      "            0.6736],\n",
      "         [-11.4016,  25.5979,   0.1378, -15.7934,   1.7958,   0.5697, -16.6728,\n",
      "           10.1373],\n",
      "         [  3.1131, -24.6767,  53.7519, -16.4624, -25.6163,  -6.4961,  37.0556,\n",
      "           22.4721],\n",
      "         [ 27.9021,  33.6605,  -6.9458,  28.0176, -21.9557,  13.7728,   4.0759,\n",
      "           24.1891],\n",
      "         [ 35.3964,  11.5041,  18.0384,  13.6282,  15.4121,  -3.3079,  35.6268,\n",
      "           25.1893],\n",
      "         [-23.2143,   9.6513,   4.5602,  37.8148,  -6.6570, -23.2462, -13.7373,\n",
      "           -7.9068],\n",
      "         [ -8.5914, -30.1675, -46.8561, -26.7170, -42.1571, -45.7405, -10.5027,\n",
      "           20.8856],\n",
      "         [ 22.3158, -35.0020, -15.6361,  12.5836, -10.3533,  -0.6850,  -2.4661,\n",
      "            1.0506],\n",
      "         [ 26.1124,  -4.1730,  21.4646, -10.2117,  -4.5949,   7.2904, -17.2795,\n",
      "           22.6990],\n",
      "         [ 22.3734,   2.0251,  44.4150,  -8.2271,  -5.3661,  12.3252, -23.1708,\n",
      "            3.3149],\n",
      "         [ 37.5908,  24.0394, -26.8010,  -2.3827, -12.5314,  28.8053, -31.6429,\n",
      "           22.6316],\n",
      "         [ -5.6394,  49.6587, -14.4782, -16.5823,   1.4476, -14.3454, -19.5890,\n",
      "          -22.4630]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[-0.3798, -0.0414, -0.0554,  ...,  0.3816, -0.4300,  0.1074],\n",
      "        [ 0.2676,  0.5419,  0.2708,  ..., -0.1942, -0.7450, -0.0255],\n",
      "        [ 0.1127,  0.1256, -0.1755,  ...,  0.0715,  0.4330, -0.1809],\n",
      "        ...,\n",
      "        [-0.1089, -0.2423, -0.1935,  ..., -0.0666,  0.8752, -0.2699],\n",
      "        [ 0.1958, -0.0453, -0.2973,  ..., -0.1263,  0.0136,  0.1812],\n",
      "        [-0.3837,  0.2339, -0.3006,  ...,  0.2533,  0.1454, -0.3684]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[  2.7136,  -7.0713, -14.2508,  10.1014,  -9.0041,   7.0346,   8.9800,\n",
      "           19.6997],\n",
      "         [-23.7751,  -3.7861,  11.7435,   7.0045, -14.9187,   9.7736,   1.6562,\n",
      "           -3.9844],\n",
      "         [-12.7748, -14.6588,  -7.3472,   3.5673,  -9.9493,  16.1965,   2.6954,\n",
      "           12.9772],\n",
      "         [  4.6329,  -3.5819,  -7.0426,  17.2670,   8.1923, -11.9121, -12.2864,\n",
      "            9.8155],\n",
      "         [ -0.1637,  11.3718,  16.9900,   0.1689,   0.7183,   9.0323,   4.0500,\n",
      "          -10.2009],\n",
      "         [ -9.9603,  15.5369, -25.7190,  19.4590,   3.5324,  -7.0078,  21.7015,\n",
      "           -3.9793],\n",
      "         [ 16.1130,  10.2326, -13.4293,  -2.2602,  -0.2373,  -2.9277,  -8.7691,\n",
      "            3.3353],\n",
      "         [  3.5644,   4.9131,  10.5151,  -6.0723,   6.0856,   3.8226,  -7.6084,\n",
      "            6.3946],\n",
      "         [  6.6336, -10.4933,  -0.7457,  20.5324,  18.7542, -13.5921, -10.2414,\n",
      "           -2.1930],\n",
      "         [ -9.0363,  16.6275,   3.4290,   1.3634,  15.1442,   7.7282,  14.3415,\n",
      "            8.8394],\n",
      "         [  8.5641,  15.2229,  20.7429,  -0.7570,  -2.7341,  -9.8181,  -2.9164,\n",
      "           21.4031],\n",
      "         [ -7.4477,   7.2554,  -7.0263, -10.7170,  -9.9671,  -6.3036,  14.4164,\n",
      "            1.5549],\n",
      "         [ 18.4419,  14.6458, -15.1330,  11.3407,  16.2772,  -7.2704,  14.3780,\n",
      "           18.7263],\n",
      "         [ -6.7414,  -2.0934,  -6.6106,  -4.3190,  -9.0449,   1.0176,   4.5238,\n",
      "            6.3707]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[-0.3443, -0.1945, -0.0892,  ...,  0.2549,  0.0013,  0.1292],\n",
      "        [-0.2315,  0.0822, -0.1276,  ...,  0.3042,  0.1821, -0.0992],\n",
      "        [ 0.2242, -0.2681, -0.0325,  ..., -0.0927, -0.0126, -0.2682],\n",
      "        ...,\n",
      "        [ 0.1960, -0.3800,  0.2186,  ...,  0.2731,  0.0576,  0.3455],\n",
      "        [ 0.0757, -0.1563, -0.2984,  ...,  0.0700, -0.0115,  0.0999],\n",
      "        [ 0.2821,  0.4257, -0.4085,  ..., -0.0666, -0.0999, -0.3530]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[-13.2838,  12.2287,   6.2761,   1.9063,  14.0709, -38.8084,   0.4969,\n",
      "            0.1916],\n",
      "         [ -5.3503,  -9.9184, -16.0647, -11.7854, -14.7518,  -1.9602,  23.7084,\n",
      "          -10.0888],\n",
      "         [  7.2078,   5.4390,  -8.6516, -13.7676, -12.8301,  -7.2596,   5.4254,\n",
      "           10.4044],\n",
      "         [-16.7742,  11.1372,   4.2324,   2.2234,  -1.0988,  15.7786,  17.1779,\n",
      "           -2.1095],\n",
      "         [ -7.5195,  23.1514,  -8.4977,   7.8400,   6.8563,  20.1641,  13.9902,\n",
      "           -6.8939],\n",
      "         [ -5.6612,   5.3470,  16.3836,   9.1793,   3.3465,   0.3635, -17.3580,\n",
      "           36.0291],\n",
      "         [ -2.5633,  15.3965,   6.7819,  -2.3063,  11.8698, -15.0648,  -1.0168,\n",
      "          -14.1739],\n",
      "         [ -2.1136,  11.8273,  15.7762, -11.8874,  13.3893,   0.1698,   1.0987,\n",
      "            3.1537],\n",
      "         [ 10.1067,   8.0881,   0.6112,  13.8451, -10.2260,   7.3976, -24.0965,\n",
      "           -5.1448],\n",
      "         [  9.6101,  -2.8186, -12.6053,   7.9861,  17.9411,  -4.2023,   7.7403,\n",
      "           -1.4874],\n",
      "         [  0.7207,  17.2894,   0.5627,  11.4696,  -7.7958,   1.6699, -21.4307,\n",
      "            8.5353],\n",
      "         [ 13.6631,   1.1359, -11.8922,   7.3001,   1.2468,  24.3329, -14.0064,\n",
      "           -4.1055],\n",
      "         [ -6.8810, -11.5603,  20.5362, -12.2498, -19.2127,   2.7600,  -5.2807,\n",
      "            7.3454],\n",
      "         [ -7.3748,   1.7486,  -0.9521,  11.2530,  -4.2038,   1.1910,   8.2640,\n",
      "           15.0667]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[-0.5928,  0.0376,  0.0988,  ..., -0.0322,  0.0795, -0.3344],\n",
      "        [ 0.0286, -0.0434, -0.0146,  ...,  0.0483, -0.7599, -0.4963],\n",
      "        [ 0.1863,  0.3187, -0.4603,  ..., -0.3014,  0.5967,  0.1911],\n",
      "        ...,\n",
      "        [ 0.0036,  0.1642, -0.2553,  ..., -0.0706, -0.2788, -0.2883],\n",
      "        [ 0.0439,  0.2031,  0.1858,  ...,  0.1606,  0.4666,  0.5111],\n",
      "        [ 0.1249,  0.3850,  0.2022,  ...,  0.6900, -0.1104,  0.6538]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[  3.8140, -11.1217,  23.7643, -64.3685, -31.4539,  31.7431,  38.4867,\n",
      "           -7.3087],\n",
      "         [ 11.6692,  -9.0611, -64.3179,  -1.2752, -36.2677,  41.5461,   1.6570,\n",
      "           33.9732],\n",
      "         [ 66.2742,   1.8295,  14.6427,  16.0748,   1.9860,  25.9680, -49.8758,\n",
      "           32.2625],\n",
      "         [  8.4187,  28.5471,   2.4009, -31.5607, -48.3978,  20.3873,  -6.3643,\n",
      "           17.6582],\n",
      "         [-37.8576, -25.5623,  10.8979,   8.5079,  10.0502,  -3.3311,  11.4272,\n",
      "          -35.5595],\n",
      "         [ 10.5063,  -0.2418,  -3.6549,  10.2415,  22.3613, -18.2379, -74.7504,\n",
      "           16.9106],\n",
      "         [ -1.7368,  41.3597,  -5.9597,  -7.8504, -47.6684, -29.0979, -11.6757,\n",
      "            3.5959],\n",
      "         [  8.0678, -10.8260,   8.4085, -36.0689,  35.7798, -11.9769, -34.5707,\n",
      "           35.7842],\n",
      "         [-14.6380,  31.7702,  -2.5073, -35.1821,  13.4213, -52.2577,  15.1175,\n",
      "           11.7985],\n",
      "         [ -8.5774,  52.8312,  -6.7924,  16.5176,  16.9373, -17.2185,  30.2217,\n",
      "           24.4386],\n",
      "         [ 26.4337,  35.7111,   6.6289,  33.6094, -20.3757,  14.2175, -14.7184,\n",
      "            5.5862],\n",
      "         [ -2.0081, -28.7285,  17.9137, -14.5501,   4.2321,  -1.1651, -16.6794,\n",
      "           -3.2573],\n",
      "         [ 38.2417,  19.3339, -13.3952, -41.1627, -23.0168,  35.4120, -13.5562,\n",
      "          -14.4712],\n",
      "         [ 14.9302, -18.1488,  39.4231,  -1.9157,  15.7067,  15.4410, -13.4166,\n",
      "            6.0645]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[-0.1703,  0.3650,  0.5714,  ..., -0.5066, -0.2768, -0.3925],\n",
      "        [ 0.2973,  0.1292,  0.1920,  ..., -0.0329, -0.5195, -0.2200],\n",
      "        [ 0.0756,  0.2317, -0.0300,  ..., -0.2889,  0.2076, -0.1744],\n",
      "        ...,\n",
      "        [-0.2914,  0.2917, -0.7474,  ..., -0.0913, -0.6017, -0.3888],\n",
      "        [ 0.0518, -0.0371,  0.1564,  ...,  0.9487,  0.0956, -0.1117],\n",
      "        [ 0.5080,  0.5743, -0.6108,  ...,  0.2945, -0.3993, -0.1038]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[-72.3242, -28.1589,  39.5968,  31.6775,  41.5250,  22.5013,  40.1333,\n",
      "          -19.7643],\n",
      "         [  4.7268, -24.5455, -55.5198, -53.7550, -19.1723,  37.3377,   2.9745,\n",
      "           61.0219],\n",
      "         [ -3.2517,  28.5790, -36.3003,  23.3764, -53.2059,  60.3955,  41.9318,\n",
      "          -23.6153],\n",
      "         [ 19.7051,  -1.1261, -11.1656, -42.7446,   0.3832, -58.7111,  63.4440,\n",
      "           34.7771],\n",
      "         [-10.3011, -67.0127, -70.8834,  18.6777, -38.1605,  46.1316, -48.0048,\n",
      "          -55.3714],\n",
      "         [-15.9736,  52.8608,   0.1939,  36.9337,  21.4274,   1.7758,  23.9830,\n",
      "           10.7921],\n",
      "         [  2.6071,  -9.4740,  -5.9821, -46.8593,  39.8389, -50.9921, -20.4498,\n",
      "            3.0289],\n",
      "         [-25.8927, -90.7542,   7.0842, -70.5446,  -4.3026,  -1.3576, -10.5578,\n",
      "           22.8896],\n",
      "         [ 14.0320,   1.7200,  50.8661, -20.9197,  57.5649, -42.0087,   9.5078,\n",
      "           88.0846],\n",
      "         [-43.4301, -82.9650,  60.9644, -25.6085, -75.9802,  14.3182,  -2.8917,\n",
      "           -1.2659],\n",
      "         [-69.2169,  20.8670,  58.4374,  72.9135, 107.3644,  -7.3515,  -5.6652,\n",
      "           73.5786],\n",
      "         [ -8.6946,   2.6144, -49.8893, -93.9833, -21.7689,  36.1568,  39.7721,\n",
      "          -34.3148],\n",
      "         [ 54.0570,   8.4436,  10.5271, -32.8930,  11.1623,   5.8109, -39.2663,\n",
      "            7.4070],\n",
      "         [-85.5211,  30.1586,   4.5274, -14.8317,  23.2854, -60.2746, -23.8167,\n",
      "          -59.5360]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.3192, -0.3487, -0.2866,  ...,  0.0187, -0.4214, -0.3092],\n",
      "        [-0.0247, -0.3892, -0.1456,  ..., -0.0658,  0.0091,  0.2267],\n",
      "        [ 0.1390, -0.1940, -0.1505,  ...,  0.2979,  0.2927,  0.4653],\n",
      "        ...,\n",
      "        [-0.4036,  0.2331, -0.4468,  ...,  0.2004,  0.1905, -0.1247],\n",
      "        [ 0.3696,  0.6630, -0.0960,  ...,  0.0994,  0.0145, -0.2640],\n",
      "        [-0.3661, -0.3656, -0.0438,  ..., -0.1368,  0.0691,  0.0071]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[-36.3766, -98.9534, -13.4569, -75.3585,  25.1685, -15.9122, -11.2799,\n",
      "           35.8558],\n",
      "         [-33.5350,  -2.9679, -15.0926, -32.5810, -22.4450, -16.5659,  80.2444,\n",
      "          -31.6491],\n",
      "         [-22.5878, -31.1126,  60.1474,  34.3240, -51.5574,  33.3681, -32.2640,\n",
      "            5.7614],\n",
      "         [-88.6225, -14.8732, -55.6670,  -8.3969,  29.0840,  -4.8749,   6.6551,\n",
      "           31.3749],\n",
      "         [-63.2276,  21.2935,  13.0953, -14.4611,  34.3294, -32.5600,  19.7953,\n",
      "          -41.1861],\n",
      "         [-21.9012, -64.1718,  37.8311,  25.7871,  38.5340, -14.9801, -14.6703,\n",
      "           21.8513],\n",
      "         [-36.3431, -19.0342,  93.8684, -32.1581, -21.3893,  23.0373,   0.2297,\n",
      "          -41.4047],\n",
      "         [-59.9027, -59.9011, -39.7127,  39.4377,  22.9868, -38.3132,  38.1630,\n",
      "           25.0869],\n",
      "         [ 17.5393,  -0.1745,   4.1279, -36.0837, -14.3295,  -3.2113,  -5.1519,\n",
      "           -5.6006],\n",
      "         [ 29.3653,  -9.8864, -13.4603, -20.8023, -45.6317,  -2.2076, -57.1170,\n",
      "          -22.4284],\n",
      "         [-89.0062, -17.2061,  11.6441,  19.9403,  -4.5374,  -4.0598,  -1.2979,\n",
      "           42.0318],\n",
      "         [  4.6778, -15.2866,  20.5507, -15.8930, -55.6856,   5.0971,  95.3240,\n",
      "           29.0411],\n",
      "         [-33.2150,  36.5905, -61.5730,  40.9750,   1.6516, -30.6301, -25.2939,\n",
      "          -16.2367],\n",
      "         [  0.5752, -38.3559, -70.7798, -48.0019, -22.8348,  51.7560,  -9.2213,\n",
      "          103.7879]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=14336, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[-0.3884, -0.1657,  0.0225,  ..., -0.0999,  0.2774, -0.2833],\n",
      "        [-0.0912,  0.0668, -0.3520,  ...,  0.0549,  0.0217,  0.0869],\n",
      "        [-0.0908,  0.5704,  0.6416,  ...,  0.1090, -0.3679,  0.9390],\n",
      "        ...,\n",
      "        [ 0.0685,  0.2660,  0.1016,  ..., -0.0366,  0.4724,  0.8363],\n",
      "        [-0.0076, -0.5430, -0.4581,  ...,  0.5171,  0.4768,  0.1063],\n",
      "        [-0.2329,  0.0541,  0.1456,  ..., -0.3110, -0.3003, -0.0613]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[  8.4697, -48.7408,  -8.2764,  15.1595,  -3.3434,  26.9973,   1.7781,\n",
      "           15.8671],\n",
      "         [-25.5318, -47.5769, -11.9303,  10.2662, -39.6576,  10.7619,  -0.2996,\n",
      "           50.5170],\n",
      "         [ 23.5023,  -4.5611, -17.9897,  29.2488,  25.5799,  44.6280,  46.8758,\n",
      "           -8.1191],\n",
      "         [-21.0680,  25.4633, -50.2804,   5.5550, -30.9449,   4.8550, -29.5249,\n",
      "            2.6648],\n",
      "         [ -0.1202,  43.9714,   3.6858,  -2.8345, -49.4542, -38.7073,  38.2690,\n",
      "           -0.1993],\n",
      "         [ 17.7044,  20.1289,  -6.5161,  19.9013,   5.9172,  -5.2033, -15.7646,\n",
      "          -12.7608],\n",
      "         [ 17.7148,  13.6252,  15.8047, -22.0347,   9.6974,  19.1182,  30.5945,\n",
      "           29.1515],\n",
      "         [-16.6202,   4.0488,  -3.4030, -29.5535,  34.3052, -21.1866,  17.2476,\n",
      "          -25.0492],\n",
      "         [ 13.1726,  -1.5963,  16.0551,  21.4006, -35.2957,   0.6574,  24.9728,\n",
      "          -65.8896],\n",
      "         [  1.1030,  10.6465,   2.3407,   1.6848, -20.1767,  -2.5789,   3.7869,\n",
      "          -15.9416],\n",
      "         [ -0.5080,  -2.0896, -15.5245,  -7.1299,  44.1290, -11.6694, -20.7488,\n",
      "          -36.7950],\n",
      "         [-17.6434,  32.7224,   3.2000,  -3.5043, -17.5021, -19.3863,  19.1738,\n",
      "          -28.1092],\n",
      "         [ -7.3342,  24.6355,  11.2326,  25.1462,  -2.6441, -18.0686, -41.9445,\n",
      "           16.7336],\n",
      "         [ 22.1134, -17.8804,  30.2964,  -7.7478,  -6.0857, -48.3086,  -2.0540,\n",
      "          -33.6457]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[-0.0690, -0.3035,  0.0824,  ..., -0.3689, -0.2414, -0.1486],\n",
      "        [ 0.1945,  0.4829, -0.2245,  ...,  0.0663,  0.1271,  0.4826],\n",
      "        [-0.0256,  0.1239,  0.0284,  ..., -0.0145,  0.0883, -0.1230],\n",
      "        ...,\n",
      "        [ 0.2272, -0.0261,  0.0379,  ...,  0.6786,  0.4878, -0.4947],\n",
      "        [ 0.1969, -0.2100,  0.3033,  ...,  0.1283,  0.4554,  0.0407],\n",
      "        [-0.0231,  0.1588,  0.3225,  ...,  0.5011, -0.7538, -0.1515]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[-13.7824, -15.4993,  17.7979,  -9.5551,  -0.7115, -10.7985,   2.0595,\n",
      "          -12.3330],\n",
      "         [ 19.1521,  16.0267,   7.1088,  17.4211, -44.9747, -15.4819,   2.8503,\n",
      "           24.0530],\n",
      "         [  2.3211,  -2.5741, -40.3462,  16.5061, -18.7036, -27.1241,  19.3273,\n",
      "           30.3527],\n",
      "         [ 20.7169,  18.8771,  -8.0047, -27.0963,  11.5934, -52.1684,  31.3317,\n",
      "           11.2954],\n",
      "         [-62.8668,  42.3693,   5.5863,  10.6913,  23.1640,  21.7523,  10.0128,\n",
      "           26.1950],\n",
      "         [-23.5217,  39.1693,  -9.7012, -15.4888,  42.9080, -19.1407, -59.1428,\n",
      "            9.3882],\n",
      "         [-49.6919, -29.1905, -12.4855, -33.6113, -14.6940, -41.5081, -33.0321,\n",
      "            3.9205],\n",
      "         [ -8.2645, -17.0790,  12.2502, -14.4191,  23.0112,  14.0365, -10.7552,\n",
      "           -4.8154],\n",
      "         [-19.6085,   2.4981,  18.3132, -13.8492,  40.9005,  -4.8514,   7.1369,\n",
      "           27.1070],\n",
      "         [-11.3321, -19.7092,  -6.3619, -19.6049,  12.9893, -14.2182, -34.5351,\n",
      "          -10.4977],\n",
      "         [-26.5657,  20.8327,   5.2131, -27.0158,  10.4650,   6.6815,  -0.4865,\n",
      "           24.4968],\n",
      "         [  2.4296,  13.1542,   0.0696,  -9.8227,   0.8652,  -3.2957, -13.7346,\n",
      "           19.3448],\n",
      "         [-15.3022,   4.4800, -15.9565,   9.9048,   1.1554,  50.3878,  36.3754,\n",
      "          -21.7606],\n",
      "         [ 25.2389, -10.7459, -29.2120,  -0.7200,  12.9353, -18.9399, -19.2650,\n",
      "           -3.0965]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[-0.1398, -0.4762,  0.3448,  ..., -0.0385, -0.3011, -0.2175],\n",
      "        [-0.1983,  0.2814,  0.5806,  ...,  0.6371,  0.0453,  0.0064],\n",
      "        [ 0.4742,  0.1923, -0.1864,  ..., -0.1569,  0.1049, -0.0214],\n",
      "        ...,\n",
      "        [ 0.1732,  0.0883,  0.4620,  ...,  0.3844, -0.3125,  0.5389],\n",
      "        [ 0.0630,  0.5635,  0.0117,  ..., -0.0093,  0.2504, -0.0555],\n",
      "        [ 0.3362, -0.2068,  0.0867,  ..., -0.3399, -0.0671,  0.3322]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[ 1.8776e+01,  1.0328e+01, -3.1428e+00, -3.1387e+00, -6.6948e+00,\n",
      "          -7.9375e+00, -1.3228e+01,  4.9640e+00],\n",
      "         [-5.8779e+00, -3.4844e+00,  1.3809e+01,  2.1513e+01, -4.3271e+00,\n",
      "           3.0293e+00, -1.9955e+01,  7.9396e+00],\n",
      "         [-6.8169e+00,  4.4568e+00,  3.1787e+00, -1.1692e+01,  2.4331e-01,\n",
      "          -5.4480e+00,  3.2521e+00,  1.2897e+00],\n",
      "         [-5.9729e+00, -2.1724e+01, -3.3218e+00,  1.6876e+00, -1.5587e+00,\n",
      "          -3.9564e+00, -1.4901e+01, -2.1943e+01],\n",
      "         [-1.7073e+01,  3.9218e+00,  1.6438e+01, -5.6894e+00,  8.2117e+00,\n",
      "           1.1212e+01, -6.3400e+00,  1.4238e+01],\n",
      "         [-2.0923e+01, -4.1812e+00,  1.2819e+01, -4.4147e-01,  3.8569e+00,\n",
      "           1.0158e+01, -5.2673e+00,  1.1491e+01],\n",
      "         [-1.9577e+01, -5.8555e+00,  4.6029e+00, -3.7940e+00, -2.0667e+00,\n",
      "           6.7860e+00, -1.2336e+01,  1.6674e+01],\n",
      "         [-6.7045e+00, -3.2355e+00, -5.5186e+00, -1.6360e+00,  8.8971e+00,\n",
      "          -4.9600e+00,  9.1807e+00,  1.0420e+01],\n",
      "         [ 1.2304e+01, -1.0025e+01,  1.1398e+01,  2.8389e+00,  1.4414e+01,\n",
      "           1.2022e+01,  1.0275e+00, -6.3983e+00],\n",
      "         [-8.8766e+00, -1.5259e+01,  1.0987e+01, -1.6411e+01, -9.0715e-01,\n",
      "           1.0299e+01, -5.4068e+00,  1.3330e+01],\n",
      "         [-6.2473e+00,  4.9628e+00,  1.7521e+01,  1.1568e+01, -1.3693e+01,\n",
      "           6.6024e+00,  5.4686e+00,  1.4838e+01],\n",
      "         [ 2.8346e+00, -1.4176e+01,  3.6025e+00,  1.2297e+01, -4.6585e+00,\n",
      "           2.8136e+01,  9.5435e+00, -9.3639e+00],\n",
      "         [-1.1771e+01,  1.3430e+01, -8.4455e+00, -4.5173e+00,  4.0288e+00,\n",
      "           1.0726e+01,  3.5970e+01,  5.9151e+00],\n",
      "         [-2.6430e+01, -5.3036e+00, -3.5861e-01,  1.5627e+01,  2.6502e+00,\n",
      "           2.6435e-02,  1.8831e+01,  1.4877e+01]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[-0.0435,  0.2213,  0.0455,  ..., -0.0104,  0.6099, -0.2086],\n",
      "        [-0.2486, -0.1695, -0.1450,  ..., -0.3921,  0.0319, -0.0587],\n",
      "        [ 0.2167,  0.5668, -0.7639,  ...,  0.3658,  0.1048, -0.0950],\n",
      "        ...,\n",
      "        [-0.8030, -0.3253, -0.3913,  ...,  0.5849,  0.3185, -0.1750],\n",
      "        [-0.2501, -0.1585, -0.4085,  ...,  0.4741,  0.3672, -0.4294],\n",
      "        [-0.0140, -0.1923, -0.2552,  ...,  0.3501,  0.5040, -0.0209]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[ 16.9595, -20.1423,   9.0637,  -1.8818,  12.6152,  -4.5142,  -7.5080,\n",
      "          -20.0109],\n",
      "         [ 19.3206,  11.6932,   2.3212,  -1.4110, -17.2428,   1.7196,  -9.3223,\n",
      "           -5.8649],\n",
      "         [ -2.0953,   3.2000,   5.1692,  15.9947, -10.4185,  10.0577,   1.8554,\n",
      "           -6.7396],\n",
      "         [-30.9543, -10.8683, -20.3785,  -7.9612, -14.4202,  12.2528,   7.2631,\n",
      "           10.1581],\n",
      "         [-14.2066,  19.1503,  -3.5453, -12.1886,  -2.2625,  18.4654,  -7.1941,\n",
      "            4.3053],\n",
      "         [ -6.8961,  -2.9457,   4.9270,   9.6564,  25.3612,  -1.1982,  -0.2803,\n",
      "          -15.1328],\n",
      "         [-12.1183, -17.1632, -11.9657,  24.7502,   9.4766,  -2.3050,  10.6456,\n",
      "            5.3533],\n",
      "         [ -3.8546,  16.8653,  -1.6525,   8.4675,   0.6650,   3.5746,  -8.2886,\n",
      "            4.9622],\n",
      "         [  3.8798,  -9.6676,  -1.3225,  14.6607,   7.1191,  -8.8865,  12.8230,\n",
      "           -3.4955],\n",
      "         [  0.5848,   8.6523,  -6.9710,  11.2469,  -6.8601,  -4.4949,  12.0286,\n",
      "            9.7910],\n",
      "         [  8.0408,   4.6355,   9.0076,   4.7316,  12.2897, -26.3906,   7.7828,\n",
      "           19.3234],\n",
      "         [ 10.9938,   1.7898,   2.8542,  -4.2199, -20.0815,   0.9928, -17.8831,\n",
      "            2.0790],\n",
      "         [-25.7485,   4.6203,   6.8353,  -7.1409, -17.5416,   5.3358,   5.5471,\n",
      "            6.1850],\n",
      "         [-22.4439,  -0.5705, -18.1139,  -6.4944,   6.6907, -13.7304, -13.6799,\n",
      "          -23.8410]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 5.2402e-01,  4.2918e-01, -3.8148e-01,  ..., -1.4299e-01,\n",
      "          2.3112e-01,  3.6651e-01],\n",
      "        [ 1.3884e-01,  2.6653e-02, -4.4231e-01,  ...,  7.0437e-02,\n",
      "         -1.4541e-01,  3.9013e-01],\n",
      "        [ 3.2771e-01, -2.8340e-01, -3.1221e-01,  ..., -9.4111e-02,\n",
      "          3.8811e-01, -2.6125e-01],\n",
      "        ...,\n",
      "        [ 6.2471e-01, -2.1788e-01, -4.9227e-01,  ..., -4.2045e-01,\n",
      "         -1.7979e-01,  4.0378e-02],\n",
      "        [ 8.6961e-03,  2.9896e-01,  1.5720e-01,  ..., -1.3351e-01,\n",
      "          3.6175e-01, -5.5130e-04],\n",
      "        [ 1.0456e-01, -2.7474e-01, -7.5763e-02,  ..., -3.4530e-01,\n",
      "         -2.7793e-02,  1.0163e-01]], device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[ -4.2001,   2.4956,  -6.8224, -10.2138,  24.8679,  14.1493,   3.1703,\n",
      "          -17.7890],\n",
      "         [  0.8505,  51.9625, -45.9040,  22.3287, -12.8080,  20.7388,   8.6478,\n",
      "          -13.0405],\n",
      "         [-19.1252, -39.5862, -51.6881,  34.6897, -42.0069, -22.4588, -15.8419,\n",
      "           -2.2209],\n",
      "         [ 30.6057,  30.6458, -11.3426,  16.4051,  -4.2128,   2.2556, -50.8898,\n",
      "           -2.8523],\n",
      "         [ -0.5290,   1.7526, -25.4284,   8.4947, -17.0967,  23.4279,  10.8757,\n",
      "           17.6249],\n",
      "         [-35.1888,  25.3314,   5.2620,  28.4740,  26.4729,  -0.9123, -13.2815,\n",
      "           18.0425],\n",
      "         [  5.5668, -34.6560,  -5.6581, -27.4363,  12.2943,  -4.3870,  -7.5865,\n",
      "          -28.9414],\n",
      "         [-17.9922,   4.8289,  25.9884,  -1.3717,  -1.2524,  -2.8267, -13.7885,\n",
      "          -32.2420],\n",
      "         [ -3.2249,  28.0640,  15.3736,  11.2343,  11.6381,   6.9060,  48.2106,\n",
      "           33.6405],\n",
      "         [-36.0950,   3.9402,  27.6331,   8.7712, -19.6130,  -3.4770,   1.3723,\n",
      "            2.9810],\n",
      "         [ -7.1011, -56.9110,  17.5333,   9.6075, -27.4269, -34.3388, -18.5859,\n",
      "           21.2465],\n",
      "         [  7.2062, -26.1672, -46.7426,   7.1435,  -5.8821,  -0.7617, -23.5484,\n",
      "           10.1185],\n",
      "         [-45.0097, -13.4063,  14.2962, -30.9556,  16.2339,  10.4368,   8.0334,\n",
      "            8.6268],\n",
      "         [ 24.1404,   5.5829, -36.5190,  10.5064,   8.1724, -13.8469, -18.5277,\n",
      "          -27.2903]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.0325, -0.1892, -0.3350,  ..., -0.1540, -0.2558,  0.2242],\n",
      "        [ 0.5666,  0.0111,  0.0748,  ..., -0.5793, -0.3368,  0.3137],\n",
      "        [ 0.3728,  0.4268,  0.2316,  ...,  0.3858, -0.0813,  0.2964],\n",
      "        ...,\n",
      "        [-0.5034,  0.4641,  0.5536,  ...,  0.2651,  0.3833, -0.4462],\n",
      "        [-0.3079,  0.3140,  0.2310,  ...,  0.5158, -0.0439,  0.0479],\n",
      "        [-0.0686,  0.0158,  0.3454,  ...,  0.2512, -0.2234,  0.5107]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[ -43.7043,  -75.0504,  -22.9132,    2.0210,   50.2954,  -24.9409,\n",
      "            32.3649,  -26.4235],\n",
      "         [  26.1413,   -2.8499,  -42.9787,   26.7501,  -31.4834,   48.1783,\n",
      "            33.2115,   50.4450],\n",
      "         [ -15.0780,  -55.2382,   50.0744,  -55.7516,   -0.4548,   -9.2295,\n",
      "            16.2472,   -8.6137],\n",
      "         [-100.4918,  -27.9370,   20.5059,  -63.1514,   75.2399,    3.1755,\n",
      "           -76.5543,  -73.4423],\n",
      "         [ -16.5937,   40.8944,   99.5261,  -14.9419,   31.1822,   30.9427,\n",
      "             1.6578, -110.2645],\n",
      "         [  20.8108,   -2.9262,   25.8986,  -19.8409,   88.5454,   28.8622,\n",
      "            34.1074,   16.5630],\n",
      "         [  22.1412,   41.3565,   52.0780,  -12.8114,    0.3359,   68.9860,\n",
      "            74.5481,  -39.5837],\n",
      "         [ -21.6987,   76.3456,  -58.5021,  -36.7359,   35.6836,   -0.5446,\n",
      "            42.4759,    0.4827],\n",
      "         [-104.2314,  -52.0387,  -37.3849,  -18.0089,    7.8695,   17.7621,\n",
      "           -49.2606,    7.6580],\n",
      "         [   2.5602,    4.4667,   80.4671,  -13.9960,   -4.6066,   21.7359,\n",
      "             3.2196,  -18.5293],\n",
      "         [  57.4807,   10.6005,  -12.4832,  -18.1913,   25.7058,    1.1361,\n",
      "            -8.1802,   49.7048],\n",
      "         [  14.5014,  -12.5795,  -11.6351,    3.6255,   37.9276,  -12.0322,\n",
      "           -31.2578,  -45.2050],\n",
      "         [  -0.5990,   28.6540,  -19.1265,  -18.7299,   -5.1666,  -26.7929,\n",
      "            18.7977,   58.2580],\n",
      "         [ -42.3054,  -13.5859,   17.2178,   26.8819,   25.4369,   40.1923,\n",
      "            31.2294,  -60.5995]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[-0.1998, -0.1198,  0.0712,  ..., -0.1577,  0.3540,  0.1872],\n",
      "        [-0.3162,  0.0042, -0.0022,  ..., -0.5330,  0.5609, -0.2326],\n",
      "        [ 0.1952,  0.5965,  0.7363,  ..., -0.1588,  0.0282,  0.2941],\n",
      "        ...,\n",
      "        [-0.0276,  0.0695, -0.7978,  ...,  0.5858, -0.3432, -0.4657],\n",
      "        [ 0.0063,  0.3099, -0.2986,  ..., -0.2872,  0.0832, -0.0850],\n",
      "        [-0.2214, -0.2150,  0.4405,  ...,  0.1383,  0.1808,  0.1320]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[-1.0466e+01,  3.1392e+01,  3.4066e+01, -6.6286e+00,  4.5545e+01,\n",
      "           1.7741e+01, -6.4609e+01,  2.5781e+01],\n",
      "         [ 2.5465e+01, -1.0440e+01,  2.9618e+01, -5.9731e+01, -8.4053e+01,\n",
      "           5.3603e+01, -2.0091e+00, -6.2838e+01],\n",
      "         [ 1.7473e+01, -5.1697e+00,  6.8306e+01, -4.7961e+01, -8.6506e+00,\n",
      "          -4.2968e+01, -3.6972e+00,  4.5558e+01],\n",
      "         [-3.4565e+01, -2.7038e+01,  4.7565e+01,  3.8893e+01, -5.6244e+00,\n",
      "          -4.5179e+01,  9.0582e+00, -8.0303e+01],\n",
      "         [-1.1446e+02,  3.9678e+01, -4.9909e+01, -3.2599e+01, -8.9126e+01,\n",
      "          -1.0465e+01,  9.4151e+01,  2.3142e+01],\n",
      "         [ 8.2779e+00,  3.1148e+01,  1.4203e+00,  2.0961e+01,  2.8641e+01,\n",
      "           1.9307e+00, -1.9731e+01, -4.7857e+01],\n",
      "         [-2.2191e+01, -1.9658e+00, -2.9762e+01,  6.6795e+01, -1.7303e+01,\n",
      "           3.7548e+01,  5.8453e+01, -2.8671e+01],\n",
      "         [-3.0713e+01,  7.5287e+01, -1.6298e+01,  1.4754e+01, -2.7428e+01,\n",
      "          -1.0959e+01,  6.5877e+01, -8.8256e+01],\n",
      "         [ 5.9949e+01, -1.6366e+01, -1.4213e+00, -3.5584e+01,  8.0517e+01,\n",
      "           7.1585e+01, -3.0677e+01,  3.5300e+00],\n",
      "         [ 1.4914e+01,  1.1039e+01, -4.2909e+01,  7.7087e+01, -1.8529e+01,\n",
      "          -4.3312e+01,  5.3096e+01,  4.8125e+01],\n",
      "         [-2.0121e+01, -6.9853e-02,  4.2566e+01,  8.1933e+01, -5.9529e+01,\n",
      "          -5.5915e+01,  3.5657e+01, -2.6855e+01],\n",
      "         [ 6.0221e+01,  5.0992e+01, -4.3772e+01,  2.2118e+01,  1.7305e+01,\n",
      "          -1.0393e+02,  4.9864e+01, -4.0635e+01],\n",
      "         [-7.3281e+00,  8.6366e+00,  8.2497e+00, -1.5304e+00,  6.8899e+00,\n",
      "          -7.0072e+00, -7.1497e+01,  1.3037e+01],\n",
      "         [ 4.2364e+01, -2.0862e+01,  5.4622e+01,  3.1042e+01,  6.8141e+01,\n",
      "           7.6197e+01, -1.2104e+01,  5.5160e+01]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=14336, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.1470, -0.3989, -0.3286,  ..., -0.2653, -0.1181,  0.1744],\n",
      "        [ 0.1648, -0.5278,  0.2363,  ..., -0.0283,  0.1551,  0.1606],\n",
      "        [-0.4585, -0.1514, -0.0925,  ..., -0.0785,  0.6078,  0.0363],\n",
      "        ...,\n",
      "        [-0.4588,  0.1890,  0.1102,  ...,  0.6404, -0.3076,  0.1008],\n",
      "        [ 0.0866, -0.0490, -0.4692,  ...,  0.1781, -0.0937, -0.0372],\n",
      "        [ 0.2184, -0.4754, -0.3621,  ..., -0.1922, -0.5018,  0.1705]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[  4.4250, -41.9595,  31.0015, -12.0129, -10.9153, -23.9128, -19.3415,\n",
      "           39.4699],\n",
      "         [  2.5724, -43.9801,   0.5756,  -0.7416,   4.0406, -18.5220, -12.2830,\n",
      "            4.9592],\n",
      "         [ 31.3249,  32.3412,  42.9007,   0.4972, -17.4159,  14.2612,  21.0915,\n",
      "           -6.2415],\n",
      "         [ 15.9698,  -4.1613,  28.2713,  24.1007,  31.9338,  29.0405,  12.6017,\n",
      "          -22.4190],\n",
      "         [ 18.2176,   6.9941, -13.4004, -16.0281, -29.1450, -23.9850,   2.3452,\n",
      "          -22.6456],\n",
      "         [ -9.9215,   5.8742, -12.6019,  28.6682,  19.1451,  -3.0568, -22.7020,\n",
      "           -6.2519],\n",
      "         [ 32.6109, -26.5802, -16.5448, -18.8452, -19.9088,  31.2833, -23.5954,\n",
      "            0.8715],\n",
      "         [-23.7747,  -7.8795,   2.5135,   9.2649,   4.3945,  18.2823, -30.3563,\n",
      "          -40.3764],\n",
      "         [  9.2905,   4.6266,  -4.0156,   0.1970,   8.7558,  -1.1710,  -3.8576,\n",
      "           -7.7208],\n",
      "         [ 35.6650,  12.7986,  38.5103,  -0.9859,  23.5897, -26.0216,  14.1389,\n",
      "           28.9272],\n",
      "         [ -2.9598, -43.3454,  33.3368,  -9.6065,  -3.5610,  -0.8370,  30.4776,\n",
      "           35.3578],\n",
      "         [-21.7121,  21.9794,  -4.5842, -10.4842,  -7.5230, -21.6295, -36.0096,\n",
      "            7.7937],\n",
      "         [ 17.2454,  -8.3608,   4.5948,   3.7012,   6.7224,   1.3340, -19.9221,\n",
      "            1.9392],\n",
      "         [ 10.0147,  16.5129,  -1.4746,  17.3375,  14.1305, -44.4730,  26.8962,\n",
      "           15.2139]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[-0.4838, -0.3195,  0.3422,  ..., -0.1451, -0.0943, -0.4645],\n",
      "        [ 0.5174,  0.3024,  0.1742,  ..., -0.5072, -0.0122, -0.2588],\n",
      "        [ 0.0478, -0.6681, -0.3427,  ...,  0.0869,  0.4448,  0.3055],\n",
      "        ...,\n",
      "        [-0.3255,  0.3754, -0.0971,  ..., -0.5403, -0.0684,  0.0113],\n",
      "        [-0.2429, -0.0892, -0.4338,  ...,  0.2373,  0.0894, -0.0040],\n",
      "        [-0.3453,  0.2062,  0.0579,  ..., -0.0278, -0.2332,  0.0409]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[  6.5602, -24.3217, -13.5248, -14.0229, -15.2004,  17.3166,  10.6429,\n",
      "          -31.0128],\n",
      "         [ 33.2705,   7.3684,   6.4077,  19.4127, -12.8149,  13.9653, -15.8776,\n",
      "          -28.2167],\n",
      "         [  1.5214,   6.5161,  11.6970,  41.9656, -14.3637,  22.5731, -15.9762,\n",
      "           -4.2358],\n",
      "         [-29.9200,  17.1964,  22.4936,  -0.5798, -38.9681,  22.9270,   2.2482,\n",
      "          -15.1325],\n",
      "         [ 57.0219,  -1.3031,  -2.2476,  37.1186, -15.9536,  22.6534,  -5.2063,\n",
      "          -34.1253],\n",
      "         [  5.4670,  35.3435,  -7.2967, -44.8607, -18.6893,   0.2767, -30.9327,\n",
      "           16.5988],\n",
      "         [ 17.8489,  30.6057, -12.4877,  21.9054, -13.7247,  -2.1101,   9.6536,\n",
      "           28.7348],\n",
      "         [ 31.8788,  30.3298,   0.0919, -24.5065,  17.6576,  -0.9179,   8.4626,\n",
      "            5.5828],\n",
      "         [-53.2602, -19.6563, -42.4603,   9.7561, -25.0183,  36.3720,  68.5661,\n",
      "           -7.0325],\n",
      "         [  0.3787, -10.7253,  -5.5087,  -7.4514, -13.6705,   4.1001,  35.8008,\n",
      "            2.4247],\n",
      "         [-27.0305, -50.8275,  29.6500, -10.0180,  11.0666,   2.0798, -12.3262,\n",
      "           34.7419],\n",
      "         [-36.8982,  20.1471, -52.5327,  11.9226, -46.7753,  11.9823,  11.5941,\n",
      "           -5.9354],\n",
      "         [ 16.7205, -26.3584,  14.1739,  30.4343,   9.0775,  43.3860,  23.7143,\n",
      "           40.7327],\n",
      "         [ -3.5263, -12.0754,  21.8351,  28.9618, -11.6281,  39.3887,  20.3344,\n",
      "            2.0111]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[-0.1021, -0.3774, -0.3944,  ..., -0.2889,  0.2165,  0.3407],\n",
      "        [-0.3507, -0.0260,  0.4060,  ...,  0.4589,  0.2465,  0.4056],\n",
      "        [-0.3632, -0.0694, -0.1602,  ...,  0.1198, -0.5920, -0.3311],\n",
      "        ...,\n",
      "        [-0.2309, -0.4391, -0.2617,  ..., -0.2405, -0.2300, -0.0463],\n",
      "        [ 0.3968,  0.2731, -0.1161,  ..., -0.2113, -0.2376, -0.0541],\n",
      "        [-0.0709, -0.0275,  0.4833,  ..., -0.2028,  0.9244, -0.4429]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[ 17.3820,  -3.1331,  -7.2614, -21.7653,   3.7183,   4.3835,   3.8970,\n",
      "            0.8214],\n",
      "         [ -9.2626,  -0.6993, -21.0877, -11.8934,  -0.7500,  14.3380,  -3.5519,\n",
      "            3.5014],\n",
      "         [ 19.2654,  11.3087,   8.1235,  19.2115,   7.9728,   4.5676,  -4.5190,\n",
      "            5.6105],\n",
      "         [ 14.9512,  15.9935,  19.5179, -19.9203,   9.7060,   9.1186,   2.0918,\n",
      "          -13.8703],\n",
      "         [-25.5657,   3.5072, -11.3189,   6.5052, -24.7824,   8.7369,  17.2227,\n",
      "            9.5056],\n",
      "         [ 14.7003,   9.7586,   7.3756,   6.8139,   2.0055,  15.9726,  -8.0030,\n",
      "          -11.0093],\n",
      "         [ -6.9003,  -8.0752, -15.1773,  -7.5675,  -1.4167, -17.4845, -17.5499,\n",
      "            5.9002],\n",
      "         [ 29.4012, -21.0596,   5.2712,  -6.4337,   5.5467,  28.2815, -14.0274,\n",
      "          -13.5506],\n",
      "         [ 23.7772,  13.0127,  -2.2605,  28.4849,  -2.7964, -10.0061,  13.1830,\n",
      "          -17.1767],\n",
      "         [-24.6611,  -2.0423,   4.1566,  19.4410,   7.4956,   9.0070,  13.5164,\n",
      "            8.2886],\n",
      "         [ -4.5818,  13.5077, -33.0775,  -8.1497, -12.8977,   7.8934,  -4.7025,\n",
      "            2.5044],\n",
      "         [ -5.7744,   7.7439,   6.2238, -13.4100, -10.7396,  18.0253,  14.9467,\n",
      "            2.9680],\n",
      "         [ 11.2238,  -5.7473,  27.6518,  10.8746,   4.4413,  -0.8668, -33.7333,\n",
      "            1.9254],\n",
      "         [-21.4319,  10.8422, -18.4210,  19.8149,  18.7161,   5.8635,  -8.8572,\n",
      "           -4.1350]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.1933,  0.2807,  0.1945,  ...,  0.4334,  0.1504, -0.2705],\n",
      "        [-0.8616,  0.1957, -0.0749,  ..., -0.4270, -0.2215, -0.1568],\n",
      "        [-0.3213,  0.5273, -0.5002,  ..., -0.0186, -0.0713, -0.3350],\n",
      "        ...,\n",
      "        [ 1.0946, -0.2366,  0.3837,  ...,  0.4452,  0.7478,  0.5819],\n",
      "        [ 0.2934,  0.1347,  0.4643,  ...,  0.6036,  0.1162,  0.3312],\n",
      "        [-0.0596, -0.1051, -0.2061,  ...,  0.2536,  0.9172, -0.5051]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[  3.7153,  -0.3228,   7.9103,   0.3820,  -7.4272,  -2.1784,   1.2806,\n",
      "            4.5102],\n",
      "         [ -3.2598,   1.8887,   3.7627, -16.6423,  -7.3654,  -9.8902,   1.4420,\n",
      "          -24.4014],\n",
      "         [ -2.6035,  18.2219,  -5.8297,  -7.3714, -16.5109,  -9.7499,  -5.9232,\n",
      "           -5.5286],\n",
      "         [  8.7981,  -6.4941,  29.1579,  -3.4532,  -5.3274,  -1.2724,   6.3031,\n",
      "          -23.0290],\n",
      "         [  1.1597,   7.1176,   8.8272, -12.9190, -11.4726,  17.2841,  12.7579,\n",
      "           -1.5999],\n",
      "         [  1.5232,   6.3578, -13.6831,   7.1444,   1.4561,   4.1622,   9.3866,\n",
      "          -11.7705],\n",
      "         [ -5.8924, -10.6129,  -7.6692,  19.4940,   6.0341,  19.8685,  -3.6727,\n",
      "           -1.7518],\n",
      "         [ -9.3655,  15.9849,   0.9529,  20.0397,  -4.1014,  22.5477,   0.8116,\n",
      "            8.6742],\n",
      "         [ -7.2196,  10.3136,  -6.2421,  13.0760,   7.0770,  -5.7595, -13.7468,\n",
      "            8.5925],\n",
      "         [ 11.4888,  -3.7669,  -1.2507,  -1.8834,   3.5988,   6.0697,  -9.5335,\n",
      "           12.4582],\n",
      "         [  1.4688,   8.5940,   9.8638,  15.2416,  16.0703, -29.5427, -12.8514,\n",
      "          -14.4089],\n",
      "         [  0.7443, -25.3055,  10.1771,  17.1880,  21.7520,   3.3746,  -7.0362,\n",
      "           10.0209],\n",
      "         [  7.3672,  -4.8810,  -1.0173,  20.0303, -20.6656,  -5.5233,   5.8011,\n",
      "           -3.5343],\n",
      "         [  3.3016,   0.2151,   0.7815,  -6.3693,  -5.7445,  -1.6644,   1.2939,\n",
      "          -10.2537]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.0966,  0.0190, -0.3253,  ..., -0.0041, -0.2015, -0.7499],\n",
      "        [-0.0240, -0.4640, -0.5738,  ...,  0.0986, -0.3151, -0.4560],\n",
      "        [-0.0293,  0.1063,  0.6955,  ...,  0.2085, -0.0263, -0.4385],\n",
      "        ...,\n",
      "        [ 0.3216,  0.1529,  0.2118,  ..., -0.1236,  0.5398,  0.0830],\n",
      "        [-0.1852, -0.1543,  0.4969,  ...,  0.1658, -0.1390, -0.3492],\n",
      "        [-0.1358,  0.1596,  0.5440,  ...,  0.1788,  0.7100, -0.3144]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[ -2.9564,   9.1079,   3.9073, -27.9362,  28.1931,   1.6467, -15.3562,\n",
      "            8.8918],\n",
      "         [-28.5012,  17.5920, -39.8512,  17.9011,  33.2256, -14.7751,  13.0765,\n",
      "          -30.1277],\n",
      "         [ -5.8499, -36.9151, -31.0860,  -9.1609,  28.9848,  -0.8455,  -6.1255,\n",
      "          -19.6752],\n",
      "         [-11.2120,  24.6537, -67.3071, -18.8737,   0.9965, -10.1187,  14.8556,\n",
      "            6.2782],\n",
      "         [ 23.4588,  12.7561,   6.1663,  53.8321,  20.4192, -15.2601, -21.6533,\n",
      "          -24.7642],\n",
      "         [-14.4713,   7.2786,   7.8697,  14.5968,  11.9889,   0.9407,   7.0220,\n",
      "          -23.6401],\n",
      "         [-23.5651,  20.7811,  19.6644,  18.8052,  -4.0470,  -3.0312, -14.9292,\n",
      "           -1.3906],\n",
      "         [ 19.1459,   8.7491,   4.8279,   1.1131, -34.3374,  33.9953, -18.3492,\n",
      "           28.0679],\n",
      "         [-69.9771, -24.0245,   4.1845,  -9.5750,  -5.3525, -34.6198,  22.6365,\n",
      "          -45.8975],\n",
      "         [ 27.2049,  11.4009,  27.3354,   6.9027,  23.3788,  34.1755,   6.2134,\n",
      "           19.5427],\n",
      "         [-15.8549,  -6.9518, -31.5893, -12.4246,  39.6393,   6.0025, -45.1172,\n",
      "            5.8096],\n",
      "         [  7.8840,  14.3689,  13.6107, -37.5822,   7.4264, -15.0853, -15.0672,\n",
      "           23.3938],\n",
      "         [-21.9867,   9.5150,  15.4729, -38.9001,  -8.6234,  51.7062,   2.9362,\n",
      "           13.3084],\n",
      "         [ -0.5059, -25.4493,  29.1679,  -2.2074,  -3.9462,  12.9661,  10.9056,\n",
      "           39.5089]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.5206,  0.2182, -0.3322,  ...,  0.5708,  0.3069, -0.2411],\n",
      "        [-0.5386, -0.3756,  0.6029,  ..., -0.0930,  0.1062,  0.3934],\n",
      "        [-0.2385, -0.1601,  0.0526,  ..., -0.1821, -0.1531, -0.1231],\n",
      "        ...,\n",
      "        [-0.1333, -0.3091,  0.1935,  ...,  0.6309,  0.3541,  0.1988],\n",
      "        [-0.0836,  0.3248, -0.0326,  ...,  0.4826, -0.6396, -0.2751],\n",
      "        [-0.1913, -0.1617,  0.0455,  ..., -0.0179, -0.3546, -0.0107]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[  28.9394,   59.2895,    5.7538,    8.6407,   43.0438, -102.2041,\n",
      "             5.6902,   -1.0410],\n",
      "         [ -38.7947,  -17.1330,  -21.3787,   -5.6797,  -47.0535,  -87.6791,\n",
      "            71.4715,  -11.0029],\n",
      "         [ -70.1279,   20.2328,  -18.9902,  -32.4920,   42.4180,   46.1429,\n",
      "             1.3402,  -16.2431],\n",
      "         [   9.5346,   17.0969,   56.3292,   13.3309,   -9.2157,  -24.5288,\n",
      "           -11.9991,   -8.3942],\n",
      "         [  96.8795,  -83.5149,   13.0460,  -21.3181,   53.2604,   56.8911,\n",
      "           -13.0148,  -26.5399],\n",
      "         [  35.2134,    5.0682,  -57.7368,   21.9375,  -36.1147,  -12.2090,\n",
      "            73.2606,  -56.9961],\n",
      "         [  -9.1651,  -38.8622,  -20.2712,  -25.0329,  -32.3754,  -34.2915,\n",
      "            24.0446,  -44.9607],\n",
      "         [ -12.8670,   -8.3091,   40.5464,   27.3501,  -41.7703,  -15.8301,\n",
      "            80.0454,   -9.2981],\n",
      "         [ -39.6719,   40.9451,   22.0218,   29.3162,   19.2572,   64.2113,\n",
      "            25.4390,   35.7415],\n",
      "         [  -2.5901,  -23.6010,   20.2595,  -46.7184,   10.7250,   54.6085,\n",
      "           -81.4014,   60.3708],\n",
      "         [ -55.1789,  -28.5073,  -20.7760,   -5.2900,  -27.6776,  -51.5103,\n",
      "             9.8146,  -47.7806],\n",
      "         [  88.0088,  -24.8560,   42.2110,   22.2656,   83.4249,  -53.3351,\n",
      "           -49.0583,  -85.3483],\n",
      "         [   2.5291,  -14.1365,  -44.2131,  -39.7203,    4.7167,  -83.5949,\n",
      "             6.6026,   11.1946],\n",
      "         [ -70.7585,   41.5612,   35.7663,   33.8267,   16.1950,    1.1593,\n",
      "             8.2738,   88.4837]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[-0.3155, -0.5155,  0.2059,  ...,  0.2563,  0.3535,  0.4739],\n",
      "        [-0.0655,  0.6812, -0.2244,  ...,  0.5594, -0.3372,  0.3287],\n",
      "        [ 0.3602, -0.5006,  0.3576,  ...,  0.0497, -0.0775,  0.2667],\n",
      "        ...,\n",
      "        [ 0.2085,  0.2021, -0.1955,  ...,  0.0564,  0.3923, -0.4506],\n",
      "        [-0.4868, -0.1206,  0.4334,  ..., -0.2815,  0.5873,  0.2980],\n",
      "        [-0.1782, -0.0950,  0.4549,  ..., -0.3812,  0.2809, -0.3099]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[ 8.3837e+01, -2.7241e+01,  5.4223e+01,  6.6874e+01, -6.9199e+01,\n",
      "           8.3962e+01, -4.8438e+01,  5.6303e+00],\n",
      "         [ 7.1537e+01,  4.1451e+00, -3.4653e+01, -6.7959e+00,  5.5386e+01,\n",
      "          -5.5106e+01, -1.2167e+01,  3.6366e+01],\n",
      "         [-4.0871e+00,  8.8835e+00,  1.6648e+01, -1.1759e+00, -6.8161e+01,\n",
      "           4.9479e+01,  1.2731e+01,  5.3273e+01],\n",
      "         [ 5.2035e+00,  7.8143e+01,  7.4616e+00,  1.1316e+02,  4.8109e+00,\n",
      "          -4.3855e+01,  1.6451e+01, -4.3649e+01],\n",
      "         [ 1.0170e+01, -1.3748e+01,  4.8821e+01,  2.3695e+01,  2.4959e+01,\n",
      "           1.6226e+01, -5.9408e+01,  8.0680e+01],\n",
      "         [ 5.4916e+00,  2.3860e+01, -3.5724e+01,  1.1889e+01, -9.2577e+00,\n",
      "          -2.5101e+01, -2.8427e+01,  5.2712e+01],\n",
      "         [ 9.1723e+00, -6.0596e+00, -9.0789e+00, -1.0975e+01, -2.4454e+00,\n",
      "           5.4308e+01, -9.2134e+00,  3.4157e+01],\n",
      "         [-4.3136e+01,  3.9001e+01,  1.2858e+01,  9.1999e+01, -3.2875e+01,\n",
      "          -1.7551e+01, -5.7748e+01,  2.0721e+01],\n",
      "         [-5.1312e+01,  1.9938e+01, -7.2662e+01,  1.8723e+01,  6.8856e+01,\n",
      "           4.5791e+01, -4.5933e+01, -4.9986e+00],\n",
      "         [ 3.0081e+00, -3.4958e+00,  8.2595e+00, -3.8835e+00, -4.2052e+01,\n",
      "           4.3521e+01,  3.0404e+01,  9.0589e-02],\n",
      "         [ 1.2711e+01, -1.2936e+01,  1.4202e+01, -1.0217e+01,  1.0061e+01,\n",
      "           4.7090e+01,  2.1860e+01,  5.0233e+01],\n",
      "         [ 8.9528e+01,  8.5138e+00, -7.0508e+01, -1.8531e+01,  1.1318e+00,\n",
      "           4.1298e+01,  4.9892e+00,  3.6403e+01],\n",
      "         [-2.4482e+01, -5.5258e+01, -1.5779e+01, -2.4082e+00, -6.5535e+01,\n",
      "          -5.0132e+01,  2.9927e+01,  3.7858e+01],\n",
      "         [-4.4097e+01, -2.2029e+01,  1.8850e+01, -2.4973e+01,  5.3556e+01,\n",
      "           2.3045e+01,  2.5751e+01,  4.8522e+01]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=14336, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.4144, -0.1136,  0.7284,  ..., -0.2012,  0.5048,  0.3649],\n",
      "        [ 0.3239,  0.3749, -0.0803,  ...,  0.1154, -0.1155, -0.3237],\n",
      "        [ 0.4684, -0.4002,  0.7307,  ..., -0.1303, -0.2405, -0.2784],\n",
      "        ...,\n",
      "        [-0.3414, -0.4567, -0.4011,  ...,  0.5368, -0.5841, -0.7251],\n",
      "        [ 0.2192,  0.2543,  0.9847,  ...,  0.4426, -0.2011, -0.1864],\n",
      "        [-0.2240,  0.4616, -0.3272,  ...,  0.5986,  0.5750,  0.0033]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[ 33.8556, -11.0728,   3.8856,  -9.9248,   9.1199,  -9.7792,  50.1847,\n",
      "            9.4721],\n",
      "         [  1.3345, -31.3060,  -6.5946, -34.8503, -15.3891,  -7.4243,   0.5956,\n",
      "          -26.2872],\n",
      "         [ -1.4216, -54.7991, -11.1210,   0.4592,  -0.3460, -41.5978, -14.5633,\n",
      "            8.2003],\n",
      "         [  4.6144, -17.8991,   8.8177, -18.3989, -24.7780, -27.6041,  19.6105,\n",
      "            8.1820],\n",
      "         [-45.1762,  -9.5662,   0.0995, -12.2475, -12.8581,  38.9922,  14.8973,\n",
      "           40.0749],\n",
      "         [  7.2614, -47.6061, -28.3645,   5.5403,  18.1704,  48.6295,  17.7789,\n",
      "           -6.9638],\n",
      "         [  4.4882, -34.9666,  32.3688,  30.4650,  -8.2226, -42.0305,  -8.2256,\n",
      "          -18.9382],\n",
      "         [ 26.9363,  -1.1907, -17.5524, -45.6134,  38.5400,  -4.3421, -11.3850,\n",
      "            7.2479],\n",
      "         [ 13.1956,  -2.3554,   4.8162,  -1.7031,   6.5384, -23.5531, -22.8830,\n",
      "           16.9831],\n",
      "         [ 67.7859,  25.3176,   8.3079, -15.5644, -27.9392, -61.5962,  -6.4198,\n",
      "           12.8333],\n",
      "         [-42.6070, -68.2378,   1.3520,   3.6143, -32.1842, -17.4375,  -8.5310,\n",
      "           33.5798],\n",
      "         [-12.1874, -10.7671,  -7.1518, -35.1053, -36.6293,  36.3589, -12.1499,\n",
      "          -46.1803],\n",
      "         [ 10.1354,  25.3428, -12.3447, -15.0314, -11.5934, -18.3716,  23.0534,\n",
      "           14.3401],\n",
      "         [-18.8905,  -4.4081,  -2.8594,   9.7069, -25.9900,   9.1681, -17.8554,\n",
      "           29.1696]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[-0.3425,  0.1293,  0.6124,  ..., -0.2944, -0.1514, -0.0130],\n",
      "        [-0.2746, -0.2220,  0.3260,  ...,  0.0786,  0.0896, -0.0010],\n",
      "        [ 0.2464,  0.1844,  0.1878,  ...,  0.1387, -0.6899, -0.1443],\n",
      "        ...,\n",
      "        [ 0.1609, -0.1208, -0.6103,  ...,  0.5331, -0.1052,  0.0822],\n",
      "        [-0.1652, -0.1344,  0.1618,  ...,  0.4062,  0.1421, -0.1072],\n",
      "        [-0.3642, -0.0699,  0.5377,  ..., -0.8102, -0.2683,  0.4024]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[-1.5924e+01, -1.6027e+01, -7.5085e+00,  9.7730e+00,  6.7343e+00,\n",
      "          -1.6010e+01, -2.6474e+01, -2.0148e+01],\n",
      "         [ 3.4115e+01,  3.3540e+01,  2.7144e+01, -8.1133e+00,  2.1053e+01,\n",
      "           2.8560e+01,  2.6738e+00,  3.4136e+00],\n",
      "         [ 1.6514e+01,  2.4510e+01,  6.1573e+01, -4.4736e-01, -6.3418e+00,\n",
      "          -1.0759e+00,  7.9487e+00, -1.1844e+01],\n",
      "         [ 1.7934e+01,  1.8332e+01, -1.6680e+01, -1.8813e+01, -6.4462e-02,\n",
      "           2.5574e+01, -8.4628e+00, -1.4883e+01],\n",
      "         [ 1.2711e+00,  4.0958e+01, -5.8605e+00, -5.5745e+00,  1.3578e+01,\n",
      "           1.6772e+01, -1.5414e+01,  3.5625e+01],\n",
      "         [ 1.6080e+01, -4.3352e+01,  1.2750e+01, -1.3022e+01, -8.9567e+00,\n",
      "          -3.0415e+01,  2.5198e+01,  3.1453e+01],\n",
      "         [ 1.5620e+01, -2.5878e+00,  3.0055e+00, -9.6829e+00, -2.1855e+00,\n",
      "          -1.3310e+01, -3.5074e+00, -2.2034e+01],\n",
      "         [ 4.7268e+00, -3.4403e+01, -2.9643e+01, -4.0582e+00,  3.1960e+01,\n",
      "          -1.2057e+01, -2.4045e+01,  7.6437e+00],\n",
      "         [-9.8952e+00, -1.2707e+01,  1.4098e+01, -8.0621e+00,  5.5658e+00,\n",
      "           1.2119e+01, -4.1360e+01,  1.2722e+01],\n",
      "         [-1.9150e+01,  3.1411e+01, -1.9132e+01, -2.9829e+01,  1.5429e+01,\n",
      "           4.2903e+01,  1.6646e+01, -2.4040e+01],\n",
      "         [ 7.6396e+00, -1.7964e+01, -4.4750e+01,  4.6136e+01,  1.8835e+01,\n",
      "           2.5196e+00, -3.1904e+01, -9.9612e+00],\n",
      "         [-2.6593e+01,  3.5199e+01,  2.4607e+00,  4.1580e+01, -3.0135e+01,\n",
      "          -6.4136e+00,  2.8671e+01, -1.0207e+01],\n",
      "         [ 1.7462e+01,  2.1074e+01,  6.5385e+01,  7.5967e+00, -7.0866e+01,\n",
      "          -6.2478e+00, -7.5626e+00,  1.3500e+01],\n",
      "         [ 1.8969e+01,  6.1985e+00,  5.5073e+01, -3.8416e+00,  3.1637e+01,\n",
      "          -2.6903e+01,  2.1701e+01, -1.4712e+01]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.3968,  0.0272,  0.7170,  ..., -0.0143, -0.1026, -0.2394],\n",
      "        [ 0.4456,  0.2695, -0.3780,  ...,  0.0104,  0.1666,  0.4588],\n",
      "        [ 0.7726, -0.2063,  0.2732,  ..., -0.1135,  0.8469,  0.1215],\n",
      "        ...,\n",
      "        [ 0.3245, -0.0070,  0.5029,  ..., -0.0127,  0.2789,  0.1793],\n",
      "        [ 0.1699,  0.0022, -0.6571,  ...,  0.2523, -0.4237,  0.2558],\n",
      "        [ 0.6604, -0.2525,  0.7919,  ...,  0.2582, -0.3325, -0.0865]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[-3.8999e+00,  9.4187e-02, -9.1619e+00,  5.4844e+00,  2.1641e+00,\n",
      "          -2.4262e+01,  1.5851e+01,  1.7828e+01],\n",
      "         [-7.7643e-01,  1.5097e+00,  7.5086e-02, -2.4092e+01,  1.9688e+00,\n",
      "          -1.3401e-02, -1.0990e+01, -9.3630e+00],\n",
      "         [ 6.8703e+00, -5.0159e+00, -2.6363e+01, -1.1498e+01,  2.1613e+01,\n",
      "           6.7894e+00, -1.3972e+01, -1.7578e+01],\n",
      "         [ 1.8419e+00,  1.6445e+01, -1.6043e+01,  1.4746e+00, -2.3810e+01,\n",
      "           7.5244e-01, -1.8005e+01,  3.0614e+01],\n",
      "         [-4.2532e+00,  8.2805e+00,  1.6777e+01, -1.8252e+01,  1.2202e+01,\n",
      "          -1.0480e+01, -6.9536e+00,  3.1118e+01],\n",
      "         [-2.0865e+00,  5.2601e+00,  5.9236e+00,  1.4124e+01, -2.7990e-01,\n",
      "           1.5758e+01,  5.1062e+00, -3.9888e+00],\n",
      "         [-9.2597e+00,  2.0753e+01, -1.5065e+01,  8.6754e+00, -7.9005e+00,\n",
      "          -4.9292e+00, -7.1690e+00, -5.9101e+00],\n",
      "         [-8.8211e+00,  1.4286e+00,  9.2855e+00, -1.5099e+00, -4.6888e+00,\n",
      "          -2.0766e+00, -3.7749e+00,  2.9318e+00],\n",
      "         [ 1.0387e+01,  2.0458e+01, -7.3001e+00, -1.2147e+01,  1.1768e+01,\n",
      "          -9.3714e+00, -1.1024e+01,  1.0479e+01],\n",
      "         [ 1.6694e+01,  8.0053e-01,  5.5121e+00, -1.2315e+01, -8.6338e+00,\n",
      "          -1.3908e+01,  7.2931e+00,  9.7357e+00],\n",
      "         [-2.3152e+00, -1.2751e+01,  1.7235e+00,  1.2416e+01, -1.7020e+01,\n",
      "          -7.2320e+00, -1.0356e+01,  6.9877e-01],\n",
      "         [ 4.8895e+00, -2.2880e+01, -1.1919e+01, -8.3005e+00, -3.1389e+00,\n",
      "          -1.7595e+01,  1.0365e+01,  1.5241e+01],\n",
      "         [ 6.4700e+00,  4.4856e+00,  2.2634e+00, -2.3384e+01,  6.8503e+00,\n",
      "          -1.4429e+01, -2.0852e+00,  1.4172e+01],\n",
      "         [ 2.0992e+01,  4.6824e+00,  3.5653e+00, -6.6435e+00,  1.9925e-01,\n",
      "           2.9781e+01, -5.3173e-01, -1.6608e+01]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.3135,  0.7673, -0.1460,  ..., -0.3740,  0.0083, -0.2046],\n",
      "        [ 0.1036,  0.2399, -0.1785,  ..., -0.1387,  0.2418,  0.1871],\n",
      "        [-0.6458, -0.1462, -0.2398,  ..., -0.7346, -0.2987, -0.1357],\n",
      "        ...,\n",
      "        [ 0.6187,  0.1334,  0.1260,  ...,  0.2285, -0.5743, -0.4611],\n",
      "        [ 0.0140, -0.0809,  0.0420,  ..., -0.5931,  0.3252, -0.1821],\n",
      "        [-0.1107,  0.0269, -0.2693,  ..., -0.7174,  0.5169, -0.4531]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[  5.2163,  -9.1469, -11.7397, -18.6138,   5.4376,  10.4099,   4.2052,\n",
      "           -8.5135],\n",
      "         [ -2.8236, -13.1529,   8.2960,   9.6496,  -9.4692, -14.0827,   2.6093,\n",
      "            3.9087],\n",
      "         [ 13.3316,  -4.6634,   0.8793, -18.8796,   7.1579,   6.0002,   2.0123,\n",
      "           -4.5583],\n",
      "         [  8.7692,  -5.6142, -21.6551, -13.0132,  30.2457,  -0.6004,   2.7646,\n",
      "            1.9927],\n",
      "         [  6.7865,   7.8617,  -0.2008,   2.3187,  -9.8630,  -5.9654,   3.9635,\n",
      "            9.2858],\n",
      "         [  5.8415, -16.2013,  -2.5600,   0.1557, -11.9265,  -2.9128,  12.2122,\n",
      "          -10.7447],\n",
      "         [-30.7962,   1.2298,  -1.8367,  -1.7690,   3.6527,   2.8341,   5.0600,\n",
      "            2.2834],\n",
      "         [-13.8308,   3.5980,  11.6588,  -4.2059,  -1.9923,   9.0083,  -3.5082,\n",
      "            3.5318],\n",
      "         [ -1.7044,   0.6945,   5.3045, -16.7655, -14.1900,   2.6501,   7.4005,\n",
      "            5.6330],\n",
      "         [ -0.1177,  -2.6522, -10.2745,  -2.2616,   3.1360,  -7.5912,   1.1071,\n",
      "          -23.2610],\n",
      "         [  0.5108,   3.1448,  18.7368,  11.7081,   3.1506,   5.7563,   3.0740,\n",
      "           -0.5130],\n",
      "         [-35.6401,  -6.0847,   2.0958,   6.8256,   7.9943,  -8.9927, -27.1251,\n",
      "            7.8783],\n",
      "         [-20.3187,   7.3370,   0.7790, -28.5853,  20.4905,  -8.4630,  -4.1759,\n",
      "           13.9665],\n",
      "         [-20.4742,  -0.2911,   3.8177,   2.4089,  -6.0841,   1.0598,   4.9827,\n",
      "           -2.3453]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.0298, -0.5445,  0.9292,  ...,  0.6360,  0.1894, -0.9588],\n",
      "        [-0.3526,  0.2147, -0.3286,  ..., -0.4938,  0.7457,  0.0849],\n",
      "        [-0.0164,  0.2142,  0.0754,  ..., -0.0747, -0.5444, -0.3859],\n",
      "        ...,\n",
      "        [-0.1708,  0.0204, -0.0148,  ...,  0.0638, -0.0346, -0.2127],\n",
      "        [-0.4314,  0.2164,  0.2613,  ..., -0.0374,  0.0759, -0.1255],\n",
      "        [ 0.5157,  0.2281, -0.1204,  ...,  0.4475, -0.4499,  0.5510]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[-30.1799,   0.6542,  22.5040,  20.2841,  42.8622,  24.2990,   4.6553,\n",
      "           -1.7649],\n",
      "         [ 17.5470,  -2.6867, -31.9968,   3.0430,  -7.2203, -45.8314,  -0.7118,\n",
      "            5.2594],\n",
      "         [-32.5186, -15.1428,   9.3158,  26.1368, -20.7129,  -3.8714,  -6.9737,\n",
      "           17.4806],\n",
      "         [ -9.8458,   0.1591, -18.4647,  40.1111,  -5.9145,  26.3510, -21.8731,\n",
      "          -31.3113],\n",
      "         [-12.9529,  -3.4286, -20.0021,   4.1048, -15.8386,  24.4476, -32.8401,\n",
      "           53.4024],\n",
      "         [-20.2169, -22.5482, -34.3142,   0.8821, -39.0196, -41.2696,   4.6560,\n",
      "           -5.4248],\n",
      "         [ -6.1080,  -1.9854,   6.4232,   4.8980,  -8.8954,   9.8934,   4.1803,\n",
      "           35.0389],\n",
      "         [-11.4180,  28.3536, -12.7085, -12.9725, -16.2154, -32.0958, -10.0542,\n",
      "           -8.4191],\n",
      "         [ -4.5972, -27.9840,  11.8197,  30.1832,   6.5595, -17.5203,   1.8351,\n",
      "           -0.2537],\n",
      "         [-14.4854,  22.6523,  -7.2158,  -9.9672,  23.8723,   8.8985,  -1.2460,\n",
      "          -19.5884],\n",
      "         [ 31.6746,   2.9466,  -4.2940,  18.6946,   6.3778, -17.0422, -23.8361,\n",
      "           -7.5852],\n",
      "         [ 39.0708,   3.6417, -29.7181,  -1.6076,  11.1988, -18.4511, -18.1911,\n",
      "          -10.2880],\n",
      "         [  7.7227,  -6.0489,   7.3240, -24.6790,  -8.7870,  19.3428, -15.1625,\n",
      "          -19.0917],\n",
      "         [ 10.2236, -17.6187,  -7.8909,  -3.8873,   5.5551,   3.0623,  -6.8026,\n",
      "          -20.4688]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.0018, -0.2266, -0.5102,  ..., -0.2101, -0.3870, -0.3267],\n",
      "        [-0.1742, -0.3508,  0.0280,  ..., -0.3973,  0.3199,  0.1895],\n",
      "        [ 0.0417,  0.1030, -0.3651,  ..., -0.1525, -0.0603,  0.2124],\n",
      "        ...,\n",
      "        [-0.3950, -0.0848, -0.1543,  ..., -0.2038, -0.0264, -0.2255],\n",
      "        [-0.2378,  0.1521,  0.0679,  ..., -0.5742,  0.0069, -0.5061],\n",
      "        [ 0.3286, -0.0866,  0.0890,  ...,  0.0524,  0.0721, -0.5149]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[-5.6664e+01,  7.5829e+01, -4.3075e+01, -1.1975e+01,  5.3817e+00,\n",
      "           7.5582e+01, -6.3414e+01, -5.7856e+01],\n",
      "         [ 1.5225e+01, -3.5552e+00, -1.1066e+02,  1.6251e-02, -2.6364e+01,\n",
      "          -6.2324e+01, -1.8389e+01, -7.2158e+00],\n",
      "         [ 2.7972e+00, -5.5259e+01,  3.0828e+00, -4.2801e+01,  1.1050e+00,\n",
      "           4.7248e+00,  8.0950e+01,  7.6004e+00],\n",
      "         [ 8.8356e+01, -2.2019e+01,  6.3811e+01,  6.7260e+01, -9.4934e+01,\n",
      "           2.1519e+01, -3.7830e+01, -1.0050e+02],\n",
      "         [-4.3507e+01,  5.1897e+01, -1.8840e+01,  1.6595e+01, -3.3758e+01,\n",
      "          -5.3818e+01,  1.2824e+01,  5.3594e+01],\n",
      "         [ 1.7050e+01, -1.2288e+01, -6.9701e+00, -3.5640e+01, -2.3510e+01,\n",
      "          -3.2707e+01, -8.5145e+01,  2.7898e+01],\n",
      "         [-4.4681e+00, -9.9127e+01, -2.5356e+01, -3.1091e+00,  1.0187e+02,\n",
      "          -3.8122e+01, -7.9749e+01,  1.1191e+01],\n",
      "         [ 9.0439e+00,  6.5996e+01,  3.9812e+01,  2.7634e+01,  6.7026e+00,\n",
      "          -7.0190e+01, -5.5571e+01,  6.4720e+00],\n",
      "         [-1.5707e+01, -2.7576e+01,  7.6496e+01, -3.5088e+01,  3.4719e+01,\n",
      "           2.8515e+01,  6.7289e+01,  4.5883e+01],\n",
      "         [-6.4286e+01, -2.0494e+01,  2.0778e+01,  1.3630e+01, -1.5191e+01,\n",
      "           1.5859e+01, -2.6043e+01,  7.8166e+00],\n",
      "         [-1.3396e+01,  2.4489e+01, -7.5910e+01, -2.6790e+01,  7.6522e+01,\n",
      "          -3.3363e+01, -2.7696e+01, -3.1123e+01],\n",
      "         [ 2.6488e+01, -4.1457e+01, -3.6808e+01,  1.3768e+01, -8.8324e+01,\n",
      "           2.3917e+01,  6.6751e+00, -5.3149e+01],\n",
      "         [ 2.4066e+01, -2.2230e+01, -6.4988e+01, -3.8002e+01,  3.7287e+01,\n",
      "           5.1162e+00,  2.8213e+00,  2.6833e+01],\n",
      "         [ 1.5145e+00,  7.9959e+01, -3.4608e+01,  6.0319e+01,  3.8091e+01,\n",
      "           8.1395e+01, -1.4440e+01, -3.3673e+01]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[-0.0978, -0.3399,  0.6464,  ..., -0.1215,  0.2218,  0.0889],\n",
      "        [-0.0738,  0.4360, -0.7793,  ..., -0.0152, -0.4264, -0.1306],\n",
      "        [-0.1227, -0.9064, -0.0624,  ..., -0.0639, -0.0763,  0.0134],\n",
      "        ...,\n",
      "        [-0.3934, -0.3640, -0.1489,  ..., -0.7264, -0.1230, -0.0515],\n",
      "        [-0.1364, -0.0242, -0.0498,  ...,  0.7569,  0.0485,  0.4353],\n",
      "        [ 0.4578, -0.1389,  0.6572,  ..., -0.1567, -0.0140, -0.0431]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[  16.9978,   21.5682,  -14.8486,  -86.7790,   -6.9668,  -29.6145,\n",
      "           -74.2335,  -44.2854],\n",
      "         [  59.3304,   86.9553,   19.5907,   22.7591,  -55.9841,   22.9912,\n",
      "            12.0413,   32.6207],\n",
      "         [ -56.6632,  -30.6157,   56.4029,   10.9582,   10.6337,   10.2930,\n",
      "            13.7686,  -72.2324],\n",
      "         [  79.7225,   -0.4218,   28.3618,   27.2940,   -9.1726,  -25.0205,\n",
      "            14.5834,   -4.5613],\n",
      "         [ -59.6015,   61.9539, -124.8856,  -71.8398,   -7.1382,   -2.2956,\n",
      "            48.7606,  -31.6786],\n",
      "         [   0.2291,  -90.0714,   -9.6986,   73.7042,   11.0224,  -21.3375,\n",
      "            56.7088,   97.8477],\n",
      "         [  -7.7519,  -20.3484,   -9.0539,    1.7783,    3.5757,   32.1544,\n",
      "            46.6785,    8.7110],\n",
      "         [ -32.0722,   38.9179,   27.2304,   59.8298,  -31.9684,   -8.0121,\n",
      "            -2.0695,  -19.6644],\n",
      "         [  14.7848,   87.0814,  -77.3149,  -34.7012,  -16.4916, -123.8039,\n",
      "             6.1758,  -12.8700],\n",
      "         [  23.8224,   -8.9186,   -6.3378,   71.5226,  -39.0400,  -17.7743,\n",
      "            47.2914,  -40.6420],\n",
      "         [ -28.3835,  -25.4667,  -30.2920,   24.3055,    4.6312,   -6.5207,\n",
      "             4.9767,   30.4747],\n",
      "         [  13.8596,  -39.5454,   79.6859,    5.2647,  -60.3474,  -50.7522,\n",
      "             6.3440,   50.3616],\n",
      "         [  49.1051,   18.1336,   93.1668,    6.7945,   32.1346,  -68.1896,\n",
      "           -95.2323,   26.9214],\n",
      "         [  12.6325,   62.2449,   -4.9013,    9.5806,  -23.1087,   52.2994,\n",
      "            25.8556,   10.9398]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=14336, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.3379, -0.2865,  0.2791,  ..., -0.2756,  0.1594, -0.4367],\n",
      "        [ 0.3153, -0.4211,  0.1382,  ...,  0.1534, -0.3257,  0.5898],\n",
      "        [ 0.4993,  0.3182,  0.0527,  ...,  0.1472,  0.4202, -0.4258],\n",
      "        ...,\n",
      "        [ 0.1150,  0.5260, -0.1944,  ...,  0.1322,  0.4071,  0.0488],\n",
      "        [-0.0358, -0.4664,  0.0523,  ..., -0.0640, -0.7573,  0.0820],\n",
      "        [-0.2087,  0.2338, -0.3985,  ...,  0.0483, -0.4240, -0.1424]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[ 2.2027e+01, -3.0025e+01, -2.9773e+01, -1.3884e+01,  1.0152e+01,\n",
      "          -5.0759e+00, -6.5404e-01,  8.1687e+00],\n",
      "         [-2.7299e+00, -1.0182e+01, -7.5434e+00, -4.8827e+01,  5.2065e+01,\n",
      "          -3.5912e+00,  3.5296e-01, -3.7522e+00],\n",
      "         [-2.1097e+01,  1.2716e+01,  3.4994e+01, -1.1519e-02, -2.1474e+01,\n",
      "          -6.6258e+00,  1.7382e+01,  1.1265e+01],\n",
      "         [-9.9258e+00,  1.0730e+01, -2.1115e+01,  3.3325e+01,  2.7686e+01,\n",
      "           5.0923e+00, -1.7330e+01,  2.6102e+01],\n",
      "         [ 2.8518e+01, -1.7419e+01,  1.5966e+01, -3.2870e+01,  5.4775e+00,\n",
      "          -5.6617e+00, -2.6075e+01,  2.8255e+00],\n",
      "         [ 1.7748e+00,  2.2928e+01,  1.6475e+00, -3.0140e+01, -4.1041e+01,\n",
      "          -4.1495e-01,  9.6475e+00, -2.3724e+00],\n",
      "         [-4.7467e+00,  3.6764e+01,  7.3867e+00, -4.7097e+01, -4.0566e+00,\n",
      "           1.7053e+01, -3.0175e+00, -1.7691e+01],\n",
      "         [ 1.0397e+00, -2.9448e+01, -2.8357e+01, -1.0835e+01,  4.5259e+00,\n",
      "          -1.0015e+01,  5.1387e+01,  6.1433e-01],\n",
      "         [ 2.5873e+01,  1.3514e+01,  2.2472e+01, -5.7694e+01, -3.3589e+01,\n",
      "           4.9409e+01,  2.5597e+01, -1.9830e+01],\n",
      "         [ 9.5000e+00,  2.6364e+01,  7.6292e+00,  7.5678e+00, -1.3983e+00,\n",
      "           3.6982e+01,  2.1046e+01, -2.3318e+01],\n",
      "         [-2.6170e+01,  6.9995e+00,  4.3240e+00, -5.0344e+01,  1.3374e+01,\n",
      "          -2.2774e+01, -1.2331e+01, -1.9538e+01],\n",
      "         [ 1.9717e+01, -1.5099e+01,  9.2341e+00,  6.6296e+00,  1.4912e+01,\n",
      "          -1.7608e+01, -2.4626e+01, -5.6947e+01],\n",
      "         [-2.6350e+01,  5.3387e+01,  2.9928e+01,  1.0441e+01,  4.2908e+01,\n",
      "          -1.3550e+00,  1.4692e+01, -5.2739e+00],\n",
      "         [-1.0499e+01,  1.5104e+01, -2.1139e+01, -1.0530e+01, -5.8841e+01,\n",
      "          -2.8119e+01,  2.6950e+01,  2.3938e+01]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[-0.1465,  0.1767,  0.0568,  ...,  0.0111,  0.0390,  0.3565],\n",
      "        [-0.3202, -0.0027, -0.0230,  ...,  0.2696,  0.0470, -0.3792],\n",
      "        [-0.2007, -0.6230, -0.1967,  ...,  0.3852, -0.5147,  0.5664],\n",
      "        ...,\n",
      "        [ 0.6196, -0.3927,  0.1707,  ..., -0.1307, -0.2632, -0.0116],\n",
      "        [ 0.7473,  0.0029,  0.3572,  ..., -0.0255, -0.5979,  0.2085],\n",
      "        [-0.3600, -0.1253, -0.2940,  ...,  0.4479, -0.5968, -0.1173]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[ 12.5731,  -3.0119,  -7.5390,  23.2890,  10.2684,   2.5695,   9.2033,\n",
      "           27.6645],\n",
      "         [ 25.1714, -36.9712, -46.5983,  54.1089, -18.5804,  35.7017,  -7.5398,\n",
      "           14.9090],\n",
      "         [  9.1921, -15.2502,  27.5184,  35.4837,  -1.1885,   6.6067,  -5.2625,\n",
      "          -35.3798],\n",
      "         [ 45.1843, -49.3905,  16.5610, -33.4318,  -1.6321,   6.2505, -24.7306,\n",
      "           45.9976],\n",
      "         [ -8.9648, -21.3402, -24.6501, -32.8422,  -9.2770,  25.5142, -17.2078,\n",
      "          -54.9326],\n",
      "         [ -1.4797, -38.3065,  34.1572,  40.3201,  29.1551,  -0.4157, -18.6632,\n",
      "            9.5865],\n",
      "         [  8.1203,  -0.1675,  -2.0150, -10.2357,  24.2591, -36.4484, -25.2827,\n",
      "          -30.2533],\n",
      "         [  6.1192,   3.5060,  31.6854, -18.2713, -52.2409,  -4.4723, -34.9139,\n",
      "            2.1689],\n",
      "         [-34.7701,  31.7552, -30.5174, -10.9146,  78.1715,  37.3539, -23.3423,\n",
      "          -15.2233],\n",
      "         [ -5.7026,   4.7547,  12.2902, -35.5968, -10.9437,  44.4421, -23.7633,\n",
      "          -21.8752],\n",
      "         [-14.3598, -13.5979,  43.2062,  23.9312,  10.9158, -44.6649,  19.7831,\n",
      "           -3.8492],\n",
      "         [ 16.7503,  52.6899, -22.9148, -10.9760,  49.3198,   3.7684,   7.9191,\n",
      "          -16.5709],\n",
      "         [ -2.4852, -29.3956,  26.6598,   3.7490, -36.8185,  26.8491, -18.0796,\n",
      "          -13.8899],\n",
      "         [  9.4497,  60.5957,   1.0644,  17.1938,  -5.6857,  29.8401,  16.8379,\n",
      "           -5.5428]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.2405, -0.2417, -0.5215,  ..., -0.3198, -0.1753, -0.3412],\n",
      "        [ 0.4063,  0.4289, -0.2566,  ...,  1.0031,  0.0397, -0.0430],\n",
      "        [ 0.1082, -0.3881, -0.1138,  ...,  0.3400, -0.7978, -0.4822],\n",
      "        ...,\n",
      "        [-0.2684, -0.0704, -0.0208,  ..., -0.7272,  0.1452,  0.2279],\n",
      "        [ 0.4947, -0.0751,  0.1485,  ...,  0.6258,  0.8168,  0.0326],\n",
      "        [ 0.1623, -0.2261,  0.3191,  ...,  0.3033,  0.2588, -0.9089]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[ 8.9927e-01,  4.1095e+00,  5.7831e+00,  1.2107e+01, -1.1992e+00,\n",
      "          -1.5318e+00,  1.3162e+01,  2.8417e+01],\n",
      "         [ 5.2445e-01,  4.5049e+00, -6.0761e+00,  7.9817e+00,  6.1613e+00,\n",
      "          -3.4926e+00,  4.6004e-01,  7.3513e+00],\n",
      "         [-1.5373e+01, -2.1153e+01, -1.4490e+01,  5.4051e+00,  1.2884e+01,\n",
      "           1.7677e+01,  5.5193e+00,  2.1509e+00],\n",
      "         [ 3.1156e+00, -4.0580e-01, -3.9150e-03, -5.0403e+00, -9.7382e+00,\n",
      "          -1.4231e+01,  2.6961e+01, -4.1718e+00],\n",
      "         [-1.3006e+01, -1.5371e+01, -2.0135e+01,  1.9259e+01,  1.2510e+01,\n",
      "          -3.3425e+00, -1.8405e+00, -2.2766e+01],\n",
      "         [ 1.1432e+01, -1.6536e+01,  2.6158e+01, -2.2364e+01, -4.7310e+00,\n",
      "           3.1085e-01, -1.5557e+01, -1.3667e+01],\n",
      "         [ 2.2623e+01, -1.0980e+01,  1.7200e+01,  3.7752e+00, -3.2647e+00,\n",
      "          -6.3211e+00, -1.8910e+00,  1.3039e+01],\n",
      "         [ 4.8185e+00, -2.9195e+01, -7.9803e-01,  1.6270e+01,  5.2282e+00,\n",
      "          -1.2275e+01,  7.4731e+00,  4.3397e+00],\n",
      "         [-1.6393e+01, -4.3818e+00,  9.2592e+00, -1.5904e+01, -2.5170e-01,\n",
      "           4.9802e+00,  1.2570e+01, -1.1002e+01],\n",
      "         [ 2.4536e+01, -1.1353e+01,  7.5516e+00,  2.2271e+01, -4.5467e+00,\n",
      "          -1.4591e+01, -1.9165e+00,  8.6634e+00],\n",
      "         [-1.7499e+00, -5.7385e+00, -2.2408e+00, -7.8968e+00,  4.1032e+00,\n",
      "          -1.6002e+01, -1.2496e+01,  6.1585e+00],\n",
      "         [ 2.5835e+01, -2.1743e+00,  6.1213e+00, -3.8992e+00, -3.1908e+00,\n",
      "          -4.8131e+00, -5.7361e+00, -9.4629e+00],\n",
      "         [-9.3727e+00,  1.2604e+01, -9.6226e+00, -1.4214e+01, -1.1291e+01,\n",
      "          -3.6497e+00, -9.1107e+00, -7.1992e+00],\n",
      "         [ 1.3962e+01, -3.7164e+00,  4.8612e+00, -8.4281e+00,  6.0101e+00,\n",
      "          -1.1002e+01, -1.3924e+01,  1.7446e+00]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.4097,  0.1094, -0.7239,  ...,  0.0830, -0.4839, -1.2226],\n",
      "        [ 0.0913,  0.0284, -0.3866,  ...,  0.5831,  0.1515,  0.8860],\n",
      "        [-0.3761,  0.2165,  0.1152,  ...,  0.0482,  0.5091,  0.0843],\n",
      "        ...,\n",
      "        [-0.3446, -0.2731, -0.5134,  ..., -0.0039,  0.3708, -0.0738],\n",
      "        [-0.1064,  0.2014,  0.0908,  ..., -0.0285, -0.2601,  0.0777],\n",
      "        [-0.3727, -0.3597,  0.7003,  ..., -0.8208,  0.4170,  0.7834]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[ 3.6941e+00, -3.6812e+00,  2.2964e+00, -1.2180e+01,  8.7983e+00,\n",
      "           9.8909e+00,  2.1108e-02, -8.8704e+00],\n",
      "         [-9.1538e+00,  1.7375e+01,  4.7825e+00, -1.8370e+01, -9.9514e+00,\n",
      "          -1.6840e+01, -7.1315e+00, -8.4077e+00],\n",
      "         [ 2.3006e+00, -5.9129e+00, -8.2298e+00, -2.3738e+01, -1.1768e+01,\n",
      "           7.6257e+00,  4.5938e+00, -3.6211e+00],\n",
      "         [-1.4457e+01, -1.2395e+01, -2.6846e+01, -7.1592e+00, -1.1894e+01,\n",
      "          -8.3507e+00, -2.5160e+00,  3.5780e+00],\n",
      "         [ 3.3245e-01,  2.2243e+01,  6.4562e+00, -2.0524e+01,  3.2692e+00,\n",
      "          -2.7737e+00,  5.2312e+00, -1.4695e+01],\n",
      "         [ 4.6455e+00,  1.0526e+01, -5.3508e+00,  7.2784e+00, -1.0931e+01,\n",
      "          -1.8098e+00,  1.0995e+01,  7.3507e+00],\n",
      "         [ 1.6088e+01, -1.2454e+01,  2.3597e+01, -5.0798e+00,  1.7935e+01,\n",
      "          -8.4766e+00, -2.2874e+01,  7.3172e+00],\n",
      "         [-3.0822e+01, -4.9099e+00, -1.6038e-01, -7.4489e+00,  1.0618e+00,\n",
      "          -2.3683e+01, -6.1980e+00, -3.0984e+00],\n",
      "         [ 9.1903e+00,  7.7719e-01,  9.7076e+00, -1.5123e+01,  3.8421e+00,\n",
      "          -2.3265e+00, -5.3088e+00, -1.5485e+01],\n",
      "         [-1.1387e+01,  8.3076e+00, -9.2473e+00,  7.8805e+00,  1.1977e+01,\n",
      "           6.4894e+00,  1.3453e+00, -1.0714e+01],\n",
      "         [ 5.2686e+00,  8.8892e+00,  2.5740e+01, -2.7469e+00, -6.2151e+00,\n",
      "           4.9392e+00,  9.8827e+00, -1.2219e+01],\n",
      "         [ 6.0440e+00,  1.1202e+01,  7.8036e+00,  3.9006e+00,  7.9314e+00,\n",
      "          -1.4455e+01, -7.1726e+00, -3.7630e+00],\n",
      "         [ 1.4324e+01,  4.2431e+00, -1.1048e+01, -1.0300e+01, -1.1737e+01,\n",
      "          -1.8167e+01,  2.9029e+00, -2.8618e+00],\n",
      "         [-3.0866e+00, -1.0450e+01, -2.2107e+01, -8.4033e+00,  1.4505e+00,\n",
      "          -1.4402e+01, -7.5283e+00,  1.1085e+00]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.4412,  0.2533, -0.5564,  ..., -0.3803,  0.4192,  0.2886],\n",
      "        [ 0.2664, -0.1921, -0.6620,  ..., -0.1799, -0.1042,  0.0411],\n",
      "        [ 0.2170, -0.2380,  0.6202,  ..., -0.2681, -0.2088, -0.5215],\n",
      "        ...,\n",
      "        [-0.0686, -0.1395, -0.2395,  ...,  0.0344, -0.1889,  0.1819],\n",
      "        [ 0.1995,  0.5152,  0.6308,  ...,  0.0068,  0.1221,  0.2453],\n",
      "        [-0.3523, -0.8831,  0.0643,  ...,  0.1149, -0.5942,  0.4003]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[-16.4061,   9.0858,  13.3327,  -1.3872, -18.0090,   6.8459,  -6.5622,\n",
      "          -11.0226],\n",
      "         [ 17.2781,   0.7726, -20.7048,  28.2531,  56.3526,   7.8829,  20.6346,\n",
      "           34.2132],\n",
      "         [  6.7148, -21.0652, -79.1910,  -4.9237,   9.6568,  -4.9728,   7.9241,\n",
      "           -3.2751],\n",
      "         [ 17.9202,   4.2132,   2.4449, -19.5454, -48.8734,   4.2455,   5.8793,\n",
      "           -7.8002],\n",
      "         [ 21.3534, -13.6089, -12.7944,  31.4029,  23.7766,  -0.9125, -21.5506,\n",
      "           -5.7641],\n",
      "         [-36.5903, -48.2252, -22.6814,  11.0205,   9.9889,  48.1645,  38.9172,\n",
      "           25.5511],\n",
      "         [ 22.2993, -22.2198,  31.0875,  44.2706,  -4.6431,  -0.7045,  22.4494,\n",
      "           10.8974],\n",
      "         [  3.7019, -15.0069, -46.4796,  28.4974, -10.6995,  16.6819,  -2.5381,\n",
      "          -28.9818],\n",
      "         [  6.9233,   2.5708,  13.8074,  34.8183,  24.2152,  28.4268,   3.9183,\n",
      "           18.5103],\n",
      "         [ 20.7701, -18.3391, -10.8315, -30.9417,  -5.5388, -16.1827,  21.7393,\n",
      "          -24.1670],\n",
      "         [-12.2848, -16.5684,   7.7593,  -2.5405,   7.2188,  13.3641,  44.0546,\n",
      "            1.8885],\n",
      "         [-10.8105,   2.3662,  52.2491, -26.8616,   3.5521,  -0.6737, -51.2674,\n",
      "            1.2702],\n",
      "         [-32.8187, -11.6733, -20.2934, -15.4616, -41.7774,  -7.7392,  34.0446,\n",
      "            9.3771],\n",
      "         [  2.8680,  39.5300, -29.9962,  12.3753, -21.1477,  10.1874,   1.3953,\n",
      "           -1.6692]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.1939, -0.2385,  0.0146,  ...,  0.2630,  0.0389,  0.2311],\n",
      "        [ 0.1346, -0.0539,  0.3340,  ...,  0.1945, -0.3963,  0.2232],\n",
      "        [-0.3951,  0.2755, -0.9658,  ...,  0.2153,  0.6384,  0.1642],\n",
      "        ...,\n",
      "        [-0.4427, -0.8658, -0.4576,  ...,  0.4220, -0.0900,  0.1524],\n",
      "        [ 0.1685, -0.2614, -0.1642,  ..., -0.3946, -0.1271, -0.7755],\n",
      "        [-0.3201,  0.5394, -0.7000,  ..., -0.4905,  0.1524,  0.0604]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[   5.8642,    1.1146,    1.9657,  -16.4193,  -28.2086,  -40.4424,\n",
      "           -33.0274,   63.7354],\n",
      "         [  55.5010,    6.6607,  -44.2870,   70.2868,   -8.8249,  -21.3376,\n",
      "            40.9966,    6.8349],\n",
      "         [ -14.2845,  -60.5720,   23.1581,  -20.5935,  -95.7256,  -74.2717,\n",
      "             0.6506,   30.3072],\n",
      "         [ -95.3607,   -9.9116,   38.8378,  -28.2909,   44.6117,  -30.3986,\n",
      "            22.1674,   20.9808],\n",
      "         [ -52.7210,   62.9100,   15.8876,   -5.8957,  -39.9413,   10.0058,\n",
      "            34.7565,   52.0978],\n",
      "         [ -18.2783,  -57.3972,   76.3403,   72.1002,   79.0525,   13.6884,\n",
      "           -28.2526,   12.8025],\n",
      "         [  32.6000,  -39.1978,  -28.2264,   19.4426,  -56.5314,  -13.0217,\n",
      "            34.7477,   19.8482],\n",
      "         [  -2.5006,   -3.5767,  -35.5511,   19.4806,   16.3341, -103.2238,\n",
      "           -69.7908,  -12.7280],\n",
      "         [  54.5366,  -33.5976,   14.4458,   56.3125,  -39.8211,  -13.8191,\n",
      "           -49.3505,   10.3057],\n",
      "         [  12.4679,   49.9072,   -1.5792,   65.0155,   15.2500,   36.2522,\n",
      "           -33.2903,   27.3231],\n",
      "         [  22.1093,  -97.4950,   25.7727,   74.4610,  -19.9795,   35.7256,\n",
      "           -40.5549,   29.3267],\n",
      "         [ -23.4493,  -32.4111,  -71.6369,  -64.7886,   14.8526,   31.1894,\n",
      "            14.2542,  -39.3893],\n",
      "         [ -33.5514,   41.7786,   41.5763,   10.5710,  -43.6520,   13.8125,\n",
      "           -22.7816,   22.6843],\n",
      "         [  -1.6310,   -6.5744,   31.9362,   35.7387,   35.9996,   -0.6315,\n",
      "           -10.2536,   -1.1145]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[-0.4104, -0.2820,  0.4523,  ...,  0.2691,  0.3394,  0.0632],\n",
      "        [ 0.6628,  0.5592,  0.2027,  ...,  0.1879,  0.1023, -0.0036],\n",
      "        [ 0.7857,  0.3166,  0.5240,  ..., -0.1168,  0.1168, -0.2006],\n",
      "        ...,\n",
      "        [ 0.2340, -0.2013,  0.2693,  ...,  0.0217,  0.5157,  0.4138],\n",
      "        [-0.0268, -0.3400, -0.3284,  ..., -0.1047,  0.0311, -0.3465],\n",
      "        [ 0.0499,  0.1079, -0.3712,  ...,  0.2292,  0.8690, -0.0533]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[ 38.3024,   1.6449,  43.5533,   5.0594,  35.3429, -29.9582, -40.7131,\n",
      "          -22.2129],\n",
      "         [ 12.4436,  12.6325,  18.1209,  27.7525, -29.2650,  -5.0991,  39.9156,\n",
      "           49.0422],\n",
      "         [-45.8585,  74.1721,  -2.8745, -65.1490, -20.7070, -25.3935, -56.3778,\n",
      "          -24.5713],\n",
      "         [-45.7327,  40.0432,  -4.3386,  15.2219,  45.3433,  74.4000, -50.6693,\n",
      "          -42.2918],\n",
      "         [ 25.7899,  14.4516,   5.5928,  -3.1683,  30.7863, -14.9033,   6.0309,\n",
      "            7.6313],\n",
      "         [-46.3721,  -4.2029, -42.3737, -42.6017,  21.7232, -30.8795,   3.8382,\n",
      "           11.2206],\n",
      "         [ -2.2920,  67.9355,  38.4318,  31.6898, -23.8404,  63.0436,  19.4778,\n",
      "           53.6275],\n",
      "         [ 21.3995,   6.7216,  25.2074,  59.3453, -27.4338, -19.9662,  29.7580,\n",
      "          -60.4625],\n",
      "         [ 45.6033,  21.9746, -21.2515, -37.5522, -47.0226, -11.5769,  38.5376,\n",
      "           29.6042],\n",
      "         [ -2.9258, -60.8493,  75.1064, -17.7021, -10.3873, -23.0788,  30.4863,\n",
      "          -13.3430],\n",
      "         [-29.3269,  11.3760,  45.4447,  20.9949, -62.2212, -49.7513,  24.6452,\n",
      "            8.5898],\n",
      "         [  1.9294,  77.2005,  22.6588,   3.5458, -84.8564,  49.1385, -50.5572,\n",
      "           -3.6211],\n",
      "         [-53.2063, -44.9192, -23.8432, -64.6918,  12.0272, -13.0030, -65.3840,\n",
      "          -70.6225],\n",
      "         [ 66.1311,   8.4818,  17.0672, -84.3102,  -0.8613,  -3.1603, -45.2192,\n",
      "           -6.8229]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=14336, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[-0.2582, -0.1012,  0.3110,  ...,  0.2217,  0.1313,  0.9178],\n",
      "        [ 0.4977, -0.2065, -0.1488,  ...,  0.1930,  0.0499,  0.2752],\n",
      "        [ 0.5488,  0.2618,  0.5401,  ...,  0.3726, -0.2060, -0.1745],\n",
      "        ...,\n",
      "        [-0.4232,  0.7214,  0.4140,  ..., -0.2306, -0.5846, -0.6314],\n",
      "        [ 0.0793, -0.7906,  0.0868,  ...,  0.1269,  0.0690, -0.7826],\n",
      "        [ 0.0191,  1.0892,  0.0432,  ...,  0.8048, -0.0629, -0.1325]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[ 22.8337,  10.9849,  -3.7193, -21.0951,  -0.3733, -12.6881,  17.0890,\n",
      "           22.3293],\n",
      "         [-26.6539,  39.4629,  12.4062, -25.9145,  26.3561,  17.5410, -17.0409,\n",
      "           34.6419],\n",
      "         [  8.7163,  28.6385,  16.1631,  -2.6813, -55.4216,  21.8737,  -5.8149,\n",
      "          -16.0891],\n",
      "         [  9.8815,  47.4897, -13.1155,  13.4008,  -2.6801,   1.3563,   8.5525,\n",
      "          -33.6959],\n",
      "         [-21.6410,  -2.1190,  16.9492, -32.9108, -11.8777, -10.7669,  46.6224,\n",
      "          -19.0809],\n",
      "         [ 36.5326,  -0.6864, -16.2797,   9.5888,  -0.1784,  18.8233,   9.4529,\n",
      "            2.3106],\n",
      "         [ 10.5974,  59.9773, -25.3505,  -7.6527, -19.2215,  28.6940,  62.6064,\n",
      "          -26.5886],\n",
      "         [ 15.2286, -12.1139, -14.3136, -15.8900,  14.3912,  -9.2421,  11.7556,\n",
      "           -2.4199],\n",
      "         [  1.9050,  -7.2768, -39.1744,  -9.1961,   4.4415, -13.8756,   5.2555,\n",
      "          -25.8465],\n",
      "         [  6.5745, -19.0919,   4.9441,   1.2269,  -5.0365, -18.2767,   3.6930,\n",
      "           17.9227],\n",
      "         [ 10.3810,   8.6615, -11.7528,  10.1576, -22.1612,  -0.8625,  21.3041,\n",
      "           -0.1726],\n",
      "         [  7.9875,  -0.4061, -10.5011,  12.3839,  33.9040,  26.6860, -59.7949,\n",
      "            4.3884],\n",
      "         [  4.9049,  -6.5610, -51.4893,   8.1324,  17.3739, -21.5840,   9.5440,\n",
      "           32.0149],\n",
      "         [-65.0946, -39.3011, -27.3821, -17.7773,  20.6803, -39.1988, -11.8019,\n",
      "           -4.7301]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[-0.1424,  0.0941, -0.2071,  ..., -0.0159, -0.2070,  0.0043],\n",
      "        [ 0.0537,  0.0174,  0.0751,  ..., -0.3417,  0.0168, -0.1383],\n",
      "        [ 0.4909,  0.1627, -0.1797,  ...,  0.5059,  0.6059,  0.2580],\n",
      "        ...,\n",
      "        [-0.3390,  0.1494,  0.0611,  ..., -0.2430, -0.0882, -0.3371],\n",
      "        [-0.2846, -0.3642, -0.2258,  ..., -0.1457,  0.1592, -0.0971],\n",
      "        [ 0.1859, -0.2731,  0.0450,  ..., -0.1695,  0.0204, -0.3489]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[  2.9272,  -5.4713, -24.3944, -13.9638,   6.3187, -14.4492,  -5.6295,\n",
      "          -18.5959],\n",
      "         [-33.5498,  -8.3523,   8.1558, -10.1006,  24.6711,  -2.5570,   5.7132,\n",
      "           16.9606],\n",
      "         [  4.5962,  35.5139,   1.9084, -23.0420,   5.2247, -32.2277, -37.6502,\n",
      "          -24.0776],\n",
      "         [-29.4233,  -7.9714, -17.9255, -24.7692, -14.1260, -26.2733,   1.7695,\n",
      "           18.0654],\n",
      "         [ -8.9281,  -8.3412,   9.6978,  38.9305, -37.0681, -13.3426,  10.7608,\n",
      "          -10.1867],\n",
      "         [ 46.6138, -55.8948,   8.6751, -17.5743,  29.4399, -13.7597,  -3.2917,\n",
      "          -25.0878],\n",
      "         [ 55.6868,   7.6645,  -2.6545,  24.3567,  -1.4943, -39.5719,  22.8205,\n",
      "           36.7646],\n",
      "         [ 23.0057, -14.8397,   6.3155,  26.0811, -26.9828, -25.9053,   7.4590,\n",
      "          -56.0901],\n",
      "         [ 11.0010,   4.0412, -36.2178,  27.5798,  45.2051,   2.0692,  -0.1434,\n",
      "           35.5051],\n",
      "         [ 19.3301,   6.8336,  23.1317, -16.1561,   9.6295, -24.9947,  10.4083,\n",
      "           37.3978],\n",
      "         [  6.5670, -19.1259, -57.6085,   1.4279,   3.7970,  41.1710,  14.0181,\n",
      "          -17.9944],\n",
      "         [-13.5389, -11.9783,  15.8419, -20.8029,   0.7718, -12.3622,   6.5119,\n",
      "           10.3694],\n",
      "         [ 22.7390,  13.5927,  17.2632,  -6.1598,  -4.8648,   0.4169,  18.3021,\n",
      "           13.4140],\n",
      "         [-12.3752,  25.5616,  11.3487,  18.2876, -19.0799,   8.3067,   7.3138,\n",
      "          -52.5036]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.1503,  0.1204,  0.0128,  ...,  0.2134, -0.3431, -0.4180],\n",
      "        [ 0.2251,  0.1134,  0.3195,  ...,  0.8734, -0.7361,  0.1525],\n",
      "        [ 0.4884,  0.2819, -0.0276,  ...,  0.0044,  0.1086,  0.2298],\n",
      "        ...,\n",
      "        [ 0.3957,  0.0988, -0.1312,  ..., -0.3480, -0.1211,  0.6820],\n",
      "        [-0.1815, -0.6824,  0.0880,  ...,  0.3192, -0.5401,  0.1977],\n",
      "        [ 0.8643, -0.0099, -0.6124,  ...,  0.6622,  0.5693, -0.2443]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[-1.1566e+01,  1.5962e+01,  5.9608e+00, -3.5778e+00, -2.4032e+00,\n",
      "          -4.0639e+00, -5.2760e+00, -4.5080e+00],\n",
      "         [ 1.1389e+01,  5.7516e+00,  2.7494e+00,  6.3906e+00, -1.2156e+01,\n",
      "          -7.3974e+00,  1.2237e+01,  2.2662e+00],\n",
      "         [-3.1438e-01,  1.2396e-01,  6.8005e+00,  1.1830e+01,  7.1560e+00,\n",
      "          -4.5819e-04,  6.0722e+00, -1.6363e+00],\n",
      "         [-9.9559e+00, -8.4579e+00,  1.8032e+00, -1.6104e+01, -1.9933e+01,\n",
      "           3.1705e+00, -1.3772e+01,  5.6787e+00],\n",
      "         [ 3.9500e+00, -8.9852e-01,  1.0876e+01, -1.0030e+01,  2.0032e+01,\n",
      "           3.4615e+00, -2.3525e+01, -2.7136e+01],\n",
      "         [ 1.1630e+01, -3.0969e+00, -3.5103e+00,  4.8307e+00,  1.3769e+00,\n",
      "           1.0962e+01,  5.1104e+00,  8.1313e+00],\n",
      "         [-5.1140e+00, -6.0014e+00,  2.3559e+01,  1.3117e+01,  2.3439e+00,\n",
      "           1.4855e+01, -1.3944e+00, -1.7453e+01],\n",
      "         [ 5.5159e+00, -2.7798e+00,  4.6179e+00, -1.6182e+01, -7.6794e+00,\n",
      "           1.1014e+01,  7.0485e+00, -1.1129e+01],\n",
      "         [-3.5829e-01,  1.5251e+01,  4.4165e+00,  8.1874e-01,  3.2730e+00,\n",
      "           2.1773e+00,  1.4903e+01, -1.9876e+00],\n",
      "         [-2.2087e+01,  1.1459e+01,  4.0047e+00, -4.5236e+00,  6.0277e+00,\n",
      "          -9.3166e+00, -2.2456e+01, -4.0823e+00],\n",
      "         [-1.1720e+01, -1.0842e+00, -2.1603e+01,  7.5945e+00,  1.7908e+00,\n",
      "           3.1817e+00,  9.5980e-01, -1.0669e+01],\n",
      "         [-5.9805e-01,  1.1418e+01,  9.5467e+00, -1.1866e+00,  4.0273e+00,\n",
      "           9.4176e-01,  4.4911e-01, -1.3463e+01],\n",
      "         [-7.5706e+00, -9.2019e-01, -1.5363e+01,  1.0794e+01,  2.7423e+00,\n",
      "          -1.0570e+01,  1.7416e+01, -2.9759e+01],\n",
      "         [-4.7057e+00, -3.4206e+00,  1.5169e+01,  1.1808e+01,  1.6788e+01,\n",
      "          -1.4517e+01,  1.3212e+01,  1.8165e+01]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[-0.0574, -0.3666,  0.1990,  ...,  0.1580, -0.1570, -0.6070],\n",
      "        [ 0.4393,  0.8347,  0.1673,  ...,  0.7088, -0.2965, -0.0732],\n",
      "        [-1.2175, -0.4916,  0.4762,  ...,  0.3164,  0.1659,  0.1111],\n",
      "        ...,\n",
      "        [-0.2988,  0.7513, -0.1331,  ...,  0.2304, -0.4611, -0.5792],\n",
      "        [ 0.2028, -0.2069, -0.3639,  ..., -0.0632, -0.3037,  0.1221],\n",
      "        [ 0.1926, -0.1099, -0.1207,  ...,  0.2912,  0.2603,  0.1802]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[ -3.5533, -11.0705,  -4.6235,  -0.8534, -15.1177,   8.1109,  -0.9034,\n",
      "            6.6300],\n",
      "         [  2.6812,  13.6888,  -6.3416,  -0.6043,   9.0196,  -2.5144,   7.9731,\n",
      "           -0.3763],\n",
      "         [ -2.8285,   3.0612,   8.2454,  -3.3439,  -0.6983,   2.5758,  -9.7125,\n",
      "           -1.7320],\n",
      "         [ -1.3436, -10.3093,  10.3884,  -3.2344,  11.0645,  -6.6236, -18.3116,\n",
      "           10.8408],\n",
      "         [  2.8072,  -6.6135,   3.0399,   5.3057,   7.9441, -11.8906,  -1.6931,\n",
      "           11.3307],\n",
      "         [ 20.0965,   8.4418,   9.6702,  15.5965,   2.6740, -13.1728,   3.0331,\n",
      "          -11.6502],\n",
      "         [  2.2831,   5.2298,   1.1348,   8.6703,   7.0753,   9.4920, -12.2583,\n",
      "           -6.4299],\n",
      "         [-10.5957,   0.9228,  34.5204, -12.1013,  -2.9238,   4.5772,  -7.6712,\n",
      "            2.0174],\n",
      "         [-19.5834,  19.3421,  13.4222,   9.9025,   4.6083,   3.4852,   2.9764,\n",
      "            5.6469],\n",
      "         [ -1.4103,  -3.0806,  13.6375, -14.4215,  12.3658,   1.9278, -10.6627,\n",
      "           -9.5526],\n",
      "         [ -0.3397,  -5.1727,  -6.1122,  17.8239,  -4.1573,   3.5842,   6.0213,\n",
      "           -6.2615],\n",
      "         [  8.0515,  -4.6906,  10.5453,  -8.1231,  -8.3707,   3.1552,   4.9820,\n",
      "           -7.0156],\n",
      "         [ 15.9643,   9.3888,  18.9967,  14.4285,  -2.7880, -10.3216,  -2.1299,\n",
      "          -18.7094],\n",
      "         [ -0.0591, -11.3094,  -3.8078,   3.4473,  17.1903,   2.3373,  22.2131,\n",
      "           -0.0815]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.2559, -0.3376, -0.0466,  ...,  0.4329, -0.8855,  0.0866],\n",
      "        [-0.1170,  0.2644,  0.7608,  ..., -0.1647,  0.2936,  0.2008],\n",
      "        [-0.3695, -0.1255, -0.3971,  ...,  0.3523, -0.1438, -0.0097],\n",
      "        ...,\n",
      "        [-0.0397, -0.2996, -0.0905,  ...,  0.5062,  0.1680,  0.3633],\n",
      "        [ 0.0603, -0.0784, -0.4679,  ...,  0.0965,  0.1976, -0.7165],\n",
      "        [ 0.0920, -0.7343, -0.5456,  ..., -0.5148, -0.0441, -0.1414]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[  3.0652, -18.7589, -34.7895,   8.2454, -28.6878,  -2.8005,  -0.3053,\n",
      "            6.4591],\n",
      "         [  2.5748,  17.2583, -22.6433,  16.8597,  37.2317, -32.4480,  64.8433,\n",
      "          -38.9508],\n",
      "         [-14.6198, -27.7637,   2.9874,   4.5734,  10.9319, -29.2073,  14.4898,\n",
      "           23.7686],\n",
      "         [ 20.1838, -25.6660,  17.4604, -29.0193,  12.6248, -34.9487, -38.0859,\n",
      "           19.0898],\n",
      "         [ 27.2286, -39.0757,  60.2959,  11.6590,  -3.6200,  -3.7320,  -3.4478,\n",
      "           12.8015],\n",
      "         [ 12.9893,  13.3704,  14.6200,  27.0382,  13.6405, -30.9148, -46.6887,\n",
      "           23.1562],\n",
      "         [ -1.9174, -22.5640,  37.0725,  10.3194, -45.1416,  -9.0396, -28.9438,\n",
      "          -26.0342],\n",
      "         [ 32.5595,   0.5566,  -0.4361,   3.0437, -18.5135, -11.5624,   5.7322,\n",
      "           28.3172],\n",
      "         [ 16.8397,  -5.1420,  -4.2396, -29.2330,  15.6966, -26.5808, -13.7714,\n",
      "          -25.4139],\n",
      "         [-29.9685, -14.3252,  -6.8739,  22.9264,  -5.4814,  -5.3108,  25.8175,\n",
      "          -20.0759],\n",
      "         [-23.6011, -27.8677, -25.5601,   2.9553, -11.3971,  -3.0221,   8.6555,\n",
      "          -41.4423],\n",
      "         [ 19.6758,  24.5607, -42.3819,  10.1516, -34.3876, -21.1029,  41.8052,\n",
      "          -24.0061],\n",
      "         [  3.6421,   8.0206, -13.1803,  19.6705,  -4.6347,  -1.7728,   9.3964,\n",
      "          -11.4951],\n",
      "         [ 33.2130,  57.8407, -52.1436, -25.3402,  12.4700,  13.1509,   9.2437,\n",
      "           15.6038]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[-0.0997,  0.1347, -0.2685,  ..., -0.6302, -0.2064, -0.6113],\n",
      "        [-0.2179, -0.0917,  0.4627,  ...,  0.0137, -0.3132, -0.4161],\n",
      "        [-0.4108, -0.2375,  0.2819,  ...,  0.4908, -0.1247,  0.5378],\n",
      "        ...,\n",
      "        [-0.4680,  0.5201, -0.2018,  ...,  0.0444, -0.4701,  0.0570],\n",
      "        [ 0.0331,  0.1623,  0.3430,  ..., -0.4450, -0.5506,  0.1552],\n",
      "        [ 0.1060, -0.3534, -0.0342,  ...,  0.1887, -0.4020, -0.1700]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[ -17.4303,   21.0921,   37.7998,    4.6962,  -16.4542,   -6.2213,\n",
      "            18.8073,   51.6935],\n",
      "         [ -40.1630,   30.0189,   46.2526,  -71.3937,    6.6826,  -19.0022,\n",
      "           -19.0380,   34.2083],\n",
      "         [ -50.4271,   55.6815,   38.8550,   14.0128,  -18.0821,  -27.4965,\n",
      "           -63.3201,   86.7269],\n",
      "         [ -29.0305,   -2.2313,  -10.8123,  -76.2997,  -50.2340,  -45.5609,\n",
      "           110.6171,  -36.8129],\n",
      "         [  33.7867,  -19.3603,   17.2814,  -12.1807,   45.7502,    6.4904,\n",
      "            -7.6600,    4.1574],\n",
      "         [  18.9001,   19.4862,   65.9508,    8.9817,  -51.5361,   32.6818,\n",
      "           -27.8468,  -73.5501],\n",
      "         [  37.8887,  -19.9480,  -67.3614,  -65.6345,   28.8701,  -20.4667,\n",
      "            -1.7036,  -68.6856],\n",
      "         [-147.8904,   25.3627,   54.9989,   31.3296,  -75.5012,   26.5405,\n",
      "           -16.1929,   -5.8486],\n",
      "         [ -71.8505,   33.6338,  -21.6819,  -19.5693,   24.1715,   27.2002,\n",
      "           -29.5538,   41.5000],\n",
      "         [   4.8441,  -15.4866,  -53.7948,   37.0078,  -11.8489,  -49.4790,\n",
      "            -7.2713,  -38.5789],\n",
      "         [  23.5424,   -5.1185,   -1.9065,   10.2108,    2.0925,  -15.6504,\n",
      "            74.0750,   40.8728],\n",
      "         [   8.5075,  -74.1863,    6.7607,   21.2385,  -39.5259,   25.1368,\n",
      "            39.3182,   37.2289],\n",
      "         [  32.6115,   12.3455,   53.0290,    4.3010,  -16.2133,   26.8010,\n",
      "            84.6466,  -39.0465],\n",
      "         [ -46.3948,  -23.9245,   34.1136,  -47.3641,   -5.4318,  -93.5501,\n",
      "           -41.8431,  -16.8848]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.2454,  0.0369, -0.1634,  ..., -0.2999,  0.3210, -0.5012],\n",
      "        [-0.8354,  0.2922, -0.3057,  ...,  0.3819, -0.1694, -0.4520],\n",
      "        [-0.0523, -0.0871, -0.0998,  ..., -0.6253,  0.1645,  0.1541],\n",
      "        ...,\n",
      "        [ 0.1729, -0.5479,  0.1229,  ...,  0.4084, -0.5771, -0.3034],\n",
      "        [ 0.9295,  0.4162, -0.0321,  ...,  0.2303, -0.3106,  0.4385],\n",
      "        [ 0.3447,  0.0336,  0.0277,  ...,  0.3311,  0.1257, -0.2379]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[  24.5212,  -43.3857,   15.9925,   21.4594,  -22.4008,   -7.0478,\n",
      "            40.6940,   47.3051],\n",
      "         [ -33.6321,    8.2427,   41.7271,   12.4290,  -13.9710,  -44.7493,\n",
      "             3.7703,  -32.9425],\n",
      "         [  35.4035,   30.8055,   77.4570,  -33.7340,  -12.8487,  -79.0922,\n",
      "           -31.7394,  -32.4062],\n",
      "         [ -31.2692,   60.8951,   55.6102,   25.0867,  -91.5330,   38.7284,\n",
      "             6.3927,   -1.0230],\n",
      "         [ -28.4474,   23.6548,  -30.1777,  -57.3292,   16.3193,  -15.7348,\n",
      "             0.1867,  -32.7747],\n",
      "         [  29.2511,   20.8781,   11.9069,   -4.7625,  -45.8465,  -30.7878,\n",
      "           -25.9429,   16.8423],\n",
      "         [  19.9789,  -52.6826,   66.5185,  -24.9267,  -33.6858,   86.8604,\n",
      "             2.3179,   54.1874],\n",
      "         [  21.5990,  -53.1717,   61.8697,   25.0865,   -9.0456,  -35.6481,\n",
      "           -66.0731, -120.8650],\n",
      "         [  70.1068,   -1.7792,    3.8425,  -32.3047,  -33.3769,   26.9736,\n",
      "           -20.2027,   14.4551],\n",
      "         [  19.8520,  -28.0560,  -35.6173,   66.8230,   29.3856,  -56.6905,\n",
      "            58.5708,    6.6830],\n",
      "         [  37.4900,  -98.3921,   28.9960,    8.5265,   60.1292,  -52.1762,\n",
      "            -4.4739,  -40.5592],\n",
      "         [  -2.2025,  -59.2186,  -25.4233,  -61.3079,   45.8015,   -9.2394,\n",
      "            14.7638,  -23.3776],\n",
      "         [  79.0921,   31.0609,    0.2874,   17.6537,   15.1688,   37.6401,\n",
      "            31.6016,  -41.5015],\n",
      "         [  15.5565,  -33.2907,   -0.5642,   -0.1371,   46.3463,  -32.8031,\n",
      "           -31.1866,  -78.3225]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=14336, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.1637,  0.2622, -0.3423,  ..., -0.0644,  0.0593,  0.7187],\n",
      "        [ 0.5473, -0.0957, -0.3338,  ...,  0.5287, -0.9920, -0.2205],\n",
      "        [ 0.1151, -0.2017, -0.1542,  ...,  0.4273,  0.3346, -0.5695],\n",
      "        ...,\n",
      "        [ 0.4640, -0.0589, -0.1891,  ..., -0.2211, -0.4527,  0.0720],\n",
      "        [ 0.2645,  0.5927,  0.5073,  ..., -0.4723,  0.0169, -0.5751],\n",
      "        [-0.4942, -0.0153, -0.2625,  ..., -0.1408,  0.2774,  0.2811]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[-13.4378,   0.6521,  18.0209,  14.0586,  28.2113,   0.0836,  21.0606,\n",
      "          -35.4685],\n",
      "         [-22.1137, -20.3445,  -1.9112, -15.5968,   5.5431,  25.4532, -11.0284,\n",
      "           -5.4721],\n",
      "         [ 22.6285,  27.3744,  -9.7534,  41.2528,  14.1972, -11.5175,   3.5907,\n",
      "           25.8311],\n",
      "         [ 54.9695,  -5.6971,  16.5107,  -0.1780,  12.7964,   4.9860,  22.9060,\n",
      "           33.1135],\n",
      "         [ -3.1861,  22.6680,   2.1697, -43.8586,  -0.8071, -52.5587, -13.3708,\n",
      "            4.2107],\n",
      "         [ 20.5076,  31.2405, -11.1983, -59.5296, -24.1382,  -7.3278, -15.8490,\n",
      "          -34.9955],\n",
      "         [-23.2418, -26.2215,  11.9690, -12.2844, -40.0709,  -4.3778,   0.6118,\n",
      "            6.0439],\n",
      "         [  4.0428,  21.3687,  -4.2334,  -3.1605, -28.8168, -41.4730,  -6.2026,\n",
      "          -21.5650],\n",
      "         [ -6.7899, -11.6891,  16.4789,  -3.6220,  18.3524,  -9.1990,   6.4096,\n",
      "           17.3921],\n",
      "         [-10.4466, -18.0691,  27.2748, -29.3340,  16.0525, -26.8028, -29.1609,\n",
      "           13.7350],\n",
      "         [ 24.6703, -40.0753, -22.2696,  -8.5819,  13.2910,  18.6928,  37.3246,\n",
      "            9.8143],\n",
      "         [-42.5118,  21.5252,  -8.0406,  -2.3728,  22.0465,  -7.1682,   2.0975,\n",
      "           -0.1828],\n",
      "         [ 13.2516, -43.3122,   1.6025, -51.5007,  28.1156, -22.6921,  22.7066,\n",
      "          -36.7998],\n",
      "         [  2.6922, -18.6931,   0.5802,  29.7825, -28.2208, -19.4940,  -7.5540,\n",
      "           17.8463]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[-1.5765e-01,  3.4161e-01,  7.8608e-02,  ..., -6.0824e-01,\n",
      "         -2.1055e-01, -1.8097e-02],\n",
      "        [ 4.1419e-02,  4.8810e-01,  1.5054e-01,  ..., -4.6437e-01,\n",
      "          8.5223e-01, -7.7439e-02],\n",
      "        [-8.3669e-02, -2.3047e-01,  1.3305e-01,  ...,  4.8214e-01,\n",
      "         -2.0178e-01, -6.0072e-01],\n",
      "        ...,\n",
      "        [ 2.6310e-01, -7.5355e-02,  2.4091e-01,  ..., -8.8871e-01,\n",
      "          1.0844e-01,  1.6285e-01],\n",
      "        [ 4.3507e-02, -9.8033e-02, -1.2463e-01,  ...,  5.3946e-01,\n",
      "         -1.2644e-01,  1.1644e-02],\n",
      "        [-3.9108e-01,  3.9739e-01, -1.8106e-01,  ..., -2.4494e-04,\n",
      "         -1.4245e-01,  4.5750e-01]], device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[-33.9716, -13.0855, -34.3097, -31.1597,  -1.8113,  -1.6820,  22.4327,\n",
      "          -21.9013],\n",
      "         [ -9.6163,  24.5787,  34.2850,  -8.0762,  15.1276,  11.6253,  45.2334,\n",
      "           13.4855],\n",
      "         [ 20.4898,  31.9200,  -0.8222,  33.9053,  -1.3061, -10.0765,  42.1133,\n",
      "           -0.9578],\n",
      "         [ 30.7974,  13.0646,  22.3071,  38.1485,  -2.4300,  19.7498,   1.4481,\n",
      "           76.2634],\n",
      "         [  6.9853,  12.5564,  11.8692,  18.5697,  13.9482,  -9.7755,  -7.4767,\n",
      "          -38.5010],\n",
      "         [ 36.9882,  -1.9928, -50.4120,   3.1217,  34.0682,  68.2680, -13.8895,\n",
      "          -20.9460],\n",
      "         [ -0.8687, -10.9390,   3.6528, -52.3711,  -8.2339, -32.0576, -32.7309,\n",
      "           -9.4505],\n",
      "         [ -2.2993,  14.1981,   6.9306,  -9.4835, -16.6407,  31.5878, -52.6171,\n",
      "           14.1834],\n",
      "         [ 34.1277,  22.0977, -28.5897, -38.0916, -40.3049, -24.6826,  33.7467,\n",
      "           16.9344],\n",
      "         [ -3.8498,  43.9157,  27.7332, -19.4036,  -7.2772, -33.3213,  -1.9164,\n",
      "           22.3234],\n",
      "         [ 11.0238, -65.0256,  -5.6794,  61.1650, -13.7347, -11.9234, -15.7158,\n",
      "           29.7750],\n",
      "         [ 13.2615, -16.9035,   9.7249, -11.0906, -24.4593, -45.7701,   6.8363,\n",
      "           18.7416],\n",
      "         [ 21.5560,  -2.9603,  -9.4892,  32.1743,  46.4220, -14.2655,  -5.0738,\n",
      "           21.3883],\n",
      "         [-29.9005,  14.9601,  31.8875,  29.7316,  31.0537,  12.9249,  -0.5641,\n",
      "           10.0959]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[-0.2317, -0.0114,  0.3497,  ..., -0.2441,  0.2013,  0.0266],\n",
      "        [-0.0372, -0.0645, -0.4164,  ...,  0.0371,  0.4471, -0.1987],\n",
      "        [-0.2764, -0.2249, -0.5564,  ..., -0.0341, -0.5711,  0.2160],\n",
      "        ...,\n",
      "        [ 0.0216, -0.3448, -0.6449,  ..., -0.4075,  0.0732,  0.5525],\n",
      "        [ 0.0412, -0.0711, -0.1104,  ..., -0.1764, -0.1875, -0.5039],\n",
      "        [-0.2614, -0.0813,  0.3115,  ...,  0.1556,  0.5933, -0.4593]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[  0.4815, -19.6277,  14.0044, -15.7391,  -7.9032,  -9.9936,  -2.4229,\n",
      "          -16.8245],\n",
      "         [  2.7546,  -0.2302, -12.6225,  -5.9641,   2.6354,  12.3753, -19.4957,\n",
      "            3.1186],\n",
      "         [ -8.7521, -10.6384,  12.4671, -17.2346,  -7.6988, -10.8811,   1.7983,\n",
      "            6.5966],\n",
      "         [  6.2243,   9.7452,  -5.9468, -20.1221, -13.8789, -17.2321,   7.2373,\n",
      "          -10.0825],\n",
      "         [  5.2336,  17.2172, -11.5588, -25.2334,  22.0183, -10.9450,  -7.9324,\n",
      "           16.6784],\n",
      "         [ -1.4071,  12.0471,  -9.9855,  -4.9654,  -0.2435,  -9.3699,   8.3044,\n",
      "            5.1454],\n",
      "         [-16.5020, -24.4149, -21.0946,   2.5038, -14.7571,  -6.4166,  12.0394,\n",
      "          -15.7113],\n",
      "         [  3.6045,   4.2724,   6.6253,   5.1713,  -1.6314,  -1.7702,   7.1765,\n",
      "           -4.2522],\n",
      "         [-17.4757,   1.0111,  -0.0727,  13.0508, -19.6858,   9.4506,  24.2523,\n",
      "          -10.1949],\n",
      "         [  5.0282,   3.9347,  -8.0681,  15.9458, -13.7429, -10.5717, -12.1277,\n",
      "            7.7550],\n",
      "         [ -7.7427, -11.0921,  18.5348, -10.5135,  -4.4856,   1.5926,   6.5380,\n",
      "          -10.2248],\n",
      "         [ -4.8838,   1.9052,   6.9802, -14.5898,  -4.6979,   4.1097,  -8.0821,\n",
      "           -9.2043],\n",
      "         [ 15.9959,  -2.6076,   9.7761,  -6.4677,   0.8866,   7.1021,  -5.9672,\n",
      "           20.9383],\n",
      "         [ -1.9245,   0.5693, -12.8156, -30.0552,   4.4534, -23.0136,   7.8363,\n",
      "          -17.4387]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.4855,  0.4114,  0.3348,  ..., -0.7767,  0.2254,  0.1507],\n",
      "        [-0.7023, -0.0758,  0.3965,  ..., -0.0172,  0.3089, -0.2135],\n",
      "        [ 0.3498, -0.1896, -0.2372,  ..., -0.0146, -0.0627, -0.8492],\n",
      "        ...,\n",
      "        [-0.2169, -0.2078,  0.4914,  ...,  0.3942, -0.1082, -0.0801],\n",
      "        [ 0.1820,  1.0064, -0.4810,  ..., -0.1560,  0.4843, -0.5906],\n",
      "        [ 0.1909, -0.1426,  0.1158,  ..., -0.3467,  0.0172,  0.1712]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[ -3.5227,  17.1961,   8.1434,   8.6725,   3.1842,  15.3285,  24.3711,\n",
      "           -0.8709],\n",
      "         [-11.4172,  -6.5549, -12.1367,   0.8429,  -0.8028, -15.3730,  -1.5709,\n",
      "           -1.4962],\n",
      "         [ 18.8618,  14.7974,  19.2749, -12.3740,   2.3830,  12.6426, -18.9860,\n",
      "            9.0869],\n",
      "         [ -8.6968,   0.9962,  -7.6929, -10.7006, -19.5071,  31.2844,  -7.2422,\n",
      "           -1.5411],\n",
      "         [ -1.5986, -14.4967,  -8.4261,  20.1930,   4.6369,  18.1062,   7.3992,\n",
      "           -6.1472],\n",
      "         [ -9.2808,  10.5736,   3.2382,  -3.4074,   6.4986,  -5.6720, -14.4138,\n",
      "           -2.8071],\n",
      "         [ -6.7418,   6.9371,  -7.1856,  -4.3717,   6.6672,  12.2970,   9.9498,\n",
      "           -6.6269],\n",
      "         [ -2.0041, -12.9355,  -9.9357, -28.3608, -38.7083,   8.1775,  12.1796,\n",
      "           20.7388],\n",
      "         [  1.3953,   1.6674, -10.6146,   8.0058,  17.0840,  12.2830, -18.3218,\n",
      "          -10.7753],\n",
      "         [ -0.2752,  -7.4963,   4.9638,  -2.2437,   3.1924,  -0.2712,  -4.8873,\n",
      "           13.9091],\n",
      "         [ 18.6559,  19.7636,   6.6342, -13.6680,   2.3538, -15.5770,   2.7565,\n",
      "            5.3581],\n",
      "         [ -2.8435,   5.9440,  -3.4266,   8.3538,   3.0808,  -5.3489,  19.7425,\n",
      "           -5.3398],\n",
      "         [  5.8041,   6.1807,   7.7859,  15.0795, -13.0255,  11.6904,  -2.8786,\n",
      "          -22.2916],\n",
      "         [ -5.8785,  10.1458,   4.9323,  -8.2305,  16.4862,  -8.6797,  -8.0242,\n",
      "           -7.9873]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[-0.6187,  0.3883, -0.7432,  ..., -0.1147, -0.6239, -0.2493],\n",
      "        [-0.2855, -0.5789, -0.1588,  ..., -0.8887, -0.2539, -0.5054],\n",
      "        [-0.5453,  0.0908, -0.2635,  ...,  0.2088, -0.7296,  0.2474],\n",
      "        ...,\n",
      "        [ 0.1734,  0.1019, -0.3368,  ...,  0.6129,  0.5641,  0.4622],\n",
      "        [ 0.2407, -0.2927,  0.0561,  ...,  0.2947,  0.4219, -0.8804],\n",
      "        [ 0.6442,  0.2281,  0.0276,  ...,  0.0628,  0.3327, -0.4673]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[-2.4266e+00,  4.2227e+01, -1.1780e+00,  7.2949e+00, -3.3701e+01,\n",
      "           4.5048e+00,  6.9580e+00, -9.5878e+00],\n",
      "         [-3.9247e+00, -4.4147e+00,  1.3062e+01,  4.2560e+01,  4.9422e+00,\n",
      "          -2.6907e+01, -4.8837e+01,  2.7133e+01],\n",
      "         [ 2.3703e+01,  1.1243e+01, -2.9303e+01, -5.2311e+00,  1.1687e+01,\n",
      "           6.3384e+00,  1.1248e+01, -5.8746e+00],\n",
      "         [ 5.8601e+01,  1.3280e+01, -1.3048e+01,  1.0788e+01, -2.8129e+01,\n",
      "           2.3237e+01, -3.3655e+01,  5.4194e+00],\n",
      "         [ 2.7182e+01,  1.6210e+01, -6.5069e+00, -2.7681e+01, -1.5444e+01,\n",
      "          -5.0356e+00, -6.6718e+00,  2.7903e+01],\n",
      "         [-3.4735e+01,  1.2528e+01, -1.8515e+01, -1.5218e+01,  2.2281e+01,\n",
      "          -7.0209e+00,  8.5078e+00, -1.2983e+01],\n",
      "         [ 1.4062e+01, -3.2863e+01, -2.7503e+00, -2.7280e+01, -1.4358e+01,\n",
      "           2.8392e+00, -4.1157e+01,  3.0063e+00],\n",
      "         [-1.9258e+00,  2.0697e+01, -3.9827e+01,  1.7958e+01, -1.0014e+00,\n",
      "          -9.1190e+00,  5.8393e+00,  2.5176e+01],\n",
      "         [-3.4122e+01, -5.4140e+01, -1.7753e+01,  4.1497e+01, -3.9162e+00,\n",
      "          -1.1647e+01, -1.2705e+01,  9.9641e+00],\n",
      "         [ 9.3862e+00,  1.3712e+01,  6.9139e+00, -7.8086e+00, -8.2483e+00,\n",
      "           3.4803e+01,  7.4377e-01,  3.0420e+01],\n",
      "         [ 8.7192e+00, -2.1483e+01, -3.7534e+01, -2.4228e+01, -4.6757e+00,\n",
      "          -4.5688e+01,  4.0513e-02,  8.5057e+00],\n",
      "         [-1.7104e+01, -5.1849e+01,  1.1061e+01,  3.3907e+01, -1.7200e+01,\n",
      "           3.2839e+01,  1.7631e+01, -2.9743e+01],\n",
      "         [-4.9096e+00,  9.5404e-01, -1.2062e+01,  3.1093e+01, -2.1341e+01,\n",
      "          -2.7713e+01, -9.6528e+00,  1.6015e-01],\n",
      "         [ 1.9307e+01,  8.9230e+00,  4.5028e+01,  1.1442e+01,  2.1502e+01,\n",
      "          -2.0389e+00, -1.8714e+01,  5.1689e+00]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.4482,  0.0898,  0.5607,  ...,  0.1124, -0.1072,  0.2161],\n",
      "        [ 0.2627,  0.1705,  0.5729,  ..., -0.3746,  0.0240,  0.2482],\n",
      "        [-0.3352,  0.2055, -0.4510,  ...,  0.1323, -0.4650,  0.1228],\n",
      "        ...,\n",
      "        [ 0.1985,  0.1451,  0.0152,  ...,  0.0306,  0.3298,  0.1186],\n",
      "        [-0.0158,  0.1353,  0.1680,  ...,  0.5901, -0.4281, -0.2010],\n",
      "        [ 0.1087,  0.5643, -0.1678,  ..., -0.0630, -0.3923,  0.8911]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[ 1.1075e+01,  1.8292e+01,  3.3174e+01, -3.0577e+00,  5.6008e+01,\n",
      "           2.2206e+01, -1.1362e+02, -4.0597e+01],\n",
      "         [-5.4423e+01, -5.1473e+01,  7.2853e+01, -2.2520e+01, -1.6494e+01,\n",
      "          -5.9089e+01,  4.0409e+01,  7.0755e+01],\n",
      "         [ 7.6931e+01,  8.4415e+01,  9.2458e+01,  4.0645e+01,  3.3756e+01,\n",
      "          -4.6566e+01, -2.7337e+01, -5.9916e+01],\n",
      "         [-4.6034e+00,  7.9204e+00, -6.6175e+01,  9.7562e+00,  2.9691e+01,\n",
      "           1.2659e+00, -2.8679e+01,  3.8198e+01],\n",
      "         [-5.1635e+01, -3.9225e+01,  3.2331e+01,  1.6472e+01,  6.2361e-03,\n",
      "           2.4462e+01,  6.7985e+01,  5.4704e+00],\n",
      "         [ 1.6039e+01,  1.7898e+01, -9.6419e+00,  5.0884e+01, -2.1130e+01,\n",
      "           4.5262e+01,  2.1791e+01,  6.8593e+00],\n",
      "         [-7.8383e+01,  4.8640e+01,  3.3935e+01,  1.4195e+01,  4.4713e+01,\n",
      "          -2.8312e+01,  7.7436e+00, -2.8174e+00],\n",
      "         [ 7.4368e+01,  3.3335e+01, -2.5929e+01,  2.2062e+01, -9.9325e+00,\n",
      "          -2.4656e+00,  3.2233e+01, -4.7042e+00],\n",
      "         [-1.7617e+01,  5.7955e+01,  1.8145e+01, -3.7102e+01,  1.1283e+00,\n",
      "          -8.1450e+01, -3.2588e+01,  6.8141e+01],\n",
      "         [-4.9091e+01, -2.1860e+01, -3.5428e+00, -3.2493e+01,  4.4162e+01,\n",
      "           1.7877e+01,  3.4062e+01, -3.0408e+00],\n",
      "         [-4.1533e+00,  3.9771e+01,  3.0746e+01,  4.8462e+01,  2.0362e+01,\n",
      "          -7.5920e+01,  2.3858e+01,  5.4029e+01],\n",
      "         [-3.2522e+01, -4.6507e+01,  4.1435e+01,  5.9404e+00,  3.8237e+01,\n",
      "          -2.7890e+01, -1.7601e+01, -3.0403e+01],\n",
      "         [-2.5114e+01, -1.3557e+01,  6.7655e+01, -4.4070e+01,  2.2392e+01,\n",
      "           5.0149e+01, -4.1002e+01, -3.5023e+01],\n",
      "         [ 3.4493e+01,  1.8201e+00,  6.3226e+01,  6.6348e+01,  8.4631e+00,\n",
      "           2.0119e+01,  3.8910e+01,  2.8288e+01]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.2742, -0.0031, -0.4598,  ..., -0.3285,  0.0559, -0.2151],\n",
      "        [-0.1978, -0.4032,  0.1377,  ...,  0.0813,  0.1461, -0.1200],\n",
      "        [-0.9569,  0.1942,  0.7608,  ..., -0.1128,  0.3684,  0.2613],\n",
      "        ...,\n",
      "        [ 0.0927, -0.9100,  0.1399,  ...,  0.2732,  0.0325,  0.1387],\n",
      "        [ 0.3843,  0.8616, -0.4125,  ...,  0.1389,  0.2723,  0.3185],\n",
      "        [-0.2479,  0.0700,  0.2517,  ...,  0.0357,  0.1882,  0.1234]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[  -7.7229,   -6.0395,   51.3511,   -3.4919,   -3.0782,   19.5726,\n",
      "           -54.5361, -110.1437],\n",
      "         [  61.4525,    2.8953,  -19.6242,   92.0539,  -97.2356,  -85.7497,\n",
      "            -4.3971,   -3.3233],\n",
      "         [  29.2411,   17.9989,  -66.5445,  -44.2196,  -29.4307,   22.3850,\n",
      "            18.4827,   50.0248],\n",
      "         [  18.1810,   26.7116,   69.5618,   37.5758,   52.5287,  -32.5242,\n",
      "            28.8500,   26.0242],\n",
      "         [  43.1863,   29.1165,  -26.4596,  -28.4644,    3.3794,   39.3616,\n",
      "           -28.5914,  -15.9994],\n",
      "         [ -16.7284,  -23.4922,   23.7763,   36.0847,  -30.0240,  -33.9150,\n",
      "             0.7379,  -19.1171],\n",
      "         [ -42.2148,   52.4553,  -15.7876,  -47.5841,    6.3733,    8.8769,\n",
      "            54.2773,  -15.8665],\n",
      "         [ -76.4117,    6.0545,   17.1152,   -8.3068,   35.2284,   72.6227,\n",
      "            71.0455,   46.1854],\n",
      "         [  -8.7921,   72.3094,   36.0208,  -14.6832,   19.1322,  -59.1682,\n",
      "            34.5835,   -2.7584],\n",
      "         [  27.1922,  -17.3238,    3.4032,    2.3674,   47.9013,   41.8774,\n",
      "            -4.3625,  -42.9650],\n",
      "         [ -28.3170,  -74.7067,   50.6435,   26.1230,   27.3485,  -68.2744,\n",
      "            41.0606, -118.0105],\n",
      "         [   5.2560,   21.2149,  -47.9979,   65.3176,   26.7957,  -10.5059,\n",
      "            -5.0294,   43.8519],\n",
      "         [ -32.6419,  -81.2590,  -13.5072, -111.4237,  -14.8445,  -11.2691,\n",
      "             5.0201,   14.6976],\n",
      "         [  19.2972,  -41.0329,   52.8189,    0.5257,  -22.6742,  -59.7427,\n",
      "             5.6777,  -20.6127]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=14336, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[-9.5634e-01,  6.1137e-01, -1.7967e-02,  ..., -1.4060e-01,\n",
      "         -2.8280e-01, -2.3368e-01],\n",
      "        [ 5.5298e-01,  5.3839e-01, -7.2924e-02,  ..., -3.5868e-02,\n",
      "         -1.8128e-01,  1.7734e-02],\n",
      "        [-3.9192e-01,  1.3806e-01, -2.6609e-01,  ..., -2.8540e-01,\n",
      "         -4.2738e-02, -4.0647e-01],\n",
      "        ...,\n",
      "        [-2.4187e-01,  6.5256e-04,  9.3902e-02,  ..., -4.8572e-01,\n",
      "         -5.2064e-01,  2.7367e-01],\n",
      "        [ 3.0508e-01, -4.2313e-01,  1.3116e-01,  ..., -4.0863e-02,\n",
      "         -1.2179e-02, -2.6886e-02],\n",
      "        [ 1.3290e-01,  8.6321e-03,  3.5263e-01,  ...,  7.0141e-01,\n",
      "          2.3972e-01, -4.2365e-01]], device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[ -3.5410, -36.0383,  14.5191,  45.8681,  -0.5608, -37.4132, -16.6137,\n",
      "           15.2082],\n",
      "         [ 24.4881,  -2.9506, -25.8863, -30.8347,  -5.2529,   5.1285, -11.2328,\n",
      "           16.2669],\n",
      "         [ -0.4302,  -6.0583,  10.9817,  24.0114,  27.9189,  39.1807,  41.7432,\n",
      "          -16.9235],\n",
      "         [ -2.7387, -42.1869,  14.3779, -23.4615,  13.8932,  37.5214, -22.9419,\n",
      "           -2.2650],\n",
      "         [  8.3952,  -2.6209,  47.4825,  42.9479, -17.7959,  21.7372, -17.9025,\n",
      "           -7.3771],\n",
      "         [ 19.9852,   3.7227, -12.8935,  -7.0017,  14.3111, -21.0385,  -5.7277,\n",
      "          -22.1002],\n",
      "         [-39.3519,  -7.3753,  24.3269, -48.7247,   0.2345, -19.6258,  16.4659,\n",
      "          -10.8437],\n",
      "         [-28.8417, -40.0207, -17.2733,   6.4587,  26.9773,   4.2131, -22.0071,\n",
      "           24.1961],\n",
      "         [ 16.8401, -38.0334, -18.0709, -41.4021, -47.6002,  15.5531, -14.7183,\n",
      "          -21.4560],\n",
      "         [ 13.1113,  16.0611,   0.9316,  -7.4755,  30.0218,  -9.9413,  25.6693,\n",
      "          -38.6379],\n",
      "         [  3.0209,   8.1678,  -2.5112, -12.9205, -18.2458,  -3.2516, -14.0058,\n",
      "           -5.8898],\n",
      "         [-38.9430,  -6.2523,  -3.2815,  -4.2934,  14.4641, -25.9051,  12.3628,\n",
      "           28.9306],\n",
      "         [-11.1712,  47.2411,  -0.6589,  -5.9911,  -2.6192,   7.1001,  14.4609,\n",
      "           16.4722],\n",
      "         [ -6.6695, -24.0063, -12.9921, -24.2048,  19.4886,  13.0180, -15.6804,\n",
      "           -9.7471]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[-0.2484, -0.0495,  0.7390,  ..., -0.4610, -0.4221,  0.4075],\n",
      "        [ 0.2071, -0.3068, -0.1448,  ...,  0.5860, -0.2982,  0.3433],\n",
      "        [ 0.4652,  0.9369,  0.1857,  ..., -0.1729,  0.1917, -0.2212],\n",
      "        ...,\n",
      "        [-0.1323, -0.3320, -0.2024,  ...,  0.0853, -0.3117,  0.0290],\n",
      "        [-0.1076,  0.0186, -0.2567,  ..., -0.2428, -0.3352, -0.3284],\n",
      "        [ 0.3206, -0.4333, -0.3729,  ..., -0.5266, -0.1674, -0.3387]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[ -6.6523,  56.4460,   3.4259,  30.4037,  27.6614,   7.3451, -17.1284,\n",
      "           16.4546],\n",
      "         [ 20.1293, -21.5179, -23.1588, -21.4627,  17.0753,   8.7754, -10.2846,\n",
      "            6.3879],\n",
      "         [-46.7891,  -3.9670, -30.5760,  34.1450, -27.7380,   7.4779, -12.8957,\n",
      "           15.2121],\n",
      "         [  2.0201,  38.3343, -23.1494,  12.5063, -26.4683, -23.6162,  20.5462,\n",
      "          -17.3968],\n",
      "         [-20.4586,  19.2104,  -6.4159,  20.5167,  10.3265,  -4.2372,  20.8187,\n",
      "            2.8161],\n",
      "         [-29.4560, -13.2661, -13.7824,  -1.9409,  -7.3329,  -7.6817,  31.1185,\n",
      "            2.9330],\n",
      "         [ 14.0468, -12.3332,  29.9920,  41.6284, -45.6302, -16.4019,  26.1229,\n",
      "           11.2971],\n",
      "         [ -0.8086,  13.2361,  27.4165,  71.3012, -40.0311,  -2.6605,  29.1731,\n",
      "            9.6448],\n",
      "         [ 18.6240,  47.2166, -15.7156,  -3.7081,  15.2983, -46.6294, -15.8513,\n",
      "           24.2300],\n",
      "         [-14.8295,  34.7835, -27.8270,  44.4443, -14.8129,   3.7513,  -3.3674,\n",
      "           -2.4340],\n",
      "         [ 57.3136,  -0.3587,  -4.1600,   6.3380,   2.0456, -28.2766,   3.3442,\n",
      "           -0.5610],\n",
      "         [-22.7357,  32.2068, -17.8810, -19.7730,  10.7366,   5.2206,  13.1151,\n",
      "          -18.1553],\n",
      "         [  3.5742, -41.5020,   0.8916, -39.2440, -29.8968,  19.4852,   3.2652,\n",
      "           -5.5389],\n",
      "         [  0.5754,   2.2570,  12.9382, -10.2701,  14.3302, -15.2389, -19.9621,\n",
      "            8.7062]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.6050,  0.3185,  0.3662,  ..., -0.0511,  0.6658, -0.0222],\n",
      "        [ 0.0065,  0.0233,  0.3580,  ...,  0.2198, -0.1476,  0.1571],\n",
      "        [ 0.1220,  0.1394,  0.3019,  ..., -0.3047,  0.3432, -0.3257],\n",
      "        ...,\n",
      "        [ 0.4910, -0.1477,  0.0825,  ...,  0.3121, -0.9555,  0.6460],\n",
      "        [ 0.0057,  0.2533,  0.2925,  ...,  0.0556,  0.1101,  0.2985],\n",
      "        [ 0.0383, -0.2248, -0.0849,  ...,  0.6610,  0.0868,  0.5471]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[-1.2525e+01,  6.2185e+00,  4.2875e+00,  1.7295e+01,  1.3173e+01,\n",
      "           1.8991e+00, -9.6951e+00, -1.6041e+00],\n",
      "         [-7.5310e+00, -6.8035e+00,  3.0893e+00,  1.0534e+01,  9.8773e+00,\n",
      "           7.1329e+00, -4.7966e+00,  8.0744e+00],\n",
      "         [ 1.4237e+01, -1.2267e+01,  5.7268e+00,  1.4585e+01, -6.7217e+00,\n",
      "          -1.5187e+00,  4.2194e+00,  2.4237e+01],\n",
      "         [ 1.1803e+01,  1.1622e+01, -9.2110e+00, -4.9327e+00, -3.3280e-02,\n",
      "           1.0607e+01,  2.2257e+01, -7.1482e+00],\n",
      "         [-1.9564e+01, -5.5412e+00,  6.5640e+00,  2.5851e+00,  6.6489e+00,\n",
      "          -1.0745e+01, -8.0230e+00,  1.0820e+01],\n",
      "         [-5.8580e+00, -5.1493e+00, -1.1182e+01,  5.7081e+00, -1.6610e+01,\n",
      "           8.4321e+00, -2.6714e+01,  1.2192e+01],\n",
      "         [ 2.8480e+00,  1.3953e+01, -7.4520e+00,  3.5951e+01,  3.4899e+00,\n",
      "           1.0628e+01, -1.5739e+01,  2.8948e+01],\n",
      "         [ 1.4314e+00, -7.2845e+00, -1.7106e+00,  3.0067e+00, -8.9441e+00,\n",
      "          -4.4547e+00,  1.8783e-01,  1.4282e+00],\n",
      "         [ 1.7373e+01,  1.3613e+01,  3.0652e+00, -6.0419e+00, -1.4159e+01,\n",
      "          -8.1039e+00, -7.7355e+00, -1.0246e+01],\n",
      "         [-5.0454e-01,  1.4035e+00, -1.0770e+01, -1.6039e+00, -9.5405e+00,\n",
      "           1.7468e+01,  3.3863e+01, -2.5053e+00],\n",
      "         [-1.7711e+01,  1.3327e+00, -4.5935e+00, -1.5779e+01,  1.6058e+01,\n",
      "          -8.3034e+00, -4.5724e+00, -8.6928e+00],\n",
      "         [ 6.3678e+00, -1.0604e+01,  1.2302e+01, -1.3190e+00,  6.0352e+00,\n",
      "          -7.2190e+00, -1.4387e+01, -1.2192e+01],\n",
      "         [ 2.7907e+00, -1.8912e+01,  1.2714e+01,  9.1479e-01,  1.1752e+01,\n",
      "           5.4047e+00, -1.1460e+00,  7.8890e+00],\n",
      "         [ 3.4881e+00, -7.3668e-01, -1.5050e+01,  1.4767e+00,  2.6955e+01,\n",
      "           8.2627e+00,  1.4322e+01, -2.9204e+00]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.3791, -0.6744,  0.2860,  ..., -0.3805,  0.1031,  0.4791],\n",
      "        [ 0.4624,  0.0539, -0.5108,  ...,  0.1124, -0.1442, -0.1179],\n",
      "        [-0.1934,  0.0697, -0.5562,  ..., -0.2647,  0.6211,  0.1035],\n",
      "        ...,\n",
      "        [-0.3533, -0.4575, -0.4929,  ...,  0.1085,  0.0576, -0.3334],\n",
      "        [ 0.0734, -0.1797, -0.3613,  ...,  0.8754,  0.2582, -0.2411],\n",
      "        [ 0.3077, -0.1728,  0.6435,  ...,  0.0628,  0.6046, -0.1539]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[ -2.3341,  21.5707,   9.2484,  -1.5392, -10.5826,  -2.5400,  -6.0376,\n",
      "           18.9313],\n",
      "         [-14.0771,  18.0036,   0.9184,  15.2913,  -9.6905, -16.2427, -25.6332,\n",
      "            8.5232],\n",
      "         [ -1.8199,  -0.5318,  13.7571,  -7.8561, -21.3908,  -3.1928,   8.9368,\n",
      "            8.6135],\n",
      "         [ -0.3729,   3.5312,  20.7919, -15.5831,   4.6766,  11.9563, -10.3571,\n",
      "           -2.3724],\n",
      "         [-12.2827,  -3.0003,  17.2341,  -2.4524, -17.0010,  17.3187,  -0.7229,\n",
      "           -4.9706],\n",
      "         [  8.0422,   7.7144,  -5.2811, -16.2933,  10.6818,  21.9313,  -9.0778,\n",
      "            8.4434],\n",
      "         [-11.1566, -21.9946,   8.4794,  17.3325,  12.8310,  -8.4808,   6.7092,\n",
      "            4.4437],\n",
      "         [-25.0982, -10.2405, -11.9242,  26.6678,  10.8112,   9.8872,   1.2052,\n",
      "            1.6797],\n",
      "         [  4.7407,   0.8183, -16.8321,  17.1050,  22.9829, -11.1378, -11.6251,\n",
      "            4.5903],\n",
      "         [ -4.7829,   7.4254, -11.2022,  -3.1474,  -8.0880,   5.5836,   3.1008,\n",
      "           -4.8456],\n",
      "         [  3.2725, -11.8727,   2.0108,  11.6783,  -9.8988,  -9.3537,  -9.4262,\n",
      "            4.1632],\n",
      "         [ -1.9538,  16.2982,  -4.0420, -18.0371,  14.4341,   3.8938,  14.2350,\n",
      "          -28.4543],\n",
      "         [-17.8205,   7.3521, -22.0656,  -6.5626,   5.1833,  -0.7651,  -0.7951,\n",
      "           -8.4406],\n",
      "         [  6.8375,   5.4165,  10.9994,  -7.5051,  -8.2056, -15.9151,  12.8478,\n",
      "          -16.0044]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.2105, -0.5261,  0.2216,  ..., -0.4622,  0.4244, -0.2647],\n",
      "        [-0.2374,  0.8518,  0.2340,  ..., -0.4700,  0.3453, -0.3580],\n",
      "        [ 0.1079,  0.0391,  0.3683,  ..., -0.4373,  0.4976,  0.2610],\n",
      "        ...,\n",
      "        [ 0.2344,  0.2859, -0.1628,  ...,  0.4348,  0.1914,  0.5230],\n",
      "        [ 0.3879, -0.2206,  0.1816,  ..., -0.1870, -0.6137, -0.1583],\n",
      "        [ 0.0877,  0.4136, -0.1805,  ..., -0.2744,  0.3687,  0.2388]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[ -3.1381,  -8.1117,   1.4000, -10.3446,   2.3478, -12.7429,   4.6522,\n",
      "           -8.6658],\n",
      "         [ 20.7151,   6.2050, -23.3700,  19.7504,   9.5388,  17.8060,   6.0409,\n",
      "           -4.5173],\n",
      "         [ -9.6605,  -5.3026, -18.8750, -12.6337, -10.7991,  14.0688, -11.6404,\n",
      "          -28.0689],\n",
      "         [ 13.8220, -14.2252, -24.1908,  30.7128,  37.5631,  31.8129,   1.4498,\n",
      "            4.4661],\n",
      "         [-19.7506,  23.8575,  40.1082,   2.6622,  22.2405,   7.4792, -22.3407,\n",
      "          -17.0478],\n",
      "         [  1.7467,   2.8671, -21.6332,  35.3297, -21.4958,  17.7710,  44.7053,\n",
      "          -11.9105],\n",
      "         [ 48.3771, -25.9659, -12.5688, -10.4438,  18.6133,  46.5868,  -2.7943,\n",
      "           11.5838],\n",
      "         [ -1.1906, -14.4011, -25.7117, -16.0043,  -8.5686, -12.5537,   5.6621,\n",
      "            4.4379],\n",
      "         [ 12.5811,  19.6924,  -3.0015,  -8.2896, -29.8993,  14.1400, -29.8370,\n",
      "           23.0035],\n",
      "         [-30.5358,  34.9752,   3.0718,  16.2396, -33.5864, -14.9990,   7.3669,\n",
      "           -2.0450],\n",
      "         [ -2.8903,  10.7243,   0.6258,  37.4508,  30.0931,   8.7781,  -5.7627,\n",
      "           28.1457],\n",
      "         [-15.4221, -46.8256,  40.9341, -11.3131,   8.7921,   1.2063,  10.5107,\n",
      "           -7.7465],\n",
      "         [ -4.7229,  24.4351,  -2.8569, -67.2427, -21.5506,   8.1326,  42.8882,\n",
      "           10.1523],\n",
      "         [ 18.3489,   9.6414,  -9.0511,   6.7806, -42.8934, -33.6568,   4.9039,\n",
      "          -25.2891]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[-0.5014,  0.5722, -0.1264,  ..., -0.1616, -0.4459,  0.4046],\n",
      "        [-0.0835, -0.4354, -0.3629,  ..., -0.4311,  0.4320, -0.1074],\n",
      "        [ 0.0542, -0.2153, -0.7172,  ...,  0.1043,  0.2428,  0.2176],\n",
      "        ...,\n",
      "        [ 0.2857,  0.2704,  0.2934,  ..., -0.1972,  0.2148, -0.1606],\n",
      "        [-0.4031,  0.2693, -0.2982,  ..., -0.1625, -0.6054, -0.5374],\n",
      "        [-0.4073,  0.6440, -0.4006,  ..., -0.1448,  0.6605,  0.1152]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[ -46.1113,  -13.1337,  -60.4922,   -1.4365,   -7.7282,   72.6704,\n",
      "           -30.9151,  -24.2347],\n",
      "         [ -29.4056,   19.6217,  -81.0717,  -93.1889,  -35.9697,  -48.9064,\n",
      "           -58.0360,   14.9455],\n",
      "         [  10.0563,  -19.6079,  -53.8111,   25.6322,   48.7661,   77.3542,\n",
      "            68.0026,   74.7913],\n",
      "         [  69.8326,  -20.6575,   27.6085,  -22.2747,  -10.4161,  -64.3487,\n",
      "            -0.4254,  -71.8881],\n",
      "         [  47.3709,  -25.2646,  -22.8742,   37.6967,  -27.5327,  -20.3496,\n",
      "           -33.2955, -117.8540],\n",
      "         [  50.5168,  139.4033,   -8.2640,   29.4452,  -20.2297,  -60.6872,\n",
      "           -11.2560,  -12.0123],\n",
      "         [   7.0725,  -16.2834,   -4.9212,   50.2250,  -14.6258,   24.0057,\n",
      "           -13.7101,   61.6258],\n",
      "         [ -40.7410,  -58.4565,    3.5139,   42.4910,   14.7162,   10.0227,\n",
      "           -24.3295,   -7.5862],\n",
      "         [  46.8537,  -17.9470,   10.7674,  -22.9090,  -14.7383,   41.8022,\n",
      "           -69.2840,  -11.8411],\n",
      "         [  47.4270,  -70.3438,   46.8526,    5.1118,   29.4235,   19.6069,\n",
      "            22.4496,  -24.5398],\n",
      "         [ -64.5905,  -17.3757,  -21.2035,  -61.9568,  -19.7480,   73.1394,\n",
      "            70.1693,   -2.0515],\n",
      "         [ -33.5163,   -6.2467,  -40.6092,   38.5111,   47.3922,  -47.7483,\n",
      "           -11.5955,  -37.4847],\n",
      "         [ -22.4102,   14.2214,  -44.7254,  -41.8270,    8.3754,   27.2352,\n",
      "            53.9273,   -1.8159],\n",
      "         [ -20.6066,   30.0253,   33.7858,   36.1383,  -29.9978,   76.7222,\n",
      "            10.0175,  -60.7660]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[-0.2649,  0.2399,  0.2030,  ...,  0.0252,  0.0192,  0.2673],\n",
      "        [ 0.9872, -0.4171,  0.2532,  ...,  0.3904, -0.4769, -0.7765],\n",
      "        [ 0.0776,  0.2227, -0.1038,  ..., -0.2202, -0.2530, -0.1689],\n",
      "        ...,\n",
      "        [ 0.2891, -0.4756, -0.0906,  ...,  0.2915,  0.2820,  0.0620],\n",
      "        [-0.3056,  0.2789,  0.2125,  ...,  0.2190, -0.0322,  0.2985],\n",
      "        [ 0.7416, -0.3370,  0.2175,  ..., -0.3237,  0.3444, -0.7210]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[  64.8568,   40.9519,  -28.2370,  -21.9148,   -1.5699,  -90.5716,\n",
      "           -15.0111,   -1.8791],\n",
      "         [  43.0285,   14.2547,   -6.4362,   46.9174,  -38.0401,   21.0139,\n",
      "           -35.3751,   -6.2996],\n",
      "         [  42.3989,  -41.0165,   24.3277,   44.3837,  -25.7822,  -43.1777,\n",
      "           -69.4944,   -1.3784],\n",
      "         [ -23.1967,    9.7062,   46.3934,  -23.7496,   94.8243,   18.3464,\n",
      "            -3.5097,   -5.8012],\n",
      "         [  14.8486,   58.0627,   78.4056,  -11.7656,  -93.0979,  -54.9023,\n",
      "           -29.1763,   -5.0882],\n",
      "         [ -47.9000,  -36.5914,  -77.6223,    9.2619,  -16.9801,   66.0483,\n",
      "            38.9106,   47.0896],\n",
      "         [ -22.3958,   38.1527,  -14.8496,  -17.0747,   10.4411,  -36.4190,\n",
      "            67.4296,   28.1548],\n",
      "         [  14.1305,  -13.9096,  -60.1413,    5.6498,   61.4563,  -66.2553,\n",
      "            58.1286,  -11.1260],\n",
      "         [  58.2777,   55.9914,  -80.8726,   22.6307,  -21.3147,    6.8063,\n",
      "            32.3016,   83.6703],\n",
      "         [   8.9447,   -3.3817,    1.1803,   -9.2525,   25.4023,  -16.1269,\n",
      "            20.8524,   51.4908],\n",
      "         [  -9.3976,   84.2767,  -20.2428,  -41.1191,  -53.5479,  -43.5318,\n",
      "           -14.0316,   44.7174],\n",
      "         [  10.9708,  -36.5026,  -45.1729,  -42.2568,   -9.2929,   64.4413,\n",
      "            44.6812,  -33.6005],\n",
      "         [  38.5384,  -34.8768,    2.0377,   -0.8465,    6.0335,   40.2503,\n",
      "            47.5148,    2.7482],\n",
      "         [-112.4959,   23.6300,   25.5096,   10.1913,   23.7754,   21.8609,\n",
      "            50.6037,   29.9143]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=14336, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[-0.6693,  0.0438, -0.3330,  ...,  0.0039,  0.0615, -0.3051],\n",
      "        [-0.7685, -0.4799, -0.3879,  ..., -0.0416,  0.4776, -0.4326],\n",
      "        [ 0.0155,  0.2253, -0.1264,  ...,  0.2029, -0.1356,  0.9626],\n",
      "        ...,\n",
      "        [ 0.6175, -0.7281, -0.3212,  ...,  0.0437, -0.1624, -0.5136],\n",
      "        [-0.0096, -0.5546, -0.0244,  ..., -0.4416,  0.0766, -0.5920],\n",
      "        [-0.0074,  0.0336, -0.4710,  ...,  0.2514, -0.3825, -0.0067]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[-13.8220,  -6.9518, -52.7240,  -9.5587,  11.2369,   1.0848, -21.3526,\n",
      "           30.3942],\n",
      "         [-85.0359,  21.8778, -26.4518,  27.6356,  -6.6794, -52.4887,   2.5889,\n",
      "          -11.8942],\n",
      "         [-47.8784,  -5.0719,  34.3497,  34.6088,   8.1752,   9.6489,  -1.7609,\n",
      "            5.5194],\n",
      "         [ 25.1252,  27.4611,   5.0818,  26.8652, -34.8232, -39.1307,   4.5204,\n",
      "          -11.2720],\n",
      "         [  4.6964,   4.9141,  -2.8246,   4.2945,   7.8139, -21.4070, -23.2895,\n",
      "          -15.6902],\n",
      "         [-28.9333,  40.7445, -26.4361,  10.8728, -11.3939, -14.5879, -21.1072,\n",
      "          -18.0437],\n",
      "         [-13.0011,  -1.8186,  -2.3763,  25.6113, -10.1897,  -3.5424, -16.3895,\n",
      "           19.1857],\n",
      "         [  5.1121,  -7.6269,  -6.3194,   6.0771, -13.7023,   5.0042,  -0.6362,\n",
      "          -11.0096],\n",
      "         [ 11.6647,  11.2066,  44.6874, -44.0894, -30.5124, -31.6966,  53.0981,\n",
      "          -21.8969],\n",
      "         [-37.4225,  18.2415,  -8.4339,   5.9095,  33.3863, -34.8271,  10.2999,\n",
      "            8.1987],\n",
      "         [ 15.3594,  26.5466,  -2.0436,  25.0148,  35.4880,  22.0534,  23.4321,\n",
      "          -11.2355],\n",
      "         [ 40.3592,  -6.8805,  13.6888,  39.5265,   8.7695,   9.3190,  -1.9956,\n",
      "           35.3032],\n",
      "         [-17.0985,   6.0797,  36.3782,  17.9398, -15.3971, -50.3983,  23.4771,\n",
      "          -27.7680],\n",
      "         [-41.1432, -42.8456,  16.7942,   4.7783, -15.0271,  -0.4446, -11.7724,\n",
      "          -41.6241]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.1232,  0.0476, -0.1246,  ...,  0.1488, -0.6970, -0.0252],\n",
      "        [ 0.5327,  0.5434,  0.5862,  ..., -0.2946,  0.0061, -0.4486],\n",
      "        [ 0.1072,  0.2662,  0.4115,  ..., -0.6564, -0.1887,  0.3381],\n",
      "        ...,\n",
      "        [-0.0066, -0.3502,  0.3269,  ...,  0.6027,  0.0953, -0.0370],\n",
      "        [ 0.2789,  0.6264, -0.2671,  ...,  0.6100, -1.1625,  0.1926],\n",
      "        [ 0.0872, -0.0790, -0.3607,  ...,  0.0277,  0.2203,  0.3261]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[  6.3713, -12.9415,   0.5473,   3.2973, -31.2789,   2.9655, -20.1653,\n",
      "            1.8745],\n",
      "         [ 32.6773,  -8.9703, -24.1371, -31.9903,  -3.0023,  -2.8622,  -9.9680,\n",
      "          -22.7688],\n",
      "         [ 35.3015,   9.5343,  17.4636,  10.9471,  14.3514,   2.9452,  -2.7669,\n",
      "           -6.7347],\n",
      "         [-28.2485,  16.5388,   5.6149,  35.5678, -14.2694,  10.3852, -31.8313,\n",
      "           33.3219],\n",
      "         [ 33.7654,   1.5300, -36.6329,  12.1247, -47.0308,  27.9656, -16.9628,\n",
      "           15.2394],\n",
      "         [ -6.3681, -11.2451, -26.8510,  47.0124, -13.2355,  41.1024,   9.0342,\n",
      "            4.9425],\n",
      "         [ 14.0600, -14.3760, -22.7005,   6.3923, -23.4497, -17.6390,   0.4310,\n",
      "            0.7141],\n",
      "         [ 35.5603,  23.8843,  14.6577, -26.3427,  35.8765,  60.5934,  -2.3981,\n",
      "          -26.2386],\n",
      "         [ 20.8149, -45.7793, -11.6941, -11.9969,  36.9514,  -0.6740,  -1.2089,\n",
      "          -19.7833],\n",
      "         [-25.9722,  16.1600,  18.0782, -44.9701,  15.8096, -20.3443,  44.7306,\n",
      "           40.1267],\n",
      "         [-32.7290,  26.4189,   0.8418,   0.5984,   2.8427,  12.0173,  10.7185,\n",
      "           -5.6776],\n",
      "         [-15.1252, -15.2493,  14.8568,   9.7242, -21.3738, -16.0550, -33.8754,\n",
      "           -8.6712],\n",
      "         [ 21.6838, -39.6728,  37.7135,  11.9963,  -9.9951,  17.2382,  24.4240,\n",
      "           13.2115],\n",
      "         [-32.0292,  45.6500,  -3.5230,  39.3170,   6.2944,  -9.6975, -12.8049,\n",
      "          -32.1882]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.5187,  0.1404, -0.3392,  ..., -0.5543,  0.1406,  0.0875],\n",
      "        [ 0.4827, -0.3850, -0.3622,  ..., -0.0500, -0.0949, -0.2797],\n",
      "        [-0.0453, -0.0219,  0.1615,  ..., -0.2968,  0.0139, -0.1737],\n",
      "        ...,\n",
      "        [ 0.6064,  0.0979,  0.0115,  ..., -0.2853,  0.3748,  0.0968],\n",
      "        [-0.3572,  0.1472,  0.0594,  ..., -0.2190,  0.1835, -0.1110],\n",
      "        [-0.1291, -0.2248, -0.1345,  ...,  0.3507, -0.0322, -0.3492]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[ -9.3717,  -7.6349,  22.0419,  10.5944,   4.9998,  11.6931,  -4.0301,\n",
      "           -0.3525],\n",
      "         [-13.4036,  -8.6364,  -3.5750,  10.1072,  -1.9700,  -2.9586,  10.4614,\n",
      "           -7.9002],\n",
      "         [ -1.8971,  -4.6620,  -4.7192,   0.8288,  10.7802,  10.3435,  -2.8225,\n",
      "            3.0254],\n",
      "         [ -8.5143,  15.0711,  21.2394,   6.3770, -18.4297,  10.3283, -29.2942,\n",
      "           -9.6539],\n",
      "         [  3.4090,   7.8819,   5.0637, -14.9398, -17.6646,   2.8915,   4.2068,\n",
      "           18.5626],\n",
      "         [  8.4920,  34.7272,   1.9125, -20.2021,  20.5269,   3.0416,   0.6232,\n",
      "           -9.0876],\n",
      "         [  6.5520,   3.3782,   5.5739,  -2.9375,  -1.0735,  -0.9925,  -6.7115,\n",
      "          -10.5373],\n",
      "         [ 11.6292, -13.1660,  -7.5414,   1.6036,   3.5018, -25.0009,   5.6226,\n",
      "           -6.6397],\n",
      "         [ -3.0779,  -4.9363,   0.1789,   8.2474, -13.6266, -25.4979,  -1.3572,\n",
      "           10.3483],\n",
      "         [ 22.4827,  -2.6950, -17.9530,   5.3329,   9.7982,  12.9515,  -0.8538,\n",
      "           -9.3331],\n",
      "         [  7.5703,   0.0996,   1.3016,  14.5483,   5.9201, -11.2356, -14.3599,\n",
      "          -14.7542],\n",
      "         [-19.0135,  -2.6243,   2.9734,   0.1189,   1.4869,   2.1868,  -2.1546,\n",
      "           11.3679],\n",
      "         [ -4.6426, -16.6326,   4.4812, -16.4561,   2.7456,   3.6362,  11.3647,\n",
      "           -8.7139],\n",
      "         [ -9.3412,   5.1277,   4.1890,  -1.7781,   7.9611,  -9.1514,   0.0575,\n",
      "            4.5687]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[-1.1175e-01, -5.4737e-01,  3.0889e-01,  ...,  3.1482e-01,\n",
      "         -5.3212e-01, -6.2843e-02],\n",
      "        [ 9.6958e-02,  5.6479e-01,  3.9059e-01,  ...,  5.7534e-01,\n",
      "          2.3792e-01,  7.0358e-01],\n",
      "        [-2.9446e-01,  2.2653e-01, -6.7647e-02,  ...,  3.1103e-01,\n",
      "         -9.3351e-03,  1.1011e-01],\n",
      "        ...,\n",
      "        [ 3.2778e-01, -4.8790e-04, -5.0143e-02,  ..., -8.0767e-01,\n",
      "         -2.4333e-01, -6.6698e-01],\n",
      "        [-2.1688e-01,  2.6419e-01, -5.0620e-01,  ...,  8.9706e-02,\n",
      "         -6.5814e-01,  4.9361e-01],\n",
      "        [-1.5150e-01, -2.3016e-02, -1.6246e-02,  ..., -6.1691e-02,\n",
      "         -5.9479e-02, -4.8864e-01]], device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[  7.8050,  -4.0289, -21.7750,  -8.2031,   1.1360,   5.7474,   0.4630,\n",
      "           28.3378],\n",
      "         [  3.2935,  -5.0782,   8.5670,   3.3228,   4.4267,   5.0765,  16.4379,\n",
      "            7.2690],\n",
      "         [  6.0739, -12.8589,   8.7906,   0.3648,   5.9045,  -4.5507, -25.9220,\n",
      "           -0.4753],\n",
      "         [ -3.1997,   5.7318,   1.2222,  13.1008,  -9.6994, -10.9890,  -6.1777,\n",
      "           -7.1936],\n",
      "         [ 10.9310, -19.2324,  -1.4380,  12.1916,  -4.2034,  -3.5492,  19.6354,\n",
      "            7.3387],\n",
      "         [ -9.8233, -10.4741, -18.4461,   6.3365,  -3.7386,   7.1200,  13.7938,\n",
      "           -2.1450],\n",
      "         [ -7.1538,  -4.9486,  -4.5553, -17.2740,  30.2769,  17.5157,   3.8203,\n",
      "          -11.4404],\n",
      "         [ -3.7285,   4.5940,   4.0595,   1.0235, -11.3370,  19.2090,  -6.4791,\n",
      "           -9.9325],\n",
      "         [ -2.6673,   2.8623,   3.1188,   8.0675, -17.3827, -13.1316,  -7.5077,\n",
      "            8.7807],\n",
      "         [ -6.9497,  -9.5176, -12.0880,  21.4415,   1.8258,   9.0716,   9.8392,\n",
      "          -18.4039],\n",
      "         [ 12.0694, -14.9424,  -6.9209, -21.8847, -13.4898, -12.0529,   0.3755,\n",
      "            6.4674],\n",
      "         [ -0.4984,   9.4052, -11.4809,  15.6222,   7.9629,  -4.3426,   7.4085,\n",
      "           -1.9059],\n",
      "         [  9.3085,  -5.6478,   6.9548,  14.1290,  23.0318,  -8.1013, -11.3426,\n",
      "            2.9309],\n",
      "         [ 13.1632, -13.0032, -10.5148, -14.1322,   7.8834,  -7.0750,  13.5604,\n",
      "            9.3495]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[-0.0735,  0.4587, -0.0957,  ...,  0.2798,  0.0092,  1.0942],\n",
      "        [-0.7752, -0.3568, -0.0815,  ..., -0.4032,  0.2677,  0.1597],\n",
      "        [ 0.3402, -0.3739,  0.5402,  ..., -0.2036,  0.4587, -0.1345],\n",
      "        ...,\n",
      "        [-0.4930,  0.4814,  0.7357,  ..., -0.3227, -0.0921,  0.0442],\n",
      "        [ 0.1495,  0.3725,  0.4449,  ...,  0.3262,  0.0963,  0.0309],\n",
      "        [-0.0822,  0.0796, -0.5828,  ..., -0.0545, -0.5412,  0.0902]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[ -4.1042,   9.5479, -10.6497,   1.6000,  23.9782,  22.9974, -33.8712,\n",
      "           23.4283],\n",
      "         [ 46.8181,  -5.9107,  38.7356, -43.6719,  26.1787,  15.6838,  15.1786,\n",
      "           -1.4961],\n",
      "         [ -2.2192, -17.2746,  45.9961,  -7.2672,  -5.1864,  -6.8334, -11.2067,\n",
      "          -41.8217],\n",
      "         [ 10.0455,  16.2808,  45.0589,  29.7837,  -9.9709,  20.0184,  -1.5096,\n",
      "           -4.6614],\n",
      "         [-21.6651, -27.9987,  16.6248, -21.4875,   3.6323,  -5.4157,   6.7127,\n",
      "           20.0540],\n",
      "         [  1.7960,  25.2129,  -4.3648,  35.0227,  -7.8017,  47.8285, -33.9634,\n",
      "          -23.1136],\n",
      "         [-16.2518,  19.1162,  32.1047, -32.9589,  -3.9659,   4.1123,  -5.7447,\n",
      "          -14.7561],\n",
      "         [ 17.4164, -14.0177,  20.4392,   3.0356, -12.5664, -41.6166,  -3.2812,\n",
      "           10.7881],\n",
      "         [ 17.5437,  18.6351,  40.3366, -23.3843,  20.3023, -14.6544,  17.5027,\n",
      "           -2.8567],\n",
      "         [-21.7526,  27.9640, -14.1742, -34.3151,  15.4880,  36.8063, -17.2777,\n",
      "           19.9015],\n",
      "         [  8.2578, -11.7609,  25.6106, -11.1579,   8.7213,  37.0534,  18.9854,\n",
      "          -16.5797],\n",
      "         [-26.1313, -13.5742, -34.0285,  16.6328,   9.9609,  25.3073,  -0.8896,\n",
      "           -3.0048],\n",
      "         [ 18.1114, -26.6864,  -7.4243,  17.2279, -34.0813,  -1.5764,  16.2867,\n",
      "          -12.7015],\n",
      "         [ 14.7234,  48.8534,  13.2201, -57.1498,   9.5693,  22.9414,   5.5158,\n",
      "           12.8381]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.0151, -0.1972,  0.0389,  ..., -0.3579, -0.1012, -0.1444],\n",
      "        [-0.2712,  0.1459, -0.2257,  ..., -0.4029,  0.3108,  0.1015],\n",
      "        [ 0.6297, -0.6338, -0.4408,  ..., -0.3506,  0.1046, -0.3968],\n",
      "        ...,\n",
      "        [ 0.0601,  0.8653, -0.0380,  ...,  0.0124,  0.5598,  0.1114],\n",
      "        [ 0.1129,  0.3416, -0.0437,  ..., -0.4431,  0.3035,  0.5270],\n",
      "        [-0.2687, -0.5995,  0.2902,  ..., -0.2492, -0.1265,  0.1431]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[ 24.7420,  17.5052, -64.0614,  43.7760, -22.9334,   4.8523,   4.7190,\n",
      "          -16.0132],\n",
      "         [-34.4452,  -4.6194,  37.2201, -12.1145, -43.3678, -54.3749, -30.7042,\n",
      "          -48.7903],\n",
      "         [ 30.8640,  50.0467, -20.4457,   0.8996,  35.3420, -73.2709, -49.2341,\n",
      "            6.2676],\n",
      "         [ 44.5438,  -6.8355,  56.7245, -25.0197,   0.9920,   7.5912, -25.5199,\n",
      "          -13.9728],\n",
      "         [-62.9979,  34.8191,  45.3730, -16.1802,  95.0991,  29.7694, -11.3252,\n",
      "           42.5495],\n",
      "         [ 55.7571,  49.8085,   9.8837,  53.3420,  27.7376,  31.3610,   4.8704,\n",
      "          -46.2117],\n",
      "         [ 33.6558,  20.9513,  56.6357, -12.7899,  -8.0213,  17.4264,  40.4774,\n",
      "           -2.6891],\n",
      "         [-81.7967, -27.9386,  12.5494,  94.3165,  -8.7124,  66.0509, -77.6723,\n",
      "          -64.6527],\n",
      "         [ -2.2937,  43.8384, -18.5880,  34.3300,  71.1260, -21.2331,  11.2853,\n",
      "          -22.8980],\n",
      "         [ 65.0118, -19.2990,   3.8572,  33.6564,  67.1826,  10.1033,  32.8848,\n",
      "           -4.7380],\n",
      "         [-37.1864, -59.1112,  14.8176, -45.3504,  18.9601, -91.5353,  11.8282,\n",
      "           47.4505],\n",
      "         [-63.6053, -74.8226,   2.1894,  15.0948, -15.4628, -22.8164,  17.8528,\n",
      "           91.4208],\n",
      "         [ 47.0048,  13.2382,  -9.5862, -53.9472, -96.7468,  32.8686,  -7.6740,\n",
      "           -8.9673],\n",
      "         [-44.2031, -37.9354, -14.1430, -32.9855,  -5.4737,  46.4576, -76.2072,\n",
      "           -7.7852]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.2539, -0.2234, -0.7091,  ...,  0.7452,  0.2167,  0.3384],\n",
      "        [ 0.6035,  0.3426, -0.1511,  ..., -0.5659, -0.8156, -0.5716],\n",
      "        [ 0.4047, -0.8998,  0.0585,  ...,  0.7088,  0.8416, -0.1295],\n",
      "        ...,\n",
      "        [ 0.0633, -1.0139,  0.6071,  ..., -0.5092,  0.0031,  0.0520],\n",
      "        [-0.3446,  0.1247,  0.3491,  ...,  0.2069, -0.2945, -0.2449],\n",
      "        [ 0.0214,  0.4334,  0.6700,  ..., -0.0550,  0.0018,  0.2355]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[-3.9033e+01, -4.7761e+01,  1.1384e+01, -7.6163e+01, -1.4326e+01,\n",
      "          -2.9313e+01,  3.5139e+01, -7.8276e+01],\n",
      "         [-5.7929e+00, -9.8547e+00,  2.2944e+01, -3.5480e+01, -8.3153e+00,\n",
      "          -3.2464e+01,  1.4615e+01, -2.1168e+01],\n",
      "         [ 5.5144e+00, -5.1177e+01, -2.0298e+01, -3.9658e+01, -1.0194e+01,\n",
      "           4.4147e+01, -5.9869e+01,  1.8605e+01],\n",
      "         [ 2.4829e+01,  3.6535e+01,  5.0669e+01,  3.6000e+01,  3.5095e+01,\n",
      "           4.8087e+01,  2.5134e-01,  4.1955e+01],\n",
      "         [ 1.9300e+01,  4.2051e-01,  1.7500e+01,  4.7265e+00, -3.0344e+01,\n",
      "          -2.0077e+01,  1.3753e+01, -2.6181e+01],\n",
      "         [-1.2704e+01, -9.4722e+00, -3.1471e+00,  9.8542e+00, -5.4758e+01,\n",
      "           3.5918e+01,  3.3210e+01, -3.1502e+00],\n",
      "         [ 2.6991e+01,  1.2189e+01, -1.2530e+02, -8.5701e+01, -2.6610e+01,\n",
      "          -3.0685e+01, -7.7231e+01, -6.3066e+01],\n",
      "         [-1.7735e+01, -4.4235e+01, -3.4864e+00, -4.2421e+01, -8.4923e+00,\n",
      "           7.3437e+01,  3.5030e+01,  2.9881e+00],\n",
      "         [ 9.3551e+00, -9.3102e+00,  5.3107e+01,  4.7100e+01, -6.5819e+01,\n",
      "           3.1567e+01,  9.9277e+01,  5.0815e+01],\n",
      "         [ 9.2576e+01, -4.5485e+01,  1.4280e+01, -2.4369e+01, -7.6338e+00,\n",
      "          -3.3467e+01, -8.5925e+01,  4.8079e+01],\n",
      "         [ 4.6807e+01,  6.1873e+01, -2.1302e+00, -5.5642e+01,  6.3659e+01,\n",
      "           7.0783e+01,  1.9232e+01,  2.2822e+01],\n",
      "         [-4.6196e+01, -1.1922e-01, -7.4715e+00,  2.9431e+01,  2.4186e+01,\n",
      "           3.3306e+01, -2.5231e+01, -9.2212e-01],\n",
      "         [-1.7310e+01, -2.3052e+01,  1.7993e+01,  5.8899e+01, -6.9239e+00,\n",
      "           4.4847e+01,  4.2243e+01,  1.0236e+01],\n",
      "         [-2.0701e+01,  4.7043e+01, -3.0601e+01, -5.0395e+01,  3.6070e+01,\n",
      "          -1.7006e+00,  1.2259e+01,  1.5241e+01]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=14336, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[-0.2586,  0.0891, -0.0662,  ..., -0.4020,  0.0140,  0.0385],\n",
      "        [ 0.1170, -0.0288, -0.1837,  ..., -0.0224,  0.4685,  0.4188],\n",
      "        [-0.0647, -0.1089,  0.7717,  ...,  0.0563,  0.6712, -0.7429],\n",
      "        ...,\n",
      "        [ 0.2018, -0.2766, -0.0866,  ...,  0.1328, -0.1324,  0.1190],\n",
      "        [ 0.2912, -0.1442,  0.3769,  ...,  0.2444, -0.2415, -0.2496],\n",
      "        [-0.2299, -0.2087,  0.0280,  ...,  0.1341, -0.0768,  0.1095]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[ -2.9110, -32.4219,   6.9147,  21.0286,  43.9240,  14.2140,   7.4525,\n",
      "           -0.6038],\n",
      "         [-23.0469, -14.4109, -17.1856, -25.0534, -23.2437,  21.1048,  35.6454,\n",
      "            6.7093],\n",
      "         [ 11.7987, -13.2917,  14.8180,  16.0614, -27.9135,  21.1721,  -9.4809,\n",
      "          -11.5765],\n",
      "         [-10.3748, -14.0025, -13.1975, -26.4921,   0.3485,  -3.6470, -10.0667,\n",
      "          -12.6467],\n",
      "         [ 10.4715,  24.1902,  -0.9953,   4.0201,   3.0298,  15.2261, -41.8780,\n",
      "           16.1768],\n",
      "         [ 11.5120, -20.6912,   8.2633,  17.7895,   5.5089,  12.5026,  14.9496,\n",
      "          -14.2495],\n",
      "         [-31.0236,  12.0011,  -3.4333,   5.5040, -22.2290,  -6.0039, -37.0731,\n",
      "           -7.6834],\n",
      "         [ -6.5768, -36.3491,  10.3682,  -8.0499,   1.3919, -26.6486, -30.6528,\n",
      "            3.6491],\n",
      "         [-21.9694, -41.8309,  39.0609,  21.0235,  15.1276,   5.6793, -41.9757,\n",
      "            6.7283],\n",
      "         [ 11.9919, -15.2547,  10.4180,   3.0798, -22.4844,  -4.6827,  -2.6706,\n",
      "          -50.0949],\n",
      "         [  9.9388,  10.6722,  22.2422,  -2.3610,   1.1552,   1.1451, -32.4891,\n",
      "           16.2512],\n",
      "         [ -4.1111,  35.0497, -21.4497,  15.8135, -29.8501,   2.7837, -28.5030,\n",
      "          -15.4422],\n",
      "         [-12.3662, -15.5046,  44.9380,   0.3339,  33.3205, -43.2517, -16.0820,\n",
      "          -13.9905],\n",
      "         [  6.4341, -15.1485, -21.2793,  31.9233,  10.3792,  13.8843, -15.3550,\n",
      "          -35.4747]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.0653, -0.0049, -0.2625,  ..., -0.3951,  0.4785, -0.0740],\n",
      "        [-0.4957, -0.1638, -0.0851,  ..., -0.1441,  0.5656,  0.3178],\n",
      "        [-0.6035, -0.0834, -0.3039,  ..., -0.4774, -0.1785, -0.2682],\n",
      "        ...,\n",
      "        [ 0.2173,  0.2601, -0.2856,  ..., -0.1417,  0.4722, -0.5094],\n",
      "        [-0.1106, -0.1623, -0.0759,  ...,  0.3462,  0.1533,  0.0143],\n",
      "        [-0.4516,  0.4781,  0.0843,  ..., -0.1330,  0.1101, -0.6122]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[ 13.2845, -22.3777,   4.1581, -17.0533,  10.4805, -45.7353, -14.7002,\n",
      "           15.9459],\n",
      "         [ 12.9797,   6.0181, -12.3670,   3.5538,   5.6459,   8.7864,   4.7553,\n",
      "          -40.0830],\n",
      "         [ 14.7828, -16.9175,  -2.2049,   1.0817, -16.1407,   1.8348,   6.0570,\n",
      "            0.2710],\n",
      "         [-17.6512, -12.0874,   0.7601,   6.3858,   5.6787,  -0.3916,  33.8831,\n",
      "          -25.4992],\n",
      "         [ -0.4340, -41.9201,  17.1443,   0.1658,  24.0526,  12.8586,  12.9383,\n",
      "           15.7740],\n",
      "         [ 13.3552,  31.1088,   2.9619,  22.2089,  -2.0546,   4.0808,  -3.6906,\n",
      "           16.6233],\n",
      "         [ 19.3651, -14.4785,  -9.3491, -19.5494,  -4.1435, -13.4722,  34.7807,\n",
      "          -14.4235],\n",
      "         [ -6.7162, -11.3504,  20.3327, -40.5518,   8.5655,   7.8873,  34.7904,\n",
      "            2.9270],\n",
      "         [  3.4564, -19.2772,   4.9250,  10.2235, -28.5119,  23.0863,  -7.6355,\n",
      "          -30.2628],\n",
      "         [-16.9641,  16.2204,  25.1102,  52.2174,  -5.1084,   2.1971, -24.6313,\n",
      "           12.2456],\n",
      "         [ 11.8417,  14.9459,  16.8788, -21.2002,  -8.2247,  36.4157,  45.2932,\n",
      "           20.0124],\n",
      "         [-26.5341,  12.1126, -15.7498,  31.3787, -36.5947,  -2.2196, -43.9047,\n",
      "          -33.9454],\n",
      "         [ 16.8769, -26.1691,  -4.0933, -10.0146, -40.0136, -23.5660,   4.9681,\n",
      "          -10.3276],\n",
      "         [-15.3298,  -8.2094,   5.1948,   9.7037, -19.9085,  22.5483, -10.5649,\n",
      "          -29.4925]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.4830, -0.1044, -0.3680,  ..., -0.3319,  0.2842,  0.2051],\n",
      "        [ 0.3994,  0.3803, -0.1965,  ..., -0.1062, -0.4461, -0.2667],\n",
      "        [ 0.3788, -0.1414, -0.0264,  ...,  0.1554,  0.5603,  0.2459],\n",
      "        ...,\n",
      "        [-0.1646, -0.2906, -0.1833,  ..., -0.0387,  0.3929, -1.0142],\n",
      "        [-0.0599,  0.3265,  0.3923,  ...,  0.1147,  0.9156,  0.2811],\n",
      "        [ 0.1030,  0.1751,  0.3317,  ..., -0.1978,  0.2925, -0.6731]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[  7.9344,  -6.2112, -24.5027,  -3.8801,  -7.6031,  -7.9266,  -6.3285,\n",
      "           -2.2709],\n",
      "         [  8.4683,  -3.6886,   3.0548,  18.5860,   2.2488,   3.0983,  -8.0879,\n",
      "           11.1206],\n",
      "         [ -3.9313,  -4.3136,  22.2179, -17.8543,  -3.4913,  19.4783,  13.1711,\n",
      "            7.7612],\n",
      "         [-11.9531, -11.5761,   6.5307,   6.4231,  -9.7023,   8.2096, -12.1504,\n",
      "            1.6844],\n",
      "         [ 21.5157,  18.0893,  -8.6795,   2.2233, -39.9551,  12.8734,   7.1862,\n",
      "           -7.0581],\n",
      "         [  6.0778, -20.5339,  -4.5966,  -5.3967, -12.7668,   4.5582, -13.5915,\n",
      "           -1.2036],\n",
      "         [ -7.4100,   4.7068,  -5.8981,  26.0959,  13.7087,   4.9157, -11.1632,\n",
      "           -6.9692],\n",
      "         [ -7.3934,  -3.4165,   6.9053,   4.1440,  -6.4155,   3.1346,  16.9384,\n",
      "          -17.9237],\n",
      "         [ 19.0714,  14.5759, -25.7084,  18.1377,  24.5655,  -0.2029,  15.4132,\n",
      "          -12.3162],\n",
      "         [ -9.7914, -21.7300,  14.0993,  -4.4849,  -6.7717,   2.5120,  -7.4992,\n",
      "            8.7436],\n",
      "         [ -3.5545,  -2.1182,   0.9094,   3.9986, -16.4188,   2.6607,  -4.0312,\n",
      "           14.8073],\n",
      "         [ -3.1475,   7.1085, -10.0866,   0.9159,  -9.0807,   6.1131,   3.4997,\n",
      "            4.9158],\n",
      "         [-19.3804,  -7.4889, -12.7594,   2.5118, -21.3997,   9.1227,  -2.3423,\n",
      "          -23.7706],\n",
      "         [ -5.6966,  -0.5736,   2.0012, -14.1520,  23.8308,  14.4786,  -4.2435,\n",
      "            5.9957]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.3691, -0.4901, -0.1575,  ..., -0.0783,  0.1350, -0.3616],\n",
      "        [-0.2751, -0.2417,  0.5432,  ...,  0.8352, -0.2039, -0.5374],\n",
      "        [ 0.4972,  0.1202, -0.1861,  ...,  0.1449, -0.2368,  0.6658],\n",
      "        ...,\n",
      "        [-0.0219,  0.4245, -0.0864,  ...,  0.0733,  0.6678, -0.1872],\n",
      "        [ 0.7130,  0.5977,  0.3234,  ..., -0.3717, -0.0899, -0.5169],\n",
      "        [ 0.1734,  0.0423, -0.4808,  ...,  0.1052,  0.3863, -0.3799]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[ -6.6207, -23.7779,  -2.6574,   8.8068,  -7.3249, -16.5960,   1.9645,\n",
      "            1.5438],\n",
      "         [ -1.2692,   8.9910,  -3.5654,  12.4633, -32.6146, -24.5732, -11.0635,\n",
      "           -9.2842],\n",
      "         [  7.8326,  16.5795, -10.5957,  -8.5003, -24.2709, -16.2597,  24.5615,\n",
      "           21.3455],\n",
      "         [-14.7854,  -4.4384, -11.3381,  -8.2523,  11.4469,   4.2575,   3.2437,\n",
      "           10.1511],\n",
      "         [ -3.2199,   0.9081,  -5.6445, -12.0742,   0.4896,  12.5391,  -1.1894,\n",
      "           -5.1755],\n",
      "         [  2.8514,  -0.3893, -13.6736,   4.5314, -20.2975, -28.5471, -10.4331,\n",
      "           -5.6696],\n",
      "         [-10.3583,   3.3868,   4.3848, -19.1661,  -9.7535,   1.6010,   1.8208,\n",
      "           -7.9882],\n",
      "         [ -0.9668,  22.2888,   4.4866,  -7.2934,  -2.1288,   1.5485, -13.1466,\n",
      "           20.5395],\n",
      "         [ -2.9217,   1.1303,   6.1732,  -9.2383, -16.7254, -11.3025, -28.3294,\n",
      "            5.7541],\n",
      "         [ 17.0665,  -7.8714,   4.0536,  21.5832,  -2.2704, -10.0779,   0.3212,\n",
      "            2.2637],\n",
      "         [ -3.5880,  -7.5553,   6.5316,  -7.0770,  -3.6158, -21.4020,  -3.7262,\n",
      "           15.6054],\n",
      "         [  8.4974, -20.4680,  -2.5366,  14.1722,   3.2818,  -0.5446,  -9.0356,\n",
      "           24.7138],\n",
      "         [-16.8636, -10.8954,  13.7875,  -5.8837,  -3.8089,   0.3101, -25.3937,\n",
      "           -1.9698],\n",
      "         [ -4.2140,  22.7677,  -8.3314,   6.9728,   1.6793,  -8.9926,   9.9306,\n",
      "          -22.6073]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[-0.0528,  1.0619, -0.1926,  ..., -0.3565,  0.1457, -0.0560],\n",
      "        [-0.5297,  0.2921,  0.0523,  ...,  0.2102, -0.0242, -0.4099],\n",
      "        [-0.0501,  0.0153,  0.2995,  ...,  0.3714,  0.1592,  0.0914],\n",
      "        ...,\n",
      "        [-0.1495, -0.1975,  0.1394,  ..., -0.7177, -0.1219,  0.2072],\n",
      "        [-0.1545,  0.1219, -0.2722,  ...,  0.2062, -0.5602,  0.3787],\n",
      "        [ 0.1618,  0.6645,  0.5992,  ...,  0.4639, -0.0032, -0.0250]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[ -7.9307,   2.2105, -35.9091,  13.4520,  -8.8980,  24.8177, -11.8091,\n",
      "           13.9080],\n",
      "         [-44.7344, -22.4375,   4.6058,   6.6549, -31.7046, -14.4801, -20.4379,\n",
      "           34.3219],\n",
      "         [-30.4497,  14.2453,  24.3714, -20.2563, -14.7386,  18.2232,  34.4569,\n",
      "           -5.2704],\n",
      "         [ -9.7536,  28.0527,   2.1207,   5.7438,   3.0145,  38.9079, -10.4345,\n",
      "           -7.2106],\n",
      "         [ 10.6196,  18.6676,  15.9545,  20.6776, -16.9065, -31.5215,  20.4099,\n",
      "          -41.0230],\n",
      "         [ -1.9140,  28.3727,  -5.3288,  10.4550,  10.8242,  18.9226,   8.6980,\n",
      "          -10.0098],\n",
      "         [  7.2982,  -7.9833,  18.4521, -12.3982, -25.7967, -10.3831,  39.5702,\n",
      "          -16.7079],\n",
      "         [  0.9942, -12.7443,   0.9561,  39.6067,  22.8856, -14.8823,  -8.1429,\n",
      "           -2.8414],\n",
      "         [ 12.6477,   0.2753, -25.5927, -36.9236,  19.9417,  -5.2244,  -8.8692,\n",
      "           -7.7072],\n",
      "         [ 35.6685,  30.4314, -18.9671, -13.1436, -27.9724,  13.0243,  15.7979,\n",
      "          -10.8555],\n",
      "         [ 21.2730, -16.5566,  -7.2148,   5.7332,   9.6098,   4.7049,   6.2189,\n",
      "            1.9478],\n",
      "         [ -2.1955, -30.0471, -14.8273,  39.3344,  54.4482, -12.9036,  35.9834,\n",
      "            1.2293],\n",
      "         [ 17.7829,  19.5083, -25.6979,  10.0195,   0.4892,  19.5223,  -5.4188,\n",
      "           -1.5852],\n",
      "         [ -5.1921,  10.4984,  -8.4099,   2.0927,  23.2547,   3.0095, -19.5460,\n",
      "           -6.7757]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[-0.2388, -0.0075,  0.0422,  ...,  0.0844,  0.4591,  0.3566],\n",
      "        [-0.0374, -1.0648,  0.7587,  ..., -0.2940, -0.3560, -0.1165],\n",
      "        [ 0.5317, -0.0461,  0.5292,  ..., -0.2909, -0.3373, -0.2961],\n",
      "        ...,\n",
      "        [ 0.3720, -0.2695, -0.1774,  ..., -0.4921,  0.1988,  0.2351],\n",
      "        [-0.3486,  0.8999,  0.5347,  ...,  0.2255, -0.2012, -0.4006],\n",
      "        [ 0.2506, -0.0210,  0.4031,  ...,  0.9713, -0.1680,  0.2506]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[  64.0045,   47.3240,   15.5198,  -12.8136,   12.7056,  -58.2116,\n",
      "           -15.8846,  -33.5921],\n",
      "         [ -49.3325,   -4.3026,   19.7294,   20.0800,   63.7333,   -8.4816,\n",
      "             4.1797,   15.6543],\n",
      "         [   5.9108,   -2.5400,    4.7086,  -15.7283,   26.9257,  -11.0089,\n",
      "            56.4049,  -28.2261],\n",
      "         [  21.8006,    2.9829,   -5.5590,   11.6702,   -2.0272,  -30.2470,\n",
      "           -14.9988,    4.2566],\n",
      "         [  -1.8025,   19.3961,  -34.3816,   36.1916,  -28.3858,  -26.4546,\n",
      "           -38.5755,  -11.6150],\n",
      "         [ -16.7857,  -86.0768,   -6.4880,   57.2348,  -30.4736,   62.8710,\n",
      "             7.1557,   -8.7046],\n",
      "         [ -33.4774,   73.2232,   26.0960,   32.3475,   -7.1290, -100.3367,\n",
      "            -3.3644,   25.6678],\n",
      "         [  39.9929,   44.4238,   83.7850,   34.3972,   24.8381, -133.2620,\n",
      "            -2.7866,   21.9611],\n",
      "         [ -58.0535,  -48.5636,  -68.0357,  -54.1097,   13.8806,  -25.0117,\n",
      "            41.8053,    7.5058],\n",
      "         [  85.4166,   65.1222,    8.8607,  -29.2792,  -15.8683,   31.3447,\n",
      "            87.3202,    6.5032],\n",
      "         [  39.7151,   -4.5827,  -24.3434,    2.9275,   27.7178,  -10.7260,\n",
      "            41.6567,   22.0303],\n",
      "         [ -39.6376,   53.1267,   77.3294,  -24.8273,   -8.4862,  -34.3278,\n",
      "             2.3286,  -89.0534],\n",
      "         [ -53.9506,  -91.1803,  -24.2715,   47.9318,  -60.8544,  -77.5500,\n",
      "             0.8229,  -86.7262],\n",
      "         [  66.9394,  -27.0284,   54.8944,   43.9371,   17.0547,   16.5128,\n",
      "             8.3039,  -48.6366]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.0169, -0.3744, -0.4696,  ...,  0.1478,  0.2272,  0.0711],\n",
      "        [ 0.0480, -0.4315, -0.1916,  ..., -0.0134, -0.0737,  0.5621],\n",
      "        [-0.2522,  0.8620,  0.2173,  ...,  0.2574,  0.2242, -0.0658],\n",
      "        ...,\n",
      "        [ 0.8329,  0.0045,  0.2826,  ...,  0.4276, -0.1199,  0.5794],\n",
      "        [-0.6192,  0.3364,  0.1393,  ...,  0.1378,  0.1462,  0.1636],\n",
      "        [-0.3735, -0.4352,  0.2042,  ..., -0.8651,  0.7801,  0.3778]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[-3.6985e+01, -3.9804e+01, -1.6878e+01,  1.6332e+01,  2.4659e+01,\n",
      "          -4.9230e+01, -1.6571e+01, -4.8937e+01],\n",
      "         [-6.8606e+01, -9.5201e+00,  2.8556e+01, -1.7708e+01,  3.9932e-02,\n",
      "          -4.6813e+01,  2.3674e+01, -3.0208e+00],\n",
      "         [-4.6246e+00, -5.5554e+01, -2.6726e+01, -1.5228e+01,  5.1557e+01,\n",
      "           3.0573e+01, -1.0969e+01,  3.1168e-01],\n",
      "         [-1.7008e+01,  6.5012e+01, -5.2897e+00, -3.6747e+01,  1.2024e+01,\n",
      "           5.5782e+00,  4.3969e+01, -3.2278e+01],\n",
      "         [ 1.4888e+01, -3.4859e+01, -3.1213e+01, -4.9363e+01,  1.9202e+01,\n",
      "           4.0052e+01,  7.6974e+01, -1.4222e+01],\n",
      "         [ 6.7693e+01,  1.5682e+01,  7.5652e+01, -5.2146e+01,  5.6825e+01,\n",
      "           5.8490e+01, -1.2273e+01, -1.4267e+01],\n",
      "         [-1.7908e+01, -4.8381e+01, -6.6629e+00, -2.5200e+01,  4.8556e+01,\n",
      "           3.0543e+01, -2.1275e+01,  2.6344e+00],\n",
      "         [-4.5073e+01, -2.3682e+01, -4.0483e+01,  6.8123e+01, -3.1552e+01,\n",
      "          -4.3238e+01, -6.5033e+00,  1.0197e+01],\n",
      "         [ 9.1220e+00,  2.6190e+01,  3.1244e+01,  5.8571e+01, -3.4938e+00,\n",
      "           2.8698e+00, -5.0565e+00,  9.2197e+01],\n",
      "         [ 5.2190e+01,  1.8246e+01, -1.0941e+00,  4.2770e+01, -6.6406e+01,\n",
      "           9.9830e+00, -1.6485e+01, -1.4464e+01],\n",
      "         [-5.0931e+01,  8.1341e+01,  5.5844e+01, -1.0062e+02, -1.4903e+01,\n",
      "          -2.7368e+01,  2.4647e+01, -3.0577e+01],\n",
      "         [ 2.1219e+01, -3.3375e+01,  1.6843e+01, -3.4788e+01,  3.6365e+00,\n",
      "          -5.5242e+01,  2.3836e+01, -3.5555e+01],\n",
      "         [-1.5569e+01, -6.0831e+00,  2.0487e+01, -7.5677e+01,  1.6691e+01,\n",
      "           4.9996e+01, -3.2672e+01,  8.2147e+01],\n",
      "         [ 2.4317e+01, -2.7037e+01,  3.5685e+01, -3.6994e+01, -3.7959e+01,\n",
      "           1.1340e+01, -5.7963e+01,  4.3438e+01]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=14336, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.2108, -0.0296,  0.2227,  ...,  0.0198, -0.3060, -0.1795],\n",
      "        [-0.4341,  0.1732,  0.4053,  ..., -0.2083,  0.4949,  0.4946],\n",
      "        [-0.2801,  0.2338, -0.1460,  ...,  0.1118,  0.2224,  0.3779],\n",
      "        ...,\n",
      "        [-0.1857, -0.4046,  0.0162,  ..., -0.3852,  0.1325,  0.1963],\n",
      "        [ 0.1470, -0.2455, -0.3758,  ...,  0.0213, -0.6404, -0.1598],\n",
      "        [-0.0611,  0.6273,  0.6831,  ..., -0.4074, -0.1141,  0.7913]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[ 2.6550e-02,  3.9515e+00, -1.8087e+01,  3.0262e+01,  2.7578e+01,\n",
      "          -1.7742e+01,  2.0290e+01,  4.0025e+01],\n",
      "         [-4.6247e+01, -4.6951e+01, -2.7862e+00, -1.0521e+01,  1.9831e+01,\n",
      "          -1.7533e+01,  3.0120e+01, -3.7250e+00],\n",
      "         [ 4.1303e+00, -2.7886e+01,  2.8360e+01,  2.7864e+01, -4.9916e+01,\n",
      "           2.0841e+01,  8.0547e+00, -5.6907e+00],\n",
      "         [-1.2688e+01,  5.0687e+01, -3.6396e+01, -1.4496e+01,  4.1458e+01,\n",
      "          -3.9752e+00, -2.5889e+01,  3.2305e+01],\n",
      "         [-2.9705e+01, -2.9283e+01,  3.6705e+01,  1.0781e+01,  1.7498e+01,\n",
      "          -1.1413e+00,  4.8986e+00, -1.7262e+01],\n",
      "         [ 2.4064e+01, -3.9070e+01, -2.9538e+01,  7.6939e+00,  7.2735e+00,\n",
      "           1.2601e+01, -1.3819e+01,  3.8089e+01],\n",
      "         [ 1.6322e+00,  1.7420e+00,  2.3294e+01,  9.3934e+00,  1.1948e+01,\n",
      "          -1.4277e+01, -1.4322e+01,  1.1661e+01],\n",
      "         [-6.6669e+00,  2.6941e+00,  4.5182e+01, -1.3760e+01, -1.5733e+01,\n",
      "          -2.9164e+01,  1.8360e+01, -2.4616e+00],\n",
      "         [-7.7255e+00, -1.0408e+01, -2.3427e+01,  1.4904e+01, -1.8363e+01,\n",
      "          -2.0869e+00, -6.8765e+00, -9.3567e+00],\n",
      "         [ 5.7911e+00,  1.3147e+01,  3.8599e+01,  1.4357e+01, -7.7129e+00,\n",
      "          -1.3911e+01, -4.3895e+01, -1.9743e+01],\n",
      "         [-5.1980e+01,  2.1959e+01, -7.5255e+00, -4.3309e+01,  1.6302e+00,\n",
      "           1.4311e+01,  5.4502e+00, -2.3552e+01],\n",
      "         [ 2.8917e+01,  4.9355e+00,  1.1296e+01,  8.0621e+00,  7.9176e+00,\n",
      "          -1.2239e+01,  2.5110e+01,  2.1146e+01],\n",
      "         [-8.0706e+00, -1.6216e+01,  2.1214e+01, -5.6842e+01, -2.8563e+01,\n",
      "          -6.8866e+00, -2.8355e+01,  1.3244e+01],\n",
      "         [ 1.2225e+00, -2.1994e+00, -3.2731e+01,  5.1796e+01,  2.4950e+01,\n",
      "          -2.0867e+01,  2.1186e+01,  1.5846e+01]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.0350, -0.1492,  0.0628,  ..., -0.2052,  0.0615,  0.3958],\n",
      "        [ 0.2081, -0.3263,  0.0348,  ...,  0.9307, -0.1479, -0.1028],\n",
      "        [ 0.4965, -0.7631,  0.1131,  ..., -0.3249, -0.4448,  0.5503],\n",
      "        ...,\n",
      "        [-0.4609,  0.0944, -0.0817,  ...,  0.3575,  0.3165, -0.5410],\n",
      "        [ 0.0842, -0.1549, -0.1926,  ..., -0.3957, -0.0650, -0.3505],\n",
      "        [ 0.0492, -0.5708,  0.0961,  ...,  0.3535,  0.4904,  0.1153]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[-31.4768,  18.8378,  21.0496, -11.3480,   1.4038,  -9.4315, -32.2210,\n",
      "          -33.9395],\n",
      "         [-14.8989,  57.9656,   8.9450, -39.7914,  -6.8136,   8.5442,  50.3238,\n",
      "           -4.8036],\n",
      "         [-39.3376,  -3.9300,  -9.2709,  44.0065,  13.5329,  -1.6615,   3.0253,\n",
      "            4.8262],\n",
      "         [-23.9679,   3.2470, -16.2118,   3.8029,  -0.8360,   9.2916,  -2.2791,\n",
      "           -7.2258],\n",
      "         [ 16.8386,  14.8431,  -5.8945,  -8.5433,   0.2450,  -8.4432, -25.6537,\n",
      "           26.2329],\n",
      "         [-42.1611,  -0.6194,  -7.5892,  -0.8418,  21.7416,   7.4759, -20.5365,\n",
      "          -14.7581],\n",
      "         [  6.1393,  30.3509,  50.8765,   1.7837, -17.0199, -26.0426,   2.6668,\n",
      "          -20.4816],\n",
      "         [  8.2691,  -8.3530,   6.9103,   9.2861,   8.4155,  36.2043,   4.8354,\n",
      "           -0.5467],\n",
      "         [ 23.1181, -17.4343,  16.6999,  10.8553,  -1.8217,   4.3521,  29.9738,\n",
      "           -1.7087],\n",
      "         [  8.5694,  -2.0090,   1.5060,  36.6006, -47.5717,   6.1351, -26.2374,\n",
      "            1.4519],\n",
      "         [  2.9339, -21.6931,   3.8507,  11.9054,  -5.7867,  -8.0094,  18.8407,\n",
      "           57.7440],\n",
      "         [  2.1259, -21.3720,   6.9419,  -0.5523,  -3.6261,  -2.4829,  -4.0838,\n",
      "           -7.1882],\n",
      "         [ 19.2707,   0.4462,   2.0919,   3.7992,  13.9026, -24.7975,  16.1798,\n",
      "           -1.9346],\n",
      "         [  0.6105, -25.3476,  25.7737,  36.8035,  10.1801, -18.4340, -19.0379,\n",
      "           44.5599]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.3396, -0.1114, -0.2780,  ..., -0.3605,  0.0592, -0.4609],\n",
      "        [ 0.1083, -0.5095,  0.2247,  ..., -0.1036, -0.3229, -0.4453],\n",
      "        [-0.4222, -0.0489, -0.4628,  ...,  0.4053,  0.2911,  0.0806],\n",
      "        ...,\n",
      "        [ 0.4700,  0.1527,  0.3101,  ...,  0.7749, -0.1664, -0.1882],\n",
      "        [-0.2096, -0.0109, -1.0031,  ..., -0.2001,  0.0100,  0.4307],\n",
      "        [ 0.1728, -0.1233, -0.1440,  ...,  0.3116,  0.1776,  0.3660]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[ -3.5011,   0.2834,  -2.6750,  16.0326,  -8.1051, -14.4099,  -8.3447,\n",
      "           -6.8883],\n",
      "         [ -6.1429,  -2.3617,   4.4606,   8.4561,  -1.2533,  -1.8973,   2.5836,\n",
      "            3.8047],\n",
      "         [ 20.4310,  -9.8321,  -0.9736,  13.9663, -11.4084, -22.1184, -16.1790,\n",
      "            9.5382],\n",
      "         [ -2.7994,  -3.1414,   1.8987, -15.1844,  -4.7902,   9.4204,   1.3707,\n",
      "           -0.9976],\n",
      "         [ -6.9665, -16.4698,  -9.9346,   4.4201,  19.9534,   8.9288,  -9.8906,\n",
      "          -14.5069],\n",
      "         [-13.6910,  28.2133, -11.1737,  -6.7733,  31.7901,   6.3418, -13.4957,\n",
      "           -3.6403],\n",
      "         [-13.6826,   8.0258, -18.7120,  -3.3698, -14.2350,   2.4457,  10.9378,\n",
      "            7.4634],\n",
      "         [ 15.9636,   0.9159,  -2.0516,  -1.2055,  16.0337,   8.6023,  15.7280,\n",
      "           -6.1297],\n",
      "         [  4.9506,  -2.6945,   3.1632,  11.2068,   6.5110,   3.8576, -17.8887,\n",
      "           -7.6325],\n",
      "         [ 16.0548,   0.0824, -11.6468,  -8.0172,  -8.3134,  -7.8433,  -9.8273,\n",
      "           -3.8068],\n",
      "         [ -4.6986,   2.2553, -17.8439,   5.3511,   1.6453,   2.3886,  14.8423,\n",
      "           18.2056],\n",
      "         [-19.1723, -10.8671,  -9.1437,   8.4055,   4.9540, -11.4526,  -8.6901,\n",
      "           -7.3584],\n",
      "         [-14.4594,   3.8122, -13.1107,  12.7822,  -7.7566,  15.3952,   4.7483,\n",
      "            7.4582],\n",
      "         [  1.8470,  -2.4756,  -5.6088,  13.2978,  -1.9178,   7.8386,  18.5145,\n",
      "           14.4905]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.7753,  0.3122, -0.0955,  ...,  0.3272,  0.5318,  0.1860],\n",
      "        [-0.9181, -0.0526,  0.1526,  ...,  0.9778,  0.2825, -0.0854],\n",
      "        [ 0.3399, -0.0028,  0.2067,  ...,  0.1021, -0.3594,  0.4888],\n",
      "        ...,\n",
      "        [ 0.1072, -0.6136, -0.3162,  ..., -0.6323,  0.2380,  0.3764],\n",
      "        [ 0.1934,  0.4893, -0.5278,  ..., -0.2068, -0.7040,  0.0995],\n",
      "        [ 0.1486, -0.0694,  0.0013,  ...,  0.0311,  0.3098, -0.0326]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[ -8.8381,   3.0102,  15.5961,   6.4311,   2.4573,  15.1384, -10.2257,\n",
      "            0.5094],\n",
      "         [ -5.8066, -11.7056,   9.7052,  -5.3150,   2.2206,  -1.0332,  15.7932,\n",
      "            5.2631],\n",
      "         [ -8.7928,   2.4492,   8.4531,  -1.0571,  -3.2485,   1.5817,  -0.8136,\n",
      "           19.6691],\n",
      "         [ -0.1785,   2.3163,   5.2130,   3.5957,   5.8777,  -4.4121,  -2.8436,\n",
      "          -32.1798],\n",
      "         [  3.3629,  -1.7825,   2.0888,   1.8638,  -7.4228,   1.1751,  -2.6030,\n",
      "          -17.3393],\n",
      "         [ -5.7381,  -7.0635,  10.5715,   6.2861,  -1.4493,   1.6496,  -2.5372,\n",
      "          -11.0742],\n",
      "         [-18.0724,  -8.2798,   7.1228,  12.2804,  12.7559,   4.0445,   6.7274,\n",
      "          -17.7451],\n",
      "         [ -8.1800,  17.6992,  12.7505,   9.7323,   5.1312, -16.3576,  20.0677,\n",
      "          -14.2191],\n",
      "         [-20.6705, -31.0933,   8.7195,   8.0440,   2.8531, -19.4408,  25.3809,\n",
      "            3.5007],\n",
      "         [-18.1611,  14.8254,  10.3107,   1.2408,  -1.4303,  -2.5129,  11.3963,\n",
      "          -16.1374],\n",
      "         [ -8.8435, -14.9403,  -2.6133,  14.7200,  -4.7553,  13.1556,  -1.6409,\n",
      "            8.1411],\n",
      "         [-14.5348,   7.7922,  -2.7700,  15.0037,   4.0918,   7.8966,  15.6327,\n",
      "           -0.1057],\n",
      "         [  4.5445,  -4.9658, -12.6706,  18.4731,   8.9990,   2.4085,   9.6918,\n",
      "          -14.0170],\n",
      "         [ 12.7203,   6.1834,   8.2780, -32.5085,   7.5727,   4.8212,   8.0820,\n",
      "            5.8853]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[-0.2951, -0.1731, -0.4020,  ...,  0.2441,  0.2205,  0.2331],\n",
      "        [-0.9272,  0.1384,  0.2433,  ...,  0.2059,  0.0825,  0.2492],\n",
      "        [-0.1658, -0.1592, -0.2195,  ..., -0.3428,  0.0585,  0.2129],\n",
      "        ...,\n",
      "        [ 0.0783,  0.2460,  0.5261,  ..., -0.1431, -0.4367,  0.1296],\n",
      "        [ 0.1138,  0.6913, -0.3467,  ..., -0.5397,  0.1611, -0.0732],\n",
      "        [ 0.2396, -0.2175, -0.3112,  ...,  0.0949, -0.4029, -0.1551]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[ 19.6560, -27.1089,  -8.9413,  -2.0799,  15.7791,  26.5025,  12.4175,\n",
      "          -10.3663],\n",
      "         [ 23.8389,   2.9668,  -6.9265,   1.1887,   3.8573,   6.0088, -36.3375,\n",
      "           10.1851],\n",
      "         [-26.2575,   0.5396, -35.6098,  31.3071, -23.6315,  22.1512,  -2.1955,\n",
      "            1.7152],\n",
      "         [ 54.4383,  46.8640,   9.7535,  17.0492,   7.7478,   7.9616,  24.4291,\n",
      "          -11.1245],\n",
      "         [-29.3285,  44.6339, -16.8044,  -4.7798,  -3.3252,  -9.4028,  71.8405,\n",
      "          -15.2179],\n",
      "         [  5.3541,  40.2415,  30.8739,   3.3722,  14.8796,  20.5246, -18.8946,\n",
      "           22.1171],\n",
      "         [-35.4778,  -4.5727,   1.0963,  24.7418,  15.7305,  42.1194, -11.6569,\n",
      "          -24.4918],\n",
      "         [-34.4899, -27.8317,  40.7809,   5.4518,  19.2397,  -2.7306, -16.2865,\n",
      "           32.2483],\n",
      "         [-23.1238,  -0.3572, -17.0839, -32.4627,  -3.5690,  18.9200,   4.0863,\n",
      "           -5.8100],\n",
      "         [ 18.6605,  21.6708,  -6.3779, -20.1759, -19.0053, -33.5788,  -2.8827,\n",
      "            7.7094],\n",
      "         [ 12.0123,   3.2918, -29.7564, -19.7205,  31.3596,  33.8828, -19.1142,\n",
      "            3.9526],\n",
      "         [-10.0891,  20.8505, -16.4544,  11.7836,   8.1387, -32.6706, -21.7125,\n",
      "           -6.8173],\n",
      "         [ 13.8406, -13.2758,   5.0109,  17.6100,  -4.9132,   2.1325,   6.6145,\n",
      "          -31.5609],\n",
      "         [ 12.8890,   0.1202,  -2.3859,  -9.9306,  -2.6373, -23.6799, -41.0892,\n",
      "           37.5540]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.5605, -0.3458, -0.1240,  ...,  0.7119,  0.4274, -0.3718],\n",
      "        [ 0.4083,  0.1465, -0.1610,  ..., -0.9319, -0.1192, -0.0878],\n",
      "        [-0.1301,  0.2734,  0.8062,  ..., -0.2208,  0.1717, -0.1406],\n",
      "        ...,\n",
      "        [ 0.3175, -0.0376,  0.3242,  ...,  0.3271, -0.2289, -0.2913],\n",
      "        [-0.0032,  0.0154, -0.3458,  ...,  0.2692, -0.5059, -0.2021],\n",
      "        [ 0.9444, -0.0924,  0.0062,  ...,  0.5089,  0.0060, -0.1941]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[ 55.3276,   4.5982, -92.4316,  20.1588,  -9.9849,  18.7660,  -8.5572,\n",
      "           11.0211],\n",
      "         [-39.4573,  70.7603, -69.4940, -16.4436,  -5.4535,  -7.0538, -81.6770,\n",
      "          -19.4640],\n",
      "         [-55.5792,  47.8691,  39.4272,  69.9325,   4.6875,  52.4797,  26.1600,\n",
      "           34.2152],\n",
      "         [ 19.8195,  -3.7221,  47.6050,  23.4151, -41.3962, -54.0556, -61.4656,\n",
      "            4.6992],\n",
      "         [  0.7676,  82.1821, -68.1729,   4.6628, -48.6087,  38.7376,  80.2704,\n",
      "          -15.5921],\n",
      "         [-24.1867,  63.6032,  38.2918, -14.3218,  38.2049,  34.1903,  27.7035,\n",
      "            7.6703],\n",
      "         [ 10.9815,  62.4455,  72.9042, -51.8952,  80.5021, -23.9541, -73.6578,\n",
      "            8.5934],\n",
      "         [ 51.1556, -36.2348, -35.3035,  -1.6424, -54.6527,  24.4499, -46.6420,\n",
      "           49.2497],\n",
      "         [-28.0382,  45.0115, -12.2838,  26.1039,  -1.3327,  10.1593,  20.7225,\n",
      "          -25.3032],\n",
      "         [-37.2723, -22.9944,  33.5321, -20.3884,  74.2138,  25.8022,   9.4966,\n",
      "          -32.0905],\n",
      "         [ 63.5886,   7.4718, -56.1170,  16.6820, -31.8485,  33.6697, -18.3960,\n",
      "          -28.5500],\n",
      "         [ 32.5058,   0.6860, -18.2204,  22.4731,  12.5635,  18.6149,  26.3302,\n",
      "           71.5043],\n",
      "         [ 30.4052, -15.4891,  23.8144, -37.8935,  16.1766,  69.4968,  27.4215,\n",
      "            1.1517],\n",
      "         [ 15.3162,  61.1587, -59.2378,  -1.8925,  31.7913, -77.2224,  -2.5671,\n",
      "           15.0104]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.2502,  0.3300, -0.3560,  ..., -0.1580, -0.9716, -0.2410],\n",
      "        [ 0.1978, -0.7895, -0.0948,  ..., -0.2236,  0.2401, -0.2059],\n",
      "        [ 0.3642, -0.1096,  0.0956,  ..., -0.0725, -0.9703, -0.2165],\n",
      "        ...,\n",
      "        [ 0.1234, -0.2567, -0.2916,  ..., -0.0633,  0.0354, -0.9629],\n",
      "        [ 0.2313,  0.3276,  0.4386,  ..., -0.1708,  0.2812, -0.3651],\n",
      "        [-0.4942,  0.1776,  0.4804,  ..., -0.0477,  0.0822,  0.2903]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[ -32.8437,  -14.6309,  -47.2463,  -52.7399,    9.3479,  -12.7773,\n",
      "            -9.1397,  -97.1626],\n",
      "         [  -3.9322,  -25.4441,   35.3867,    9.1106,   69.1799,  -34.8355,\n",
      "            26.6707,   22.2071],\n",
      "         [  21.8389,  -18.5705,  -58.8295,   31.2765,    4.7417,   28.6403,\n",
      "           -68.0414,   30.4042],\n",
      "         [ -94.6369,  -73.4024,   17.9562,   -7.2091,  -40.6761,  -16.3509,\n",
      "             5.6878,   28.8316],\n",
      "         [ -34.4232,   -5.3375,   59.1750,   -5.3987,   46.2118,   34.5866,\n",
      "            16.4088,  -51.3854],\n",
      "         [  64.3636,   40.3022,  -13.6542,   52.4876,   -4.9081,   16.8979,\n",
      "           -50.3528,  -29.2945],\n",
      "         [  -3.0336, -117.1993,  -10.3503,  -61.7403,    1.2568,   33.2498,\n",
      "            13.4285,   38.2151],\n",
      "         [ -14.4765,   34.0207,  -44.9095,  -30.7864,    9.2925,   58.6611,\n",
      "             4.4301,   -2.0516],\n",
      "         [ -17.4906,  103.3855,   37.7282,  -39.7645,   12.7334,   39.2589,\n",
      "           -35.1883,  -53.2310],\n",
      "         [  13.1289,   47.8925,   23.0889,   65.7503,   58.4676,   85.7482,\n",
      "           -51.1852,  -49.1625],\n",
      "         [  14.6733,  -41.7138,  -16.7638, -115.1646,  -92.8108,  -53.7001,\n",
      "           -26.8951,   41.2561],\n",
      "         [ -32.3797,  -11.0819,   31.4169,   30.7371,  -31.3171,   -5.9587,\n",
      "           -21.8620,   10.7754],\n",
      "         [ -59.4583,  -19.8161,  111.2271,   24.4516,   11.3128,    8.7255,\n",
      "           -28.7327,  -22.5915],\n",
      "         [ -22.1795,   53.5577,   16.6505,  -16.1763,   20.5805,   31.1788,\n",
      "           -11.5614,  -88.1092]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=14336, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[-0.3684, -0.2174, -0.2008,  ...,  0.0105, -0.0162,  0.1365],\n",
      "        [ 0.0811,  0.1612,  0.6876,  ...,  0.1478,  0.4906, -0.3785],\n",
      "        [-0.8470,  0.3944,  0.0902,  ...,  0.1805,  0.0940,  0.0098],\n",
      "        ...,\n",
      "        [ 0.3601,  0.2284, -0.4022,  ...,  0.5576,  0.0692, -0.2919],\n",
      "        [ 0.1571, -0.3297,  0.1227,  ...,  0.1279, -0.1431, -0.5151],\n",
      "        [-0.3822,  0.1858, -0.1715,  ..., -0.2371, -0.1831, -0.2411]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[-42.4187,   8.2401,  -9.3651,  26.4470,   6.7374, -19.4121,  -0.5358,\n",
      "            0.4528],\n",
      "         [ -0.2867,  42.5566, -24.5421, -27.1068,  30.0410,  32.8309,   1.1370,\n",
      "           -3.8277],\n",
      "         [ -8.1535,  20.6162,  -4.2617,  25.6674,  -6.0121,  16.7785,   9.0957,\n",
      "          -29.5087],\n",
      "         [  2.6807,  33.3283,  47.5060,  -7.4741,  41.3509, -10.1314, -20.1913,\n",
      "            3.2590],\n",
      "         [  5.9629,   4.5780,  24.1736,  19.9330, -16.7480,  -5.8442,   1.6823,\n",
      "           17.7594],\n",
      "         [  8.9491, -29.5017,  21.4653,   7.5201,  20.9534, -10.3563,   2.9686,\n",
      "          -18.7816],\n",
      "         [ 48.5201, -20.5033, -11.5594, -16.3246,  27.2295,  -7.3638,  11.9546,\n",
      "          -31.8872],\n",
      "         [ -7.9741,  18.8135,  17.5764,   7.4744,   4.9829,  27.7198,  -4.5262,\n",
      "           16.5525],\n",
      "         [ -9.0100,   7.8608, -19.1267, -47.1456,  16.6936, -14.0198,  42.8058,\n",
      "          -27.1060],\n",
      "         [  8.5305,   4.7904,  -6.8307, -34.1923, -27.4748, -21.6691, -28.5368,\n",
      "           35.9988],\n",
      "         [-45.9884,  12.7087,   1.9026,  -6.3299,  -9.9478, -39.4511,   7.8441,\n",
      "          -27.0313],\n",
      "         [-13.3817,   1.2653,   0.7852,  25.9893,  -2.8635, -65.7929, -15.0606,\n",
      "            8.4782],\n",
      "         [  7.5398,   7.9235,  -9.0530, -30.0836, -42.4788, -21.0939,   7.3086,\n",
      "          -38.3749],\n",
      "         [-43.2080,   4.5884, -32.6838,  -0.5808,  12.6663,  44.0966,  47.6702,\n",
      "            1.0344]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[-0.2190, -0.5892, -0.1362,  ...,  0.0021,  0.0172, -0.7426],\n",
      "        [ 0.1768, -0.1194, -0.1691,  ...,  0.3283,  0.1720,  0.0502],\n",
      "        [-0.5124, -0.2573,  0.2047,  ..., -0.0405,  0.1202,  0.3342],\n",
      "        ...,\n",
      "        [-0.3475,  0.3828,  0.0259,  ..., -0.0323,  0.1748, -0.0891],\n",
      "        [-0.7928, -0.0531,  0.0885,  ...,  0.0174, -0.1106,  0.3128],\n",
      "        [ 0.1664, -0.2699,  0.1320,  ...,  0.1472,  0.7543, -0.0257]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[-3.2006e+01,  3.3171e+01, -1.5563e+01, -1.5497e+01,  1.3754e+01,\n",
      "           2.0257e+01, -1.4900e+01, -5.6348e+01],\n",
      "         [ 8.2504e+00, -9.7880e+00,  4.1329e+00, -5.2207e+00,  1.6492e+01,\n",
      "           6.1508e+00, -1.4565e+01,  1.9586e+01],\n",
      "         [-1.1600e+01,  2.6029e+01,  2.2950e+01, -2.0607e+01,  6.9661e+00,\n",
      "          -4.2286e+01,  1.5118e+01, -4.6180e+00],\n",
      "         [ 4.9015e+01,  7.7277e-01, -2.0847e+01, -1.2711e+00, -8.5458e+00,\n",
      "          -2.1340e+01, -2.1896e+01,  1.6095e+01],\n",
      "         [ 6.9793e+00,  1.6601e+01,  4.9120e+00, -2.4800e+01,  4.0147e+00,\n",
      "          -1.1734e+01,  1.5317e+01, -4.9856e+01],\n",
      "         [-5.1625e-02, -8.9889e+00,  1.3832e+01, -8.8590e+00, -1.6812e+01,\n",
      "           1.9185e+01,  2.4344e+01,  1.3919e+00],\n",
      "         [-1.4225e+01,  1.3978e+00,  1.9947e+01, -8.8375e+00, -1.9025e+01,\n",
      "          -1.6693e+00, -3.0689e+01, -3.1552e+00],\n",
      "         [ 3.7383e+00,  3.8932e+01, -8.1107e+00, -3.7381e+01,  1.9989e+01,\n",
      "          -7.1178e+00, -1.0419e+01, -5.4234e+01],\n",
      "         [ 1.3125e+01, -3.1115e+01, -2.5023e+01,  3.2655e+01, -2.5530e+01,\n",
      "          -5.3328e+01,  2.4052e+01, -1.9100e+01],\n",
      "         [ 3.0669e+01, -7.2590e+00, -2.5093e+01,  3.8058e+00,  1.1037e+01,\n",
      "           3.6679e+00, -2.1423e+01, -3.0335e+01],\n",
      "         [ 4.2626e+01, -4.0871e+01, -2.7031e+00,  4.3813e+01,  1.9215e+01,\n",
      "          -2.8445e+00,  6.4965e+01, -1.5473e+01],\n",
      "         [ 1.4506e+01, -6.2321e+00,  2.8990e+01, -5.9198e+00,  1.0043e+01,\n",
      "          -1.0840e+01, -5.5520e+01,  3.2970e+01],\n",
      "         [-1.1953e+01,  1.1246e+01, -3.0337e+01,  4.6638e+00,  1.4878e+01,\n",
      "           2.9711e+01,  1.5470e+01,  3.3210e+00],\n",
      "         [ 6.8242e+00, -2.6074e+01, -8.6872e-01, -1.1631e+00, -2.9494e+01,\n",
      "          -5.3851e+00,  1.0513e+01, -1.2216e+00]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.5866, -0.3098, -1.2709,  ..., -0.2947,  0.6622,  0.1125],\n",
      "        [ 0.1084, -0.0271, -0.4062,  ...,  0.1601, -0.3102, -0.3495],\n",
      "        [ 0.1919,  0.4529,  0.0537,  ...,  0.4372, -0.1521, -0.0410],\n",
      "        ...,\n",
      "        [ 0.1487,  0.0701,  0.6048,  ..., -0.1893, -0.4866,  0.2722],\n",
      "        [-0.6864,  0.5646,  0.0188,  ..., -0.3263,  0.2631, -0.1490],\n",
      "        [-0.2478,  0.0824,  0.5952,  ..., -0.0455, -0.2247, -0.4769]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[  5.1534,   5.6511,   4.2325,  -5.3139,   2.2546,   2.9086,   1.5573,\n",
      "           14.0684],\n",
      "         [ -0.3644,   6.8678,  -9.3352,  -1.5977, -38.3617,  13.9134,   1.5881,\n",
      "           -2.5295],\n",
      "         [ -3.3295, -12.0530,  -4.0407,  -4.0951,  -4.3161, -13.3515,  27.9203,\n",
      "           -1.8694],\n",
      "         [-12.1305,  -3.3257,  -2.0195,   0.0933,  16.2247,  -8.6741,   3.3581,\n",
      "            3.9989],\n",
      "         [  7.1756,  24.1318,  16.0285,  15.6246, -16.5104,  -4.2286, -15.0217,\n",
      "           12.0453],\n",
      "         [  7.9078,   0.0660,   2.0710,  19.1751, -16.0398,   1.3273, -11.9718,\n",
      "          -27.5242],\n",
      "         [ 19.4723,  13.6659,  12.7499, -12.3249,  -8.6371, -17.4300,   2.4347,\n",
      "            2.8318],\n",
      "         [-13.2414,   2.8800,  -4.0809,  -4.3912,  18.0816,   1.1095,   8.3682,\n",
      "           16.5016],\n",
      "         [  4.9791, -13.4491,  -7.3568, -11.8091,  10.1061, -11.9078,  -2.0459,\n",
      "          -11.1206],\n",
      "         [ 30.5844,   2.7218,  19.5747,   1.5456,   5.3819,  -6.1082, -14.9223,\n",
      "           -7.7012],\n",
      "         [ 12.7956,  10.6494,  -3.3717,  -4.7245,  -5.1087,  11.0790,  -5.3634,\n",
      "           23.0837],\n",
      "         [ 18.1165, -10.9889,   0.3713,   1.9743, -13.4740,  -0.6240, -15.0287,\n",
      "            4.9965],\n",
      "         [ -2.8505,   3.2818,  -1.0091, -19.4100, -11.2746,  -3.8615,   9.3972,\n",
      "           -2.4877],\n",
      "         [  8.3050,   2.5569,  11.2048,   7.3902,  21.4729, -26.3034,  10.2947,\n",
      "           17.8463]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[-0.1503, -0.6850, -0.2170,  ...,  0.6438, -0.0876,  0.4019],\n",
      "        [-0.4853,  0.1976, -0.4817,  ..., -0.0814, -0.0302, -0.2549],\n",
      "        [ 0.0430, -0.1865,  0.1253,  ...,  0.2056, -0.0471,  0.1209],\n",
      "        ...,\n",
      "        [-0.5006, -0.0875, -0.0372,  ...,  0.1697, -0.1516,  0.3393],\n",
      "        [-0.4395, -0.0670, -0.5278,  ..., -0.2128, -0.2416,  0.3150],\n",
      "        [ 0.0883,  0.7083,  0.1384,  ..., -0.3461, -0.5128,  0.0413]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[ 15.7835,   3.4173,  29.0755,   0.9041, -23.0146,   2.8656,   0.3629,\n",
      "            4.6853],\n",
      "         [  7.4686, -10.0311,   7.3437,  -2.0441,   3.0359, -13.9458, -16.6729,\n",
      "          -21.7765],\n",
      "         [ -2.4768, -18.9490,  10.4963,  -6.8960, -10.9199,  11.5267,  -6.8905,\n",
      "           11.9699],\n",
      "         [ -5.1115,   6.8334,   4.0005,   2.9884, -14.0728,  13.0321,  -6.2528,\n",
      "           14.1183],\n",
      "         [ -3.5805,  -2.0333,   1.4219,  13.9934,   8.9852, -10.2169,  -9.8226,\n",
      "           11.3484],\n",
      "         [  7.9411, -11.8528,  11.8621,   3.9726,  12.4233,  13.4425,   2.8425,\n",
      "          -21.2151],\n",
      "         [ -5.0525,   2.2118, -12.7296,  12.2666,  -7.1656,  11.8261,  -3.3245,\n",
      "            3.1756],\n",
      "         [ -5.7182,   8.4297,  11.8856,  13.2383,  -9.7104,   2.2214,  34.1199,\n",
      "            4.9587],\n",
      "         [ -2.8771,  -6.0064,   2.6243,   9.2796,   1.7083, -18.8136,  -0.8954,\n",
      "           -4.3404],\n",
      "         [ 14.7065,   1.1776,  -1.8665,  17.1903,   7.1593,   1.4291,  -2.5209,\n",
      "          -16.7114],\n",
      "         [  0.0769,  12.4248,   5.5526,  -1.7836,  -9.1000, -10.4694,  14.3604,\n",
      "          -20.0302],\n",
      "         [ -3.7927,   5.1409,   3.0782,  -6.5531,  -4.5749,  -6.3710,  -6.6269,\n",
      "            1.8804],\n",
      "         [  4.2298,  20.5989,  10.2407,   5.0057,  -2.6501,   5.3841,  -9.8970,\n",
      "          -14.4248],\n",
      "         [-19.3558, -24.8189, -10.2775,  -1.9355, -14.3163,   8.8025,  -2.7313,\n",
      "           -9.8288]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.6292, -0.4230, -0.1179,  ..., -0.0823, -0.1766,  0.3787],\n",
      "        [-0.4425,  0.2933, -0.0454,  ...,  0.4952, -0.3991,  0.1673],\n",
      "        [-0.2724, -0.2789, -0.2775,  ..., -0.3354, -0.2302,  0.2454],\n",
      "        ...,\n",
      "        [-0.5490,  0.0062,  0.0224,  ...,  0.3230, -0.2243, -0.4186],\n",
      "        [-0.7443, -0.4243,  0.1302,  ..., -0.2491, -0.4341, -0.3565],\n",
      "        [ 0.1050, -0.5789,  0.4897,  ...,  0.0760,  0.0883, -0.1683]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[-29.2173,   8.0148,  21.6710, -16.5564, -15.0531,  16.3263,  -1.2780,\n",
      "           -8.8514],\n",
      "         [-33.8204,   9.2958,   0.9339, -10.0796, -29.0945,  -5.0091, -12.3337,\n",
      "           -2.5078],\n",
      "         [  6.0930,  12.8297,  -4.9215,  32.0761,   1.6806, -16.5259, -33.0210,\n",
      "           -3.6690],\n",
      "         [ 20.0894,  40.7193, -15.2784,  20.6611, -23.8140, -56.2306,   2.7573,\n",
      "          -35.6149],\n",
      "         [ -1.8452,  -2.6549, -21.0352, -46.8011, -26.7120,   8.4025,  -3.2421,\n",
      "           17.5857],\n",
      "         [  3.4284,   2.8689,   3.8426,  18.5068, -35.6708,   5.9851, -32.0650,\n",
      "           15.4966],\n",
      "         [  3.9193,   9.3849,  10.4043, -49.0929, -11.9360,  25.4264,   7.0816,\n",
      "           11.1437],\n",
      "         [ -1.9611,  -5.7840, -20.7609,  -0.4390,   7.9808, -32.0014,  32.4006,\n",
      "            6.3732],\n",
      "         [ 37.5268,   5.0449,  20.7143, -17.1432,  -0.4809,  -4.4662,  -8.7351,\n",
      "           -4.5236],\n",
      "         [ -7.7905, -20.1069, -10.1882, -44.9463, -39.1856,  14.2388, -51.0746,\n",
      "            1.6620],\n",
      "         [-31.3457, -14.6946,   2.3258,  28.9516,  22.5439,  -0.7469, -32.6086,\n",
      "            0.8503],\n",
      "         [ -1.1395,   9.2986,  -4.1386,  12.6232, -34.5129,   9.5420,  18.1180,\n",
      "          -33.3657],\n",
      "         [ 13.5258,   5.1716, -32.4113,   3.1113, -16.2069,  11.9998,   9.2271,\n",
      "           35.3204],\n",
      "         [ -3.0947,  13.3377,  21.5248, -39.6666, -35.9714,  11.4790,  15.4396,\n",
      "           -3.7172]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.3771,  0.3349,  0.4440,  ...,  0.0573, -0.1775, -0.7441],\n",
      "        [ 0.0032,  0.3728, -0.2759,  ...,  0.6269,  0.6046,  0.3542],\n",
      "        [-0.1412, -0.9162,  0.4080,  ...,  0.3199,  0.2445, -0.2744],\n",
      "        ...,\n",
      "        [-0.0189, -0.1183, -0.0142,  ..., -0.3649, -0.3468, -0.0257],\n",
      "        [-0.1252,  0.1170, -0.2988,  ...,  0.1527,  0.2922,  0.3181],\n",
      "        [-0.7299,  0.6606, -0.0765,  ...,  0.2761, -0.2905, -0.0376]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[-2.9123e+01,  4.9634e+01,  3.6949e+01,  1.9456e+01, -8.0587e-01,\n",
      "          -2.5891e+01,  9.0930e+01,  6.6211e+01],\n",
      "         [-4.7357e+00,  4.2763e+01,  6.1551e+01,  4.0307e+00,  1.1809e+01,\n",
      "           8.2359e+00,  4.6507e+01,  8.3411e+01],\n",
      "         [-1.7832e+01, -9.6163e+00, -2.5316e+01, -3.8410e+01,  1.1344e+01,\n",
      "           1.0775e+01, -9.5974e+00,  3.9301e+01],\n",
      "         [-1.8576e+01, -3.5368e+01,  1.1825e+01,  1.0732e+01, -1.0703e-01,\n",
      "           1.8404e+01, -5.3322e-01,  6.9772e+01],\n",
      "         [-5.3601e+01,  5.4982e+01,  8.9457e+00,  1.5895e+00, -1.7906e+01,\n",
      "           2.2688e+01,  3.5628e+01,  3.6782e+01],\n",
      "         [ 6.7972e+00, -2.8181e+01, -1.9872e+01,  1.4941e+01, -4.0066e+01,\n",
      "           4.2357e+00, -6.1174e+01,  5.1138e+01],\n",
      "         [-3.2022e+01, -1.1355e+02,  6.8491e+01,  1.9682e+01,  9.1613e+00,\n",
      "          -3.6116e+01,  1.8042e+01,  5.0704e+01],\n",
      "         [ 7.0287e+00, -8.7082e+01, -1.8741e+01,  3.5992e+01, -7.4338e+01,\n",
      "          -8.0292e+00,  5.4698e+01, -2.9828e+01],\n",
      "         [-7.1546e+01, -2.3296e+01, -4.2895e+01, -2.2353e+00,  1.5581e+01,\n",
      "          -8.0462e+01, -2.8981e+01, -2.8725e+01],\n",
      "         [ 6.3079e+01,  3.2311e+01, -1.5535e+01,  1.4724e+00,  7.5606e-01,\n",
      "           1.6357e+01, -9.8168e+00,  2.2365e+01],\n",
      "         [ 3.7928e+00,  1.0861e+02,  9.0476e+00, -4.2960e+01, -4.9953e+01,\n",
      "           6.2604e+00, -1.5757e+01,  9.3994e+00],\n",
      "         [-1.1545e+01, -6.8400e+01, -1.6330e+01, -7.6927e+00,  2.2322e+01,\n",
      "          -1.2029e+01, -2.2006e+01, -2.3645e+01],\n",
      "         [ 5.0258e+00, -1.0079e+01,  4.3135e+01, -4.6342e+01, -2.2372e+01,\n",
      "          -1.8849e+01, -3.9256e+00,  8.2397e+01],\n",
      "         [ 4.6467e+01, -2.5351e+01, -8.2605e+01,  4.6771e+01, -3.3457e+01,\n",
      "          -2.4595e+01,  9.7159e+01, -7.0006e+01]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.7969,  0.5835,  0.1159,  ..., -0.0579,  0.0906, -0.3284],\n",
      "        [-0.0968, -0.6753,  0.6979,  ...,  0.1619,  0.4596, -0.0271],\n",
      "        [-0.1990, -0.3131, -0.1542,  ...,  0.2492,  0.0531, -0.0759],\n",
      "        ...,\n",
      "        [-0.7069, -0.2984, -0.4044,  ..., -0.8870,  0.3359,  0.2671],\n",
      "        [ 0.0426,  0.4457, -0.3314,  ..., -0.3917,  0.3424,  0.2495],\n",
      "        [ 0.7579, -0.1840,  0.4049,  ..., -0.2702, -0.0767,  0.0106]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[-1.0269e+01,  4.4237e+01,  3.2426e+01,  3.7099e+01, -1.3579e+01,\n",
      "          -5.1906e+01,  6.3141e+00, -2.3087e+01],\n",
      "         [-1.5609e+00, -9.1911e+01, -1.5781e+01,  2.6818e+01, -2.8544e+01,\n",
      "          -5.2812e+00,  4.8888e+00, -4.9887e+01],\n",
      "         [-1.2521e+01,  4.3962e+01, -2.9725e+00, -4.0526e+01, -5.1720e+00,\n",
      "          -1.0217e+02,  2.9648e+01, -7.5768e+00],\n",
      "         [ 4.8093e+01, -4.2006e+01,  2.9201e+01,  1.8925e+01, -7.5611e+01,\n",
      "           2.8848e+00, -4.4070e+00,  1.7943e+01],\n",
      "         [ 7.0417e-01, -4.4536e+01,  6.5577e+01,  7.2798e+01,  2.4323e+01,\n",
      "          -3.0084e+00, -2.4445e+01,  3.6943e+01],\n",
      "         [ 7.0270e+01,  5.4317e+01, -3.0236e+01,  5.8409e+00, -4.2583e+01,\n",
      "          -4.2793e+01,  4.7483e+01,  2.5769e+01],\n",
      "         [-1.4825e+01,  4.7759e+01, -4.5661e+01,  3.1712e+01,  1.1583e+01,\n",
      "           6.0760e+01,  1.0825e+01, -1.0787e+01],\n",
      "         [-4.9353e+01, -2.9210e+01, -3.8425e+01, -9.1644e+00, -2.8173e+01,\n",
      "           6.7325e+01,  3.2049e+00,  3.1902e+01],\n",
      "         [ 6.2131e+00,  4.4569e+01, -1.2789e+01, -4.5817e+01, -3.3738e+01,\n",
      "           4.3110e+01,  2.1035e+01,  5.7743e+01],\n",
      "         [-3.4595e+01,  4.0630e+01,  1.0119e+02,  3.1237e+01,  4.5256e+01,\n",
      "           2.9602e+01,  3.6080e+01,  3.8805e+01],\n",
      "         [-4.6615e+00,  3.1522e+01,  5.2769e+01,  2.6504e+01, -1.0239e+01,\n",
      "           1.4819e+01,  5.6530e+01,  7.5943e+01],\n",
      "         [ 1.2117e+01,  4.6197e+00, -2.6282e+00, -2.8919e+01,  4.1289e+01,\n",
      "          -3.9268e+00, -3.0853e+01,  1.5026e+01],\n",
      "         [-6.5763e+01,  2.3405e-01, -7.6923e+00,  1.9119e+01,  1.1747e+01,\n",
      "           6.2499e-01,  6.8674e-02,  4.9799e+01],\n",
      "         [-3.4005e+01,  2.3308e+01,  3.2245e+01,  2.3596e+01,  2.0082e+01,\n",
      "          -1.2867e+02,  3.6518e+01, -2.5708e+01]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=14336, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[-0.2225, -0.1704, -0.2960,  ...,  0.3769,  0.4106,  0.7510],\n",
      "        [-0.2077,  0.2216, -0.4483,  ...,  0.2844,  0.0569,  0.1286],\n",
      "        [ 0.0785, -0.2086,  0.3116,  ...,  0.1037, -0.2385, -0.4675],\n",
      "        ...,\n",
      "        [-0.0543, -0.0991,  0.4318,  ..., -0.0496, -0.2279,  0.2857],\n",
      "        [-0.2827, -0.1921,  0.0725,  ...,  0.0679, -0.3066,  0.6696],\n",
      "        [-0.0048, -0.1734, -0.1160,  ..., -0.2492, -0.1642, -0.3365]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[ 28.6949,  -7.1643, -26.0145,  16.3026,  -5.7553,  20.4618,  28.4666,\n",
      "           -2.7911],\n",
      "         [-29.9740,   5.4029, -25.7696,  15.5866,  46.3625,  20.3539,  27.9780,\n",
      "           42.2450],\n",
      "         [ 49.7875,   5.4225,  27.9271,  30.6593,  -6.6411, -18.7500, -12.6153,\n",
      "           27.8966],\n",
      "         [ 36.5513,  26.4484, -11.1492,  28.2148,  16.5655,  28.9334,  11.1140,\n",
      "           -3.2723],\n",
      "         [ 30.3070, -32.2311,  13.5959,  -4.9978,  14.1084,   3.9126,   0.0722,\n",
      "           -4.2853],\n",
      "         [ 11.2441, -47.9029, -21.0106,  -7.3262,  59.4470,  -7.5197,  37.6401,\n",
      "           -2.0785],\n",
      "         [ 34.2170, -24.8808, -27.1469,  -0.4519,  11.7853, -41.5458,   4.2124,\n",
      "          -12.0570],\n",
      "         [ -8.4898,  -8.4298, -26.3657,  30.1828, -11.7902, -36.1173,  32.2347,\n",
      "            6.0586],\n",
      "         [ 61.4032,  -3.3387,   5.5297, -32.5108,  -8.8241, -26.0988,  24.4087,\n",
      "          -35.7915],\n",
      "         [ -8.5579, -12.8830,   9.4361, -58.3518, -34.4252,  27.0357,  11.6980,\n",
      "           -9.0847],\n",
      "         [-22.6186,   6.1704, -25.9305,  -2.8837,  -2.2605, -38.5580, -14.9676,\n",
      "          -66.4218],\n",
      "         [ -3.6844,  -2.9440, -15.3585, -42.6571,  20.3701,  34.1347, -13.1310,\n",
      "           57.4251],\n",
      "         [  3.5379,  11.4720,  22.9195,   5.5209,  -0.3701,  -1.1068,   8.2695,\n",
      "          -17.9815],\n",
      "         [ -1.2391,  20.7094, -16.0060, -13.1442,  22.9134,  -2.0330,  33.6246,\n",
      "           -6.7699]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.5432,  0.1598, -0.7131,  ...,  0.2604, -0.1502,  0.2163],\n",
      "        [ 0.2973, -0.3640, -0.2282,  ..., -0.2889, -0.3114, -0.2504],\n",
      "        [ 0.1715, -0.3740, -0.4059,  ..., -0.0946,  0.4325,  0.2142],\n",
      "        ...,\n",
      "        [ 0.1854,  0.4878, -0.0849,  ...,  0.1139, -0.4631,  0.4271],\n",
      "        [ 0.2830, -0.8472, -0.7094,  ...,  0.2108,  0.0049,  0.0820],\n",
      "        [ 0.2751,  0.5008, -0.6867,  ..., -0.1115, -0.2483, -0.1896]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[-17.3599,   6.1728, -62.5963,  39.8248,   1.9025,  43.2772,  23.9108,\n",
      "            1.8101],\n",
      "         [ 23.4207, -10.1278,   5.5466, -17.0710,   1.4515, -12.6446,   4.3154,\n",
      "          -16.2302],\n",
      "         [ 37.0419,  39.3245, -84.7089, -24.8951, -12.3177,  -9.4354,  30.8049,\n",
      "           10.6752],\n",
      "         [  1.4061,  23.2927,   6.3047, -15.7604, -22.4856,  -6.2092,  10.2005,\n",
      "           23.5815],\n",
      "         [ 45.2990, -19.1160,   3.7370, -50.7605,   1.2563,  22.7254,  10.4973,\n",
      "          -49.1511],\n",
      "         [-39.2339,  17.9504,   6.7754,  16.4558,  51.8856, -34.6744,   9.5243,\n",
      "          -24.2959],\n",
      "         [  6.3862, -55.5564, -17.2982, -16.0228,   0.9678,   4.7526,   2.7660,\n",
      "           28.3317],\n",
      "         [  1.6730,  21.3601,  20.8908,  47.8975, -24.5522,  51.1375,  26.5832,\n",
      "           20.7127],\n",
      "         [ 17.6470, -10.3496,  -4.8844,   5.8014,  16.2160, -22.6646, -37.4691,\n",
      "           49.9307],\n",
      "         [-10.1541,  14.3519,  19.8448,  13.9441,   5.8748,   1.1594, -27.5577,\n",
      "          -15.6382],\n",
      "         [ -9.3057,  -2.1041, -20.7487,  -4.1390,  29.5913, -28.2440, -21.9151,\n",
      "          -30.4416],\n",
      "         [ -4.4543, -35.4094, -21.7002,  28.1641,   7.8981, -16.2591, -13.6245,\n",
      "           11.4778],\n",
      "         [-27.4068, -39.0062, -18.2995,  -2.1392, -15.6678,  15.8982,  -1.2340,\n",
      "          -20.2811],\n",
      "         [ 24.9898,  45.1540,   4.5629,   4.0001,  16.2876,  -0.4720,  21.8326,\n",
      "           -0.8727]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.1661, -0.2008,  0.5535,  ...,  0.1981, -0.0832,  0.1296],\n",
      "        [-0.4328, -0.1340, -0.0381,  ..., -0.0269,  0.4649,  0.3194],\n",
      "        [-0.1651, -0.1312, -0.3665,  ...,  0.1134,  0.1980, -0.5120],\n",
      "        ...,\n",
      "        [-0.2175, -0.0947, -0.1330,  ...,  0.3104, -0.0543,  0.2833],\n",
      "        [-0.0867, -0.7408,  0.1517,  ...,  0.1983, -0.1380,  0.4365],\n",
      "        [ 0.2328, -0.5500,  0.5913,  ...,  0.2869,  0.1067,  0.9249]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[-22.0163,  10.0150, -22.7778, -19.1442,   6.4766,  -1.3989,  10.6164,\n",
      "            4.4039],\n",
      "         [  3.9153, -17.3007,   1.2212,   2.4937,  -5.9090,   6.2879,   7.7226,\n",
      "           -2.3168],\n",
      "         [ -3.6370,  -5.6356,   7.5885,  16.5341,  17.5036,  -6.9541, -14.7332,\n",
      "           -8.2578],\n",
      "         [ -5.1657,   8.4438,   8.6307,   4.0464,   3.8531,  -0.5257,  -7.9738,\n",
      "           -5.0209],\n",
      "         [  8.2975,   2.4705,  -4.4302,   7.1229,   7.5534,   5.4390,  21.1536,\n",
      "           -1.2718],\n",
      "         [ 13.8889,  19.7817, -17.2241,  13.7121,   4.3839,   7.1201,   5.2824,\n",
      "            8.7412],\n",
      "         [  8.9217, -23.1720,   3.6942,  -0.1718,  -5.1383,  12.0495, -17.1228,\n",
      "            6.9347],\n",
      "         [ 13.0208, -13.3403,   2.3815,  -8.4479,  10.3084,  -0.2940, -11.3677,\n",
      "           23.1649],\n",
      "         [ 18.3878,   1.2446,  11.8319,  -5.4484, -33.3556,   0.7962,  13.2668,\n",
      "            0.0445],\n",
      "         [ -0.6393, -21.2069,  21.8834,   7.9261,   2.7527,  20.7325,   6.7144,\n",
      "           31.1045],\n",
      "         [  2.1360,  -3.1178,  -9.7245,   0.6366, -13.7727,   1.1240, -19.9016,\n",
      "          -10.1815],\n",
      "         [  3.0267,  -2.5852,  11.1161,  -8.2418, -17.3624,   5.3030,  18.0550,\n",
      "           -0.6274],\n",
      "         [ -4.4942, -40.4780, -15.2342,   2.7225,  -2.3096,  -9.9240,  -5.1418,\n",
      "           14.8554],\n",
      "         [ -2.2332,   1.6823,  -5.9272,  -9.7107,  -0.3928,  13.9626,  12.2109,\n",
      "            7.9243]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.1120,  0.3804, -0.0768,  ...,  0.0931, -0.5230,  0.3001],\n",
      "        [-0.0826,  0.1949,  0.2492,  ...,  0.1281,  0.3722,  0.2054],\n",
      "        [ 0.1274,  0.5681, -0.3488,  ...,  0.2874, -0.2846,  0.0063],\n",
      "        ...,\n",
      "        [ 0.2664, -0.8089,  0.2377,  ..., -0.0292,  0.2696, -0.3128],\n",
      "        [ 0.2061, -0.1652, -0.1343,  ..., -0.0895, -0.1150, -0.2340],\n",
      "        [ 0.1425, -0.0505, -0.4582,  ..., -0.2618, -0.1679,  0.2413]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[  3.3086,  13.5197,  -3.5201,  -8.1898,  11.8526, -11.0130,  20.3697,\n",
      "          -18.1625],\n",
      "         [  6.0197,  13.3777,   8.4030,  -7.0619,  29.6050,  11.5988,  -2.2291,\n",
      "          -19.1223],\n",
      "         [ 17.3281,   8.8839,   2.2650,   4.1785,  21.3531,  -5.1214,  17.1311,\n",
      "            0.3849],\n",
      "         [  5.8578,  -1.8174,  -3.7368, -13.3795,   0.9568, -21.6605,   7.5249,\n",
      "           -0.1341],\n",
      "         [ -5.7208,  -6.6437,  -1.3922,  15.0713, -12.8013,   5.7913,  -4.7283,\n",
      "            7.7786],\n",
      "         [ 13.0512, -16.1218,   4.5969,   8.5503,   6.9349,   0.2115,   3.6825,\n",
      "            4.3289],\n",
      "         [-12.5739,   9.7454,   7.4095,   9.3197,  12.2875,  16.9772,  -9.6351,\n",
      "           17.6349],\n",
      "         [-27.4780,   6.0288,   2.5336,   5.9023,   3.8651, -18.6093, -19.6456,\n",
      "            0.8069],\n",
      "         [-14.3070,  10.9240,   3.4704,   6.9810,   6.7889,   3.7195,   6.3500,\n",
      "           -8.1426],\n",
      "         [ -8.5168,   2.0861,   1.9249,  -8.0366,  -3.7104,   0.4617, -26.7275,\n",
      "           -8.7075],\n",
      "         [-10.2851,   9.0282,  13.0039,   3.5848,  -2.5291,  -7.3401,  -4.8453,\n",
      "           10.9935],\n",
      "         [  6.6892,  13.9253,  -2.6811,   5.5190,  -2.4067,   5.5589,  23.5350,\n",
      "           -8.8250],\n",
      "         [  1.0561,   9.8552,   1.5593,   7.9334,  -9.6052,   2.3443,   9.6424,\n",
      "          -16.0303],\n",
      "         [ -5.3219,   2.0737,   1.1294, -14.1463,   2.8125,  10.5915, -13.7345,\n",
      "           -9.0183]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[-0.3459,  0.4079,  0.1240,  ..., -0.0716, -0.0612, -0.1478],\n",
      "        [ 0.2981,  0.0650, -0.4147,  ...,  0.0057,  0.9691,  0.4705],\n",
      "        [ 0.6604, -0.0252, -0.0481,  ...,  0.2742, -0.1688, -0.1751],\n",
      "        ...,\n",
      "        [ 0.0149, -0.3816,  0.0771,  ..., -0.8611, -0.2096, -0.1441],\n",
      "        [ 0.2692, -0.9159,  0.7406,  ...,  0.0224, -0.1194,  0.5733],\n",
      "        [ 0.0508, -0.5395, -0.0674,  ..., -0.3494,  0.2465, -0.0492]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[ 18.0015,   0.5323,  -5.9149,   9.3812,  23.1848,   3.7639,  33.1818,\n",
      "           -0.5097],\n",
      "         [  1.0576,  -5.0899,   3.4553,   5.6503,  13.9505,  43.5460,   6.4491,\n",
      "           26.0309],\n",
      "         [-37.4595,  -2.2827,  -1.3124,  22.6365, -47.9068,  -9.9980,  16.8125,\n",
      "           -3.1360],\n",
      "         [-16.5892,  27.8795,  24.3694, -10.9536,  42.6863,  10.6131,  30.7024,\n",
      "          -35.5070],\n",
      "         [ 35.6219,  16.3797,   9.5944,  38.8174,  17.1377,  29.5211, -27.2675,\n",
      "          -17.8618],\n",
      "         [-24.8911,  54.2906,  -0.4587,  28.4882,  36.7204,  -0.5057,   2.2795,\n",
      "            6.7793],\n",
      "         [-19.5449, -13.8110, -12.5243,  16.9642,   5.5651,  15.8930,  60.1960,\n",
      "           25.9041],\n",
      "         [-42.5596,  70.8858,  11.1566,  32.9690, -26.0994,  32.4249, -58.4981,\n",
      "           22.7226],\n",
      "         [ 40.0985, -14.8451,   1.3868,   8.7658,  15.5422, -28.2614,  23.4087,\n",
      "          -12.0747],\n",
      "         [ -8.2938,  -1.1668,  -3.1968,  -3.0189,  -5.1189,   8.8016,   9.0413,\n",
      "            0.3895],\n",
      "         [  0.9790,  -3.8937,   0.1100,   3.7303, -10.3804,  15.3356,  37.1058,\n",
      "           42.5478],\n",
      "         [ 21.9666,   1.5207,  41.8447,   3.4582, -19.8929,  -1.5549, -12.6674,\n",
      "            1.4475],\n",
      "         [-52.2187, -14.4227,  -7.6689,   3.5833,   1.3974,  -9.0311,  26.9566,\n",
      "           -8.0501],\n",
      "         [-22.4269,   4.3608, -21.6508, -15.8746, -19.4632,   2.3603,  50.0913,\n",
      "           11.0441]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[-0.0135,  0.7594, -0.1673,  ...,  0.2153, -0.1734, -0.5722],\n",
      "        [-0.0479, -0.5219,  0.3431,  ...,  0.4040, -0.1613,  0.6427],\n",
      "        [ 0.0121,  0.3123, -0.2301,  ...,  0.3397, -0.0904, -0.1205],\n",
      "        ...,\n",
      "        [-0.0540, -0.3507, -0.1583,  ...,  0.4786,  0.1737,  0.3584],\n",
      "        [-0.4002, -1.0335, -0.0521,  ...,  0.5239, -0.1204,  0.3110],\n",
      "        [-0.0340, -0.1850, -0.7842,  ...,  0.1906, -0.0261,  0.8877]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[ 19.9602,  -7.7242,  46.6325, -38.0487, -11.1871, -21.4638,  37.6040,\n",
      "           12.1605],\n",
      "         [ 20.7769, -31.3873, -34.2295, -21.1228,  20.4929, -23.0732,  -7.1081,\n",
      "            3.5633],\n",
      "         [ 23.6005,  20.1434, -22.1050, -18.0084, -42.1380,  80.7696,  13.4360,\n",
      "           15.2506],\n",
      "         [-22.1524,  57.1304, -43.4767, -13.7731, 103.6492,  85.7349, -24.3182,\n",
      "           -2.8789],\n",
      "         [ 51.7930,  11.1894,  38.3930, -10.8378, -33.4424,  50.4838,  56.9874,\n",
      "          -56.7671],\n",
      "         [-31.1273,  37.2679,  26.1292,  13.2575, -25.5916, -45.2477, -17.7771,\n",
      "            5.0300],\n",
      "         [-27.4752, -46.3794, -61.5833,  12.8015,  31.2203, -61.2930,   8.7340,\n",
      "          -42.5559],\n",
      "         [-30.8025,  15.9560,  82.6168,  39.9568,   4.2070,  -9.4141, -23.2073,\n",
      "           18.6409],\n",
      "         [ -2.2689,  45.0682,  13.5435,  66.1772,  -5.7233, -23.1517,  -3.5975,\n",
      "          -10.2614],\n",
      "         [-36.4408,  22.7283, -13.0133, -13.3145, -91.6726, -39.0227,  85.2722,\n",
      "           -5.3529],\n",
      "         [-14.9814,   9.3704,  34.5266,  12.1183,  14.1965,  -8.7644,  24.2786,\n",
      "            9.0094],\n",
      "         [ 30.4334,   5.0022,  25.1062,   8.1417, -22.1030, -33.2352,  71.9499,\n",
      "          -16.7658],\n",
      "         [-33.1120, -41.9812, -28.3739,  24.6181, -10.3208,  61.3366,   9.5392,\n",
      "           31.2042],\n",
      "         [  5.9191, -49.2563, -82.0947,   0.7934,  71.9991,  44.1256, -17.2547,\n",
      "           46.1913]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.1222,  0.1387, -0.0714,  ..., -0.2601,  0.2003, -0.3354],\n",
      "        [ 0.4490,  0.1119, -0.1700,  ...,  0.6045, -0.4270, -0.7568],\n",
      "        [ 0.2668, -0.4093, -0.0189,  ..., -0.5620, -0.4000, -0.5950],\n",
      "        ...,\n",
      "        [-0.0436, -0.2344, -0.8945,  ...,  0.9559, -0.5943,  0.1769],\n",
      "        [ 0.1955,  0.2195,  0.6322,  ..., -0.2055,  0.2307, -0.1005],\n",
      "        [-0.1060,  0.5192, -0.1998,  ..., -0.3353, -0.6280,  0.3231]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[ 23.8707,  18.5948,  19.3820, -69.3599, -26.0783, -41.9329,  10.9294,\n",
      "           -1.8400],\n",
      "         [-12.7343, -25.6301, -19.8873, -66.4671, -29.9261, -48.1329, -10.2608,\n",
      "           58.0848],\n",
      "         [ -2.0507, -16.9173,  53.4620, -49.6897,   6.8397, -53.4033,  31.1981,\n",
      "          -50.6618],\n",
      "         [-15.6190,  -2.3048, -25.2417,  48.7208,  32.7645,  65.9618,  46.9371,\n",
      "           59.7718],\n",
      "         [ -8.9133, -54.8591, -85.7426,   5.8810,  23.9514, -88.7726,  47.6236,\n",
      "           34.3558],\n",
      "         [  2.7262, -17.8393,  13.6848,  25.2389,  -9.2730,  -6.7387, -91.1948,\n",
      "          -47.7035],\n",
      "         [-32.9318,  12.3823,  52.2708, -23.0521,  16.8565, -43.9680,  20.3568,\n",
      "           49.6459],\n",
      "         [-45.3642, -29.0219,  28.3811,  75.5451,  46.5696,   5.8848,  79.0314,\n",
      "           -8.5421],\n",
      "         [-19.7287,  40.0610,  35.6416,  22.3635,  86.8247,  76.4594,  29.2441,\n",
      "           64.8156],\n",
      "         [ 29.3076,  28.0041,  -1.6111,   7.3645,  33.7005,  33.0877,  34.5207,\n",
      "            3.9490],\n",
      "         [-30.4919, -23.2038,   4.0442,  26.3881,  -3.7824, -74.2387, -59.5120,\n",
      "           14.2266],\n",
      "         [-43.0608,  32.6920, -88.1573, -18.8480,  32.7384, -16.5131,  13.5831,\n",
      "           74.3610],\n",
      "         [-53.8272, -41.0138,  33.2324, -39.9919,  63.5573,  28.0242, -11.3589,\n",
      "           24.0132],\n",
      "         [ -8.0186,  36.2992,   7.1993,   1.8743,  24.2325,  -7.6386,  -0.7156,\n",
      "          -15.0240]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=14336, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.0941,  0.1839, -0.1982,  ...,  0.2698, -0.0448, -0.2668],\n",
      "        [-0.2969, -0.2532, -0.6295,  ...,  0.1663,  0.0461, -0.2506],\n",
      "        [-0.5411,  0.2340,  0.1257,  ..., -0.0838,  0.1014, -0.6194],\n",
      "        ...,\n",
      "        [-0.2679,  0.1610, -0.3020,  ...,  0.1303,  0.1651,  0.0061],\n",
      "        [-0.6189, -0.2115, -0.0753,  ...,  0.2727,  0.2728,  0.2828],\n",
      "        [ 0.2701, -0.0698, -0.2164,  ..., -0.0837,  0.2985,  0.2458]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[ 19.7368, -12.4082, -17.9081,   5.3317,   7.3357,  -7.4861, -33.7318,\n",
      "           30.9922],\n",
      "         [-26.4352,   9.1451,  28.8083,  -8.5362,  -4.4914,  -1.4481,  30.9913,\n",
      "           13.6107],\n",
      "         [-46.9269, -22.7673,  -4.7575,   5.2043,   1.0822,  18.0075,   1.9515,\n",
      "           20.8091],\n",
      "         [ 10.2973,   9.3403,  25.8674,   7.5795,  -9.8553,  28.3551, -35.3068,\n",
      "            4.6373],\n",
      "         [ 14.0713, -19.8884, -29.8384,   3.5265,  16.3230, -29.3286, -54.8857,\n",
      "          -39.3012],\n",
      "         [ 26.8501, -23.1023,   4.2331,  -3.1962, -43.9862,  14.1859, -39.5260,\n",
      "          -22.4034],\n",
      "         [  0.7036,  24.6199, -14.8132, -22.4062,  -1.9091, -24.2748,  -1.0075,\n",
      "           -0.8219],\n",
      "         [ -5.9566,   5.7811,  39.3808,   7.1985,  33.1849, -26.4430,   1.1672,\n",
      "           24.5386],\n",
      "         [ 24.4445,  29.5218,  11.7004,  -8.3552,  22.2020,  17.9981, -15.4193,\n",
      "          -17.3627],\n",
      "         [ 28.3483,  -5.4542,  13.6644,  -1.8062,  18.9219,  -8.2244, -10.1107,\n",
      "            5.0631],\n",
      "         [ 25.7245,  -2.3197,  20.5568, -26.2377, -24.6568,   0.7584,  48.8114,\n",
      "           -7.5566],\n",
      "         [-18.6653,  23.3108, -12.2339,  30.4259,  23.2011, -26.1283,  -5.8979,\n",
      "          -25.1253],\n",
      "         [-22.4276, -18.1055,   0.1011, -27.4974, -23.4597, -13.5256, -16.5348,\n",
      "           12.5080],\n",
      "         [ -4.9626,  19.1537, -32.0600, -10.7017,   5.6638, -63.4345,  -1.8301,\n",
      "           10.7981]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.2202,  0.4147, -0.1924,  ..., -0.1766, -0.5663, -0.0012],\n",
      "        [-0.5579,  0.2241, -0.1979,  ...,  0.0708,  0.1581,  0.0995],\n",
      "        [ 0.2880,  0.0677, -0.3454,  ...,  0.3673, -0.5026, -0.4557],\n",
      "        ...,\n",
      "        [ 0.6442,  0.2198,  0.4690,  ..., -0.4625,  0.3494, -0.3034],\n",
      "        [ 0.1265, -0.1220, -0.1277,  ..., -0.2739,  0.1339, -0.1814],\n",
      "        [ 0.1921,  0.0305,  0.4972,  ...,  0.2656,  0.1736, -0.1603]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[ 26.0941,  24.1548,  15.1558,   8.5022,  21.3569,  13.8585,  -7.5150,\n",
      "          -25.6318],\n",
      "         [-17.9183,  -2.3666, -30.9885,  18.5697,  -5.9473,  32.1842, -42.3092,\n",
      "           28.5851],\n",
      "         [ 11.1243,  41.1419,  19.4008, -22.3851,  -0.1459,   9.7745,  -2.3236,\n",
      "            9.5916],\n",
      "         [ 10.7364, -37.8014, -19.0430, -11.0105,   1.5652,  37.1483,  -5.2980,\n",
      "           -0.7227],\n",
      "         [-13.7934, -28.5441,  -6.5057,  16.3393,  -9.1003,   8.8467, -26.4944,\n",
      "           12.7806],\n",
      "         [-17.1604,  25.5517,   3.7422,   5.1867,  16.1629, -27.4857, -21.6592,\n",
      "           50.2108],\n",
      "         [ -5.9877,  32.6902,  -8.5611, -34.3889,  15.3573,  34.2932,  -6.8288,\n",
      "           -8.4817],\n",
      "         [-23.8625,  -1.6745, -32.2350, -37.6975, -13.4949,   7.9705,   1.8991,\n",
      "            4.1585],\n",
      "         [ 14.0627,  38.1274, -21.3273,  -2.4739,  -9.5255,  32.4362,  30.7972,\n",
      "           -1.0318],\n",
      "         [ 51.1009, -16.6045,  -0.8125, -31.6171,  31.9284, -15.8343,  -1.5550,\n",
      "           31.0355],\n",
      "         [ 35.8994,  -1.8381,  -7.7821,  18.7820,   5.8436,  16.3585,   6.5733,\n",
      "           10.8525],\n",
      "         [  2.9049, -17.2640,  24.3691,   0.3144,   6.9038,  23.6091, -21.4927,\n",
      "           22.6981],\n",
      "         [ -6.0818, -24.2292,  19.5267, -51.5643, -15.0030,  13.4263,  25.2739,\n",
      "          -35.2356],\n",
      "         [-14.4217, -10.5142, -21.3010,   5.0459, -13.3698,  -1.1643, -36.8727,\n",
      "           28.2707]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.4246, -0.2343,  0.2872,  ...,  0.0033,  0.2960,  0.3679],\n",
      "        [ 0.0763,  0.0603, -0.4813,  ...,  0.6430,  0.4337,  0.0600],\n",
      "        [ 0.1137, -0.1433,  0.0644,  ..., -0.3389, -0.1805,  0.7930],\n",
      "        ...,\n",
      "        [-0.5634,  0.3386,  0.0577,  ...,  0.5698,  0.1851, -0.5841],\n",
      "        [-0.0541, -0.1161,  0.4131,  ...,  0.1830, -0.4017,  0.1111],\n",
      "        [-0.3650, -0.1180,  0.4153,  ..., -0.2188,  0.1285, -0.2299]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[ -7.6652,  -0.2431,  -5.9761, -10.0266,  -7.3027,  -5.0961, -22.1469,\n",
      "           13.1322],\n",
      "         [  4.0159,   3.4692,  13.3744,  -6.1720,  -0.7940,   5.9169,  -2.3816,\n",
      "           10.8842],\n",
      "         [ -4.0605,  -6.2048,   5.1886, -12.1865,  -0.2466,   2.9639,   0.9675,\n",
      "           -3.1687],\n",
      "         [  8.0568, -10.3734,  -2.4937,   4.2323,  -5.4248,   9.1702, -11.1833,\n",
      "            5.5809],\n",
      "         [-12.7749,   8.6521, -23.4899, -13.6389,  -7.7145,  -1.5164,   3.3321,\n",
      "           -7.5768],\n",
      "         [ -3.8081,   5.7257,   5.1056,  28.7018, -11.3972,  -1.6917,  -8.1821,\n",
      "          -23.2524],\n",
      "         [ 11.1326,  -0.9759,  19.1754,   8.1023,  -7.5451,   8.0226, -18.5838,\n",
      "            0.6557],\n",
      "         [ -5.1844,  -2.6243, -15.0448,  -7.3893,   0.1735,   9.6609,   2.3215,\n",
      "           18.2132],\n",
      "         [ -8.8786,  -6.5230,  -9.5860,  -2.4361,  -9.5498, -13.6012,  17.5287,\n",
      "           -5.0474],\n",
      "         [-10.4292,   9.7550, -10.7700, -21.9118,   4.0048,  -1.5712,   0.4931,\n",
      "          -17.6531],\n",
      "         [-11.0568,  -5.1937,  20.1244,  -7.3226,  11.3376, -14.8292,  -8.2262,\n",
      "          -11.3035],\n",
      "         [  0.8605,  -0.4672, -10.5024,  23.3863,   5.6928,  -5.5465,  14.4780,\n",
      "           14.1748],\n",
      "         [ 18.8430,  -3.2346,   7.5292,  -4.9157,   2.0599,  13.9503,   6.2604,\n",
      "           12.4231],\n",
      "         [-11.5053,  -1.4275,  -0.9655,  -8.8986, -11.5143,  -8.3879, -17.3997,\n",
      "           -0.3852]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.3606, -0.3187,  0.0940,  ...,  0.2811, -0.5115,  0.1220],\n",
      "        [-0.2583,  0.6391, -0.0323,  ...,  0.0146, -0.0523, -0.1503],\n",
      "        [-0.3564, -0.4540,  0.2659,  ...,  0.3181, -0.0873, -0.0473],\n",
      "        ...,\n",
      "        [ 0.1719,  0.2855,  0.0197,  ...,  0.0707,  0.1825,  0.6276],\n",
      "        [-0.2353,  0.1785,  0.5012,  ...,  0.0292, -0.3898,  0.0034],\n",
      "        [ 0.3173, -0.2397,  0.3999,  ..., -0.4406,  0.5527, -0.2808]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[  8.2071, -19.4599, -11.7978,   1.9825,  -1.1166,  -0.1061,  13.5514,\n",
      "            3.9454],\n",
      "         [  9.1197,  -6.8470,  -7.9483,  11.4152, -14.5678,   0.7117, -13.2236,\n",
      "           16.4593],\n",
      "         [ -2.8658,   2.1205,  -1.3531, -13.8441,   5.4187, -10.0766,   5.0811,\n",
      "           -5.3272],\n",
      "         [ 24.5986, -27.8847,  -1.2558,   2.6089,  -1.7946,   8.7123,  -6.8741,\n",
      "           -3.7736],\n",
      "         [  8.4899,   8.9681,   1.1057,  -5.7736,  15.4748,  -5.6907,  -4.9589,\n",
      "           -0.0400],\n",
      "         [  8.2344,   1.9885,  -8.8847,   5.7905,   4.0222,   0.6838,   4.6221,\n",
      "            4.8071],\n",
      "         [ 19.1029,  -0.7595,   6.2457,  -6.0261,  -6.5110,  15.4007,  17.3710,\n",
      "            9.6599],\n",
      "         [ -7.5792,   1.7345,  -4.5399,   0.6825,  -6.9490,  -0.0646, -12.8539,\n",
      "           -4.9548],\n",
      "         [-12.5271,  -2.3345,   1.4503,   4.7693,   8.0821, -12.0999,  12.3581,\n",
      "            5.5605],\n",
      "         [  1.0791,  -9.0102,  -7.3948,  15.4391,  -3.4008,  -0.9510,  11.1796,\n",
      "           -9.5100],\n",
      "         [  7.1477,   2.3774,   6.7564, -23.3447,   9.3377,  19.9290,  -9.8750,\n",
      "            2.7276],\n",
      "         [ -8.7636, -13.1354,  11.4133,   0.0859,  -2.0357,   5.0489,   7.6314,\n",
      "           -5.4864],\n",
      "         [ -3.7195,  11.8736,  23.9841,   5.6458, -12.5609,  -5.6934,   2.9980,\n",
      "           14.5032],\n",
      "         [ 15.1552, -12.1848,  -8.1238,   4.5222,   0.1341,   5.3997,   0.4305,\n",
      "           -3.6811]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.2446,  0.0161, -0.8748,  ...,  0.7485,  0.1582, -1.1158],\n",
      "        [-0.0228, -0.7316, -0.3294,  ..., -0.4519, -0.0461,  0.2357],\n",
      "        [-0.3569, -0.2085, -0.6338,  ...,  0.2547,  0.1091,  0.0637],\n",
      "        ...,\n",
      "        [ 0.4888,  0.8218, -0.2942,  ...,  0.1181, -0.1768, -0.2350],\n",
      "        [-0.1319, -0.2449,  0.2658,  ..., -0.0632, -0.0395, -0.0070],\n",
      "        [ 0.4521, -0.2661,  0.0975,  ..., -0.4984, -0.0400, -0.0704]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[ 44.8945, -16.1817,  10.7796,  -4.0366,   0.4061,  10.8135,  17.3316,\n",
      "          -13.1057],\n",
      "         [-13.0895, -15.9775, -21.7109,  -3.7146, -28.7723, -24.3811,   8.6670,\n",
      "           16.5842],\n",
      "         [ -5.9705,  13.8626,  15.5683, -18.2065,  19.3485, -23.4174, -14.9357,\n",
      "          -20.1171],\n",
      "         [ -5.5650,  -0.7492,   0.1118, -16.7466, -20.1255,  -1.1658, -29.0794,\n",
      "          -17.2977],\n",
      "         [  8.6892,  45.0347, -18.7910,  16.3691, -33.1128,  20.9044,  43.2976,\n",
      "           -6.5611],\n",
      "         [-34.2814,  29.9674,   0.8413,  10.7260, -25.7494,   2.7296,  14.2357,\n",
      "           -1.2307],\n",
      "         [-44.4314, -19.0176,   7.0376, -25.7024,  -6.2832, -38.8483, -35.1851,\n",
      "          -14.2437],\n",
      "         [ -7.5941,  37.2602,   6.2686,   6.4667, -15.1702,  16.4861,   5.8663,\n",
      "           59.2451],\n",
      "         [  0.0845, -14.8754,  -7.1643,  11.8727, -15.1585,  32.2922,   7.4655,\n",
      "          -23.4013],\n",
      "         [  9.2972, -18.8743,  31.4900,  33.9746,  -1.2999,  22.2109, -21.8384,\n",
      "           24.0009],\n",
      "         [-35.1815,  23.2672,  28.3607,   2.9787,  -2.1004,   5.6537,  -7.6336,\n",
      "          -26.8999],\n",
      "         [  9.5708, -22.3596,  24.0761,  15.3889,  27.3943,  11.0799,  -0.5937,\n",
      "          -53.3481],\n",
      "         [ 13.3353,  30.5094,  25.0519,  17.7664,  30.6658, -29.7108,   8.5437,\n",
      "          -28.9306],\n",
      "         [ 26.6889, -17.8601, -15.4981,  15.6837, -50.5987,  -1.3942,  -9.8787,\n",
      "           32.6248]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.0320,  0.0112, -0.3611,  ...,  0.0288,  0.6364, -0.3476],\n",
      "        [-0.6820, -0.0992, -0.3536,  ..., -0.1439,  0.0551, -0.0961],\n",
      "        [ 0.0802, -0.1974, -0.1599,  ...,  0.4800,  0.0307,  0.2457],\n",
      "        ...,\n",
      "        [-0.0836,  0.1786, -0.3592,  ..., -0.3704,  0.1726,  0.6343],\n",
      "        [-0.3517, -0.4916,  0.1919,  ...,  0.1644,  0.4893, -0.3935],\n",
      "        [ 0.3014, -0.3871, -0.1950,  ..., -0.1230, -0.3545,  0.0529]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[ -5.2398, -33.1465,  30.9270, -19.4339,  33.8382,  19.5325, -22.7138,\n",
      "          -67.3097],\n",
      "         [ 33.8886,  29.9158,  11.8029,  58.5794,   5.2875, -27.6842, -76.9857,\n",
      "            9.2134],\n",
      "         [ 73.4005, -31.8552,  29.2991, -26.9447,  91.2127, -67.3686, -25.8285,\n",
      "           -7.5026],\n",
      "         [ 48.7331,  41.8634,  10.6073,  39.0815, -24.1172, -84.9554, -44.2442,\n",
      "           11.0901],\n",
      "         [  5.1449,  -1.3735,  19.6486,  14.8869, -12.4138, -68.6992,  64.0222,\n",
      "          -17.4571],\n",
      "         [-54.7853, -40.6007, -20.8128,  15.4152,  19.2415,  14.7523, -28.4927,\n",
      "           26.2463],\n",
      "         [ 65.5704,  40.6091, -42.6686,  66.8714,  28.6556, -40.2964, -68.2787,\n",
      "          -39.2731],\n",
      "         [-49.0274, -37.1720,  -1.3330,  52.8494,  71.9143, -25.8821,  -8.1948,\n",
      "           35.2222],\n",
      "         [ 12.0202, -21.2851,  26.4937, 108.6805,  11.8827,  24.2179,   6.9707,\n",
      "           17.8446],\n",
      "         [ 51.1905,   6.2277, -55.8413, -48.6858,  76.8677,   6.8391, -18.8167,\n",
      "           11.0711],\n",
      "         [ 37.2755,  50.3331,  30.1426, -18.6338,  45.6081,  62.0556, -40.7547,\n",
      "           -2.4729],\n",
      "         [ 65.2393, -76.5594, -24.9279,  60.2441,  14.8798,  80.8866,  21.4066,\n",
      "            6.0043],\n",
      "         [ 20.0010, -34.5542, -27.9180,   7.2619,  -2.5220,  -4.7995,  18.7939,\n",
      "           12.5114],\n",
      "         [-31.0411, -30.2052,  23.7147,  39.2861, -19.5431, -29.1794,  41.0695,\n",
      "          -50.2838]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[-0.6755, -0.2033,  0.3549,  ..., -0.2303,  0.1231, -0.1065],\n",
      "        [ 0.2078,  0.1062, -0.1655,  ...,  0.1831, -0.0192,  0.0914],\n",
      "        [ 0.1427, -0.1648, -0.0334,  ...,  0.0077, -0.0122,  0.1544],\n",
      "        ...,\n",
      "        [-0.0198, -0.1498,  0.1219,  ...,  0.0093,  0.3698,  0.2629],\n",
      "        [-0.3170, -0.0270,  0.3661,  ...,  0.0651,  0.3109,  0.0338],\n",
      "        [-0.3768, -0.0441, -0.1776,  ...,  0.4254, -0.1643, -0.3560]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[ 104.0127,   62.8966,   12.0996,   28.9767,   22.0429,   16.6075,\n",
      "           -25.0087,  -44.2563],\n",
      "         [  52.9908,  -17.2004,  -24.5854,  -16.6320, -117.6825,  -21.4229,\n",
      "            28.7179,   13.0684],\n",
      "         [   9.9439,   14.3607,  -28.9457,  -24.2519,  -61.3822,   22.4145,\n",
      "           -19.5479,   -7.3323],\n",
      "         [ -37.7361,   22.1143,   30.2796,   31.0990,   -4.7718,  -38.6631,\n",
      "            59.7031,   10.0837],\n",
      "         [  33.7023,   11.7627,   38.4201,    1.7595,   72.0173,  -15.7413,\n",
      "            23.0226,   -3.7614],\n",
      "         [  12.6020,  -18.9035,   46.8743,  -22.6835,  -56.0281,   50.5585,\n",
      "            61.8370,    8.1722],\n",
      "         [   2.2686,   -3.7430,  -21.2619,  -70.8426,  -36.7103,  -11.2730,\n",
      "           -61.2252,   19.0904],\n",
      "         [  29.5872,   22.7155,  -42.1533,   -1.9487,   -5.3240,  -49.0223,\n",
      "           -28.1289,   19.4985],\n",
      "         [   1.5704,   21.2775,  -12.3831,   -5.2538,   -6.7707,  -40.6973,\n",
      "            19.3580,   22.0627],\n",
      "         [ -73.6842,  -30.6685,   11.7541,   13.8951,  -21.0876,   64.2880,\n",
      "            14.8112,    9.9130],\n",
      "         [  38.3433,  -29.8906,  -31.2902,  -47.8259,  -31.5955,   75.4291,\n",
      "            -8.8355,   -6.6106],\n",
      "         [ -34.5571,  -15.7906,   -5.9384,   12.8536, -126.5454,    1.8718,\n",
      "            19.2772,   21.0361],\n",
      "         [ -15.3045,  -12.0752,   49.1996,   -0.5316,   29.7580,   28.2033,\n",
      "           -55.7164,  101.7550],\n",
      "         [  15.2771,   11.6695,   35.0262,   90.9194,    0.2864,   -4.3707,\n",
      "             5.9629,  -14.7020]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=14336, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[-0.6328, -0.1088,  0.1100,  ..., -0.0733, -0.1151,  0.0912],\n",
      "        [ 0.1002,  0.0898, -0.0158,  ..., -0.3753,  0.4726,  0.0520],\n",
      "        [-0.3943,  0.2905,  0.4762,  ..., -0.0754, -0.0730, -0.0930],\n",
      "        ...,\n",
      "        [-0.2603, -0.3452, -0.1562,  ..., -0.7344,  0.0291, -0.7046],\n",
      "        [ 0.2296,  0.7479, -0.5571,  ...,  0.1451,  0.2394,  0.3634],\n",
      "        [-0.1143,  0.0083, -0.0888,  ...,  0.6870, -0.5604,  0.4275]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[  2.1748, -12.5513,   0.0700,  24.2866,  20.3761, -31.0284, -29.0970,\n",
      "           37.4011],\n",
      "         [-48.7477,  10.8345, -39.4825,  29.7269,  -9.6402,  17.8410,  -2.5552,\n",
      "           21.8606],\n",
      "         [ 19.9608,  30.8776,   7.3125,  47.0212,  13.6022,   0.6225, -23.0710,\n",
      "           -4.6550],\n",
      "         [-44.1213,  20.8078,  32.0015, -38.9615,  19.6364, -27.7457,  55.9315,\n",
      "           -9.0171],\n",
      "         [ 10.4028,  11.6131,  10.5719, -21.3609,  45.5492,  26.4023, -26.5365,\n",
      "          -20.9704],\n",
      "         [-43.1073, -19.7422, -20.5600, -35.0990,   0.6765,  14.2991,   4.7069,\n",
      "          -20.9093],\n",
      "         [ 22.7429,  16.3420,  -2.0090,  12.4558,  -0.9106,  -4.2781,   6.3922,\n",
      "           18.6064],\n",
      "         [ -6.9886,   3.7611,  40.5291,  -8.5976,  17.8013,  27.1732, -19.1709,\n",
      "          -11.2893],\n",
      "         [ 11.7514,  21.0250,   0.3410,  15.8920,   8.9613,  23.9056, -24.2153,\n",
      "          -18.1450],\n",
      "         [  3.0241, -14.2571,  -7.5869,   1.5429,  -3.5835, -27.6347, -11.5244,\n",
      "          -21.0866],\n",
      "         [  1.8987, -28.5447,  -6.5986, -10.2028,  29.2814, -38.8029, -10.9277,\n",
      "           -9.7712],\n",
      "         [-50.7392, -25.2006,  -6.9320,   5.4633,  -1.3851,  -8.1759,  18.5235,\n",
      "          -36.0399],\n",
      "         [ -6.6060,  30.3101,   0.3260,  13.5012,  24.0915,  -6.5290,  14.3405,\n",
      "           31.7259],\n",
      "         [ -2.3861, -44.2098,  19.0684,  33.5965,  43.7838,   0.7763, -22.6619,\n",
      "           33.7531]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[-0.4572, -0.0616,  0.7452,  ...,  0.6804, -0.1025,  0.3564],\n",
      "        [ 0.1742, -0.3852,  0.1541,  ...,  0.1012,  0.2750, -0.0037],\n",
      "        [ 0.8901, -0.0955,  0.1306,  ...,  0.2323, -0.2824, -0.3291],\n",
      "        ...,\n",
      "        [-0.1435, -0.2790, -0.3736,  ...,  0.1137,  0.6158, -0.1575],\n",
      "        [-0.1415,  0.3828,  0.4816,  ..., -0.0776, -0.0857, -0.1764],\n",
      "        [-0.1306,  0.0695,  0.2387,  ..., -0.1314,  0.0575,  0.2643]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[ 13.9012, -30.4365,  12.0628,  -1.2622,  34.9564, -31.3699, -28.8165,\n",
      "           -5.1154],\n",
      "         [ -5.6708, -11.0401,  10.4037,   1.3878,  -6.4813,  40.4344, -19.3919,\n",
      "           -7.4780],\n",
      "         [  7.0787,  14.3042,  26.1789,  18.6065,  14.1716,  22.6734,  27.3127,\n",
      "           58.5444],\n",
      "         [  4.9141,   1.3777,  -1.1696,   8.4098, -30.7551,   2.6571,   4.0746,\n",
      "          -30.4807],\n",
      "         [ -6.0743,  11.7165, -23.6432, -23.5604, -39.2126,  13.6778,  -1.6200,\n",
      "           25.8887],\n",
      "         [ 23.9307, -25.9656,  -0.5968,  -4.7458, -14.2584, -12.7324,  34.6616,\n",
      "           19.9653],\n",
      "         [ 19.0822,  -5.4985,  18.7020,  32.0560,  18.8273, -46.9052,  17.7331,\n",
      "           -1.2868],\n",
      "         [ -8.8663, -28.4959, -46.8145,  -5.0963,  -1.0451, -47.9110,  10.3466,\n",
      "          -11.0760],\n",
      "         [  6.2995,  14.8413, -28.1905,  21.8007,  54.0489,  18.4412,  -5.8626,\n",
      "          -21.4647],\n",
      "         [-20.1295, -48.2780, -15.9170, -27.2621,  -5.1451,  47.1317, -18.7367,\n",
      "           22.2224],\n",
      "         [-16.6907,  10.0519,  32.2452,   0.9340,   0.8393,   4.8167,  22.7467,\n",
      "            6.0760],\n",
      "         [ -6.5080,   5.7887, -15.2351,  21.8063, -26.1277,   1.2021,  36.6609,\n",
      "           53.6787],\n",
      "         [ 17.7515, -38.4447,  15.7148,  -9.8072, -14.2887,  -0.5994,   6.1773,\n",
      "          -15.0100],\n",
      "         [ 20.7800, -40.1946,  -8.0521,  31.8350,   4.4481,  13.2532,  -5.4111,\n",
      "          -31.7469]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[-0.6773, -0.0289, -0.9993,  ...,  0.1925,  0.5103,  0.5681],\n",
      "        [ 0.1145, -0.4039, -0.0596,  ..., -0.6471, -0.0586,  0.1208],\n",
      "        [ 0.0138, -0.3686,  0.1845,  ..., -0.3109, -0.1251, -0.6002],\n",
      "        ...,\n",
      "        [ 0.0066,  0.1636, -0.4313,  ...,  0.6162,  0.0875, -0.2948],\n",
      "        [ 0.5629, -0.5263,  0.2669,  ...,  0.0311,  0.7862, -0.1237],\n",
      "        [-0.4654, -0.4009, -0.5894,  ...,  0.2472,  0.2094, -0.4526]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[ -5.4987,   2.0964,  -6.1030, -10.1293, -16.4590,  -7.3946,  -5.9904,\n",
      "           13.2370],\n",
      "         [ -1.5560,  11.6317,   3.1736, -13.6119,   5.9630,   6.6291,  10.1536,\n",
      "            1.6809],\n",
      "         [ -3.0328, -26.6162,   1.6238,  -7.3146,  16.3755,  11.5363,  14.9140,\n",
      "          -12.5692],\n",
      "         [ -3.9859,  12.5893,   8.4885,  -7.4641,   9.6232,  23.8788,  -8.5521,\n",
      "            0.3845],\n",
      "         [ -5.1472,  30.9942,  14.9569, -14.6529,  27.6849, -24.5801,  -4.6588,\n",
      "           -5.5740],\n",
      "         [ -2.0656, -18.8202, -11.5624,  21.0156,   4.8693, -13.8109,   8.7358,\n",
      "          -17.6988],\n",
      "         [-16.7952, -12.9517, -20.2647,   9.1166,   3.3827,  26.0631,   5.7570,\n",
      "           11.0192],\n",
      "         [  8.8053,   0.7875,   5.9971,  -3.5662, -22.2954,   4.1347,  -2.7644,\n",
      "           10.2133],\n",
      "         [  3.0172, -10.3958, -12.2649,  16.4319,  -1.0935, -20.7151,   7.4833,\n",
      "            3.6706],\n",
      "         [-18.6960,  -1.9205,  17.9024,  -1.5471,   4.4423,   6.6415,   2.9068,\n",
      "            7.3711],\n",
      "         [  4.3437,  24.2521,   5.3766,  -1.1446,  -4.7424,   4.9582,   8.7514,\n",
      "           -9.4386],\n",
      "         [  8.1478,   3.0958,   4.9340,   3.2105,  -6.6353,  -2.1633,  -8.1684,\n",
      "            8.7741],\n",
      "         [ -1.2677,  -7.2361, -19.6626,   8.4563,   4.6336, -13.1852,  -5.5280,\n",
      "           12.2006],\n",
      "         [ 21.6699, -10.7706,  -0.7068,   1.0486,   4.4839,  -9.8311,  -2.1265,\n",
      "          -13.9613]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.5317, -0.1951, -0.3365,  ...,  0.6080,  0.0887,  0.4865],\n",
      "        [ 0.3724,  0.2406, -0.1481,  ..., -0.8460, -0.4993,  0.2124],\n",
      "        [ 0.1075,  0.1061,  0.1093,  ..., -0.4457, -0.4417,  0.1459],\n",
      "        ...,\n",
      "        [ 0.4867,  0.0253,  0.4750,  ..., -0.1963, -0.3643,  0.5366],\n",
      "        [-0.1001, -0.4553,  0.9110,  ...,  0.0167,  0.0449,  0.3925],\n",
      "        [ 0.0822,  0.3368, -0.0819,  ..., -0.5341,  0.0090,  1.0329]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[ -7.7755,   1.6643,  -6.2920,  20.2384, -11.7158,  11.2273,   8.4097,\n",
      "           10.3198],\n",
      "         [-21.7039,  28.2774,   9.3462,  -1.5195,   2.4159,   9.7207, -20.1473,\n",
      "           -0.3701],\n",
      "         [ -3.3781,  14.9029,   7.2141,   6.5965,  14.0142,  -4.9830,   6.8843,\n",
      "            1.6404],\n",
      "         [-14.7437, -10.7345,  13.8966, -10.5843,  -1.4610,  -7.8749,   1.6859,\n",
      "           -4.9969],\n",
      "         [  2.5463,  -9.0594,   0.2591,   7.3712,  -0.6458,  -2.1808,   0.3223,\n",
      "           -9.5681],\n",
      "         [  0.5531,  -1.6582,  -2.2321,  13.2097, -11.3126,  16.3516,  -6.2095,\n",
      "            6.5667],\n",
      "         [-16.9154,   8.6220,  11.8155,  -5.5093, -16.6307,   8.7593,  -7.6324,\n",
      "           25.7140],\n",
      "         [-17.9225,  16.3320,  15.1217,  -3.7680,  -1.8486, -14.6423,  -2.0355,\n",
      "            9.0305],\n",
      "         [ 14.1780,  23.3732, -12.7610,  11.0118,   1.4346, -17.3237,  -3.2574,\n",
      "           -4.8500],\n",
      "         [  4.1898,  -7.8411,   1.1724,   5.8025, -13.7438,   4.2177,  -7.4273,\n",
      "           -9.3662],\n",
      "         [  6.2913, -10.7004,  10.7708,   8.1983, -10.4308, -14.6801,  -8.3874,\n",
      "           -2.6391],\n",
      "         [ 17.0729,  -6.6336,   4.4337,  11.0116,   1.6912,  23.9398,   2.6149,\n",
      "            0.7825],\n",
      "         [ -3.6492,  -1.1026,   4.8105,  24.6959, -19.9014,  -7.2415,   1.6349,\n",
      "           -2.3692],\n",
      "         [-13.9865,  10.8264,   7.2553,  -0.3082,  -9.9431, -13.5180,   8.5433,\n",
      "            0.1361]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.0140,  0.1848,  0.3384,  ...,  0.2467, -0.2839,  0.0594],\n",
      "        [ 0.3600, -0.0410,  0.4590,  ..., -0.3836,  0.1998,  0.0556],\n",
      "        [-0.1905, -0.3677, -0.0608,  ..., -0.3936, -0.0700,  0.2640],\n",
      "        ...,\n",
      "        [ 0.5589,  0.3333, -0.1234,  ..., -0.3079,  0.5101,  0.2839],\n",
      "        [ 0.2435, -0.1284,  0.1977,  ...,  0.2238,  0.2144, -0.2177],\n",
      "        [ 0.4723,  0.3251, -0.1200,  ..., -0.2805,  0.2234, -0.3037]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[-2.1036e+01, -5.2867e+00, -3.0031e-02, -2.1946e+01, -2.7686e+01,\n",
      "           2.3906e+01, -9.5399e-01, -2.2437e+01],\n",
      "         [ 1.2584e+01, -3.1366e+01, -1.7026e+01, -2.4695e+01, -5.7237e+01,\n",
      "          -5.2850e+01,  5.0722e-02,  2.4007e+01],\n",
      "         [ 4.3003e+00, -3.8977e+01,  1.8586e+01,  2.0601e+01,  4.4420e+00,\n",
      "           1.8621e+01, -3.1652e+01,  1.4216e+00],\n",
      "         [-2.7425e+01, -3.5915e+01,  1.5971e+01,  1.2815e+01, -2.9823e+01,\n",
      "           1.0344e+01,  2.7491e+01, -1.6502e+01],\n",
      "         [-3.3700e+01, -2.7149e+01, -1.1505e+00,  1.5612e+01,  9.0260e+00,\n",
      "           2.8396e+01,  7.4050e+00,  2.2903e+01],\n",
      "         [-1.3645e+01, -1.3171e+01, -1.4514e+01, -3.8248e+01,  1.7307e+00,\n",
      "           2.5382e+01, -1.2654e+01, -1.1572e+01],\n",
      "         [ 2.3037e+01,  1.2684e+01, -2.9268e+00, -4.5362e+00,  7.9675e+00,\n",
      "          -2.2157e+01,  1.1780e+01,  6.7944e+00],\n",
      "         [-8.3575e+00, -6.6876e+00,  9.8851e-01, -5.5141e+00, -9.5923e+00,\n",
      "          -7.1509e+00,  2.0104e+00, -2.7867e+01],\n",
      "         [-5.8338e+01,  2.0159e+01, -2.6542e+01, -9.3506e+00,  1.5647e+01,\n",
      "          -1.9731e+01, -3.2334e+01,  1.6550e+01],\n",
      "         [-5.5974e+00,  2.2364e+01, -2.0757e+01, -1.7189e+01, -3.3057e+01,\n",
      "           3.6744e+01, -2.4831e+01,  1.3395e+01],\n",
      "         [-2.0988e+01, -4.8115e+00, -1.5708e+01,  1.0120e+01,  2.7039e+01,\n",
      "          -1.3332e+01, -4.3902e+00,  2.7488e+01],\n",
      "         [-5.3368e+01, -1.1705e+01, -3.4497e+01,  1.1189e+01,  8.5603e-01,\n",
      "          -5.1985e+00,  2.5114e+01, -6.8141e+00],\n",
      "         [-6.5777e+00,  6.6802e+00, -8.7871e+00,  3.8514e+01,  6.2317e+00,\n",
      "          -2.3471e+01, -2.9077e+01, -1.8799e+01],\n",
      "         [ 3.7667e+00,  1.4906e+00, -1.2737e+01, -3.1087e+00, -5.9218e-01,\n",
      "          -2.2351e+01,  4.5477e+01, -4.8500e+01]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[-1.0283,  0.4695,  0.4959,  ..., -0.3184, -0.0294, -0.0687],\n",
      "        [-0.1164, -0.0746,  0.0156,  ..., -0.0640,  0.2163, -0.2314],\n",
      "        [ 0.7099,  0.1912, -0.1265,  ...,  0.1743, -0.2294, -0.1094],\n",
      "        ...,\n",
      "        [ 0.0735,  0.1125,  0.0867,  ...,  0.0338, -0.1979,  0.1072],\n",
      "        [ 0.8314,  0.5295,  0.3810,  ..., -0.2499,  0.4473,  0.0969],\n",
      "        [-0.0652, -0.0502, -0.5257,  ...,  0.4606, -0.5246,  0.3643]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[ 36.3345, 119.2572,  22.5494, -57.0479, -10.0295, -21.4162,  42.0439,\n",
      "           94.2821],\n",
      "         [ 18.9471,  25.4054,  18.1502, -65.7327, -24.2181, -49.9905, -64.3804,\n",
      "            6.7652],\n",
      "         [ -2.6986, -15.8803,  56.3796, -38.9126,  -7.4229,  18.0728, -15.7477,\n",
      "           -9.3610],\n",
      "         [ 74.6225,  20.3419, -44.1388,  -0.1768,  23.1155, -34.3926,  -9.7019,\n",
      "          -30.1880],\n",
      "         [ -5.4726,  46.2092,  10.4448,  36.6561, -34.8240,  39.0458, -26.6902,\n",
      "           -6.8504],\n",
      "         [-12.0746,  21.8581,  12.5958,  12.6767,   7.5964,  67.9297, -29.7282,\n",
      "            6.3188],\n",
      "         [  8.6840, -14.5209, -26.5245,  56.3763, -30.9345,  47.2270,  14.8989,\n",
      "            3.3170],\n",
      "         [  9.4838,   4.6005, -39.5334,  -0.3574,  29.5421,  48.6601,  -4.6412,\n",
      "          -25.6691],\n",
      "         [-38.3398,   6.9389,  32.1713,  26.1660,  59.5869, -43.5929, -18.2703,\n",
      "            1.4482],\n",
      "         [ 27.0551,  90.7529, -19.5816, -27.4611, -47.8589,  32.5781,  28.5485,\n",
      "           41.8652],\n",
      "         [-57.0198, -45.1904,  17.1974,  30.8480,   7.8512,  30.9765,  -8.6327,\n",
      "          -43.9456],\n",
      "         [ 19.7546, -43.4938,  55.4680,  15.9998, 106.6603, -66.2969, -30.4426,\n",
      "           -6.0192],\n",
      "         [ 42.1446,  20.4326, -52.2136,  21.9906, -32.3373, -73.2330, -20.1537,\n",
      "           12.9341],\n",
      "         [ 68.2766,  49.6758, -76.8270,  12.0536,  29.8956, -13.1878,  42.0686,\n",
      "            8.3783]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.1364, -0.2370,  0.2358,  ...,  0.3007, -0.4723,  0.3246],\n",
      "        [ 0.1312, -0.5687, -0.1785,  ..., -0.2599,  0.1988, -0.4662],\n",
      "        [-0.3866, -0.0097,  0.3904,  ..., -0.2028, -0.2079,  0.2627],\n",
      "        ...,\n",
      "        [-0.4145, -0.0670,  0.1611,  ..., -0.0182,  0.4010,  0.6703],\n",
      "        [-0.3172,  0.5009,  0.3443,  ..., -0.0548, -0.2349,  1.0982],\n",
      "        [-0.7126,  0.0405,  0.6578,  ..., -0.0216,  0.5117,  0.0032]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[  -5.3783,   79.6199,    1.9774,  -39.6741,  -43.9490,  -24.2036,\n",
      "           -52.6836,   52.6188],\n",
      "         [ -28.3097,   46.2509,   49.6002,   42.7186,  -14.6100,   26.5652,\n",
      "            -8.5372,   34.4390],\n",
      "         [ -18.3068,  -41.0530,    8.0612,  101.1707,  -39.3809,   62.7639,\n",
      "           -66.2617,  -24.1238],\n",
      "         [ -22.7887,   48.1074,   -8.7237,  -79.6959,   24.0220,   -7.2915,\n",
      "             0.6046,   90.9881],\n",
      "         [  -2.6617,  -64.9225,   70.3484,   50.1319,   23.7145,  -22.2340,\n",
      "           -93.7076,   12.1481],\n",
      "         [ -35.3650,   93.5597,   18.6033,  -17.2846,   19.9142,   49.6358,\n",
      "            25.5874,  -27.9007],\n",
      "         [   6.4710,   24.6454,  -64.0087,   20.1883,   -4.6637,  -33.9652,\n",
      "           -20.0898,   34.5983],\n",
      "         [-104.1165,  -61.5612,  -70.0163,  -44.1736,   -2.7198,    0.6479,\n",
      "            45.3193,  -39.8551],\n",
      "         [   3.4964,   42.1397,  -30.8406,  -50.3075,  -41.0792,  -12.9877,\n",
      "            33.1555,   75.5413],\n",
      "         [-105.1888,   18.0869,   13.3058,   52.0528,   78.8202,  -78.3291,\n",
      "           -17.5903,  -38.0761],\n",
      "         [ -56.2671,  -27.0735,  -32.9693,  -11.8481,   48.1381,  -19.3406,\n",
      "            56.6314,  -17.1121],\n",
      "         [ -24.2811,   29.6487,   26.0613,    1.9299,   25.5846,   23.7230,\n",
      "           -41.1579,  -32.0025],\n",
      "         [  52.0007,   -5.8261,   15.5555,   49.9353,   10.1770,   -5.0662,\n",
      "            15.6756,  -20.4736],\n",
      "         [ -39.4688,    5.2080,  -11.6823,  -19.0701,   -5.8245,  -48.3706,\n",
      "            12.6811,    2.5604]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=14336, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.1821, -0.1747, -0.5446,  ...,  0.1062,  0.2516, -0.1748],\n",
      "        [-0.0223,  0.1593,  0.2715,  ..., -0.3026, -0.0901, -0.0804],\n",
      "        [ 0.4457, -0.1831, -0.2050,  ...,  0.0086,  0.2453,  0.4814],\n",
      "        ...,\n",
      "        [-0.2018, -0.4959,  0.2500,  ...,  0.0729, -0.4300,  0.1870],\n",
      "        [-0.0272, -0.2325, -0.1635,  ..., -0.7452, -0.0116, -0.3233],\n",
      "        [ 0.1510,  0.1238,  0.1755,  ...,  0.3521,  0.2246,  0.3301]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[ 10.7118, -26.0635,  40.2977, -38.9459,  13.3093, -21.6890,  39.8705,\n",
      "           11.2348],\n",
      "         [ 44.6604,  -4.0314, -18.5604, -21.8431,  -7.8941,  17.5560,   0.7637,\n",
      "           -5.2242],\n",
      "         [ 24.3027,  51.1375, -21.9713,  -9.8939,   7.7034,  -4.8732, -10.1440,\n",
      "           22.6107],\n",
      "         [-20.0416,  29.1514,  12.7475,   1.0449,  58.3029,  20.2168, -34.4026,\n",
      "          -20.7330],\n",
      "         [-16.5556,  -6.7909,  28.9149,  35.0011,   8.0542, -26.2795,  16.3336,\n",
      "            8.0622],\n",
      "         [ -3.7579,   1.2606,  -5.2167, -11.9009,  18.1295, -15.6347, -13.9731,\n",
      "           -1.1677],\n",
      "         [ 22.1754,  -8.4260,  10.5864,   1.5047,  20.9352, -19.2703,  -6.5473,\n",
      "           13.8850],\n",
      "         [ 10.0598,  -4.3931,  -6.0332, -17.5637, -30.1058,   0.3783,  35.2084,\n",
      "          -15.0460],\n",
      "         [  6.9319,  -2.8350,  -6.1524, -18.2127, -28.1465,   6.4914, -45.6106,\n",
      "          -24.7395],\n",
      "         [ 24.8423, -24.6648,  51.3538,  -5.3368,  32.4898,   5.1935, -30.4794,\n",
      "           16.8509],\n",
      "         [ 13.2111,   7.2272,  21.5362,  22.3061, -32.5143,   2.2592, -30.4543,\n",
      "          -22.1513],\n",
      "         [ -0.3985, -13.6683, -10.5977, -16.7757,   1.6634,  -8.2133,  59.0007,\n",
      "           18.8421],\n",
      "         [-10.1998,  -6.5702,  35.7268,  22.5857, -14.9910,  32.8444,   1.2747,\n",
      "            6.5923],\n",
      "         [-33.6416, -31.8349,  10.1820,  -0.1505,  32.7746, -34.0307,  24.2451,\n",
      "          -13.4627]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.1329,  0.2948, -0.5272,  ..., -0.1099, -0.5537,  0.6252],\n",
      "        [-0.3204,  0.1944,  0.2486,  ..., -0.1086,  0.2063, -0.2172],\n",
      "        [ 0.3207, -0.3660, -0.6244,  ..., -0.3697, -0.0227, -0.2057],\n",
      "        ...,\n",
      "        [ 0.5833,  0.0024, -0.1378,  ...,  0.0686,  0.3605,  0.8519],\n",
      "        [-0.0025,  0.4482, -0.0396,  ..., -0.0906,  0.2776,  0.6928],\n",
      "        [-0.4321,  0.1508,  0.0859,  ...,  0.0801, -0.0739, -0.1203]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[ -3.9635,  24.8877,  44.6247,  20.3585,  23.9352, -11.5993,  37.6981,\n",
      "           14.6102],\n",
      "         [-17.4466,   2.0969,  -7.4433, -18.3129,  -5.2415, -17.2910,  17.3848,\n",
      "          -22.8001],\n",
      "         [ 26.2758,  24.3931,   0.7659,  13.1414,  -7.4007,  -9.5336,  11.5223,\n",
      "           38.4070],\n",
      "         [ 32.7037,  43.5297,  12.5823,   5.2991,  19.6572, -23.7972, -14.5358,\n",
      "           18.3957],\n",
      "         [  6.5426,   4.3068,  -6.5109,  -5.9393, -19.1035, -30.9965,   3.6703,\n",
      "           20.1253],\n",
      "         [ -6.1939,   2.7371,  -6.2840, -22.4556,  -7.7237,  13.4682,   7.1242,\n",
      "          -26.5878],\n",
      "         [-14.2042,  27.3895,   7.8525, -23.6218, -49.8653,  44.0053, -25.8875,\n",
      "          -10.2209],\n",
      "         [ -0.9005,  10.3260,  14.4514, -31.5374, -11.9959,   8.2438, -25.0136,\n",
      "           28.9064],\n",
      "         [-12.3714,  12.1809,  34.3601,   0.0625, -23.9140, -10.6443, -10.1962,\n",
      "           13.5348],\n",
      "         [ 13.2184,  26.8215,  14.2406,  -8.6691,  -9.0657,  10.9521, -25.6836,\n",
      "          -10.5301],\n",
      "         [-42.3286, -23.1097, -29.1816, -21.8189,  -1.2887,   1.2904,  -5.1409,\n",
      "          -22.1064],\n",
      "         [-25.4676,   7.8459,  -7.2574,   5.0607,  39.7349,  35.6640,   0.6176,\n",
      "            7.8482],\n",
      "         [-37.5106,  21.8198,  27.1963,  -8.3404, -12.9349,  -8.1863,  27.4749,\n",
      "           -1.0416],\n",
      "         [  7.2405,   4.9939, -14.5586,  20.5803,   4.8467,   6.9302, -44.2607,\n",
      "            3.5260]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.6455, -0.2975,  0.3308,  ..., -0.4376,  0.0536,  0.6646],\n",
      "        [ 0.4281, -0.1742, -0.1362,  ..., -0.1339,  0.6080,  0.0711],\n",
      "        [ 0.3995,  0.1415,  0.2051,  ..., -0.0105, -0.2062, -0.5353],\n",
      "        ...,\n",
      "        [-0.4975, -0.0742, -0.2462,  ...,  0.1258,  0.0009, -0.0896],\n",
      "        [ 0.6965, -0.0594, -0.0180,  ...,  0.1368,  0.0673,  0.5164],\n",
      "        [ 0.3776,  0.3538,  0.1626,  ...,  0.2107,  0.3707, -0.3929]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[ -5.8696,  -0.8575,  -3.4055,   3.4271,   6.2166,  -0.5516, -10.3407,\n",
      "           -1.4254],\n",
      "         [-19.4882,  16.3528,  -1.0730,  -7.2599,  13.9287,   0.8105,  14.8750,\n",
      "          -21.5663],\n",
      "         [ 25.1241, -21.8182,  15.2536,  10.6221,   7.7252,  15.3440, -17.1314,\n",
      "            8.9128],\n",
      "         [ -7.5618,   3.9391,   3.6918, -18.0653,  -3.4185,  -3.2226, -26.3795,\n",
      "            1.3283],\n",
      "         [-29.1432,   1.8745,  11.2091,  22.9161,   4.7619,  16.2818,   7.8666,\n",
      "           16.9512],\n",
      "         [ -8.1757,  25.9795,   9.8752,  -1.1738,  -6.8881,  -3.2120, -12.4705,\n",
      "           11.4497],\n",
      "         [ -5.8918,  -1.3796,   8.9406, -16.0631, -12.1438,   5.6105,   7.9661,\n",
      "            7.8092],\n",
      "         [ -8.8138,   9.3330,  -7.3722,  10.6454, -10.3853,   4.5493,   2.8595,\n",
      "           15.8119],\n",
      "         [  2.7532,   2.3081,   0.5728,  -0.6559,  -8.3052,  18.0018,  15.3114,\n",
      "           -2.4674],\n",
      "         [-34.9230,   6.5284, -14.2283,  15.0265,  -1.8285,  -1.9758, -28.1136,\n",
      "          -14.3344],\n",
      "         [ -0.4107,   1.8937,   4.5833,  -9.1328,  11.8854,   9.6898,  -9.9449,\n",
      "          -11.2720],\n",
      "         [  1.0640,   6.4492, -14.4855,  11.5711,   2.6380,  -3.0632,   7.3158,\n",
      "          -12.9563],\n",
      "         [  8.2220,  -4.1435,  -9.1359,  -3.7948, -15.5558, -14.1581, -11.4028,\n",
      "            1.2383],\n",
      "         [ 14.7537,  36.6382,  -2.9835,   2.1126,   7.4821,   2.1089,   4.4741,\n",
      "            3.7860]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[-0.1126, -0.1473,  0.4952,  ...,  0.1397, -0.2409,  0.1236],\n",
      "        [-0.4338, -0.4970,  0.3910,  ...,  0.4395,  0.0535, -0.3303],\n",
      "        [-0.2350,  0.2121, -0.3638,  ..., -0.1437, -0.1894,  0.2675],\n",
      "        ...,\n",
      "        [-0.0628,  0.5185, -0.0555,  ..., -0.5908, -0.0382,  0.1243],\n",
      "        [ 0.5839, -0.1748, -0.2476,  ...,  0.1677,  0.0332,  0.2436],\n",
      "        [ 0.0268, -0.3367, -0.0826,  ...,  0.2278,  0.0498, -0.1606]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[ 3.6114e+01,  1.1803e+01,  2.6648e+01, -1.4855e+01, -6.9997e+00,\n",
      "           1.1274e+01,  8.3487e+00, -1.4223e+01],\n",
      "         [-1.9805e+01,  1.5130e+01,  6.5169e+00, -9.8573e+00, -3.6011e+00,\n",
      "          -6.3796e+00,  5.5414e+00,  1.5242e+00],\n",
      "         [-2.4579e+01, -6.0227e-01,  8.4760e+00, -9.7437e+00, -1.0612e+01,\n",
      "          -4.6087e+00, -4.6145e+00,  7.9271e+00],\n",
      "         [ 6.5800e+00,  7.8137e+00, -2.2597e+00, -2.3266e+00,  2.1511e+01,\n",
      "           2.6823e+01, -1.7774e+01, -9.6662e+00],\n",
      "         [-2.6266e+01, -9.9747e+00, -2.8753e+00, -8.1221e+00, -5.5086e+00,\n",
      "           1.8233e+01,  2.2725e+01,  1.9382e+01],\n",
      "         [ 1.8813e+01,  5.4744e+00, -1.6383e+01,  3.2507e-02,  2.1627e+00,\n",
      "          -1.0048e+00,  3.7870e+00,  3.3291e+00],\n",
      "         [ 8.5000e-01, -2.0671e+00, -3.0107e+01,  1.5324e+00,  4.8562e+00,\n",
      "           1.0210e+01,  2.3101e+01,  2.6274e+01],\n",
      "         [ 7.9916e+00,  5.6174e+00,  1.1661e+01,  2.4112e+01,  1.7496e+01,\n",
      "          -1.9767e+01,  1.4839e+00,  1.4584e+01],\n",
      "         [ 1.1455e+01, -7.4861e+00, -8.7927e+00, -6.4820e+00, -5.3008e+00,\n",
      "           2.0396e+01, -2.1198e+00, -3.1699e+01],\n",
      "         [ 2.2827e+01,  3.2951e+00,  4.1929e+00,  1.8567e+01,  5.9252e+00,\n",
      "           2.4836e+01, -7.3646e-01,  9.8101e+00],\n",
      "         [-1.0660e+01,  1.0970e+01, -2.0259e+01,  1.0372e+01,  5.8276e+00,\n",
      "           6.2975e+00, -7.3316e-01, -3.3484e-01],\n",
      "         [ 5.0381e+00,  5.6099e+00, -3.9917e+00,  2.1560e+01, -4.3419e+00,\n",
      "           1.1235e+01,  2.8183e+00, -1.3414e+01],\n",
      "         [ 6.7727e+00,  9.5237e+00,  1.1163e+00, -9.1763e-01,  7.0704e+00,\n",
      "          -1.4239e+01, -7.7933e+00, -1.3653e+00],\n",
      "         [ 4.7518e+00,  7.0723e+00, -2.5643e+00,  2.0388e+01, -6.7827e+00,\n",
      "          -1.1880e+01,  4.9799e+00,  1.6864e+01]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[-0.4351, -0.8148,  0.0175,  ..., -0.3368,  0.3671, -0.4349],\n",
      "        [-0.2588, -0.1855,  0.1389,  ..., -0.6431, -0.2732, -0.3362],\n",
      "        [ 0.1831, -0.3074,  0.3035,  ...,  0.1713,  0.0265, -0.3170],\n",
      "        ...,\n",
      "        [ 1.1338, -0.0731, -0.1295,  ..., -0.0888, -0.0679, -0.2942],\n",
      "        [ 0.3049, -0.1862, -0.0996,  ..., -0.3950,  0.0344,  0.2263],\n",
      "        [ 0.3283, -0.0809,  0.1363,  ..., -0.4144,  0.2798,  0.5766]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[-18.9920,  24.0928,  41.2596, -13.8731,   7.7006,  -0.3944,  -5.6097,\n",
      "            1.7106],\n",
      "         [ 29.7257, -19.8660,   7.9770,  40.6747,   8.8032, -14.5288, -21.6758,\n",
      "           24.5144],\n",
      "         [ 20.2433,  -5.8499, -10.7496,  35.8374, -40.6317, -24.3899, -59.2663,\n",
      "          -23.4082],\n",
      "         [ -7.7050,  -9.4692,   9.1056,  12.3248,  -6.4986, -36.3527, -25.0200,\n",
      "           -3.7926],\n",
      "         [  7.8112,   0.8035,  61.0004, -14.9099, -12.8531,  18.1344,   8.2756,\n",
      "           -4.1270],\n",
      "         [  8.5959,  -2.8853,  20.0311,   1.3111,  31.5245,  40.0269, -14.9310,\n",
      "          -20.6379],\n",
      "         [ -0.4655,   6.4270,   5.6001,  19.9319,  25.4864,  23.4822, -22.9649,\n",
      "            7.8270],\n",
      "         [ -5.1782,  -1.2702,  42.5438,  49.3850,  20.0422, -27.3928,  27.0016,\n",
      "           -3.9991],\n",
      "         [-22.4740,  -2.6781,  35.3512,  26.3181,   7.9396, -18.9662, -36.8915,\n",
      "           -2.3429],\n",
      "         [-11.3569, -19.4788,  -8.9457,  25.6776,  -6.4071,  -3.2202,  41.2625,\n",
      "           12.4435],\n",
      "         [ 11.0187,  34.2812,  -3.8337,  32.2815, -19.9497,  16.8526,  15.5858,\n",
      "           40.0329],\n",
      "         [-31.2900,  -6.1627,  -4.3432,   7.2321,   4.1354, -11.3400,   5.0190,\n",
      "            5.3927],\n",
      "         [-20.5941,  21.5681,  19.6195, -47.9091,   5.3749,  -9.8434,  12.2218,\n",
      "           11.8514],\n",
      "         [  9.3585,  11.9729,  21.0433,  24.8143, -41.0349,   8.7207, -58.2845,\n",
      "          -19.9866]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[-0.1357, -0.3588, -0.0908,  ...,  0.3598, -0.2143,  0.7780],\n",
      "        [-0.1909,  0.1659,  0.0981,  ..., -0.7695, -0.3383,  0.4242],\n",
      "        [-0.3359, -0.1692,  0.9196,  ...,  0.1727,  0.2995,  0.2015],\n",
      "        ...,\n",
      "        [ 0.3218,  0.4080,  0.2087,  ..., -0.3097,  0.5508, -0.1108],\n",
      "        [-0.0124, -0.4322, -0.5597,  ..., -0.0675, -0.4141,  0.6732],\n",
      "        [ 0.2567, -0.2755, -0.2947,  ...,  0.1350, -0.1427,  0.0229]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[-4.8131e+01, -5.8147e+01, -4.3769e+00, -7.0181e+01, -6.5945e+01,\n",
      "          -8.0035e+01,  7.5298e+01,  3.5135e+01],\n",
      "         [-1.9588e+01, -2.8568e+01,  4.5378e+00,  3.3632e+01, -8.2369e+01,\n",
      "           1.7885e+01, -2.6738e+00,  4.4309e+01],\n",
      "         [-8.3486e+00, -4.4665e+00, -4.2775e+00,  4.8984e+00, -2.9833e+01,\n",
      "          -3.8088e+00,  2.5148e+01, -3.8370e+01],\n",
      "         [ 1.1771e+01,  3.3333e+00, -1.5704e+01,  4.7409e+01,  1.2596e+00,\n",
      "           2.1038e+01,  6.5932e+00,  7.3153e+01],\n",
      "         [ 1.2167e+01, -9.7067e+00, -1.4104e+01, -5.0194e+01, -5.7053e+01,\n",
      "          -8.3438e+01,  8.0141e+01, -6.8215e+01],\n",
      "         [ 2.0296e+01,  9.5518e+00, -9.8384e-01, -1.4607e+01, -9.6457e+00,\n",
      "          -5.3073e+01,  9.6781e-03,  1.4905e+01],\n",
      "         [ 1.1493e+02, -1.5102e+01, -1.0911e+02,  5.7871e+01,  1.2005e+01,\n",
      "           2.9952e+01, -1.5225e+01,  6.5557e+01],\n",
      "         [ 2.7587e+00, -4.7713e+01, -5.5672e+01, -6.0158e+01, -3.4129e+01,\n",
      "           7.7738e+01,  5.5233e+01,  2.0595e+01],\n",
      "         [ 2.6613e+01,  1.1910e+00, -1.0014e+00, -2.2844e+01,  4.4246e+01,\n",
      "           8.5574e+01,  2.5838e+01,  3.3634e+01],\n",
      "         [ 4.3991e+01, -3.6484e+01,  6.1237e+00,  2.8714e+01,  5.3285e+01,\n",
      "           7.1884e+00,  4.6501e+01, -4.2107e+01],\n",
      "         [-1.2508e+01, -2.9471e+01,  9.9919e+00, -6.5373e+01,  2.9605e+01,\n",
      "          -3.9390e+01, -1.3184e+02, -4.0734e+01],\n",
      "         [-1.9590e+00,  4.5798e+01,  1.2427e+01, -1.6954e+01,  5.0850e+01,\n",
      "          -3.7275e+01,  3.9117e+01,  5.1019e+01],\n",
      "         [-4.6513e+01, -5.8204e+00,  5.0921e+01,  4.1918e+01,  6.0819e+00,\n",
      "           3.4024e+01,  6.7327e+00,  3.3920e+00],\n",
      "         [-6.5175e+01,  3.2827e+01,  1.8011e+01,  1.6554e-01, -5.0441e+01,\n",
      "          -2.6704e+01,  8.5324e+01,  6.9745e+01]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.3875,  0.1507,  0.2254,  ...,  0.0743, -0.6916, -0.6917],\n",
      "        [-0.4433, -0.3127,  0.2590,  ..., -0.1036, -0.5928, -0.2159],\n",
      "        [-0.4856, -0.1217, -0.4437,  ..., -0.0927, -0.0666, -0.4052],\n",
      "        ...,\n",
      "        [ 0.0286,  0.1934,  0.7479,  ..., -0.0538,  0.1335,  0.5482],\n",
      "        [-0.0088, -0.2695, -0.2243,  ...,  0.5320, -0.1469, -0.0276],\n",
      "        [-0.4587, -0.1250,  0.1219,  ...,  0.3045,  0.0833,  0.1831]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[ 8.9870e+00,  2.2878e+01,  2.9651e+01,  8.8062e+00,  5.6351e+01,\n",
      "           1.2387e+00,  5.0556e+00,  2.0444e+01],\n",
      "         [-1.6611e+01, -9.7647e+00, -9.0291e+00,  1.6547e+01,  2.8939e+01,\n",
      "          -1.5983e+02,  1.5967e+00,  3.6058e+01],\n",
      "         [ 6.8506e+01,  2.7222e+01, -1.5958e+01, -7.5178e+01, -2.8657e+00,\n",
      "          -2.4741e+01,  2.4752e+00, -2.2032e+01],\n",
      "         [-3.5594e+01,  1.3218e+01,  4.8728e+01, -3.6783e+01,  6.9500e+01,\n",
      "          -3.2668e+01, -7.6236e+01,  4.9285e+01],\n",
      "         [-7.6654e+01,  7.4299e+00,  2.4081e+00, -9.0014e+01, -3.5323e+01,\n",
      "           4.3308e+01, -2.4269e+01,  8.0729e+01],\n",
      "         [-8.2126e+01,  2.4914e-01,  4.0062e+01, -1.9446e+01, -3.4451e+01,\n",
      "           7.7954e+01,  2.1623e+01,  4.5671e+01],\n",
      "         [ 3.1837e+01, -4.5136e+00,  1.1448e+02, -1.2562e+01,  1.7330e+01,\n",
      "           2.6097e+01, -1.6678e+01,  1.4141e+01],\n",
      "         [ 5.2633e+01,  1.9478e+01,  1.3460e+01, -2.3120e+00, -2.2169e+01,\n",
      "          -4.5901e+00, -2.7929e+01,  6.0107e+01],\n",
      "         [-1.6296e+01,  5.7252e+00,  4.6618e+01,  8.1221e+01,  3.7657e+01,\n",
      "          -4.7751e+00,  3.6641e+01,  6.3661e+00],\n",
      "         [ 4.6560e+01,  3.2133e+01, -4.3380e+01, -7.0811e+01,  2.7396e+01,\n",
      "           5.6024e+00, -4.9520e+01,  4.6140e+01],\n",
      "         [ 3.6702e+01,  7.3491e+01, -2.8999e+01, -2.0822e+01, -1.9800e+00,\n",
      "           5.0890e+01, -7.7613e+00,  5.0290e+01],\n",
      "         [ 4.9205e+01, -5.5883e+01,  1.7712e+00,  2.2599e+01,  1.0060e+02,\n",
      "          -1.8403e+01,  2.6610e+01,  3.3783e+01],\n",
      "         [-6.4053e+01, -7.2959e+01, -2.2685e+01, -5.4689e+01, -3.3882e+01,\n",
      "           4.8310e+01,  6.6526e-01,  2.4085e+01],\n",
      "         [ 2.3808e+01, -8.4589e+01,  3.8756e+01, -1.2209e+01, -1.8369e+01,\n",
      "          -3.0690e+01,  6.5315e-02, -4.9357e+01]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=14336, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[-0.7286,  0.0953, -0.1105,  ...,  0.0540, -0.2846,  0.0073],\n",
      "        [ 0.2726, -0.1131,  0.2634,  ...,  0.6680,  0.7902, -0.3172],\n",
      "        [-0.1412,  0.3088,  0.1261,  ..., -0.7847,  0.0750, -0.4451],\n",
      "        ...,\n",
      "        [-0.4241,  0.2092,  0.4867,  ...,  0.8822,  0.3511,  0.2128],\n",
      "        [-0.0394, -0.0297,  0.2985,  ..., -0.4595, -0.3722, -0.0323],\n",
      "        [ 0.2099, -0.0642, -0.4648,  ...,  0.1159, -0.5655, -0.0088]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[-36.7490,  -2.9513, -22.5844,  10.4568,   2.0299, -26.0930,  16.7921,\n",
      "           13.0002],\n",
      "         [ -2.2128,  22.1004,  19.5557,   9.3394, -45.2828, -33.2195, -28.4742,\n",
      "           21.8049],\n",
      "         [-20.6120,  36.4984,  -9.1525, -18.6537,  29.4437, -69.9420,  -2.3324,\n",
      "           14.4917],\n",
      "         [ 52.8419,  13.1945,  -3.6661, -30.2773, -13.9132, -15.8172,  18.5469,\n",
      "            3.8260],\n",
      "         [-19.5158,  21.7955,  -8.2661, -21.0142, -46.5263,  21.8056,   8.5036,\n",
      "           -8.1611],\n",
      "         [ 35.0894, -13.0255, -10.6205,   9.7949, -15.8526,  33.2999, -19.9045,\n",
      "           -5.4533],\n",
      "         [-25.7989,  44.0436, -12.2335, -27.9128, -18.1255,  12.3930, -10.6119,\n",
      "           31.7302],\n",
      "         [ 33.8223, -15.8180,  14.1913, -11.1964, -24.3591,  42.4776,   3.3959,\n",
      "            2.2810],\n",
      "         [ 43.3892,   2.0883, -41.7249,  -9.9685, -32.9772, -14.6335,   5.1797,\n",
      "           16.8871],\n",
      "         [ 13.9598,  42.6121, -32.8889, -27.8350,  28.1670,   8.9441, -40.3246,\n",
      "           35.8632],\n",
      "         [  3.5228,  23.9572,  29.1741,   0.5620, -11.2770,  28.6960, -11.9552,\n",
      "          -15.4002],\n",
      "         [ 17.9155,  15.6639, -13.5377,   7.6447,   3.6917, -12.7229, -16.5493,\n",
      "           23.3001],\n",
      "         [ -1.8042, -31.9363,   5.5045,   6.0020,   0.8965,  -3.1441,  -9.9120,\n",
      "           -6.4515],\n",
      "         [  0.7945, -14.7200,  42.4692, -27.3253, -20.3588, -31.0862, -20.3905,\n",
      "           11.3400]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[-0.0961, -0.3100,  0.4138,  ..., -0.0305, -0.3013, -0.2548],\n",
      "        [-0.4162, -0.0120, -0.2510,  ..., -0.2257,  0.0949, -0.0627],\n",
      "        [-0.0715,  0.1993, -0.2020,  ..., -0.4431,  0.6077, -0.0765],\n",
      "        ...,\n",
      "        [ 0.1182, -0.5382,  0.1103,  ...,  0.2201,  0.0330,  0.1785],\n",
      "        [ 0.3570, -0.1698,  0.4274,  ...,  0.4742,  0.7716,  0.3682],\n",
      "        [-0.6779,  0.2578, -0.3638,  ...,  0.2480, -0.2586,  0.1433]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[ -0.9025, -24.7317, -14.9061, -45.2499,  11.8326, -19.8427,  -5.8953,\n",
      "          -13.6860],\n",
      "         [-10.7114, -20.2116, -36.4623, -24.3265,   1.5088, -44.6063, -31.5775,\n",
      "           35.8244],\n",
      "         [-27.8259, -10.9233,  25.2979,   1.5063, -15.2318, -28.0126,  12.3235,\n",
      "          -38.3362],\n",
      "         [ -6.3858, -21.1583,  -9.2974,  36.4963,  -0.5816, -33.8775,  -7.2052,\n",
      "           38.4776],\n",
      "         [-13.5943,  20.8515,   5.8142, -12.8223,   0.3371, -11.7548,  -6.4615,\n",
      "           16.8964],\n",
      "         [-23.1329, -46.9584,  16.0883,  -0.4929,  60.8833,   1.6655, -19.9250,\n",
      "            1.4456],\n",
      "         [-39.0458,  12.7947,  33.3833, -49.3352,  -3.5551,  13.6214, -35.7341,\n",
      "          -13.2771],\n",
      "         [ 16.4738,  -2.2272,  32.4303,  -8.0682, -19.8938,  -1.1841,  12.9699,\n",
      "           34.2788],\n",
      "         [ 24.5455,  29.4112, -19.5787,  33.5494, -35.0393,  13.9352,  16.3012,\n",
      "           18.9389],\n",
      "         [ -1.7263, -29.5065, -31.8399, -23.5674,   3.3106,   5.0329,   4.1065,\n",
      "           22.9885],\n",
      "         [ 23.3021, -10.0037,   7.6259, -29.8589,   8.9743,   1.0780,   9.0877,\n",
      "           -2.8527],\n",
      "         [ 13.9899,  47.2292,   6.2139, -17.9452, -23.5618,  46.6759,  28.1530,\n",
      "           -0.9810],\n",
      "         [ -0.9525,   9.9904,   1.0694,  16.0832,  -1.8475,   4.7808,  -5.8522,\n",
      "            3.6600],\n",
      "         [ -9.1916,   5.5745,   0.8123,  18.9134, -15.8024, -16.1284,   0.7013,\n",
      "          -22.5133]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.5094,  0.1840,  0.1728,  ...,  0.3918,  0.0897, -0.0025],\n",
      "        [ 0.0999,  0.2800,  0.0525,  ..., -0.3390,  0.3068, -0.2411],\n",
      "        [-0.1877,  0.6067, -0.3303,  ..., -0.3295,  0.1908,  0.0593],\n",
      "        ...,\n",
      "        [ 0.3315, -0.0093,  0.0318,  ...,  0.2241, -0.1056, -0.2131],\n",
      "        [ 0.1940,  0.6245,  0.0939,  ..., -0.3570,  0.0706,  0.2555],\n",
      "        [-0.0605, -0.0691, -0.9051,  ..., -0.0951,  0.0829, -0.2965]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[  8.6731,  -0.5151,   7.8901,  -2.3898,  22.9108, -16.2970,  -4.5287,\n",
      "            1.7415],\n",
      "         [ 20.6325, -11.1456,  15.8154, -15.3248, -20.1830, -15.4875,  21.8450,\n",
      "           15.4372],\n",
      "         [  8.0324,  -8.1697,   3.8694,   1.0365, -21.0960,   3.3070,  -6.8379,\n",
      "           24.2230],\n",
      "         [ 14.5911,  -6.8164,  -1.1309, -10.6071,  -2.8570,  -2.9528,  10.3133,\n",
      "           -0.1880],\n",
      "         [ -1.2687,  13.1458,  -2.4580,  10.5975, -22.2361,  13.9342,  -0.2371,\n",
      "            9.0203],\n",
      "         [  0.4691,  -6.5709, -12.1574,  -1.0222,  10.3791,   4.3740,   5.0300,\n",
      "           -5.2277],\n",
      "         [  1.8707,  -5.5929,   8.4066,   2.6326,  20.8612,   5.8842,  17.5978,\n",
      "           12.5862],\n",
      "         [-12.5262,  18.8153,   0.6723, -22.4178, -26.0243,  11.3405,  -3.0720,\n",
      "           -0.6698],\n",
      "         [ 25.9686,  20.5976, -19.4822,   7.4664, -30.0435,   3.8766,  -6.1572,\n",
      "          -19.9901],\n",
      "         [  1.4114,   1.5970,  -7.9155,  -0.0493,  -1.7495, -11.1685,  -3.0109,\n",
      "           21.3553],\n",
      "         [-13.5904,  29.2343,   1.9845,  14.1468, -21.7105,   6.1163,   2.7549,\n",
      "            1.9436],\n",
      "         [ -9.7237,  -7.7916,  -0.3491,   6.6158, -12.0529,  -5.1152,  13.4225,\n",
      "           -5.3008],\n",
      "         [ 27.2652, -17.0048,  -5.9484,  16.6627,   9.6432, -27.5562,  -4.2637,\n",
      "           13.3386],\n",
      "         [ -0.9328,  -3.5292, -26.5250,  -7.1646,  -0.3360,  15.6309,   2.5790,\n",
      "            2.4023]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.4211,  0.0724,  0.5005,  ..., -0.3530, -0.1756,  0.0395],\n",
      "        [-0.4654,  0.1046,  0.4834,  ..., -0.0018, -0.2028,  0.3009],\n",
      "        [ 0.6944,  0.3528, -0.6494,  ...,  0.3813, -0.4335, -0.2119],\n",
      "        ...,\n",
      "        [ 0.2515,  0.1194,  0.2144,  ...,  0.4112,  0.3349, -0.3202],\n",
      "        [ 0.6867,  0.6858, -0.2004,  ..., -0.5271,  0.1013,  0.6491],\n",
      "        [ 0.0382,  0.7280,  0.0529,  ..., -0.5063, -0.0277,  0.5253]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[ -3.0956,  -1.9445, -12.4623,   2.7571, -15.2622, -11.6031,  13.7984,\n",
      "           25.0744],\n",
      "         [ -1.1551, -14.0015,  -2.5489,  11.3983, -35.3247,   8.9273,  12.0291,\n",
      "           20.2285],\n",
      "         [  4.5740,   7.0023,   2.8291,  12.8410,  -6.4925,  -5.4493,  -8.5391,\n",
      "          -22.9571],\n",
      "         [ -4.7421,   4.3548,  -5.8215, -15.4523, -18.2392,  -4.6252,   6.1977,\n",
      "           14.5802],\n",
      "         [ -7.9723,   6.8351,   8.3573, -20.5028,   1.5151,   7.6576,  14.4713,\n",
      "            6.8011],\n",
      "         [ -1.1559,  -0.8084,   7.3112,  11.8696,  14.9469,  -8.3182, -10.1783,\n",
      "            1.5553],\n",
      "         [  5.5215,   6.5898,  -7.4885,  -7.3583,  -6.0171, -19.7899,   1.1502,\n",
      "            7.0399],\n",
      "         [-11.5666,   3.2409,  12.3614,  28.8158,   0.8487,  -4.7648, -13.4027,\n",
      "           -7.2923],\n",
      "         [  2.9438,   2.1151,  36.5744,  -1.8847,  12.8482,   7.6371,  -9.4857,\n",
      "            5.2988],\n",
      "         [  8.5024, -28.2985,   1.9210, -13.9056,   2.2580, -21.3524, -11.2328,\n",
      "          -17.2226],\n",
      "         [ 17.5000,  -3.3285,   6.8058,   0.2705,   3.2723,  10.4762, -15.6898,\n",
      "            7.6375],\n",
      "         [  0.5080,  -4.8196,   1.0101,  -6.7431,  -5.5657,   1.2768,   1.2919,\n",
      "            0.7833],\n",
      "         [  2.2853, -13.6182,  -5.1176, -11.2996, -19.0469,  -1.3069,  -1.3654,\n",
      "           -2.6003],\n",
      "         [ 19.6997,   3.3703,   8.5495,  -0.5621,  23.1585,  -8.8385,  -0.1754,\n",
      "            2.8636]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[-0.3010, -0.4045,  0.2636,  ...,  0.1890, -0.0333,  0.2274],\n",
      "        [-0.2203,  0.5073,  0.6744,  ..., -0.5936,  0.0928,  0.1783],\n",
      "        [ 0.4794,  0.2092,  0.0247,  ...,  0.1709, -0.3209,  0.2819],\n",
      "        ...,\n",
      "        [-0.5542, -0.3221, -0.2331,  ...,  0.2022, -0.0913, -0.4333],\n",
      "        [ 0.1475, -1.0155, -0.5831,  ..., -0.2778, -0.5381,  0.0944],\n",
      "        [ 0.0086,  0.2452,  0.1485,  ..., -0.2207, -0.0177, -0.9206]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[ 38.3744, -27.5576, -48.7212, -22.9026,  -2.4302, -25.8752, -71.8777,\n",
      "           11.1240],\n",
      "         [ -1.1082,  -8.3310, -19.8200,  20.0763,  20.1961,   9.0160,  14.4330,\n",
      "          -32.4936],\n",
      "         [-12.6004,  27.2393, -18.9552,  14.9279, -28.2451, -12.8756, -23.3260,\n",
      "          -13.9326],\n",
      "         [ 24.4181,  18.1586, -22.3465,  13.4361,  -8.9123,  -4.4307, -14.9318,\n",
      "           -9.3485],\n",
      "         [-18.9322,  -1.7085,  10.3155,  -1.9630,  60.5122,  -4.5491,  15.3597,\n",
      "           13.6821],\n",
      "         [-18.8321,  -2.7740,   6.2997,   0.3240,   8.7155,   4.1275,   8.8975,\n",
      "           25.9150],\n",
      "         [ 22.5880,  -9.7123, -50.2605, -12.1279,  -7.4301,  11.8865,   4.6283,\n",
      "           -7.0344],\n",
      "         [ -6.1683,  17.0510,  -7.1423,  13.0919,   6.9798,  22.0147,  40.3507,\n",
      "          -16.5894],\n",
      "         [ -6.0868, -58.4355,  -6.7435,  -5.6870, -10.2461,  37.6074, -23.4495,\n",
      "          -30.3854],\n",
      "         [ 32.2495,   1.3034, -24.4234,  23.3587,  11.1783, -16.8518,   2.7412,\n",
      "           18.7126],\n",
      "         [-36.1881, -30.8528,  65.0438,  13.1821, -36.4104,  22.6294,  19.0673,\n",
      "          -11.8393],\n",
      "         [-10.9435,  21.7314,  -3.3670, -16.3256,  -4.5093,  -7.0008,   0.8078,\n",
      "           50.8974],\n",
      "         [-12.7931,   1.9081, -43.9240,  61.6509, -20.9060,  12.9722,   0.0763,\n",
      "           -8.7423],\n",
      "         [ 25.6479,  39.1709,   6.9672,  19.1310,   5.0116, -13.7969, -16.7310,\n",
      "          -27.7340]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[-0.0292,  0.1253,  0.3325,  ..., -0.4630,  0.1230, -0.0228],\n",
      "        [-0.1263,  0.4719,  0.1086,  ..., -0.3575, -0.0130,  0.0320],\n",
      "        [ 0.2875,  0.0409, -0.1656,  ..., -0.1694,  0.3646,  0.1680],\n",
      "        ...,\n",
      "        [ 0.4621,  0.4333,  0.1256,  ...,  0.0334,  0.4533,  0.1060],\n",
      "        [ 0.7489, -0.2027,  0.3973,  ...,  0.4984,  0.0942,  0.3052],\n",
      "        [-0.8403, -0.3770,  0.1133,  ..., -0.0553,  0.4975, -0.1164]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[ -26.0013,   66.8824,   30.8280,   16.4465,   34.5194,  -63.3135,\n",
      "           -35.5214,  -15.4706],\n",
      "         [  31.4686,  -36.6026,   46.4186,  -28.5462,  -11.2228,    8.4454,\n",
      "            49.5242, -104.2089],\n",
      "         [  -5.1347,  -21.4943,  -15.6281,  -68.3170,    4.6883,  -43.1137,\n",
      "           -28.7076,  -65.4714],\n",
      "         [ -49.5886,  -38.2285,  -67.1439,    9.1893,  -24.8187,   70.4787,\n",
      "           -18.5260,   31.6170],\n",
      "         [  -0.6751,  -27.7974,  -34.0964,  -28.4876,   55.5247,   25.1714,\n",
      "             8.0894,  -13.2763],\n",
      "         [ -21.4199,  -37.2353,    8.0062,   82.1334,  -33.4680,   33.0731,\n",
      "           -18.6289,  -16.2251],\n",
      "         [ -66.8788,  -51.2852,   11.1598,   25.6178,   45.4245,    3.1550,\n",
      "            24.7545,  -35.7751],\n",
      "         [ -64.4288,    0.7959,  -57.2170,   -4.1024,  -47.2096,    8.1432,\n",
      "           -68.2896,    4.9554],\n",
      "         [ -50.1348,  -27.6907,   37.1305,   58.0223,  -26.0841,   25.4579,\n",
      "          -102.3837,  -16.9061],\n",
      "         [ -20.8752,   -0.6438,   18.4762,   -3.7130,   14.2248,   84.7751,\n",
      "            28.3595,   29.4665],\n",
      "         [ -24.1146,    6.9433,   50.2762,  -49.3895,   -2.1613,   -3.0549,\n",
      "            64.4191,   59.2288],\n",
      "         [ -32.2443,  -53.2399,   -5.6601,  -35.3402,  -18.2013,    3.7313,\n",
      "            21.6599,  -10.5739],\n",
      "         [  27.7074,   41.7346,  -25.3843,   43.2546,  -49.3662,    7.8295,\n",
      "           -46.2350,  -18.8930],\n",
      "         [ -30.3703,    2.4258,  -45.0115,  -23.1991,   42.7346,   69.1550,\n",
      "           -14.4498,  -26.4375]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[-0.6853,  0.5893, -0.3637,  ...,  0.1796, -0.0875,  0.1493],\n",
      "        [-0.0203, -0.0226,  0.2854,  ..., -0.9044, -0.1162,  0.3483],\n",
      "        [-0.0704, -0.3330, -0.3065,  ...,  0.6400,  0.4262, -0.1436],\n",
      "        ...,\n",
      "        [ 0.8714,  0.4333,  0.5048,  ..., -0.1278, -0.2725,  0.6339],\n",
      "        [ 0.1259,  0.0767,  0.2310,  ..., -0.2287, -0.1684, -0.3893],\n",
      "        [-0.7008,  0.3940, -0.5403,  ..., -0.1470, -0.6779,  0.1491]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[  42.2732,   27.6508,   14.6495,  -15.5200,   -3.4105,   38.2767,\n",
      "            77.8803,   28.4635],\n",
      "         [ -72.4659,   -9.5472,   55.6381,   26.2170,  -51.0659,  -12.7506,\n",
      "           -32.5213,   13.3388],\n",
      "         [  51.9175,   96.5807,  -31.2949,    1.5735,   11.6145,   37.2747,\n",
      "            13.9822,   24.5308],\n",
      "         [  57.8603,  -28.0388,  -32.0199,  -64.5034,  -25.6196,  -66.0398,\n",
      "             7.8124,  -41.5388],\n",
      "         [ -17.6865,  -40.4857,  -46.4263,   26.3308,  -61.8859,   52.5052,\n",
      "            26.9809,  -31.4242],\n",
      "         [ -30.7421,  -77.6779,   56.0931,   24.3951,  -49.1261,   -0.2835,\n",
      "           -94.5742,   14.6792],\n",
      "         [  38.4457,  -15.1813,   74.3174,   75.0457,  -52.6973,  -40.6808,\n",
      "           -48.1037,   46.8768],\n",
      "         [ -26.5009,  -80.1283,   38.0649,  -49.2833,   26.2155,   22.3110,\n",
      "            46.5849,  -35.7496],\n",
      "         [  12.3469,  -56.0153,   46.9003,  -96.2427,   13.0802,   43.7158,\n",
      "           -11.9551,  -45.6601],\n",
      "         [  49.2969,   34.7438,   41.4726,   14.3806,   19.9558,  -30.2156,\n",
      "           -23.5500,   -6.4061],\n",
      "         [  -6.2387,   -5.5674,  -36.2597, -110.7437,  -52.0217,  -27.1522,\n",
      "            24.6498,  -20.8441],\n",
      "         [   9.7685,   25.2388,  -59.0407,  -39.2978,  -25.5002,  -10.4854,\n",
      "           -39.5777,   13.6772],\n",
      "         [  38.4378,   58.9729,    7.3648,  -54.0700,   17.2845,   72.9804,\n",
      "           -74.7403,    7.9342],\n",
      "         [ -11.4991,   59.6917,    6.7198,   48.6324,   26.0847,   88.1825,\n",
      "           -73.8515,    6.9375]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=14336, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[-0.2005,  0.1120, -0.0343,  ...,  0.1830, -0.1816,  0.4060],\n",
      "        [ 0.0831, -0.1948,  0.7222,  ..., -0.2033,  0.0584, -0.0844],\n",
      "        [ 0.0353,  0.3606,  0.0516,  ...,  0.2543,  0.0828,  0.2303],\n",
      "        ...,\n",
      "        [ 0.3568, -0.4473, -0.9572,  ...,  0.1908, -0.5060,  0.3161],\n",
      "        [-0.3630, -0.1215, -0.1342,  ..., -0.1535,  0.8678, -0.3511],\n",
      "        [-0.2561,  0.0782,  0.0849,  ..., -0.0883, -0.3735,  0.1532]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[ -3.3248,   6.7450, -16.7797,  -0.1566,  10.7751,  23.5185,  30.8865,\n",
      "           26.9798],\n",
      "         [  5.2755,   2.5239,  27.0859, -32.1601,  24.8007, -31.8077,  -2.0270,\n",
      "          -49.4725],\n",
      "         [-13.8144,   0.5825, -29.3956,  52.9493, -21.9299, -10.9139,  17.0896,\n",
      "          -14.7527],\n",
      "         [-11.1506,  -2.4663, -29.0601,   6.3870,   9.3560, -31.2231,  16.2496,\n",
      "          -31.6859],\n",
      "         [ 12.7120,   9.7463,  12.3117,  29.5893,  50.1012, -24.2078,   2.4644,\n",
      "           19.8742],\n",
      "         [-42.0344,  33.3950, -20.8365,  -6.7114,  -6.6285,  15.1477,   6.1857,\n",
      "           41.5461],\n",
      "         [-16.9468, -18.0972,  18.4416, -12.8706,  40.9830, -13.1540, -44.5124,\n",
      "            5.9310],\n",
      "         [-16.2925,  -1.3679,  -3.7488, -17.1141,   3.2757,  26.0348,  -6.0853,\n",
      "          -22.6752],\n",
      "         [ -0.1957,  -8.5372,  28.0457, -20.8910,   0.6705,  16.1490,  -8.3855,\n",
      "          -37.5792],\n",
      "         [ -6.0868,   4.3934,   7.6189,  -4.0591,  -4.7909,  29.7626,   7.9198,\n",
      "          -16.8278],\n",
      "         [-44.7415,  -1.3822,   9.9374, -21.5692,  24.4609, -18.4908, -33.7622,\n",
      "          -13.5286],\n",
      "         [-19.5484, -10.2556, -30.3729,  42.2875,  10.6027, -33.0279,  17.7094,\n",
      "           29.6987],\n",
      "         [-38.8212,  18.9225, -12.2021,   7.0159, -19.4314, -13.5688,   1.2911,\n",
      "          -10.6190],\n",
      "         [-43.6106,  37.4512,  -8.5960,  59.1554, -21.2560,   9.9925,  15.9508,\n",
      "           -8.9202]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[-3.6053e-01,  2.9127e-01, -3.9437e-01,  ...,  9.9530e-03,\n",
      "          1.3461e-02, -3.3370e-01],\n",
      "        [ 1.0136e-02,  2.8118e-01,  1.3248e-04,  ...,  5.7390e-01,\n",
      "         -3.2695e-01,  4.0610e-01],\n",
      "        [-7.9156e-01,  3.5382e-01, -1.1617e-01,  ..., -2.8531e-01,\n",
      "         -3.1295e-02,  5.6252e-01],\n",
      "        ...,\n",
      "        [-7.2023e-02,  4.2268e-01, -8.5810e-01,  ...,  4.6346e-01,\n",
      "         -1.3313e-01, -2.1376e-01],\n",
      "        [ 1.3728e-01, -7.8332e-02,  3.0366e-01,  ..., -2.1090e-01,\n",
      "          3.0386e-01,  3.0652e-01],\n",
      "        [-2.4984e-01,  1.2591e-01, -1.7684e-01,  ...,  3.5682e-02,\n",
      "         -1.0451e+00,  3.7360e-01]], device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[ -6.5774, -11.2023,  37.1339,  14.2595,   2.1332,   1.4556,   0.7705,\n",
      "           17.4357],\n",
      "         [ 11.9862, -25.5886,  26.2463,  -0.5537, -17.5506,  40.4895,   7.2090,\n",
      "          -11.3881],\n",
      "         [-16.7502, -22.4851, -23.4300, -15.5286,  32.7551, -23.9793,   7.5531,\n",
      "           -6.1911],\n",
      "         [-40.2742,   2.7073, -38.3234,  14.1331,   1.2201,  10.6378,   0.5334,\n",
      "           -3.7790],\n",
      "         [ 11.2257, -12.6636,   5.2148,  56.9713,  20.0164,  30.9141, -24.4113,\n",
      "          -11.4462],\n",
      "         [ 22.2015,   0.4588,  34.1346,   6.2606,  -8.9894, -15.9815, -23.8534,\n",
      "          -28.0069],\n",
      "         [-18.1577,  32.0429,  13.5530, -23.9766, -21.5289,  -4.4905, -14.2446,\n",
      "          -35.7045],\n",
      "         [ -7.5513,   9.9492,  -8.5472,  11.1260,  -7.4731,   0.4663,  -9.5292,\n",
      "            1.6210],\n",
      "         [ 29.8630,  -2.7915,  -2.1087,  10.1344,   1.6704, -14.5948,  41.3510,\n",
      "           28.5167],\n",
      "         [-30.0999, -32.9777,   6.8610, -13.8594, -21.7425, -36.6644, -38.7888,\n",
      "          -21.4802],\n",
      "         [ 29.9911, -27.9987, -26.0513,   8.5254,  -1.1062,  21.4659,  -7.5568,\n",
      "           18.3598],\n",
      "         [ 31.6377,  40.6427,   2.5750, -13.0567, -41.2166, -32.5709, -14.2853,\n",
      "            9.0216],\n",
      "         [-14.9343, -11.1062, -13.6803,   2.7919,   6.5342,   4.8597, -19.4363,\n",
      "           -8.5186],\n",
      "         [ 11.5708,  25.1228,   7.3017,  35.9350, -10.0915, -21.8229,  -5.4749,\n",
      "          -20.8126]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.7851, -0.2721,  0.9004,  ...,  0.7612,  0.3098, -0.8885],\n",
      "        [-0.5382, -0.4095, -0.6768,  ..., -0.2096, -0.1081, -0.0912],\n",
      "        [-0.0492,  0.0051,  0.0658,  ..., -0.4666,  0.2702, -0.9918],\n",
      "        ...,\n",
      "        [ 0.2835, -0.2084,  0.3995,  ...,  0.3275,  0.0716,  0.0977],\n",
      "        [ 0.2049, -0.2529, -0.3069,  ..., -0.6115, -0.1514, -0.1692],\n",
      "        [ 0.0470, -0.5534,  0.1718,  ..., -0.2575,  0.3921,  0.2243]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[ 10.7142,  -4.6808,  -6.0500,   1.6448,  14.4530,  11.2706,   6.0392,\n",
      "          -12.7175],\n",
      "         [-12.5550,   4.7277,   5.2997,   0.5482, -16.8055,   9.6617,  18.6610,\n",
      "           -8.0644],\n",
      "         [  3.2275,  11.1223,  -4.1651,  -6.1193,  13.6383,  -3.6911,  -7.4189,\n",
      "          -23.2300],\n",
      "         [ -1.5058,  -5.2612,  -3.6234, -19.2091, -18.0136,  10.3761,   1.4786,\n",
      "           23.4622],\n",
      "         [ 15.0756,   6.1765,  -2.5167,   3.9383,   6.0352,  -8.1718,   5.1109,\n",
      "           14.0052],\n",
      "         [  9.5465,  19.6772,  -4.2213,  -1.5911,  -6.3490,  -0.3115,  -2.6720,\n",
      "            0.6490],\n",
      "         [  5.5682,   0.5840,  10.9780,   4.5021, -22.5074,   1.9742, -13.2946,\n",
      "          -19.6982],\n",
      "         [ 13.2411,  -9.7428, -11.7788,   5.8939,  13.1109,   5.4955,  -7.0414,\n",
      "           19.0426],\n",
      "         [  0.2782,  11.0597,   0.2951,  -1.6156,  15.4754,  -9.6978,  13.8952,\n",
      "          -10.6924],\n",
      "         [-12.0777,   0.7794,   2.8253,  -0.1595,  14.5671,  -0.7227,   4.2712,\n",
      "           -0.8806],\n",
      "         [  1.9776, -10.1524, -10.8486,  10.8499,  -0.9721,  -0.0706, -12.4520,\n",
      "           21.8765],\n",
      "         [ 13.9784, -11.7723,   8.7386,  14.7494, -13.6589,  -2.2124, -14.6861,\n",
      "            6.6738],\n",
      "         [-12.1061,  20.4871,  13.1210,   2.6698,  10.1234,  17.0688,   7.1332,\n",
      "           -2.7227],\n",
      "         [-12.3852,   3.4135,   5.1552, -12.3906,  -3.3943,   9.9540,  17.8356,\n",
      "           -3.5831]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.4300, -0.0527, -0.2491,  ...,  0.1084, -0.0263, -0.8352],\n",
      "        [-0.2030, -0.1274, -0.2683,  ...,  0.5360,  0.1435, -0.0188],\n",
      "        [-0.7282, -0.0610, -0.2486,  ...,  0.0437,  0.0548,  0.0052],\n",
      "        ...,\n",
      "        [ 0.5715,  0.4927, -0.2114,  ...,  1.0192, -0.5162, -0.2547],\n",
      "        [-0.6339, -0.4739, -0.5878,  ...,  0.0412, -0.6576, -0.1098],\n",
      "        [-0.5452,  0.3970,  0.3545,  ...,  0.3081,  0.3385, -0.2852]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[-18.6233,   5.6424,  -5.8890,   7.1025,  13.5441,  -2.2516,   0.1208,\n",
      "            1.1897],\n",
      "         [  9.4594,  -8.9148, -10.0486,   6.1004, -20.1059,  -4.4923,   9.5430,\n",
      "           -5.3516],\n",
      "         [  0.3480,   3.3669, -12.2214,  -4.6418, -18.1071,  10.0348,  10.3819,\n",
      "           11.9277],\n",
      "         [  2.5628,  15.9128,  13.5336,  28.7255,   6.8971,   8.3462, -26.8687,\n",
      "           -2.8362],\n",
      "         [  6.6533,   7.9375, -12.2833,   1.9341, -25.2540,  -2.1795, -11.0235,\n",
      "           -6.8578],\n",
      "         [-14.6653,  -5.8449,  -4.1580, -27.0757,   5.7089,  13.1229,   4.4071,\n",
      "           -4.6547],\n",
      "         [  7.1420,   8.3726, -13.4091,  -2.7988, -24.5631,  -6.9596,   2.7925,\n",
      "            8.9488],\n",
      "         [  1.3280, -22.8784,  -7.0786,   4.1852,  -7.5601,  -1.7513,  16.4321,\n",
      "           10.2333],\n",
      "         [-15.7029,  -2.7929,  -4.8652,   5.3983,   4.7617,   8.5439,   0.7942,\n",
      "            3.1647],\n",
      "         [ -2.1855,   4.9406,   7.9577,  19.8082,  -5.2289,   4.2720,   8.3888,\n",
      "          -10.0608],\n",
      "         [  4.0744,  17.3231,   2.5904,  -4.6050, -11.8921,  -1.6104,  -7.3162,\n",
      "            7.5586],\n",
      "         [ -7.0070,  24.4916,  -0.2912,  14.4871,  -7.9163,  11.6170,  11.4378,\n",
      "           15.0977],\n",
      "         [  7.7086,  12.2994,   5.8031,  -6.1077,  -5.9462,   0.6441,   3.4381,\n",
      "            9.2384],\n",
      "         [ -6.2409,   4.7185, -12.7306,  -0.8461,  -6.4237,  -4.4939,   8.2152,\n",
      "          -20.8246]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[-0.1803, -0.0502, -0.0521,  ..., -0.3647,  0.0202,  0.0305],\n",
      "        [-0.0357, -0.2937,  0.1481,  ...,  0.1444,  0.7405,  0.2483],\n",
      "        [-0.0075, -0.5608, -0.4516,  ..., -0.0137, -0.2961, -0.0369],\n",
      "        ...,\n",
      "        [-0.1456,  0.3348,  0.0022,  ...,  0.1695,  0.2156,  0.4480],\n",
      "        [ 0.1442, -0.1615, -0.5765,  ...,  0.6190, -0.3585,  0.4439],\n",
      "        [-0.2820, -0.2339,  0.3359,  ...,  0.7039,  0.3729, -0.2737]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[  2.1505,  -6.8379, -10.3705,  13.8292,  -2.7620,  -8.7547,  24.6768,\n",
      "           11.5429],\n",
      "         [  4.8418,  -7.5162,   3.6255,  15.0796, -30.5251,   1.8787, -12.9134,\n",
      "           12.2742],\n",
      "         [  1.3752,  -7.6536,   1.3858,  37.0993,  37.8182,  27.4567,  43.1218,\n",
      "           -5.5410],\n",
      "         [-19.2400, -20.8761,  20.0843,  39.6314, -11.6296,  18.1194,  -6.1009,\n",
      "           13.3714],\n",
      "         [-16.6078, -25.4315,   4.5870,  40.6782,   6.7905, -30.6937,  21.9353,\n",
      "            0.3773],\n",
      "         [ 27.0073,  12.3135, -16.4923,   8.4180,  26.9560, -29.9674,  26.3404,\n",
      "           -6.7936],\n",
      "         [ 21.1139,   3.4510, -25.9891,   7.3218,   4.3856,   5.1595,  -2.7023,\n",
      "          -66.0579],\n",
      "         [ 17.2724,  -3.2113,  20.2020,  -5.0758,   5.4680,  -4.8362, -29.1441,\n",
      "            3.5744],\n",
      "         [-27.4619,  15.2384,  -9.4860, -28.3118,  39.0099,   4.7314,  34.4816,\n",
      "          -48.9180],\n",
      "         [-50.0508,  34.4369,  15.3025,  16.6834,  25.1896, -25.1124, -15.5122,\n",
      "           -6.2246],\n",
      "         [ -0.1130,  -9.0989,  26.7760, -15.5864, -17.0154,   9.5832, -26.2006,\n",
      "          -17.8380],\n",
      "         [ 19.1574, -30.3710,  11.3948,  31.9343,  -3.8927,   8.3155,  46.5484,\n",
      "            2.9653],\n",
      "         [ 21.2475,  -3.7716, -10.6124, -12.8580,   4.6051,  15.5790,  23.2669,\n",
      "           24.9318],\n",
      "         [-43.8215,  13.1253,  19.4892, -21.9902,  -7.0404,  -5.7040, -12.3669,\n",
      "            1.3329]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[-0.4464, -0.0362, -0.1375,  ...,  0.0347,  0.0519,  0.3124],\n",
      "        [-0.0697,  0.3402,  0.0854,  ...,  0.0868,  0.1859,  0.2606],\n",
      "        [ 0.0391,  0.4456,  0.3203,  ...,  0.0278, -0.6275, -0.3338],\n",
      "        ...,\n",
      "        [ 0.0211, -0.3446, -0.1731,  ..., -0.1473,  0.3865,  0.2926],\n",
      "        [-0.0703, -0.1043,  0.7703,  ...,  0.2711,  0.1921, -0.0499],\n",
      "        [-0.2705, -0.2955, -0.0084,  ..., -0.0115, -0.3049, -0.2335]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[-3.1823e+00, -2.9686e+01,  2.4868e+01,  1.5384e+01, -1.3331e+01,\n",
      "          -1.5084e+01, -6.3578e+01,  4.3466e+00],\n",
      "         [ 1.5113e+01,  3.8964e+01, -1.0134e+01, -4.5799e+01,  7.8820e+01,\n",
      "           2.9444e+01, -4.4613e+01,  1.4491e+01],\n",
      "         [-1.0953e+02, -9.8840e+00,  2.8385e+01,  1.8002e+00,  4.6869e-02,\n",
      "          -1.4573e+01,  4.4409e+01, -4.2661e+00],\n",
      "         [-2.0802e+01,  4.2552e+01,  1.1034e+01,  2.6679e+01, -2.9299e+01,\n",
      "           2.9029e+01, -8.1981e+00,  3.7873e+01],\n",
      "         [ 1.7462e+01,  6.1234e+01,  4.2619e+01,  4.3859e+01,  4.0174e+01,\n",
      "          -6.4338e+01, -3.4194e+01, -6.1117e+01],\n",
      "         [-2.4391e+01,  2.7955e+01,  4.0732e+01, -4.4454e+01, -5.8226e+01,\n",
      "          -9.3199e-01,  1.2346e+01,  2.3357e+01],\n",
      "         [ 6.8674e+00, -2.3472e+01,  4.8101e+01,  2.2796e+01,  2.2034e+01,\n",
      "           3.3263e+01, -8.5499e+01, -3.3982e+01],\n",
      "         [-8.0760e+00, -1.8357e+01, -2.1975e+01, -1.8832e+00, -6.5785e+00,\n",
      "           5.5238e+01,  4.0775e+01,  9.4130e+01],\n",
      "         [ 6.8743e+01, -6.0803e+01,  6.0915e+00, -1.9823e+01, -4.5220e+01,\n",
      "           3.2229e+01,  1.7704e+01,  5.5764e+01],\n",
      "         [ 3.6629e+01, -5.1181e+01,  6.0100e+01, -1.0124e+00,  1.7095e+01,\n",
      "          -9.2627e+01, -2.3692e+01, -6.2088e+00],\n",
      "         [ 3.5871e+01, -5.0261e+01, -1.9234e+01,  2.2370e+01, -3.7044e+01,\n",
      "          -7.8614e+01,  2.9807e+01, -2.2262e-01],\n",
      "         [-2.9929e+00,  1.3056e+01, -3.5107e+01, -4.5242e+01,  2.4421e+01,\n",
      "          -1.9920e+01, -4.0340e+00, -2.9458e+01],\n",
      "         [ 1.1281e+02, -4.0964e+01,  4.0066e+01, -6.7696e+01,  5.7562e+00,\n",
      "          -1.0109e+02,  3.7785e+01, -6.1411e+01],\n",
      "         [ 3.5761e+00, -4.2785e+01,  4.4550e+00, -3.5679e+01,  2.3675e+01,\n",
      "           2.2637e+01, -4.1235e+01, -2.3881e+01]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[-0.3295, -0.1736,  0.4299,  ..., -0.3571, -0.0953, -0.3377],\n",
      "        [ 0.0641, -0.2167,  0.4245,  ..., -0.3437,  0.5004,  0.0830],\n",
      "        [-0.3724, -0.2574, -0.0012,  ...,  0.3259, -0.0727, -0.1262],\n",
      "        ...,\n",
      "        [-0.5837, -0.0841, -0.0772,  ...,  0.1974, -0.3101,  0.5294],\n",
      "        [ 0.5389, -0.2082,  0.1187,  ..., -0.2895,  0.0516,  0.2144],\n",
      "        [-0.3354,  0.4335, -0.2710,  ..., -0.5399, -0.4020, -0.4379]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[-35.7567, -53.3463,   3.3573, -48.7824,  34.7370, -26.7610, -15.4122,\n",
      "            0.8354],\n",
      "         [108.9421, -32.4586,  24.8219,   0.8014, -20.5879,  83.3643, -32.4206,\n",
      "           12.9509],\n",
      "         [-36.9839,  31.4070, -57.3018,  -3.3064,  11.4723, -44.4854,  20.5850,\n",
      "          -58.2006],\n",
      "         [ -9.0109,  -5.5479,  49.4206,  22.8468, -45.1242,  46.7450, -44.7929,\n",
      "          -51.9969],\n",
      "         [  2.5389,   4.0608,  31.3807, -46.7603, -27.9603, -28.0494, -38.9950,\n",
      "           33.7775],\n",
      "         [ 17.6871, -30.2008,  38.7714, -54.9683,  24.0617, -27.9453,  15.8398,\n",
      "            9.3338],\n",
      "         [ 21.3818, 103.0906, -53.0749,  71.6960,  22.9843,  32.5372,   9.4734,\n",
      "            4.5088],\n",
      "         [-38.6476, -37.9429, -23.7027, -22.6216, -28.2289, -65.2827,  40.9773,\n",
      "           60.8322],\n",
      "         [ -2.1123, -30.8317,  25.4377,  56.7665, -67.4920, -16.5446,   1.1445,\n",
      "           22.8024],\n",
      "         [-31.8768, -32.6244,  21.4815, -63.2016,   4.8388, -18.4377,   7.9809,\n",
      "          -12.8280],\n",
      "         [-22.4417,  19.1467, -36.6256, -51.6644,  76.1947, -76.4101,  42.8944,\n",
      "          -32.6307],\n",
      "         [-89.0482,  27.0406, -28.9918, -72.9438, -66.5425,  23.4220,  -7.6920,\n",
      "            6.6504],\n",
      "         [ 14.2870, 108.5479,  40.8556,  -2.9758,  61.5886, -33.5886,  22.1440,\n",
      "          -58.0007],\n",
      "         [  5.2503,  11.8982,  -7.2658,  -3.4446, -27.1650, -39.9524,  -9.2009,\n",
      "            0.9065]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=14336, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.0930, -0.2553, -0.0013,  ...,  0.1940,  0.2902, -0.0124],\n",
      "        [-0.4728,  0.2637,  0.1231,  ...,  0.1427,  0.1056,  0.0134],\n",
      "        [ 0.5344,  0.0902,  0.0172,  ...,  0.2863,  0.3637,  0.0419],\n",
      "        ...,\n",
      "        [-0.1551, -0.4569, -0.0415,  ..., -0.0023,  0.0361,  0.1311],\n",
      "        [-0.4510, -0.3408, -0.0774,  ..., -0.3349,  0.1446,  0.0919],\n",
      "        [-0.4948,  0.1935, -0.7031,  ..., -0.2472, -0.7087,  0.3994]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[  5.5774,  28.4520,  28.0704,  33.4004,   4.8286,   6.9015, -11.4701,\n",
      "           17.2786],\n",
      "         [  9.3347,   7.6304,  34.5727,  18.2805, -17.3939,  10.4897,   2.4424,\n",
      "           -7.0965],\n",
      "         [-11.3578, -18.6368,  -9.8906,  18.9320,  38.2055,  -5.1026, -33.4820,\n",
      "           38.4586],\n",
      "         [  9.9860, -34.7167, -38.2016,  18.5428,  20.5904, -49.9499, -21.9751,\n",
      "          -16.1598],\n",
      "         [-50.1251,  10.2850, -16.1545, -22.7039,  19.3775,  29.6208,  45.1705,\n",
      "           -2.7420],\n",
      "         [  2.5059, -11.2672,  39.8850,  -1.4070,   1.0064, -15.0874, -14.0811,\n",
      "           17.5175],\n",
      "         [-14.7882,  22.7008,   6.1900,   0.7074,  13.6778,  -4.5408, -20.8526,\n",
      "          -21.2871],\n",
      "         [-11.1263,  15.6234, -21.2394,   2.6558, -15.7680,  -5.7430, -24.2731,\n",
      "           -6.3064],\n",
      "         [ 17.3148,  21.2102,  12.8845,   2.4493,  33.2799,  37.1713, -20.9127,\n",
      "           67.1757],\n",
      "         [ -3.1904,   3.4196,  10.1816,  34.1999,  29.6498, -30.9541,   3.6482,\n",
      "           -2.8238],\n",
      "         [ 26.6004,  11.5117,  27.7785, -12.7890, -12.2493, -25.9629,  22.7535,\n",
      "           -6.0467],\n",
      "         [ -7.0626,   1.4729, -22.7980, -22.2454,  29.4202,  14.0167,  13.7140,\n",
      "           16.4178],\n",
      "         [  4.4691, -15.8589,  52.7668, -20.3115, -15.6691,  16.5638,  27.8460,\n",
      "           41.7163],\n",
      "         [ 17.4510, -26.4926, -29.5023,  -1.5781,  30.8203, -18.5753, -17.8495,\n",
      "          -19.1811]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.2062, -0.5172, -0.0819,  ..., -0.2665, -0.1962,  0.6930],\n",
      "        [-0.2450,  0.7976, -0.4234,  ...,  0.3097,  0.3689, -0.3815],\n",
      "        [-0.0769,  0.1597,  0.2945,  ..., -0.2647,  0.5933, -0.3047],\n",
      "        ...,\n",
      "        [-0.0886,  0.4770, -0.1571,  ..., -0.0067, -0.4958,  0.2027],\n",
      "        [-0.0946, -0.0952,  0.2018,  ..., -0.0797, -0.6399,  0.1117],\n",
      "        [ 0.3943,  0.0523, -0.7269,  ..., -0.0609,  0.4078, -0.6869]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[-12.8712, -24.1805, -17.5475, -20.2988,  -3.7700, -16.2545,  -8.3035,\n",
      "           10.1185],\n",
      "         [ -5.5456, -40.5859,  30.9133, -23.3367,  10.8697,   6.1551,  30.2505,\n",
      "            6.1499],\n",
      "         [  2.4172,  22.6611,   7.6695,  17.5117, -21.3996,  17.5314,   1.9464,\n",
      "           16.2804],\n",
      "         [ 24.9520,   0.7749,  -4.5279,  35.1476,  -0.2612,  -3.2695,  24.7140,\n",
      "          -12.0259],\n",
      "         [ 13.6654,  35.3625, -12.4793,   0.2692, -35.0025,  27.6379,  -3.9529,\n",
      "           -9.9446],\n",
      "         [ -9.4863, -20.3326,  25.6686, -33.4944,   5.5838,  19.5050,  17.8676,\n",
      "          -12.1867],\n",
      "         [ 44.0251, -24.3737,  -6.6812, -29.8617, -10.2990, -15.4708, -22.3062,\n",
      "            9.5654],\n",
      "         [ -0.3491, -10.2288,  16.7296, -15.0865,  -5.8056, -13.7012, -51.1333,\n",
      "            3.2809],\n",
      "         [ 12.8022,  13.8443,  28.7942,  16.8534,  17.4850,   2.0312,   3.9828,\n",
      "           24.0191],\n",
      "         [-20.2462,   3.2122,  21.4682,  32.9874, -27.4646,  -1.6169,  -7.6650,\n",
      "          -18.4757],\n",
      "         [-17.5841,  42.9770,  24.4824, -38.2389,  27.1399,  24.7362, -11.7815,\n",
      "           13.9800],\n",
      "         [-16.1199,  30.3208,  26.2534,  12.5760,   0.4172, -24.5093,  14.5393,\n",
      "           15.6453],\n",
      "         [-29.5810,  27.9681, -23.8715, -29.3208,   1.9058,  28.4166, -29.5518,\n",
      "           27.5183],\n",
      "         [-27.3588,  11.0787, -22.8263,  -8.9557, -11.2136, -11.0325,  22.2713,\n",
      "           -3.7442]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.6068, -0.0441, -0.0222,  ..., -0.1887,  0.1913, -0.2708],\n",
      "        [-0.3376, -0.2995, -0.3985,  ...,  0.2067, -0.4103, -0.1067],\n",
      "        [-0.2648, -0.0032, -0.7237,  ...,  0.1467,  0.3832, -0.0313],\n",
      "        ...,\n",
      "        [ 0.4370, -0.1232,  0.4923,  ..., -0.6168, -0.0441,  0.2618],\n",
      "        [-0.0384, -0.0360,  0.4656,  ..., -0.1720,  0.1719,  0.0930],\n",
      "        [ 0.0768, -0.1674,  0.0282,  ...,  0.3818,  0.1351,  0.3670]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[-2.7800e+00, -1.1421e+01,  2.8872e+01,  1.3249e+01,  1.5947e+01,\n",
      "           2.2562e+00, -3.2005e+00, -1.5362e+01],\n",
      "         [-1.8111e+01, -2.1037e+01, -1.1092e+00,  5.9828e+00,  3.3155e+00,\n",
      "          -3.4503e+00,  5.7783e-01,  3.2592e+00],\n",
      "         [ 1.2227e+00, -1.7559e+01, -2.6404e+00,  7.6844e+00, -3.1342e+00,\n",
      "          -1.8027e-02,  1.3580e+01, -1.4764e+01],\n",
      "         [-1.4575e+01,  1.4248e+01,  1.1436e+01,  8.1508e+00, -4.2184e+00,\n",
      "          -1.0518e+01, -5.5698e+00, -2.0301e+00],\n",
      "         [-2.5824e+00, -2.2398e+00,  8.9607e+00, -4.2934e+00, -1.4339e+00,\n",
      "          -1.0327e+01,  2.4165e+01,  4.3195e+00],\n",
      "         [ 1.8187e+01,  7.2725e+00, -8.7662e+00,  8.6331e+00, -1.1748e+01,\n",
      "          -8.8161e+00,  1.2777e+01,  5.4958e+00],\n",
      "         [ 1.0631e+01, -1.2223e+01, -2.2643e+00,  1.6666e+01, -7.4671e+00,\n",
      "           5.2399e+00, -1.1584e+01, -6.4094e+00],\n",
      "         [ 7.9580e+00, -2.5727e+00,  1.2704e+01, -1.0747e+01,  1.1879e+00,\n",
      "           4.9789e+00, -9.0377e+00, -1.1571e+01],\n",
      "         [-2.1009e+01,  8.0696e+00, -1.4090e+01, -4.1771e+00, -9.8575e+00,\n",
      "           2.9975e+00, -2.4379e+01,  5.8506e-01],\n",
      "         [-1.0181e+01, -5.3164e+00, -2.9169e+01, -1.0176e+01,  8.7777e-01,\n",
      "           2.0307e+01,  1.3341e+01,  1.2004e+01],\n",
      "         [ 1.5604e+01, -1.6090e+01, -1.3871e+00, -2.1791e+00,  2.5161e+00,\n",
      "           2.3788e+01,  8.6506e-01, -1.0349e+01],\n",
      "         [-2.3949e+00, -7.0193e+00,  7.5900e+00, -2.6555e+00,  9.7214e+00,\n",
      "           2.3351e+00,  2.0814e+00, -1.2499e+01],\n",
      "         [ 1.1595e+00,  1.8970e+01, -9.1811e+00, -1.4129e+00, -1.4166e+01,\n",
      "          -8.7926e+00, -5.2472e+00, -1.3929e+01],\n",
      "         [-3.5165e+00, -8.7288e+00,  4.6441e+00, -7.9812e+00,  6.9836e+00,\n",
      "          -3.6025e+00, -9.6044e+00,  1.2505e+00]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.2119, -0.1232,  0.1916,  ...,  0.0213,  0.1828,  0.0875],\n",
      "        [ 0.2055,  0.1588, -0.3543,  ...,  0.6079, -0.3206,  0.0891],\n",
      "        [ 0.6736,  0.0634,  0.1387,  ...,  0.0626,  0.2243, -0.2066],\n",
      "        ...,\n",
      "        [-0.0651, -0.4273, -0.0709,  ...,  0.0953, -0.1409,  0.2155],\n",
      "        [ 0.1765,  0.0511,  0.3793,  ...,  0.0105,  0.0731,  0.0917],\n",
      "        [ 0.2233,  0.3136,  0.3798,  ..., -0.0523,  0.4717,  0.5366]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[  3.3045,  -1.0673,   0.2590,  16.6010,   1.7305,   9.7440,  10.4214,\n",
      "          -16.5603],\n",
      "         [-23.2264, -10.3281,   3.1081,  -3.7753, -11.2932,   7.9209, -14.1184,\n",
      "           26.5956],\n",
      "         [ -2.2303,  21.7104,  10.9620, -12.0043,  -8.0871,  -4.3521, -10.5766,\n",
      "          -28.0517],\n",
      "         [ -0.7266,   2.0201, -22.2036,  25.0363,  13.4430,  -1.2505,   5.3944,\n",
      "           12.9896],\n",
      "         [  9.2570,   8.5005,  -4.3208,  21.3440,  -2.2087,  -3.9551,  -7.0357,\n",
      "           -4.4626],\n",
      "         [ -0.7090,  26.4385,  -6.3760,  14.2655,   0.2358,  -8.7110,   2.1052,\n",
      "            5.2799],\n",
      "         [ -1.6437,  -7.2864,  14.9105,  -1.8159, -16.7077,   2.6471,   0.0602,\n",
      "           12.9281],\n",
      "         [  5.1979, -20.3849,  -0.5430,   0.8128,   6.5943,   7.9924,  -1.4370,\n",
      "           -5.9077],\n",
      "         [  2.8916, -22.1335,  12.5752,   8.3434, -16.4099,  18.0730,  13.4574,\n",
      "            1.5785],\n",
      "         [-12.2329, -18.6397,  -8.1648, -11.1995,   7.5531,  -7.6011,  -1.6276,\n",
      "           -9.6224],\n",
      "         [  0.4091,   1.3486,  -6.7268,  13.7048,   0.7294, -10.7310, -12.6599,\n",
      "            4.3354],\n",
      "         [  5.5686,  12.5391,   4.6106, -15.2285,  -9.0961,  -4.9368,  -0.1038,\n",
      "           -6.4763],\n",
      "         [  3.6935,  -7.4311,  -7.8247,  -9.5641,  -7.8122,  13.6141,  20.0037,\n",
      "           -2.5442],\n",
      "         [ -7.9946,   1.2961,  -0.1319,   2.5736,  -1.0601, -18.9345,  20.2222,\n",
      "           -1.4473]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.4966,  0.2117,  0.1932,  ..., -0.3219,  1.0571,  0.1795],\n",
      "        [-0.3797,  0.0816,  0.0280,  ...,  0.6041,  0.0538, -0.1523],\n",
      "        [ 0.3182,  0.0080, -0.0266,  ...,  0.3688,  0.5293, -0.1463],\n",
      "        ...,\n",
      "        [ 0.2081, -0.3314,  0.2676,  ..., -0.2284,  0.6162, -0.5721],\n",
      "        [-0.2861,  0.2715, -0.0275,  ...,  0.5289,  0.1457,  0.5313],\n",
      "        [ 0.3318,  0.4180, -0.2786,  ...,  0.0845, -0.3253, -0.1317]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[ 33.3922,  19.1443, -15.2196,  -7.7470, -40.6826, -12.4958, -24.9689,\n",
      "          -22.4711],\n",
      "         [ -5.7465,  32.7959,  -9.3078, -24.5617,  -7.5167,   6.0341,  48.8258,\n",
      "           -4.7504],\n",
      "         [-30.3624, -24.6027,  16.7547, -12.4203,  -5.6982,  17.6803,  10.1275,\n",
      "           15.4457],\n",
      "         [ -8.4757, -30.5556,  26.3925,   4.0337,  -3.6675, -51.2319, -25.7387,\n",
      "          -11.6953],\n",
      "         [-22.1984,  -2.1044, -42.0648,  -7.6480,  17.2671, -16.5840,  23.1751,\n",
      "          -20.4990],\n",
      "         [-52.6881,  10.3621,   0.6227,   0.9557,  -3.3140, -17.1229, -22.3141,\n",
      "           12.8959],\n",
      "         [  0.4510,   3.4069,  19.1680, -25.7966,  23.3925,   4.4728,  27.6775,\n",
      "            7.6812],\n",
      "         [ 13.1188,  13.2202,  38.5094,  20.5348, -31.0152, -24.7082, -35.0793,\n",
      "           -1.6287],\n",
      "         [ 10.2173, -17.7208, -37.5067, -18.9335, -22.0363, -30.2146,  63.7568,\n",
      "           22.3756],\n",
      "         [ 41.0262, -17.4628,  14.4443, -16.0222,  26.3595, -26.8639,  -6.4762,\n",
      "           13.6249],\n",
      "         [ 41.3582,   3.1676,  41.4898,  -3.2631,   7.3960,  29.5973,  -0.9914,\n",
      "           -3.1403],\n",
      "         [-25.9561, -24.9711, -25.8574,  -4.0652,  15.3360, -21.9976, -12.5627,\n",
      "            5.3175],\n",
      "         [ 29.2985,  15.8767,  26.3190,  53.3628, -26.0511,   6.0759,  -3.8129,\n",
      "          -12.4130],\n",
      "         [ -2.0826,  -4.0800,  -5.8312,   7.1948, -13.8488, -11.5573,  20.6257,\n",
      "            2.0038]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[-0.0443,  0.4711, -0.1343,  ...,  0.4743,  0.0153, -0.0866],\n",
      "        [-0.1746,  0.0359, -0.9822,  ...,  0.1376,  0.7029, -0.0467],\n",
      "        [-0.2059, -0.0240,  0.2190,  ..., -0.1392, -0.1776, -0.5616],\n",
      "        ...,\n",
      "        [-0.2297,  0.3616, -0.1509,  ...,  0.1031, -0.2896, -0.8416],\n",
      "        [-0.2761,  0.0070,  0.0968,  ..., -0.1425,  0.0315,  0.3273],\n",
      "        [ 0.4508, -0.0971, -0.0777,  ..., -0.1674,  0.0125,  0.1717]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[  44.4713,   25.7143,    0.9055,  -27.8378,   46.6729,  -17.7672,\n",
      "            -4.2947,   90.8141],\n",
      "         [  13.1198,  -46.2160,    5.1455,   13.9783,    0.1842,   29.8023,\n",
      "           -40.4771,   50.8998],\n",
      "         [ -12.8604,  -23.8126,   88.1965,    9.1968,    8.6748,   44.7920,\n",
      "           -20.3495,   33.5079],\n",
      "         [-109.6847,  -59.9522,   64.1474,   72.1181, -100.6905,  -21.5599,\n",
      "           -52.5329,  -23.3954],\n",
      "         [ -35.8254,   11.4282,   35.4867,  -19.1044,   99.6870,   48.0328,\n",
      "            61.4810,   28.2213],\n",
      "         [ -19.6805,   74.6618,   23.6689,   28.9035,   25.3781,   70.2051,\n",
      "            -4.0086,   10.9822],\n",
      "         [ -24.1686,  -35.9250,  -37.0668,    5.8308,  -16.2589,   60.7816,\n",
      "           126.0353,   44.3674],\n",
      "         [  51.9231,   21.5601,   61.0288,  -32.4004,   51.4183,   17.7780,\n",
      "            -1.9694,  -55.8827],\n",
      "         [  -9.8515,  -42.4530,   -7.8261,  -54.5657,   14.6192,   64.7158,\n",
      "           -61.6039,    3.0029],\n",
      "         [  43.7816,   29.2636,  -30.8620,  -16.7985,   27.0773,  -14.5796,\n",
      "            12.1571,  -16.2749],\n",
      "         [ -21.2940,   11.3927,   15.0080,   -2.6443, -130.4085,   13.8055,\n",
      "             0.7164,   11.4254],\n",
      "         [ -80.3021,  -27.3782,   13.6222,   33.1969,  122.7502,   44.5151,\n",
      "          -134.5047,   17.5875],\n",
      "         [ -59.4262,   30.6995,   67.1989,  -50.1554,   -9.5422,   62.8080,\n",
      "            26.5736,   27.7384],\n",
      "         [ -13.9940,    8.3989,   24.8559,  -28.3947,   19.3479,   64.9041,\n",
      "            29.7508,  -11.6626]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.9675,  0.0650, -0.1885,  ..., -0.0386,  0.2851, -0.0923],\n",
      "        [ 0.3432,  0.0786, -0.0433,  ...,  0.1795, -0.3163,  0.0387],\n",
      "        [-0.5349, -0.4047, -0.5951,  ..., -0.0303,  0.5920, -0.2025],\n",
      "        ...,\n",
      "        [-0.4778,  0.2641,  0.1813,  ..., -0.3026, -0.2342, -0.1069],\n",
      "        [-0.0861, -0.2613, -0.2380,  ..., -0.1173, -0.3086, -0.4627],\n",
      "        [-0.3615,  0.4315,  0.3907,  ..., -0.0126,  0.7499, -0.6935]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[ -62.1321,   48.4953,   31.3571,    6.3272,   -4.9906,  -56.7615,\n",
      "             6.6753,   42.7634],\n",
      "         [ -43.0087,   69.3376,    8.5474,  -39.2751,  -42.8495,    9.7722,\n",
      "            31.1912,   49.4338],\n",
      "         [ -35.2141,   33.5848,   -7.2968,   38.8050,  -66.6137,   45.2594,\n",
      "            -3.0850,   35.5943],\n",
      "         [   4.2334,   -8.2446,   26.7054,   98.8919,   78.4434,   11.3262,\n",
      "            36.4629,   10.7151],\n",
      "         [ -13.0275,  -30.9845,   19.6171,   45.9265,  -33.1750,    9.9510,\n",
      "            19.0831,   37.5294],\n",
      "         [  14.6413,   59.4773,   21.5274,   -3.2620,    4.9593,   76.9765,\n",
      "            40.9601,  -24.3760],\n",
      "         [ -30.7083,   24.6903,    7.1399,   72.7483,   74.0355,    5.9905,\n",
      "           -38.0181,   94.5356],\n",
      "         [ -48.2546,  -39.4630,   34.9110,   52.0579,  -12.7052,  -12.7474,\n",
      "            18.9243,   58.9061],\n",
      "         [  35.2096,  -37.1973,   -3.1403,  -80.6787,   19.2318,   48.0880,\n",
      "             6.8050,  -49.7478],\n",
      "         [  21.2378,   54.6999,  -58.6109, -117.8178,  -15.9384,  -35.3619,\n",
      "            40.4535,  -63.3068],\n",
      "         [  54.8317,  -27.7248,   -0.9792,   69.6638,  -43.6792,  -77.8827,\n",
      "            52.1989,   -6.2501],\n",
      "         [ -22.1979,    3.5081,   -2.4685,  -42.0514,   43.0214,  -21.2156,\n",
      "            45.8373,    0.4983],\n",
      "         [ -56.4206,   -2.0419,  -47.7395,  -18.4669,   69.8036,   -1.2149,\n",
      "            -7.3813,   98.8430],\n",
      "         [  -7.1982,   24.1508,  -30.3414,  -69.9428,   34.2330,    5.6698,\n",
      "            46.9771,  -41.8413]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=14336, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[-0.2655, -0.0474, -0.1147,  ..., -0.0636, -0.2339, -0.2729],\n",
      "        [ 0.6762,  0.1026, -0.3735,  ...,  0.0678,  0.2274, -0.2556],\n",
      "        [ 0.5609,  0.2463, -0.1210,  ..., -0.5112, -0.7975,  0.1426],\n",
      "        ...,\n",
      "        [ 0.1697,  0.3606, -0.1284,  ...,  0.1841, -0.6694,  0.2597],\n",
      "        [ 0.4808, -0.0257, -0.2392,  ..., -0.5951,  0.0123,  0.2847],\n",
      "        [ 0.1594, -0.3421,  0.4338,  ..., -0.2111, -0.1984, -0.0775]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[ 16.2859,   7.4380,  55.1837,  11.9454,  12.6304, -31.4053,  19.1824,\n",
      "            4.9673],\n",
      "         [  4.2239,  -6.5024, -15.5178, -39.3041,  -6.5241, -25.8683,  23.1440,\n",
      "          -15.1768],\n",
      "         [-50.8918,  14.3796,   3.7949, -29.9006,  16.6895,  -5.2215,  23.7016,\n",
      "           18.2195],\n",
      "         [-33.4428,   5.5935,  14.4041,  31.7283,   4.4767,   3.7273,  12.7173,\n",
      "           -8.0906],\n",
      "         [ 26.2258,  38.2575,  -0.5751,  12.7566,   5.1360,  -9.5023, -15.3310,\n",
      "           30.6634],\n",
      "         [ -9.7364,  32.9488,  10.4838,  -4.4717, -29.7265,  14.7089, -20.5218,\n",
      "           16.3211],\n",
      "         [ 34.9055,  24.5237, -66.7683,  26.7528, -14.0798,  51.5268,  15.4341,\n",
      "          -16.7128],\n",
      "         [-11.8635,  26.8599,  17.0096, -29.8678, -36.9965,  16.6093,  -7.2878,\n",
      "           26.1510],\n",
      "         [  0.6892,  23.1584,  -2.8568,   1.8819, -16.2971,  18.3837, -16.7601,\n",
      "          -26.5569],\n",
      "         [-23.3837,   2.0302, -22.9050,  19.7693,   9.6094, -59.5780,  18.2590,\n",
      "          -14.6705],\n",
      "         [ 46.0108,  -2.2773,  26.7519,  12.9757, -13.0041,  -3.4298,  40.3261,\n",
      "          -20.0973],\n",
      "         [ -6.4690,  42.1759,  20.1197,  -6.9636,   1.3329, -20.4661,  -3.3218,\n",
      "           12.8077],\n",
      "         [ 10.8410, -27.1845,  26.4523,  -2.9617,  -7.0876, -15.3872, -15.1021,\n",
      "           32.9306],\n",
      "         [  2.1321,  -4.5124,  11.1050,  -8.7206,  27.1412,  21.4762,  20.7104,\n",
      "            4.4416]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.0186, -0.1328,  0.3636,  ..., -0.1184,  0.4823,  0.0073],\n",
      "        [-0.2076,  0.2861, -0.3527,  ...,  0.1344, -0.5941, -0.2029],\n",
      "        [ 0.0627,  0.0637,  0.2443,  ..., -0.4574, -0.3057,  0.7353],\n",
      "        ...,\n",
      "        [-0.0246,  0.6552, -0.3512,  ..., -0.2152,  0.2475, -0.0261],\n",
      "        [ 0.0852, -0.5982, -0.0246,  ...,  0.2729, -0.1475, -0.2166],\n",
      "        [-0.4064, -0.4608, -0.2328,  ...,  0.2737,  0.1072,  0.5719]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[ -2.8274, -13.6416, -20.9872, -21.7358,  -7.0869, -21.6581,  -1.3272,\n",
      "          -11.2822],\n",
      "         [  7.3340,  36.2792,  15.2760,  -9.2112, -28.1118, -19.7285,   7.6988,\n",
      "           -8.4964],\n",
      "         [-12.4266, -33.2593,  62.7282,   7.2006,  17.4769,   5.8796,  -7.1002,\n",
      "            8.6569],\n",
      "         [ 22.6721, -22.5577, -12.9218,   0.9976,   8.5637, -30.9417,   6.2796,\n",
      "          -23.7153],\n",
      "         [ 46.8410, -29.9037, -33.2240,  28.1350,  30.3713, -44.5438,  19.1705,\n",
      "          -13.8157],\n",
      "         [  0.9040,  34.6716,  -9.6366,  -8.5289,  -6.2732,   6.3235,  29.1106,\n",
      "          -23.8513],\n",
      "         [ 27.5125,   7.4978,  -3.1563, -17.8682, -29.6769,  18.7191,  -2.5578,\n",
      "           21.2563],\n",
      "         [-46.9529,   0.4028,  20.9398,   7.1188, -16.2997,  15.2918,  -3.3231,\n",
      "          -14.4757],\n",
      "         [  4.4259,   4.2906,   5.1164,  -9.6462,  18.2406, -18.3006,  13.3494,\n",
      "           22.1343],\n",
      "         [-36.6578,   0.6855, -10.6242,   9.1361,  -7.8255,  38.2962, -34.6306,\n",
      "           11.0506],\n",
      "         [-30.2505,  31.9627, -29.0275,   7.7098,  -2.6553, -11.9060,  -0.3897,\n",
      "           -5.3008],\n",
      "         [-11.9919, -26.3148,   0.9467,  26.1931,  -6.6506,  56.2056,  12.6888,\n",
      "          -16.7714],\n",
      "         [ 34.4412,  21.8611, -13.9322,  28.3678,  -5.0495,  12.4626, -31.1543,\n",
      "          -12.8873],\n",
      "         [ 23.4319, -34.0117,  -1.0563, -15.5450,  -3.9190,  18.7956,  10.0115,\n",
      "          -10.5177]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.2048, -0.1954, -0.5693,  ..., -0.0774,  0.0984, -0.6302],\n",
      "        [ 0.3633,  0.1989, -0.3957,  ..., -0.1016, -0.0317,  0.2331],\n",
      "        [-0.9205, -0.5899, -0.1134,  ..., -0.0178, -0.5603,  0.6730],\n",
      "        ...,\n",
      "        [ 0.0597, -0.3092,  0.2994,  ..., -0.5871, -0.3799, -0.2325],\n",
      "        [ 0.8830, -0.2355,  0.3822,  ..., -0.2002,  0.1905, -0.2076],\n",
      "        [-0.3883,  0.2003, -0.2316,  ..., -0.7804, -0.0453, -0.0540]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[-8.9327e+00,  5.2675e+00,  1.2070e+01,  1.7426e+01, -6.1875e+00,\n",
      "          -6.3294e-01, -9.5923e+00, -9.6251e+00],\n",
      "         [ 6.9737e+00, -5.0655e+00, -9.7111e+00,  1.2710e+00, -1.5637e+01,\n",
      "           1.7102e+01,  2.0975e+00,  7.2058e+00],\n",
      "         [ 1.3937e+01, -9.3767e+00,  6.3631e+00, -1.0400e+01, -4.5066e+00,\n",
      "           1.7244e+01,  6.3049e+00,  7.5737e+00],\n",
      "         [-8.9213e+00, -3.2556e+00,  1.3702e+00, -1.1638e+01,  3.0155e+00,\n",
      "           1.4773e+01,  1.2817e+00,  2.3194e+00],\n",
      "         [ 1.4148e+00, -1.9569e+00, -1.0059e+01, -3.3740e-01, -1.0565e+01,\n",
      "          -1.2601e+01, -2.7648e+01,  6.2201e+00],\n",
      "         [ 1.2605e+01,  7.7483e+00, -3.1360e+00, -9.1931e+00, -1.5340e+01,\n",
      "          -3.0667e+00,  5.8716e-01, -1.8676e+01],\n",
      "         [-6.6641e-01,  6.1163e+00,  1.5712e+01, -2.5262e+01,  1.0123e+01,\n",
      "          -6.6968e+00,  5.4155e+00,  2.3320e-02],\n",
      "         [-1.6134e+01,  9.6970e+00, -4.2720e+00,  1.4658e+01,  3.9094e+00,\n",
      "           1.4772e+01,  2.6806e+01,  6.5073e+00],\n",
      "         [-3.2299e+00,  5.2000e+00,  6.7176e+00,  1.2047e+01,  2.6651e+01,\n",
      "           1.4384e+01, -1.1855e+01,  7.5535e-01],\n",
      "         [ 8.3814e+00, -1.6709e+00,  7.9489e+00,  2.4548e+01, -1.6327e+01,\n",
      "          -1.6387e+01,  9.7724e+00, -6.7937e+00],\n",
      "         [ 4.9975e+00,  5.6556e+00, -9.7277e+00,  7.5123e+00, -1.2288e+01,\n",
      "           1.3768e+01,  2.7090e+00,  5.5878e+00],\n",
      "         [ 1.3975e+01, -9.5547e+00,  2.4089e+01,  2.0522e+01,  1.1974e+01,\n",
      "           8.1006e+00, -4.9970e+00,  1.7818e+01],\n",
      "         [ 5.7167e+00,  3.9812e+00,  7.4281e+00, -1.0647e+01, -4.2444e+00,\n",
      "          -7.7425e+00,  1.9284e+01, -6.3632e+00],\n",
      "         [ 9.9621e+00, -8.7970e+00,  1.7622e+01,  5.8254e+00,  1.2852e+01,\n",
      "           1.2946e+01, -2.2306e+01, -6.1194e+00]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.0167,  0.1302,  0.5039,  ...,  0.4451, -0.0555, -0.3179],\n",
      "        [ 0.8897,  0.0875,  0.1310,  ...,  0.5861,  0.2410,  0.6236],\n",
      "        [ 0.3417, -0.1242,  0.2117,  ..., -0.3362, -0.2219, -0.0502],\n",
      "        ...,\n",
      "        [-0.3551, -0.0687,  0.2590,  ...,  0.1819,  0.0815, -0.1646],\n",
      "        [ 0.4822, -0.5256, -0.5589,  ..., -0.0960,  0.0459,  0.0098],\n",
      "        [ 0.7352, -0.2709, -0.0675,  ..., -0.3622,  0.2083, -0.0978]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[ 11.3873,  25.8867,   5.0009,   7.1955,   6.3584,  -3.1284, -22.4141,\n",
      "            6.4498],\n",
      "         [ 16.2287, -35.6327,   5.7275,  15.6552,  15.5075,  -0.9554,  21.8696,\n",
      "            2.3618],\n",
      "         [ 17.3842,   0.3338,  -2.7895,  -1.8938, -13.2421, -18.5138,   8.8439,\n",
      "            6.1523],\n",
      "         [ -8.5893,   5.7910,  16.3002,  -6.2513, -17.3883,  -6.2390,   6.3695,\n",
      "           -4.8057],\n",
      "         [ -8.4286,   9.2775,   7.8247,  25.3866, -25.9917,  -8.2099,  21.2031,\n",
      "            6.0895],\n",
      "         [  6.8186,  -2.5866,   4.8294, -13.3182, -10.7893,  -3.1947, -22.1066,\n",
      "           -1.8585],\n",
      "         [  2.9443,  -4.0442,  -1.8784,   8.4333,  -3.1270,  -2.8251,  19.2960,\n",
      "           -5.8154],\n",
      "         [ 10.4451, -11.6120,  14.0485,  11.0251,  -1.6462,  12.2865,  -9.7750,\n",
      "            2.8974],\n",
      "         [ -7.1455,   1.0238,   6.3461,   1.5920,   3.8649,  10.5121,   5.6955,\n",
      "            9.7993],\n",
      "         [ 12.5673,   3.1148,   6.1842, -11.3337,   0.7263,   2.7087,  26.3254,\n",
      "           21.8855],\n",
      "         [ 10.1143, -15.4960,   6.5723, -18.6404,  11.9559, -26.0647,   4.5983,\n",
      "          -22.2066],\n",
      "         [-25.4000,  -3.7393,   1.0323,  -1.2705,  -4.3058,   0.8461,   7.9054,\n",
      "            2.3908],\n",
      "         [  7.9742,  10.7198,   8.5405,  -4.3911, -12.8506,   2.1109,   6.8417,\n",
      "           -6.4259],\n",
      "         [ 39.5540, -17.6119,  -0.6061, -18.5593, -23.8706,   0.4023,   5.8234,\n",
      "            7.7854]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.4453,  0.7385,  0.0260,  ..., -0.1446,  0.2050, -0.1736],\n",
      "        [-0.1874, -0.5743,  0.4901,  ...,  0.7082, -0.3350,  0.4540],\n",
      "        [-0.3744,  0.2336,  0.4986,  ..., -0.3657, -0.5760, -0.0432],\n",
      "        ...,\n",
      "        [-0.3340, -0.0923, -0.1318,  ...,  0.3828,  0.2743,  0.0491],\n",
      "        [ 0.2504, -0.0649,  0.2581,  ...,  0.1048, -0.0454,  0.4413],\n",
      "        [-0.3131,  0.2718,  0.0819,  ..., -0.0984,  0.4784, -0.0065]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[-46.6184, -11.8666, -20.3412,   0.7701,  31.4450,  12.6959, -23.9506,\n",
      "           17.6475],\n",
      "         [  5.5771, -30.4997,  -7.0238,  32.9251, -28.7808,  -1.3177,  11.4673,\n",
      "          -10.6996],\n",
      "         [ 57.3680,  -5.7071,  15.5159, -28.1636, -39.3375, -42.1040,  26.4912,\n",
      "            4.3322],\n",
      "         [-37.3349,  10.8903,  -6.8534,   2.6989,  -6.1242,   0.9592,  -8.2236,\n",
      "           19.0805],\n",
      "         [ -8.9656,  32.2938,  52.8928,  -0.4360, -13.8391,  12.3426, -15.1537,\n",
      "            9.8418],\n",
      "         [ -7.6390,  -9.4554, -12.1935,   6.8616,   4.8175,  21.1050,  -1.8271,\n",
      "           -0.5505],\n",
      "         [ -9.3389, -62.4112,   3.0947,  10.4533, -34.9402,  14.6735,   8.2610,\n",
      "          -28.4792],\n",
      "         [ -2.3116, -17.6084, -29.4176,  15.1962,   7.7794,  -5.9179, -35.9159,\n",
      "          -40.6470],\n",
      "         [ 15.7235,  -5.2909,  10.0345,  28.1551,   5.9588,   2.8705,  22.3575,\n",
      "            3.9204],\n",
      "         [ -3.2589,  18.6782,   2.2728,  -8.1670, -12.7907,  -8.4317,  13.9389,\n",
      "          -13.1361],\n",
      "         [ -2.2403,  28.6301,  24.3966,   2.1480,  -6.1589,   6.6237, -15.0660,\n",
      "           12.1693],\n",
      "         [-19.7938,  -4.2921,  -4.4805,  10.4092,   0.0781, -18.6063,   4.5441,\n",
      "          -11.3473],\n",
      "         [-13.5260, -21.8903,  -1.8375,  20.5374,  -9.2411, -30.6641, -15.9799,\n",
      "          -17.0908],\n",
      "         [ 10.1958,  -5.9944,   8.5119, -22.7193,  -6.4688,  -4.9376,  -2.4336,\n",
      "          -27.8446]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 3.2781e-02, -1.3279e-01, -2.7949e-01,  ..., -1.0984e-01,\n",
      "         -2.6781e-01,  9.1919e-01],\n",
      "        [ 3.2225e-01,  3.6085e-01,  1.2883e-01,  ...,  1.8672e-02,\n",
      "         -4.8465e-01, -1.9040e-01],\n",
      "        [ 1.4066e-01,  1.4710e-02,  1.0164e-01,  ..., -2.3175e-01,\n",
      "         -5.8120e-01,  2.2699e-02],\n",
      "        ...,\n",
      "        [-2.1433e-01, -7.3270e-01, -9.2258e-04,  ...,  1.3186e-01,\n",
      "         -1.9861e-01,  2.5227e-01],\n",
      "        [-7.7378e-04,  4.2280e-02,  1.2675e-01,  ...,  1.4428e-02,\n",
      "          6.1296e-01,  5.3731e-01],\n",
      "        [-1.8240e-01,  3.6642e-01, -9.9241e-02,  ...,  2.3626e-01,\n",
      "          4.3145e-01,  3.8566e-01]], device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[-70.4347,  44.4531, -32.1478,  -2.2649, -14.3567,  73.7024,  44.8889,\n",
      "           53.5066],\n",
      "         [-11.2129, -45.3005, -42.5963,   4.7324, -59.1137,   2.2646,  56.1127,\n",
      "           58.4626],\n",
      "         [-23.9435, 103.5350,  11.0799,  40.8403,  69.0377,  36.0039, -12.9401,\n",
      "           82.7406],\n",
      "         [-18.3414, -38.2017, -80.1861, -22.7505,  61.3940,  13.4281,   8.3721,\n",
      "          -12.9371],\n",
      "         [ -3.7930,   2.6454,   9.0595, -29.0472,  15.3961,  -0.3846,   4.4616,\n",
      "           21.8610],\n",
      "         [-47.6744, -46.8049,  48.7985,  45.6059,  29.4772, -42.3624,  47.0463,\n",
      "          -35.3208],\n",
      "         [ 80.4784,  77.9464, -14.2552, -12.7056, -83.3275,  76.1201,  11.6035,\n",
      "          -36.6719],\n",
      "         [-16.3103,  -3.1238,  27.4260,   3.5730,  69.3797,  24.9071,  13.1443,\n",
      "          -59.5980],\n",
      "         [ 36.6975,  -4.3682,   1.0264,  35.6171, -41.9358, -12.8756, -60.0666,\n",
      "           36.8220],\n",
      "         [ -5.7452, -35.1135, -38.8098, -11.8042,  49.5565, -26.4232,  60.6950,\n",
      "           76.9638],\n",
      "         [  8.6964,  23.0200, -70.3627, -34.2262,  11.2808,  19.7179, -29.1398,\n",
      "          -35.5379],\n",
      "         [ 15.5472, -27.2402,  25.5353,  12.7657,  13.0474, 110.8082, -40.2515,\n",
      "           26.1411],\n",
      "         [-75.3460,  -1.3135,   3.6584, -51.5625, -13.8526,  -1.8664,  25.7709,\n",
      "           -9.9766],\n",
      "         [-80.5961, -21.5748, -46.9469,   7.6263, -45.1731,  27.7453,  21.0809,\n",
      "           47.9189]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.4872,  0.2751, -0.3412,  ...,  0.2029,  0.4175,  0.0906],\n",
      "        [ 0.7153,  0.0624, -0.5716,  ...,  0.2790, -0.1637,  0.2730],\n",
      "        [ 0.2105, -0.0260, -0.2588,  ...,  0.6282,  0.2586,  0.4912],\n",
      "        ...,\n",
      "        [-0.4523,  0.3169,  0.5205,  ...,  0.2466,  0.4447,  0.2756],\n",
      "        [ 0.1482, -0.1465,  0.3824,  ..., -0.0794,  0.4180,  0.0907],\n",
      "        [-0.0460, -0.0185,  0.6504,  ...,  0.2252, -0.4843,  0.5988]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[ -1.9827,  26.1227,   4.5836,   2.3387,  11.8039,  54.6747, -46.8519,\n",
      "           42.3945],\n",
      "         [ -1.7800, -69.7066,  -3.2182,  -4.7166, -60.4927,  -5.4463,  -3.2785,\n",
      "          -55.2227],\n",
      "         [-27.5468,  -8.4498,  41.4264, -45.7020, -57.5551, -26.7767, 109.3841,\n",
      "           22.4905],\n",
      "         [ 49.2154, -32.8863,   2.4870,  26.9096,  23.0720, -53.8117, -54.2268,\n",
      "            0.4136],\n",
      "         [ 47.9769,   7.8204,  14.2372,  53.7131,  24.9634,  57.1763,  43.7826,\n",
      "          -10.5406],\n",
      "         [  7.7156,  -9.8012, -76.1162,  -0.9900,  59.7251, -26.6449,  -5.8166,\n",
      "           28.6450],\n",
      "         [-17.2648, -25.8553,  28.4810,  49.8349,  -0.8237, -24.6815,   9.1152,\n",
      "           96.6952],\n",
      "         [ 71.6040, -28.3604, -34.6592,   5.6071, -65.1666,  88.7116,  -4.5582,\n",
      "           -8.2380],\n",
      "         [130.6153,  78.5354, -31.1395,   5.5869, 122.5722,  26.9461,  -9.9224,\n",
      "           23.1402],\n",
      "         [ 15.3522,  46.4676,  37.8501, -50.8222, -84.4677,  -8.3566,  20.1844,\n",
      "           73.2354],\n",
      "         [ 33.1114, -20.3238, -43.2487, -47.8043, -32.3996, -33.4117, -12.4215,\n",
      "          -34.0843],\n",
      "         [-25.6575, -29.6250, -46.8418, -11.9422, -13.0076, -83.8088,  -8.8875,\n",
      "          -62.2944],\n",
      "         [-54.6126,  12.2792,  -8.1167, -42.5160, -83.4873,   4.7017,  53.5739,\n",
      "           19.9395],\n",
      "         [ 52.1783,  25.0840,  38.1703, -62.9097,   4.5144,  54.7962, -58.5933,\n",
      "           70.4723]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=14336, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.1108, -0.2274, -0.2534,  ..., -0.3909, -0.0870, -0.1382],\n",
      "        [ 0.4708, -0.2582,  0.4852,  ..., -0.3123,  0.7333,  0.5732],\n",
      "        [ 0.2107, -0.3115,  0.3013,  ...,  0.4940, -0.4784, -0.0611],\n",
      "        ...,\n",
      "        [ 0.3759, -0.1437, -0.7527,  ..., -0.1442,  0.8619,  0.6761],\n",
      "        [-0.3008,  0.0731,  0.1996,  ...,  0.0201,  0.8794, -0.4717],\n",
      "        [-0.5977, -0.1393, -0.1650,  ...,  0.7844,  0.1323, -0.1638]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[-4.0997e-01,  3.7699e+01, -1.5844e+01, -3.3169e+00, -2.4097e+01,\n",
      "          -1.2073e+01,  1.3431e+01,  1.1229e-01],\n",
      "         [-2.5031e+00,  5.4591e+00, -1.4637e+01,  2.5965e+01,  9.8477e+00,\n",
      "           1.7121e+01, -1.5407e+01,  1.6199e+01],\n",
      "         [ 1.1464e+01,  3.4817e+01,  1.5568e+01, -1.8075e+01, -1.8812e+01,\n",
      "          -1.4295e+01,  3.5314e+01, -1.9029e+01],\n",
      "         [-2.5462e+01,  1.0936e+01,  1.6441e+01, -4.4203e+01, -6.9287e+00,\n",
      "          -9.5750e+00, -2.9228e+00, -1.0335e+01],\n",
      "         [ 9.9749e+00, -6.9801e-01, -3.2394e+01, -1.6358e+01,  3.7402e+01,\n",
      "           4.9406e+01, -3.5197e+01,  1.9898e+01],\n",
      "         [ 2.4660e+01,  8.7574e+00,  1.2305e+01, -1.5238e+01,  5.3128e+00,\n",
      "           3.1828e+00, -2.2320e+01, -1.5978e+01],\n",
      "         [-1.3598e+00,  2.2744e+01, -4.0492e+01, -2.1725e+01,  2.8524e+01,\n",
      "           8.6664e+00, -1.2573e+01,  6.9846e+00],\n",
      "         [ 3.9626e-03,  4.0458e+00,  4.2747e+01, -5.8755e+01, -6.9315e+00,\n",
      "          -1.6873e+01,  1.4827e+01,  1.9692e+01],\n",
      "         [ 3.7836e+01,  2.7397e+01, -6.4237e+00, -9.9818e+00, -8.4254e-01,\n",
      "           4.0955e+01,  1.9603e+01, -1.8476e+01],\n",
      "         [ 3.2913e+01, -1.3598e+01,  3.3294e+01, -9.9678e+00,  4.5496e+01,\n",
      "          -2.5700e+01, -8.0560e+00,  3.0991e+01],\n",
      "         [-4.0074e+01, -2.6204e+01, -4.0181e+01, -3.5899e+00,  1.4044e+01,\n",
      "           8.2394e+00,  3.4563e+01,  2.8833e+01],\n",
      "         [ 1.7155e+00,  5.3941e+00, -2.8800e+01,  6.0128e+01,  1.3389e+01,\n",
      "          -1.2411e+01, -4.1647e+00, -2.4391e+01],\n",
      "         [-4.0494e+01,  2.6725e+01, -1.5996e+01, -3.7190e+01, -2.9658e+01,\n",
      "          -1.4110e+01,  1.6027e+01, -9.3072e+00],\n",
      "         [ 8.2585e+00, -8.3937e+00,  2.6645e+01, -1.1546e+01,  3.0529e+01,\n",
      "          -5.6597e-01,  1.5456e+00,  5.9213e-01]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[-5.7947e-01, -1.2126e-01,  3.1367e-02,  ..., -6.7303e-01,\n",
      "         -6.4920e-03,  4.4218e-01],\n",
      "        [ 1.5684e-04,  3.2310e-01, -2.3910e-01,  ..., -7.3255e-02,\n",
      "          2.8150e-01,  1.0080e-01],\n",
      "        [ 2.5794e-01, -3.1593e-01, -2.3481e-01,  ..., -4.8199e-01,\n",
      "          1.1996e-01,  4.6411e-02],\n",
      "        ...,\n",
      "        [-2.3270e-01,  3.9057e-01, -1.2375e-01,  ...,  6.4429e-01,\n",
      "          4.0255e-02,  8.6126e-02],\n",
      "        [-1.2782e-01, -2.5212e-01,  1.1745e-01,  ..., -1.1860e-01,\n",
      "          3.2269e-01,  3.6815e-01],\n",
      "        [ 1.4485e-01, -1.2318e-01, -3.9168e-01,  ..., -3.0819e-01,\n",
      "          2.8021e-01, -2.7674e-01]], device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[  7.8163,   1.5031, -15.3569, -27.4503, -34.1254,   6.7095,  -0.6482,\n",
      "            6.9553],\n",
      "         [  6.9840,   5.9837,  29.2446,   8.7249,   4.5355,  -2.0442, -21.8824,\n",
      "          -36.1910],\n",
      "         [ -5.3194,  31.5938,  42.4398,  -5.7273,  27.5047, -24.8152, -51.8799,\n",
      "            4.7430],\n",
      "         [  0.0676, -36.5000,  -4.5664, -28.8745, -13.7438,   2.4770,  14.4160,\n",
      "           23.0410],\n",
      "         [ -6.1021,  34.1127,  37.8061,  12.6842,   6.7081,  26.5541,   5.1472,\n",
      "           19.7937],\n",
      "         [  3.9450, -12.6747,  -8.3477,   0.8911,  19.3574, -19.7713, -60.2683,\n",
      "          -16.3821],\n",
      "         [ 42.8058,   2.4037,  -9.0916,  30.1656,  50.2651,  44.6042, -30.4135,\n",
      "          -32.6364],\n",
      "         [-21.9258, -13.3278, -18.3037, -33.9470,  34.5515,  14.1379, -13.9845,\n",
      "          -12.3556],\n",
      "         [-32.7185, -27.3940,  19.7801,  -5.5953, -22.9519, -14.6520,  -9.3864,\n",
      "          -43.9210],\n",
      "         [ -6.4165, -34.1139,   0.9769, -20.7678, -14.4091,  -1.8027,  19.1065,\n",
      "            4.2803],\n",
      "         [ -0.2225,  31.8796,  33.0732,  -1.6991, -11.6508,   7.1250, -15.2061,\n",
      "           -7.7783],\n",
      "         [  6.1870,  17.5823, -12.6727,  -9.5269,  37.1924,   8.6848, -21.7371,\n",
      "           -0.5207],\n",
      "         [ 17.8046,  27.4544,   1.8776,   7.5678,   5.7472,  38.9311,  12.2859,\n",
      "           -0.6002],\n",
      "         [  7.0510,  14.5817,  12.0946,  28.3593, -28.3335, -12.9117,  21.0902,\n",
      "          -12.8617]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 7.2288e-02, -2.6604e-01,  2.3647e-01,  ...,  4.5754e-01,\n",
      "          4.6108e-01,  2.0117e-01],\n",
      "        [ 5.0184e-01, -5.4837e-05,  2.8961e-01,  ..., -4.4442e-01,\n",
      "          4.1535e-01,  7.4007e-01],\n",
      "        [ 2.5067e-01,  2.7702e-01,  5.5797e-01,  ...,  1.4746e-01,\n",
      "         -1.8206e-01, -1.1185e-01],\n",
      "        ...,\n",
      "        [-3.0359e-01, -4.8014e-01, -4.9987e-01,  ..., -3.5921e-01,\n",
      "          3.3583e-02,  9.0332e-01],\n",
      "        [-1.0420e+00,  4.4977e-01,  3.1919e-02,  ..., -1.0937e-01,\n",
      "          3.8211e-01,  3.9089e-01],\n",
      "        [-2.6680e-01,  1.3868e-01, -9.1740e-02,  ..., -5.9409e-02,\n",
      "         -2.4626e-01,  9.6445e-02]], device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[ 1.7924e+01,  1.0157e+01,  4.3263e+00,  7.1342e+00,  1.1940e+01,\n",
      "           5.2065e-01, -2.1395e+00, -3.2263e+00],\n",
      "         [-5.9336e+00,  4.2523e+00,  9.8285e+00,  8.2722e-01, -2.5560e+00,\n",
      "          -1.5928e+01,  2.3413e+00, -1.2378e+00],\n",
      "         [ 6.8130e+00, -4.2270e+00,  2.6818e+01, -1.9814e+00, -1.0060e+01,\n",
      "           2.1298e+01,  7.0614e+00, -6.0505e+00],\n",
      "         [ 1.5693e+01,  1.0899e+01, -1.9085e+01, -1.4906e+00, -1.6896e+01,\n",
      "          -2.8975e+00,  8.1199e+00,  7.7799e+00],\n",
      "         [-6.8676e+00, -3.5228e+00,  1.5986e-01,  7.1458e+00, -3.5590e+00,\n",
      "          -9.9569e+00,  8.6767e+00, -1.0791e+01],\n",
      "         [-4.9319e+00,  1.4020e+01, -3.6234e-01,  1.2596e+01,  1.8794e+00,\n",
      "          -6.9077e+00, -9.9659e+00, -3.9634e+00],\n",
      "         [-5.6524e+00,  1.5641e+01,  2.1268e+00,  7.3115e+00,  3.5358e+00,\n",
      "          -1.7344e+01,  1.8814e+01, -1.0326e+00],\n",
      "         [-1.0092e+01, -9.6318e+00,  8.1810e+00,  8.0047e+00,  3.5988e+00,\n",
      "           1.6732e+01, -4.5994e+00, -1.0987e+01],\n",
      "         [-1.1575e+01,  8.0622e+00, -2.6372e+00,  4.2001e+00,  8.8619e+00,\n",
      "           4.6599e+00,  2.0166e+00, -1.2512e+01],\n",
      "         [ 9.2008e+00, -3.9644e+00,  1.0745e+01,  4.8306e+00, -3.5794e+00,\n",
      "           1.6457e+01,  5.3238e+00, -2.4404e+00],\n",
      "         [ 3.5228e-01, -1.7137e+00, -1.0693e+01, -2.0521e+01,  7.7092e+00,\n",
      "           1.5369e+01, -1.1806e+01, -1.8169e+01],\n",
      "         [ 2.5302e+01,  8.2596e+00,  4.2429e-01,  1.9453e-02,  7.3531e+00,\n",
      "           9.0158e-01, -1.0113e+01,  6.0778e+00],\n",
      "         [ 9.5258e+00,  4.0027e+00, -7.1915e+00,  2.6613e-02,  6.0218e+00,\n",
      "          -2.0529e+01, -2.4494e+01, -7.6478e+00],\n",
      "         [ 5.7222e+00, -8.3936e+00,  4.3172e+00, -7.5890e+00, -2.3012e+01,\n",
      "           2.1533e+01,  2.9160e+00,  5.6310e+00]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[-0.5313, -0.2117,  0.0719,  ..., -0.3027,  0.0523,  0.1424],\n",
      "        [-0.4732, -0.2389, -0.1150,  ...,  0.1168,  0.0878,  0.3926],\n",
      "        [ 0.0391, -0.1616, -0.2026,  ...,  0.2678,  0.4092, -0.0376],\n",
      "        ...,\n",
      "        [-0.0799,  0.0728,  0.3513,  ..., -0.1695,  0.6593,  0.1211],\n",
      "        [-0.2131,  0.0721,  0.3102,  ...,  0.2068, -0.2814,  0.1349],\n",
      "        [ 0.3365, -0.1632, -0.4754,  ...,  0.0920,  0.1050,  0.1850]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[ -5.3248,  -4.7617,   5.1664,  -1.2995,   0.1705,   3.1891, -16.9525,\n",
      "            9.3819],\n",
      "         [  9.8389, -16.8494,  17.0044,  -0.1477,  -9.4590, -12.1009,   9.7880,\n",
      "            7.2532],\n",
      "         [ -0.2094,  -5.1003,  13.5786,  -0.6256,  -2.7721,  19.4141,  -9.0489,\n",
      "            3.4071],\n",
      "         [ -7.0970, -12.1939, -22.2295,   0.8084,  -3.6189,  -5.5857,   4.1763,\n",
      "          -17.5924],\n",
      "         [ 11.1418, -10.2394,  -9.9419,   8.6729,   8.6590,  -5.9916, -18.6050,\n",
      "           24.0922],\n",
      "         [  7.6521,  18.7829, -11.8637, -15.3357,   7.2700,  20.6995,  16.5401,\n",
      "            1.3408],\n",
      "         [ -4.3968, -14.3046,   1.7895,   0.9909,   5.0707,  -1.2084, -11.3387,\n",
      "          -30.6683],\n",
      "         [ -6.4690,  18.4599,  13.9226,  -8.1101,  14.1468,   7.8160, -23.6966,\n",
      "           29.2310],\n",
      "         [-11.7822, -12.7302,  -3.2803,   8.8357,  10.5227,   3.9022,   9.5552,\n",
      "           -7.7296],\n",
      "         [-22.2932,  17.1509,  12.0999,   4.1758,  -4.5642,   1.4103,  30.6947,\n",
      "           -9.4001],\n",
      "         [ -6.7256,   2.9533, -22.3477,   0.3368, -15.0003,   8.0437,  21.1969,\n",
      "          -10.2272],\n",
      "         [-14.2719,   6.7230,  -9.6397,  -1.8526,   4.0569,   3.9854,  -7.1545,\n",
      "           -0.5343],\n",
      "         [-10.4256, -12.7110,  19.6971,   4.1912,  -6.2259,  13.6752,  -6.3260,\n",
      "           -1.9837],\n",
      "         [  6.5722,  -0.1635, -11.9279,  19.0995,   6.1610,  -1.8396, -11.7524,\n",
      "          -18.6405]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.1303, -0.4844,  0.5146,  ...,  0.0963, -0.0752, -0.4738],\n",
      "        [-0.1051,  0.4275, -0.1100,  ..., -0.2546, -0.2015,  0.0661],\n",
      "        [ 0.4001,  0.0236, -0.0921,  ..., -0.0342,  0.2105,  0.1145],\n",
      "        ...,\n",
      "        [-0.1009,  0.3720, -0.1044,  ...,  0.2852,  0.2610,  0.1402],\n",
      "        [-0.1153,  0.1952,  0.1938,  ..., -0.0945, -0.0500,  0.2937],\n",
      "        [ 0.0305,  0.3124,  0.2297,  ...,  0.0057,  0.1101, -0.2335]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[-2.3009e+01, -2.3212e+01, -3.8930e+01, -1.0288e+01, -1.4301e+01,\n",
      "           3.2105e+01, -4.3332e+01,  1.2368e+01],\n",
      "         [ 4.3044e+01,  6.1008e-02, -1.1700e+01,  5.4419e+00, -2.7006e+00,\n",
      "           9.7001e+00, -2.9817e+01, -3.7569e+01],\n",
      "         [ 2.0349e+01, -6.2649e+00, -3.4522e+00,  9.0474e+00,  2.8063e+01,\n",
      "           4.4882e-02,  7.3704e+01,  7.8420e+00],\n",
      "         [ 2.6044e+01, -4.0626e+01,  6.7234e+00, -1.3942e+01,  8.6473e+00,\n",
      "          -2.3777e+00, -2.7674e+01,  1.4677e+01],\n",
      "         [-2.2105e+01, -1.0590e+01, -6.5403e+01, -2.9189e+01, -6.6891e+00,\n",
      "           5.6552e+00,  3.7898e+00, -1.7909e+01],\n",
      "         [ 2.5300e+00, -2.4283e+01,  1.4645e+01,  2.2157e+01,  4.2292e+01,\n",
      "           9.2486e-01, -4.1001e-01, -1.6186e+01],\n",
      "         [-5.7030e+00,  4.1461e+00, -3.6058e+01,  1.3416e+01, -3.4919e+00,\n",
      "           5.0735e+00, -2.2955e+01, -2.5905e+01],\n",
      "         [ 3.3146e+00, -1.2167e+01, -1.2949e+01,  2.4827e+01,  9.6731e+00,\n",
      "          -6.7089e+00,  2.9423e+01, -3.5095e+00],\n",
      "         [-3.6135e+01, -1.8063e+01, -8.3676e+00,  7.1885e+00,  2.1033e+01,\n",
      "          -2.2090e-02, -1.9979e+01,  9.7742e+00],\n",
      "         [ 1.5211e+01,  2.5875e+01, -2.7004e+00, -2.9607e+01,  1.3170e+01,\n",
      "          -4.6937e+00,  5.1929e+00, -4.0142e+00],\n",
      "         [-1.2203e+01, -8.8055e+00, -1.6059e+01,  2.8686e+00, -2.2900e+01,\n",
      "          -9.7399e+00,  8.7797e+00, -9.2862e+00],\n",
      "         [-7.1401e+00, -2.3132e+00, -4.5396e+00, -2.2985e+01, -3.8228e+01,\n",
      "           3.3305e+01, -2.8816e+01, -3.1987e+01],\n",
      "         [-2.1836e+01,  2.9406e+01,  6.0999e+00,  7.7088e+00, -4.4000e+01,\n",
      "          -1.7159e+01,  2.9496e+01,  1.6065e+01],\n",
      "         [-2.5925e+01, -5.4256e+00, -2.2517e+01, -2.4934e+01,  1.5251e+01,\n",
      "          -3.1790e+01,  1.1930e+00, -2.1063e+01]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.0674, -0.0378, -0.5494,  ...,  0.2952, -0.4135,  0.0729],\n",
      "        [ 0.1176,  0.1719,  0.3030,  ..., -0.0660,  0.1779,  0.1218],\n",
      "        [ 0.0235, -0.0189,  0.4268,  ..., -0.3901,  0.6334,  0.1713],\n",
      "        ...,\n",
      "        [-0.3491,  0.0475,  0.3262,  ...,  0.4514, -0.0141,  0.2634],\n",
      "        [ 0.3023,  0.5028,  0.0488,  ...,  0.6201,  0.4424,  0.4522],\n",
      "        [-0.0862, -0.0647, -0.1553,  ..., -0.9023, -0.0119, -0.2789]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[ -40.8187, -102.3758,  -18.0049,  -34.3751,   53.1148,   -6.3461,\n",
      "           -16.4181,   -5.3915],\n",
      "         [  51.3618,   19.2177,   -3.9952,  -29.1363,  -28.3749,  -12.1379,\n",
      "            -3.1848,   13.6487],\n",
      "         [  59.7996,  -69.3803,  -17.3000,   25.5497,  -10.7048,  -48.1096,\n",
      "            31.3181,   48.8402],\n",
      "         [  79.0384,   34.7036,   75.7861,  -72.5960,  -23.6674,   19.7520,\n",
      "           -25.8665,  -10.7739],\n",
      "         [ -51.8965, -125.9250,   41.4648,    5.9191,  -34.7125,  -48.5829,\n",
      "           -55.8296, -107.6768],\n",
      "         [   4.1695,   -5.0812,  -10.8767,   23.8654,   54.6928,  -13.4888,\n",
      "           -55.0744,   -4.6195],\n",
      "         [ -68.6639,    8.1761,  -15.2629,  -47.4693,   43.8138,   38.1164,\n",
      "            22.4555,  -10.0134],\n",
      "         [ -37.2655,  -12.4039,   27.3159,   46.2832,  -95.7897,  -15.6038,\n",
      "          -104.6283,   39.0991],\n",
      "         [   2.4586,  -59.9430,   12.6581,   19.7120,  140.5266,   10.3082,\n",
      "            21.2863,  -20.5345],\n",
      "         [  43.8914,   62.2104,    2.6296,  -21.1903,  -88.5816,  -27.7161,\n",
      "            25.4598,   12.6260],\n",
      "         [  63.1264,    0.9804,   -8.9450,  -19.2111,  -19.7265,  -19.3980,\n",
      "             5.7598,  -86.7492],\n",
      "         [  -0.5124,   43.3462,    6.5868,   -4.7417,   70.2859,   87.5940,\n",
      "            43.5800,   26.2552],\n",
      "         [  16.4777,   61.8678,   15.7336,  -19.0562,   42.8872,   68.4392,\n",
      "            48.2059,  -25.0215],\n",
      "         [  13.1513,   -1.3607,  -85.9172,  -27.5788,   41.0826,   -3.5960,\n",
      "            -1.9937,  -16.3208]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[-0.0456, -0.2706, -0.4569,  ..., -0.7537,  0.5404, -0.2375],\n",
      "        [ 0.7275, -0.0596, -0.4518,  ..., -0.2036,  0.0165, -0.7209],\n",
      "        [ 0.1898, -0.1749,  0.2955,  ...,  0.1930,  0.4805, -0.7040],\n",
      "        ...,\n",
      "        [ 0.0972,  0.3572,  0.1843,  ...,  0.1285,  0.6720, -0.0127],\n",
      "        [-0.0962,  0.2409,  0.6550,  ..., -0.0106,  0.5720, -0.1718],\n",
      "        [-0.0772,  0.0027,  0.0087,  ...,  0.1741,  0.1756, -0.5381]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[ 57.6653, -63.0351,  62.3930, -46.2635,  34.9667,  22.8841,  51.4650,\n",
      "          -18.3669],\n",
      "         [-15.3677,   1.7153,  31.7117,  69.4782, -23.1736,  19.4364,  -9.4254,\n",
      "           74.7544],\n",
      "         [ 31.9697,  14.1224, -94.0872, -39.2390, -30.3314, -32.7835,  81.5897,\n",
      "            6.6220],\n",
      "         [-25.1704,  63.7892,  56.8063, -20.3557, -19.1770, -28.2576, -78.8751,\n",
      "            1.2145],\n",
      "         [ 10.5556,  26.0504, -26.8246,  39.9858, -14.8927,  -1.0192,  31.9900,\n",
      "          -32.5929],\n",
      "         [ 17.2043,  36.4102,  -3.7242, -12.6292, -96.4851,  61.1171,  41.6770,\n",
      "          -15.6894],\n",
      "         [ 55.7411,  12.3064,  97.7289,  19.1683, -14.7412,  11.3358,  21.1714,\n",
      "          -57.9815],\n",
      "         [ 48.0165, -30.5154,  31.5071, -15.7700,  21.0322, -24.5333,  15.5696,\n",
      "           -0.1688],\n",
      "         [-73.7401,  54.5516, -64.2338,  -7.6077, -13.1352,  67.8051,  25.0015,\n",
      "          -13.4576],\n",
      "         [-33.2214, -66.0816, -24.5576,  -4.9962, -71.5893,  30.7324, -18.0836,\n",
      "           11.7860],\n",
      "         [-43.8437, -48.5777, -19.6091,   2.4857,   3.7930,  55.3816,  14.1356,\n",
      "          -11.2001],\n",
      "         [  7.5273,  49.2002,  -7.5548, -19.1848, -21.0322, -64.2232, -41.8388,\n",
      "            2.2806],\n",
      "         [-47.8333,  11.1981, -17.6271,  30.5902,   9.3009,  19.0417,  17.1941,\n",
      "           23.3412],\n",
      "         [  3.4421,  42.4499, -76.0113, -28.5736, -77.5371, -32.8580,  -9.5688,\n",
      "          -16.0883]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=14336, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[-0.2378,  0.0271, -0.3725,  ...,  0.1259,  0.2553,  0.2316],\n",
      "        [-0.3093,  0.1427,  0.3100,  ..., -0.5761, -0.6581,  0.1761],\n",
      "        [ 0.4490, -0.0167,  0.5873,  ..., -0.5969, -0.2414, -0.2162],\n",
      "        ...,\n",
      "        [-0.1143, -0.0892,  0.0047,  ...,  0.2552,  0.2521, -0.0770],\n",
      "        [-0.1726, -0.0576,  0.2783,  ...,  0.6323, -0.3600,  0.5842],\n",
      "        [-0.7444,  0.2503, -0.4140,  ...,  0.2424, -0.4148,  0.1432]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[ 36.6035,  17.5290,   2.0507,  43.4231,   6.8441,   0.8102,  -1.5445,\n",
      "           14.4830],\n",
      "         [-20.6090, -27.1495,   4.1884,  -3.1716,  31.0508, -12.4217, -25.8553,\n",
      "           17.0733],\n",
      "         [ -3.2952,  44.9198,   2.3292, -21.3849,  -8.6060,  -8.7451,  23.3252,\n",
      "          -18.6070],\n",
      "         [ 39.6853,  10.3442, -26.5588,  23.1780,   8.2411,  -5.5056,   9.3234,\n",
      "            7.9426],\n",
      "         [ -9.8241,  13.6546,  -1.1566, -20.8398, -10.6546,  39.1756, -32.8150,\n",
      "           19.0943],\n",
      "         [  3.2164, -32.0560,  29.1593, -45.1953,  -9.9630,  24.5240,  19.4344,\n",
      "          -51.3463],\n",
      "         [-29.8855,   8.8997, -25.2588, -17.8952,  -9.6840,   3.6553, -12.3686,\n",
      "           22.5490],\n",
      "         [ -7.7418, -23.9276,  -4.8905, -23.3368, -13.3162, -13.4981, -35.5817,\n",
      "            8.8268],\n",
      "         [-25.0488, -19.4938,  -7.0597, -28.3814,  -7.8930,   7.2234,  10.4975,\n",
      "            2.0106],\n",
      "         [ 27.1887, -21.2908,  31.0493, -12.1725,  11.0388,   9.5949,   6.0062,\n",
      "          -17.2636],\n",
      "         [-25.7778, -14.2945,  -7.7342, -20.5789, -17.1385,  21.0867,   4.4752,\n",
      "           12.7127],\n",
      "         [ -2.9705,  -8.2258, -22.0205, -26.9455,   5.2049, -17.8046,  18.3535,\n",
      "          -26.1634],\n",
      "         [-34.1534, -33.8389,   1.4245, -29.9566, -16.5032, -19.2556, -21.2386,\n",
      "           -5.9376],\n",
      "         [ 20.9360, -17.7072,  -3.6290,  17.9235,  -0.7991,  -2.4609,  -8.2535,\n",
      "           -8.0273]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[-3.2530e-01,  8.4716e-02, -8.9655e-04,  ...,  4.6507e-02,\n",
      "         -7.6901e-02, -9.6891e-02],\n",
      "        [-3.8793e-01, -7.3150e-02, -5.7939e-01,  ...,  2.5022e-01,\n",
      "         -1.1255e+00, -1.1482e-01],\n",
      "        [-6.6655e-02,  3.2422e-01, -3.6384e-01,  ..., -2.1933e-01,\n",
      "          3.0273e-01, -4.4936e-01],\n",
      "        ...,\n",
      "        [ 2.3525e-01,  7.6718e-01,  3.2283e-03,  ...,  3.8832e-01,\n",
      "         -1.9899e-02, -4.9891e-02],\n",
      "        [-7.4769e-02,  2.7746e-01,  7.5643e-01,  ...,  9.8338e-02,\n",
      "          4.8098e-01, -4.8142e-01],\n",
      "        [-5.6098e-02, -4.7021e-01, -2.1485e-01,  ..., -1.4742e-01,\n",
      "          1.6703e-01, -4.3660e-01]], device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[ 14.4543,  12.0656,  23.1267,  -1.6384, -41.5760,  14.8747, -13.7095,\n",
      "            2.5072],\n",
      "         [ 13.0319,  15.5953,   4.7841, -15.7097,  18.5203,  12.6697,  23.9829,\n",
      "           26.0067],\n",
      "         [-14.4308,  17.6627, -10.3931,  26.9455,  24.2195,  16.9353, -14.8839,\n",
      "          -31.8576],\n",
      "         [ -9.1506,  21.9273,  35.4606,  11.2468, -51.1026,  24.4461,  -7.5914,\n",
      "           11.9730],\n",
      "         [-13.9168, -16.1803, -21.5217,   1.5095,  21.4076,  -1.3210, -22.2748,\n",
      "          -34.9489],\n",
      "         [ 52.8918,  85.8734,  -8.9824,   8.2894,  -2.2433,  -6.5206,  34.0940,\n",
      "           11.3475],\n",
      "         [  2.2331,  -2.8500,   9.7926,   3.6934,  -4.2574, -19.2376,  -1.9409,\n",
      "            4.2686],\n",
      "         [  1.7475,   9.4251,  12.5217, -14.7165,  -3.4516, -44.3753,  10.3874,\n",
      "           -8.0171],\n",
      "         [  9.0468,  25.6150, -39.5653,   3.2721,  -6.5794, -15.0131,  13.3818,\n",
      "          -19.2006],\n",
      "         [-17.9551,  28.4071,  29.8059,  46.3378,  29.4279, -30.3757,   9.0913,\n",
      "            4.5343],\n",
      "         [ -8.8672,  13.1063, -25.5718, -29.5536,  -1.3738, -29.8708,  -3.7134,\n",
      "          -28.5018],\n",
      "         [-23.0945,  -5.8221,  13.5344,  -4.4431, -35.2475, -40.8409, -25.4208,\n",
      "            7.4744],\n",
      "         [ 11.7611, -17.7254,  -3.1502,  30.8527,  82.6713, -69.0749,  18.2076,\n",
      "          -18.1399],\n",
      "         [  6.3329, -24.3877, -29.2364, -27.5326,  41.5406, -29.8006,   8.6753,\n",
      "           19.0777]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.7409, -0.1990, -0.0103,  ..., -0.5213,  0.7884, -0.2220],\n",
      "        [-0.0791,  0.1614, -0.2363,  ...,  0.5409,  0.3789,  0.1535],\n",
      "        [-0.4113, -0.3747, -0.6447,  ...,  0.6202, -0.2779,  0.6496],\n",
      "        ...,\n",
      "        [ 0.2371, -0.2381, -0.1322,  ...,  0.5416, -0.5281, -0.1806],\n",
      "        [-0.1081,  0.0677, -0.0519,  ..., -0.1775, -0.0717,  0.1314],\n",
      "        [ 0.1981, -0.9394,  0.0727,  ..., -0.2198, -1.1908,  0.1941]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[  6.1764,  -3.2619,  -2.3918,  11.9691,  -3.2304,  -8.6898,   9.0767,\n",
      "            7.6303],\n",
      "         [ 18.2656, -13.4702,  18.2538, -16.1258,  -2.1405,  12.5272,   0.6502,\n",
      "           -0.8694],\n",
      "         [-30.4144,   0.8236,  -2.0631,   1.0080,  -5.7140, -11.0259,  12.4274,\n",
      "          -17.9148],\n",
      "         [ -1.1961,   3.8633,  -6.1069,  22.0105,   4.9121,   8.5489,  10.7194,\n",
      "           -5.9446],\n",
      "         [-12.9253,  -6.9422, -14.9082, -10.5794, -17.8775,  -4.5877, -17.2086,\n",
      "            8.7239],\n",
      "         [ 11.9163,  -7.3488,  -4.2240,  -2.0748, -24.4140,  20.9780,  14.0458,\n",
      "            4.7886],\n",
      "         [-13.3137,   9.8636,  -8.9818,   1.5315,   7.6489,   9.4629,   0.1171,\n",
      "           -8.4858],\n",
      "         [  3.2832,  17.2545,  13.3543,  10.8207,  -3.9159,  -4.1462, -13.6730,\n",
      "            6.3888],\n",
      "         [ -5.9618,  -6.5230,  13.8423,   8.1468,   8.1735,  -3.6158,   4.1553,\n",
      "          -19.4639],\n",
      "         [ -9.2851,   2.2925,   8.3599,   1.2930,   4.3223, -13.2255,  15.7154,\n",
      "          -17.5232],\n",
      "         [-12.3511,   0.9138,  33.3137, -11.8419,  24.6520,   5.5620,   0.9549,\n",
      "            4.1730],\n",
      "         [  1.2266,  12.2963,  14.3599, -12.3163,  11.5619,   0.2636,  14.5138,\n",
      "           19.8700],\n",
      "         [  9.3738, -21.6528,  -6.3410,  -1.1655, -20.4212, -24.4950,  -4.5151,\n",
      "            9.3014],\n",
      "         [ 13.8659,   8.0788,  15.1522,  -2.2249,   0.1846,   2.8035,   7.0604,\n",
      "           18.1981]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[-0.0367, -0.2346, -0.0905,  ..., -0.0802,  0.0205,  0.0365],\n",
      "        [ 0.0235, -0.3615,  0.6462,  ...,  0.1014, -0.0594, -0.4561],\n",
      "        [-0.4570, -0.2005, -0.3281,  ..., -0.8757,  0.1275, -0.2230],\n",
      "        ...,\n",
      "        [-0.0126,  0.0775,  0.1538,  ..., -0.5793,  0.0179,  0.2320],\n",
      "        [-0.0105,  0.3766, -0.1740,  ..., -0.1232,  0.3820, -0.0214],\n",
      "        [ 0.4456,  0.2075,  0.1572,  ..., -0.0016, -0.1222,  0.0538]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[ -8.9848,   3.4017,  14.9327,  -7.6280,  15.2417,   4.6802,  -5.1800,\n",
      "           -4.8386],\n",
      "         [ 15.4147, -20.1848, -10.4026,   6.8818,  -4.7262,  -4.5984,  -2.7489,\n",
      "           14.4916],\n",
      "         [-37.5952,  -1.5064,   1.0857, -14.1105, -13.3380,  -1.8880,  17.2068,\n",
      "          -13.0266],\n",
      "         [ -3.4773,   8.1284,  -6.2418,  -3.4442,   0.9092,   7.1610,  -3.7930,\n",
      "          -13.9301],\n",
      "         [-21.0071,  35.4596,   6.0601,   0.3897,   3.7950,  -2.4162,  15.8346,\n",
      "          -18.1729],\n",
      "         [ 15.3536, -20.7296,  13.8452,   6.5659, -10.1414, -17.1567,  -9.3840,\n",
      "            3.6601],\n",
      "         [  1.8947,   3.1216,   0.5251,  -8.9488,   7.5765,   3.2405,  -7.3043,\n",
      "            6.6282],\n",
      "         [ -7.3854,   1.0806,   6.4206,  -5.8690, -16.6453,  -4.9832, -17.9391,\n",
      "          -13.6458],\n",
      "         [-16.5413,   1.9440, -12.2744,  -0.2664,  -8.9313,   5.9844,  -1.0917,\n",
      "           -7.2084],\n",
      "         [ 12.6607,  -3.3871,  -9.1469,  15.2340,   5.0849,   2.7844,  21.4301,\n",
      "           -4.0614],\n",
      "         [  1.8913,   1.8453,  -5.2950,  -1.5548,   3.0466, -17.4975, -11.2898,\n",
      "            4.8313],\n",
      "         [ -3.1757, -13.7157,   7.8153,   7.2510, -10.6379,   5.4702,  -4.9440,\n",
      "           -5.7021],\n",
      "         [  8.6966,   2.9272,  -2.9227, -11.0514,  12.7408,   4.3211,  -8.6054,\n",
      "           -5.6345],\n",
      "         [ -4.6291,  15.4992,  10.7884,  13.8151,   4.3223,   2.1590,  -8.1724,\n",
      "           21.8156]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[-0.1038,  0.6568, -0.0690,  ...,  0.1110, -0.3452,  0.2766],\n",
      "        [ 0.2151,  0.0669, -0.2057,  ..., -0.9533,  0.5650,  0.1487],\n",
      "        [ 0.5603, -0.0496,  0.4043,  ...,  0.0060,  0.3836, -0.2852],\n",
      "        ...,\n",
      "        [-0.5848,  0.5940,  0.0696,  ...,  0.4692,  0.1670,  0.2850],\n",
      "        [-0.0948,  0.5121,  0.2308,  ...,  0.2352, -0.6891, -0.0037],\n",
      "        [ 0.0367, -0.0882,  0.2576,  ..., -0.3627,  0.0367, -0.5465]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[ 20.9126,  -5.1246,  -2.0389, -10.1084,   8.3196, -36.2868,   6.9072,\n",
      "           24.8193],\n",
      "         [-15.0546, -37.5438, -13.3479,  14.8558,  43.5186,  -2.8718,  35.8712,\n",
      "            9.8932],\n",
      "         [-35.4124, -11.6776,  10.4519, -16.8096,  10.7254,  24.7788,   5.2816,\n",
      "           11.8162],\n",
      "         [-12.9029, -35.1814,   5.9913,  15.4968, -33.2026, -20.3705,  19.5582,\n",
      "           26.4519],\n",
      "         [  3.8263, -28.7220,   4.6838,  12.1517,  30.1387,   5.1364,  -2.8932,\n",
      "           -0.7857],\n",
      "         [-14.6943,  -4.2845, -30.2271,  25.1300,  21.0562,  32.8168, -31.0342,\n",
      "           19.3794],\n",
      "         [-14.4969, -12.4331,   5.2905,  16.0690,  -4.3442, -17.4884,  -5.9527,\n",
      "           -7.6778],\n",
      "         [ 29.6196, -13.3017,  28.2024, -31.1295,  49.4547,   7.4601,   1.9714,\n",
      "           -9.3352],\n",
      "         [ -9.3559,  29.6943, -24.7007,  -7.5760, -37.6112, -44.6386,  -2.7089,\n",
      "            2.1447],\n",
      "         [ -3.2349, -13.8147,  27.6785,  -6.7843,  42.1567,   9.6835, -19.0589,\n",
      "            2.8182],\n",
      "         [ -1.4233,  20.5638,  40.5719,  31.6066,  18.9296, -23.4463,  10.2484,\n",
      "           -9.5266],\n",
      "         [ 13.6864, -38.6225, -25.3670,  11.3013,  14.1815,   9.2264,   7.6769,\n",
      "          -24.7647],\n",
      "         [-14.5353,   8.4102,  -4.6300, -25.0064,   1.3858,  16.4486,  -5.3273,\n",
      "          -15.6897],\n",
      "         [ 23.3344,  43.1618, -19.3517, -17.0642, -13.6872,  -0.4617,  24.0073,\n",
      "           -2.3813]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[-0.0730, -0.3152,  0.0140,  ...,  0.0370,  0.2410,  0.0296],\n",
      "        [ 0.4494,  0.1854, -0.3253,  ..., -0.3724,  0.1203, -0.7039],\n",
      "        [-0.2194, -0.4160, -0.0802,  ...,  0.5536,  0.2085, -0.4009],\n",
      "        ...,\n",
      "        [-0.0569,  0.0052,  0.1343,  ...,  0.2711, -0.3529, -0.2306],\n",
      "        [-0.2700,  0.3057,  0.5253,  ...,  0.5416, -0.4376, -0.1845],\n",
      "        [ 0.1391, -0.0750,  0.4935,  ..., -0.3237,  0.0082,  0.2665]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[ 105.2405,  -25.8664,  -11.2329,   43.9743,    6.5296,   29.5136,\n",
      "           -11.4566,   26.7511],\n",
      "         [ -13.3430,   27.1033,   32.6665,    9.1639,  -12.4873,  -18.2497,\n",
      "            43.2650,  -26.4610],\n",
      "         [  19.1166,   11.3204,  -18.6260,   31.6690,  -57.2455,   48.2788,\n",
      "            17.4471,   -8.6117],\n",
      "         [ -31.2251,  -16.9568,  -40.0070,   40.3120,   -5.0247,   42.0071,\n",
      "            30.2001,  -50.6939],\n",
      "         [ -57.7637,   26.7796,   -2.5681,  -59.7126,  -22.5646,   -1.7687,\n",
      "           -39.8756,  -49.3602],\n",
      "         [  36.3738,   -6.2562,    5.8113,   12.3253,    0.6286,  -59.1974,\n",
      "            -9.4475,   -2.4110],\n",
      "         [  -6.4711,  -13.8031, -132.0829,   16.6058,   46.1822,  -42.6340,\n",
      "            -3.6822,   17.9286],\n",
      "         [  15.2448,  -30.2997,  -49.4050,  -84.9739,   48.0868,  -70.7126,\n",
      "           -84.7630,  -34.7737],\n",
      "         [ -40.3492,  124.8605,   51.1424,   -7.7414,   16.1859,    3.0904,\n",
      "             3.2720,   92.0024],\n",
      "         [ -58.9649,  -17.7987,   45.7265,  -27.3933,   24.5872,  136.5735,\n",
      "            12.1596,  -25.5147],\n",
      "         [ -20.3284,   12.5536,  -17.4719,   39.5891,  -77.4926,   37.2050,\n",
      "            -0.3496,  -58.8561],\n",
      "         [  56.0267,  -17.9123,    5.0014,   61.2509,   39.4062,  -12.2995,\n",
      "            14.0773,  -29.3884],\n",
      "         [  19.4486,  -48.9836,  -30.8261,   -2.4950,   31.6086,  -45.2928,\n",
      "            47.2613,  -39.6723],\n",
      "         [ -60.9570,  -45.3381,  -30.1984,  -12.8876,  -18.5935,   29.5991,\n",
      "            24.0211,   19.3921]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[-0.4171,  0.1934,  0.1014,  ...,  0.0381,  0.3239,  0.3939],\n",
      "        [ 0.3096,  0.8273, -0.4636,  ..., -0.1212,  0.0587, -0.4512],\n",
      "        [-0.6692, -0.8471,  0.2293,  ..., -0.6013, -0.2865,  0.0182],\n",
      "        ...,\n",
      "        [ 0.4263, -0.2219,  0.0746,  ...,  0.5101,  0.6682, -0.3046],\n",
      "        [ 0.2444, -0.3939, -0.0678,  ..., -0.0392,  0.4112, -0.4922],\n",
      "        [-0.2301,  0.0578, -0.6198,  ..., -0.0962,  0.1713, -0.2874]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[-78.4184,   2.7795,  15.9681,   8.2095, -30.6829,   1.4342, -82.0515,\n",
      "           62.8437],\n",
      "         [-46.5392,  -3.8640,  41.1566,  77.8610, -23.5366, -67.4579, -46.0339,\n",
      "           24.7502],\n",
      "         [-32.5825,  35.4890, -20.8288, -25.4316,  66.0308, -20.0128,  33.3987,\n",
      "            8.2502],\n",
      "         [ 17.7607,  50.8098,  23.2349, -72.8708, -48.3934, -38.7075, -18.3465,\n",
      "            9.7335],\n",
      "         [ 14.0578, -34.9725,   6.7616, -16.9511,  59.9135,  65.6408,  51.3862,\n",
      "           48.7844],\n",
      "         [-48.4344,   0.5286, -19.5287, -62.8872,  13.0209,  38.4971, -43.5955,\n",
      "           22.3984],\n",
      "         [-26.7380, -19.8156,  91.5580, -21.2142,  94.1888,  10.5538, -36.3977,\n",
      "          -97.3284],\n",
      "         [-33.3847, -56.7004,  -3.1578, -86.3890,  -3.4952,  34.1815,  21.9119,\n",
      "           67.1904],\n",
      "         [  3.9185,  91.7896,  50.8828,   1.6654, -23.8901,  42.5691,  13.5901,\n",
      "           18.1044],\n",
      "         [-69.7625,  17.6556,  12.5592,  -5.7521,   8.6591, -12.4328, -11.2267,\n",
      "           50.3048],\n",
      "         [ -0.5210,  55.7396,  52.1361,   1.9733, -51.9881, -19.0428, -37.9145,\n",
      "           24.8528],\n",
      "         [-15.3592, -31.8876,  28.3802,  61.7523,  11.8310,  87.7718, -13.2736,\n",
      "           36.5612],\n",
      "         [ 53.9153,  -3.1256, -66.8873, -28.1501,  24.0518, -11.2533,  20.8834,\n",
      "           36.4994],\n",
      "         [-18.6232, -61.2648, -18.2981,   5.1836,  59.6717, -63.4843, -66.9163,\n",
      "           55.3940]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=14336, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[-0.1618, -0.1189,  0.3291,  ...,  0.2612, -0.6095, -0.3821],\n",
      "        [-0.5197,  0.1451,  0.0643,  ..., -0.3187, -0.1026,  0.1451],\n",
      "        [-0.1406,  0.0764, -0.3347,  ...,  0.0583, -0.1060, -0.1099],\n",
      "        ...,\n",
      "        [ 0.0247, -0.4718, -0.4431,  ..., -0.0469, -0.2648, -0.3998],\n",
      "        [-0.0248, -0.2968,  0.0070,  ..., -0.2283, -0.0167, -0.1130],\n",
      "        [-0.8445,  0.4988, -0.0661,  ..., -0.1195, -0.2608,  0.1159]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[ 16.2384,  20.0406,  -1.4083, -17.8113,  47.0304, -30.9465, -24.5610,\n",
      "            9.0400],\n",
      "         [  8.3907,   6.7916,  24.3255, -19.3061,  -1.4357,   8.1864,  36.3474,\n",
      "           -9.6144],\n",
      "         [ 42.2881, -43.7583, -44.7903, -11.5418,  -2.1815, -22.3802, -27.2899,\n",
      "          -16.9021],\n",
      "         [-32.9781, -20.8894,  23.6535, -11.3628, -25.4802,  -9.5901,  -4.2454,\n",
      "           23.1177],\n",
      "         [-24.0200,  39.5205,  12.7339,  70.8350,  18.3303,  53.7731,  -2.2972,\n",
      "          -14.5581],\n",
      "         [-13.1330, -27.9494, -17.5240, -39.2464, -16.3181,  26.8614, -19.5050,\n",
      "           -3.5377],\n",
      "         [ 13.7467,   4.4436, -16.0422, -20.7022, -18.9766,  41.7385, -39.5843,\n",
      "           -6.1025],\n",
      "         [  4.4432,   6.1889, -14.4053,  -9.7125, -11.9858,  19.5481, -20.8402,\n",
      "          -15.9561],\n",
      "         [-15.7610, -24.7860,  38.4300,  40.4759,  -3.2588,   5.4030,   7.2159,\n",
      "          -19.7572],\n",
      "         [ -4.9740, -12.2681, -15.3010,  -1.7599,   9.5673,   9.5863, -16.4695,\n",
      "           -6.6466],\n",
      "         [ 28.2814, -13.8791,  40.8920,  36.1801,   9.0355,  -1.0523,   4.4013,\n",
      "           -4.3530],\n",
      "         [-16.6283,  34.8882,   2.9772,  -4.5048,  37.0630,  -3.7427,  15.4647,\n",
      "           -9.4701],\n",
      "         [-11.3291,   7.1197, -39.2865,  15.0961,  -6.4515,  -9.9567,  20.1707,\n",
      "          -49.4013],\n",
      "         [ -9.1700, -13.6671, -14.4671,  -8.4335, -28.4275,  16.5111,  16.2673,\n",
      "          -30.3003]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.0629, -0.2161, -0.3287,  ...,  0.0281, -0.1942, -0.0158],\n",
      "        [-0.2111,  0.3471, -0.2741,  ..., -0.0057,  0.4080,  0.5943],\n",
      "        [-0.3618,  0.5634,  0.0793,  ..., -0.2489, -0.1984,  0.1616],\n",
      "        ...,\n",
      "        [-0.1939, -0.5168,  0.6093,  ...,  0.0358,  0.3370, -0.9471],\n",
      "        [-0.0484,  0.0456, -0.0148,  ..., -0.2408, -0.1517,  0.0384],\n",
      "        [ 0.0522, -0.1323, -0.4230,  ..., -0.3400,  0.2638, -0.1857]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[-3.9516e+01, -2.8328e+01, -2.8165e+01,  1.4494e+01, -3.7215e+01,\n",
      "          -1.6113e+01,  2.4946e+01, -3.6741e+00],\n",
      "         [ 2.1158e+01,  1.0536e+01,  4.7440e+01, -1.1039e+01,  6.1403e+01,\n",
      "           2.8250e+00, -2.6118e+01, -1.9813e+01],\n",
      "         [-3.2604e+00, -3.1544e+01, -3.3609e+00,  7.8773e+00,  1.0378e+01,\n",
      "          -4.0879e+00,  1.4237e+01,  5.7515e+00],\n",
      "         [ 2.3581e+01, -2.5869e+01, -5.8604e+01, -2.5390e+01, -1.4542e+01,\n",
      "           1.8688e+01, -9.5118e+00, -2.4017e+01],\n",
      "         [-1.1064e+01, -1.2857e+00,  1.6374e+01, -9.5779e+00,  1.8497e-02,\n",
      "          -2.1173e+01, -1.6892e+01, -1.5813e+01],\n",
      "         [ 5.2977e+01,  2.0319e+01,  6.5106e+01,  1.8360e+01, -6.8681e+00,\n",
      "          -3.1615e+01,  2.4839e+01,  1.3314e+00],\n",
      "         [-1.8056e+01, -6.0980e+01, -6.9040e+00, -2.2872e+01,  4.5522e+01,\n",
      "           1.7045e+01, -3.2151e+01,  3.3730e+00],\n",
      "         [-1.2321e+01,  1.3399e+01,  2.1380e+01, -3.8807e+00, -8.9363e-01,\n",
      "          -2.9194e+00, -2.9724e+01,  4.3994e+01],\n",
      "         [ 3.2120e+01,  1.7741e+01,  6.8405e+00,  5.0527e+00, -3.8478e+00,\n",
      "           8.8422e+00, -2.1709e+01, -3.8001e+01],\n",
      "         [-7.4084e+00, -2.4553e+01,  3.6448e+01,  3.6083e+01,  1.4376e+01,\n",
      "           5.8950e+01, -1.1234e+01, -1.3565e+01],\n",
      "         [-2.1278e+01,  1.2101e+01, -2.8050e+01, -1.4922e+01, -8.4129e+00,\n",
      "          -3.9079e+01,  4.5735e+01, -3.4714e+01],\n",
      "         [ 3.0597e+01,  2.2593e+01,  1.1595e+01, -6.5273e+00, -1.5711e+01,\n",
      "          -8.8847e+00, -1.7967e-01,  9.0746e+00],\n",
      "         [-2.7932e+00, -3.8461e+01, -2.8307e+01,  2.4495e+01,  9.9904e+00,\n",
      "           3.0245e-01, -3.3407e+01, -2.3795e+01],\n",
      "         [-6.6763e+00,  2.3878e+01, -8.3542e+00,  2.0455e+01,  3.6825e+01,\n",
      "          -1.9446e+01, -5.5204e+00, -1.3626e+01]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.5044, -0.5324,  0.1057,  ..., -0.2988, -0.3144, -0.0320],\n",
      "        [ 0.4091,  0.0429,  0.3011,  ...,  0.4400, -0.0584, -0.2558],\n",
      "        [-0.0679,  0.0171,  0.3652,  ...,  0.2859,  0.0700,  0.1099],\n",
      "        ...,\n",
      "        [ 0.4954, -0.3010, -0.1836,  ..., -0.4800,  0.2401,  0.2034],\n",
      "        [-0.1933, -0.0395,  0.2526,  ...,  0.1168, -0.1406,  0.4410],\n",
      "        [-0.1125,  0.1314, -0.3266,  ...,  0.3803,  0.5447,  0.3536]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[ 14.9059,  15.5058,   9.7452,  15.6436,  -6.8418,   9.4243,  36.7773,\n",
      "            9.6114],\n",
      "         [  2.5627,   1.6447,  13.7212, -17.6914, -14.4983, -16.1429,  -5.0338,\n",
      "          -11.2337],\n",
      "         [-11.8684,  -5.9911,  -4.9640,  -9.5496,  -4.8863,   4.9816,  13.1026,\n",
      "           -8.5762],\n",
      "         [ 15.5249,  -4.7938,  -3.8481, -18.7092,   2.5486, -21.4273,  -8.0000,\n",
      "           -3.2092],\n",
      "         [ -0.9619,   7.1619,  -3.1776,  11.0013,  15.5064,  10.7382,  -7.2685,\n",
      "            0.8841],\n",
      "         [  0.9041,   3.2545,  -7.0977,  -5.6906,  -7.4049,   2.7276, -14.7349,\n",
      "          -25.7274],\n",
      "         [-13.2664,   9.7240,  -9.7559,   7.3063,   9.5800,   5.4961,  17.4286,\n",
      "           -3.0999],\n",
      "         [ -2.0376, -17.8551,  -1.2257,   1.7271,   2.6469,  -6.5319, -13.9290,\n",
      "           21.3936],\n",
      "         [  1.5756,   5.2573,   1.0459, -15.1738,  17.5301,  26.3713,  -5.1274,\n",
      "            7.7536],\n",
      "         [ -9.6819,   5.7077,   6.7673, -19.0259,  -3.2219, -13.7895,  -8.1975,\n",
      "          -10.7034],\n",
      "         [  3.1140,  13.1222,   9.2494, -18.4736,  14.1869,  -2.1501,  17.7676,\n",
      "            5.8415],\n",
      "         [ -6.8164,  -3.7968,  -2.0581,   2.0777,   5.9694,   2.8953,   1.7839,\n",
      "           -3.4738],\n",
      "         [ -1.6239,  -7.7868,  -6.1478,  -6.1599,  -3.3518,  13.0150,  -7.2634,\n",
      "            1.7918],\n",
      "         [ -6.3672,  -1.0204,  -2.5703,   0.7341,  -3.9080,  -6.2696, -24.4257,\n",
      "           -1.5852]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[-0.2842, -0.7390,  0.7415,  ..., -0.0380,  0.2923,  0.0842],\n",
      "        [ 0.1384, -0.0712, -0.0321,  ..., -0.1276,  0.5078,  0.2365],\n",
      "        [ 0.4132, -0.2191,  0.0218,  ...,  0.2151,  0.4924,  0.3797],\n",
      "        ...,\n",
      "        [-0.8002,  1.0735,  0.0708,  ..., -0.8102,  0.5477, -0.3565],\n",
      "        [-0.6132,  0.0971,  0.2033,  ...,  0.1430,  0.5437, -0.2708],\n",
      "        [-0.2084, -0.5426, -0.2868,  ..., -0.0856, -0.2794,  0.8531]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[  2.8384, -18.7754,  -4.5661,  11.7919,   3.7186,   3.0946,  -2.4759,\n",
      "            1.8164],\n",
      "         [ -5.9909,   9.3557,   3.2560,   0.3935,   2.4636,  -2.0774,  20.9718,\n",
      "            0.4760],\n",
      "         [ -9.4827,   1.5075,  -2.7079,   5.4860,  18.3331,   4.7680,   7.9185,\n",
      "           -9.3899],\n",
      "         [  7.0865,   3.1812,  -0.9371,  -2.3481,  20.8057,  10.0544,  14.8916,\n",
      "           -5.8495],\n",
      "         [ -1.0703, -11.9386,  -0.0857, -12.1405,  18.4198,   8.0804,  -1.1181,\n",
      "          -17.5747],\n",
      "         [  9.3411, -14.3351,  -2.1793,  -3.1110,  -8.3753,  -1.3152,  -0.5112,\n",
      "          -17.5074],\n",
      "         [ -9.5335,  11.5476,  -7.8827,  11.3094,  10.9063,  10.2848,  -0.1069,\n",
      "            4.3643],\n",
      "         [ -1.4150,  -5.8862, -17.1628,  -9.8231, -13.1865,   8.9171,  -2.1094,\n",
      "            2.9860],\n",
      "         [ 12.0341,  10.8672,  12.0200, -19.7215,   7.7907, -12.2064,  -1.4550,\n",
      "          -22.8504],\n",
      "         [-10.2941,  -8.6833, -21.6782, -35.7050,  -3.7647, -15.6246,  12.2612,\n",
      "            6.9759],\n",
      "         [ -5.7131,   6.5813,  -9.5639,  10.4266,  -1.5063,   1.1455,   8.5453,\n",
      "           -1.4825],\n",
      "         [-19.0584,  -5.5833,   3.1011,   9.4840,  -6.1129,  -7.7588,   2.4897,\n",
      "           -0.4191],\n",
      "         [-11.9386, -11.7894,   6.3120,   6.7081,  15.5100,  12.5443, -12.5795,\n",
      "           -6.6040],\n",
      "         [-44.0014,  -7.0516,  10.2562,   8.2256, -15.5501,   8.6578,  13.0194,\n",
      "            4.6899]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.2799,  0.3353,  0.0965,  ..., -0.0605, -0.0341, -0.1196],\n",
      "        [ 0.8917, -0.0868,  0.6123,  ..., -0.3494,  0.6811,  0.1992],\n",
      "        [-0.0095, -0.5018,  0.4690,  ...,  0.2806,  0.6549,  0.3803],\n",
      "        ...,\n",
      "        [ 0.0871, -0.5636,  0.0236,  ..., -0.2240,  0.1141, -0.2136],\n",
      "        [-0.2672, -0.1958,  0.4396,  ...,  0.2332, -0.1930, -0.5096],\n",
      "        [ 0.3043,  0.0278, -0.3958,  ...,  0.0156, -0.2911,  0.4658]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[ 42.6628,  15.6178, -12.1499,  -5.6084, -51.1714, -39.7844,  14.1307,\n",
      "          -29.8654],\n",
      "         [ 22.0497, -16.7590, -11.9170, -24.8150,   1.2155,  -7.8567,  20.8024,\n",
      "           28.7876],\n",
      "         [  9.3691,   4.2203,   1.0686, -23.2193, -14.1371,  10.4278, -35.8360,\n",
      "          -11.6341],\n",
      "         [-35.5975,  -3.1421,  22.8922,  19.8501,  27.5811, -16.0891,  -3.0550,\n",
      "          -20.3705],\n",
      "         [  8.8142,  10.2838,  10.9245,  -9.4475,  34.2610,  22.6766,  30.0262,\n",
      "           21.5375],\n",
      "         [-26.9917,  16.5244, -27.7065,   6.1247,  27.3933,   6.8608, -48.4186,\n",
      "          -18.8075],\n",
      "         [ -8.6237,  23.0155,  -2.7667, -17.3305,  -2.1013, -21.2944,   6.7879,\n",
      "           -8.1028],\n",
      "         [ -9.5312,   4.1553,   4.5172, -35.2674,  25.7337,   0.9276,  -1.8019,\n",
      "           42.0562],\n",
      "         [-39.2609,  21.1413, -17.3540,  23.1609,  26.2729,   5.9031,  -5.0486,\n",
      "           45.5073],\n",
      "         [-19.3520,  16.4763,  22.7752,  33.7796,  23.5684,  -3.3338,  37.8905,\n",
      "           11.7196],\n",
      "         [ -4.3061,  22.6130,  35.1005,  41.5264,  37.7251, -25.5931,  31.2751,\n",
      "          -18.7221],\n",
      "         [  7.9814, -17.8175, -31.6125,  40.6787,  29.4952, -31.9373,  -5.8106,\n",
      "           26.4622],\n",
      "         [ -5.8210,  24.8448,  -2.6588,  24.6138,  -0.9666, -18.7979,   6.2347,\n",
      "          -35.5779],\n",
      "         [  8.3656,   1.5192, -17.7578,  34.5366,   7.9770,  -4.3792,  24.6212,\n",
      "           -2.3737]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[-0.7744,  0.1783,  0.2430,  ...,  0.0574,  0.3677,  0.3171],\n",
      "        [ 0.2542,  0.1458, -0.5333,  ...,  0.3950,  0.0819, -0.5423],\n",
      "        [-0.1257, -0.1663,  0.1742,  ..., -0.3642, -0.0383, -0.1707],\n",
      "        ...,\n",
      "        [ 0.5553, -0.4257,  0.4033,  ..., -0.1789, -0.4567,  0.0116],\n",
      "        [ 0.0851, -0.1227, -0.1421,  ...,  0.3144,  0.3992,  0.3493],\n",
      "        [ 0.1647, -0.1553, -0.3395,  ...,  0.0527,  0.5711,  0.4881]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[  46.7757,  -18.2050,  -21.6575, -100.8146,   14.8741,   49.9964,\n",
      "            68.6997,   11.4039],\n",
      "         [ -40.6784,  -40.2289,    4.3904,  -33.9920,    9.6157,  -15.5651,\n",
      "          -107.1719,  -21.6354],\n",
      "         [  35.9293,  -35.4437,  -42.8452,   24.7963,   -0.8804,  -16.3600,\n",
      "            -0.8624,   93.7224],\n",
      "         [  11.1415,  -12.9457,  -47.4866,   72.2683,   14.4849,   88.4124,\n",
      "            24.1387,  109.6904],\n",
      "         [  -7.0807,  -52.6510,   -2.7066,   -7.2438,  -23.8748,    5.0532,\n",
      "            -1.1287,  -64.6255],\n",
      "         [  57.9942,  -16.9860,   62.2160,   47.3778,   -9.9799,  -41.9118,\n",
      "            15.4809,   53.6703],\n",
      "         [ -54.9499,  -54.5502,   47.9315,  -51.0308,   19.3262,  -11.5986,\n",
      "            57.9919,  -64.0378],\n",
      "         [  24.0795,   67.0945,   62.9518,  -29.0882,  -12.3959,  -54.0004,\n",
      "            36.7613,  -17.8173],\n",
      "         [  15.5002,  -14.5438,  -16.8936,   19.1554,  -85.0374,   90.8050,\n",
      "            32.4429,  -17.9678],\n",
      "         [ -30.0636,   59.3110,   -7.0808,  -55.0705, -101.3041,  -19.1273,\n",
      "            -4.2102,  -24.2050],\n",
      "         [ -13.7914,   19.8898,  -66.4967,   11.8430,   49.4008,   19.8019,\n",
      "            -6.6495,   28.6789],\n",
      "         [  30.1239,   39.7505,   63.8933,    1.2830,   18.9038,  -34.7293,\n",
      "           -43.0545,   37.4265],\n",
      "         [  14.4253,  -10.8786,  -47.7591,  -21.6138,  -68.0469,  -64.5814,\n",
      "            16.4735,   28.3899],\n",
      "         [   7.9782,  -25.7668,   67.6711,   28.9513,   18.2540,   15.8992,\n",
      "           -49.4675,   14.4587]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.3661, -0.3804,  0.3438,  ..., -0.3952,  0.7799,  0.2497],\n",
      "        [-0.0941, -0.2397, -0.8625,  ..., -0.2595,  0.3145, -0.0816],\n",
      "        [ 0.3610, -0.0898,  0.1634,  ...,  0.2971, -0.2030, -0.0288],\n",
      "        ...,\n",
      "        [ 0.0604,  0.4834,  0.4774,  ...,  0.2681, -0.4124,  0.0360],\n",
      "        [ 0.1121, -0.0148,  0.1652,  ..., -0.1117,  0.1351,  0.2595],\n",
      "        [-0.0882, -0.1502, -0.0863,  ...,  0.0570, -0.1038, -0.0273]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[ -55.6247,  -86.1739,   83.3496,   10.2980,  -79.2847,  -28.6039,\n",
      "           -35.2184,  -89.8087],\n",
      "         [  11.0005,  -21.1830,   26.6963,  -63.7851,   12.4478,  -21.1018,\n",
      "            16.7749,   10.8474],\n",
      "         [ -55.4417,  -50.4435,   28.6120, -105.0812,   18.4840,  -34.8339,\n",
      "            22.1683,   49.0327],\n",
      "         [   4.2347,    4.3211,   18.8988,  -19.9718,  -24.2914,   24.0469,\n",
      "           -11.2539,   28.0967],\n",
      "         [  16.1672,   14.7713,   61.0101,  -72.7757,   49.9634,   59.5184,\n",
      "            -6.3560,   52.8060],\n",
      "         [  -7.6532,  -38.6303,  -48.9687,  -53.6829,   -7.3323,   -6.8016,\n",
      "             3.8279,   31.4779],\n",
      "         [  46.8049,  -22.1175,   -8.7464,   -1.7664,  -36.4912,  -20.7420,\n",
      "           -22.2357,  -55.5519],\n",
      "         [  43.5962,    6.0696,   43.0144,   26.9957,  -78.1234,   32.4935,\n",
      "           -18.1041,   40.2413],\n",
      "         [  81.6051,   24.0303,   34.8351,  -19.3085,  -34.6369,   31.5809,\n",
      "            32.4029,  -85.3526],\n",
      "         [ -38.9992,  -40.7709,   15.4361,  -10.6924,   14.5894,   41.7521,\n",
      "           -22.4887,   11.3304],\n",
      "         [ -47.4216,  -50.7964,  -27.0458,  -28.1520, -102.0295,   49.6719,\n",
      "           -46.3390,  -79.7708],\n",
      "         [  34.6672,    6.1499,   91.3500,   -7.1960,  -19.2009,   52.3254,\n",
      "            -2.2547,    3.6478],\n",
      "         [  22.9787,  -88.5530,  -29.4276,   40.3525,  -22.1138,  -38.2861,\n",
      "           -37.5327,   25.7384],\n",
      "         [  81.7410,   32.2008,   53.9343,  -24.3760,   -6.5020, -100.4055,\n",
      "           -13.4579,  -42.5228]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=14336, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.0473, -0.0962,  0.4338,  ...,  0.5867,  0.3054,  0.0461],\n",
      "        [-0.3876,  0.1796,  0.3316,  ..., -0.2050, -0.0674, -0.1205],\n",
      "        [ 0.3967,  0.4680,  0.2227,  ..., -0.5914, -0.0509,  0.6141],\n",
      "        ...,\n",
      "        [ 0.3456, -0.0845,  0.0870,  ...,  0.3651,  0.1083,  0.1628],\n",
      "        [ 0.2237, -0.0493,  0.5120,  ...,  0.0930, -0.1501,  0.1656],\n",
      "        [ 0.0221,  0.2432, -0.1734,  ...,  0.1930, -0.0632, -0.1244]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[-29.0930, -15.4092,  21.6601, -21.7842,  -6.5793,  17.9799, -10.9010,\n",
      "           13.8648],\n",
      "         [ -2.9088, -20.6589,   3.4058, -16.7651,  25.0841,  14.0167,  11.1279,\n",
      "           -7.7400],\n",
      "         [ 26.3797,   2.5901,   1.3551,  17.7533, -29.0115,  -5.8481,  24.3244,\n",
      "          -39.9924],\n",
      "         [ 23.2446,  -9.0264, -16.9857,  50.1364,  -3.6664,  11.6441,  12.2885,\n",
      "          -33.0532],\n",
      "         [ 10.2162,  13.4358,  -6.2015,  33.3521,  37.3298,  22.2890,  29.4522,\n",
      "          -22.6511],\n",
      "         [  4.2938,  -7.9967,  -2.5299, -23.8448,  13.9457, -15.3510,  19.7000,\n",
      "            7.6290],\n",
      "         [-20.3488,   7.9154, -16.4629,   5.3740, -14.2561,   0.2297,  40.7760,\n",
      "           17.7530],\n",
      "         [  2.7439,  13.0667,   2.3764, -24.2857, -31.2336, -30.9680, -15.0625,\n",
      "           -9.9238],\n",
      "         [-23.7556,  31.7331,  -9.0734, -37.8463,   9.9114,  20.9748,  -0.1110,\n",
      "           18.3261],\n",
      "         [ 11.7269,  -9.1964, -10.3492,   9.7662, -18.0423, -16.7178,  30.8480,\n",
      "           10.8599],\n",
      "         [  6.2155,   7.7748,  -9.7173, -28.5678,   1.4397, -17.9920,   0.9194,\n",
      "           16.5942],\n",
      "         [ -3.2401,   5.5618, -63.9492,  47.1606, -33.9963,  -8.4633,   9.9110,\n",
      "           42.4076],\n",
      "         [ 22.9799,   0.2437, -27.1380,  23.4312, -11.0723,   5.1625,  -4.8447,\n",
      "           30.4854],\n",
      "         [-22.4846,  12.6075,  38.6732, -11.7204, -30.3144,  -7.2328, -19.5313,\n",
      "           18.2738]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[-0.2070,  0.4725,  0.2152,  ..., -0.9459,  0.1010,  0.5910],\n",
      "        [-0.3540, -0.4310,  0.4912,  ...,  0.0153, -0.1728,  0.1484],\n",
      "        [-0.5532, -0.2314, -0.1759,  ..., -0.2052, -0.8674,  0.6331],\n",
      "        ...,\n",
      "        [-0.2488,  0.4193,  0.0298,  ...,  0.4912, -0.1491, -0.5100],\n",
      "        [-0.4217,  0.2487, -0.2294,  ...,  0.1712,  0.4541,  0.1425],\n",
      "        [ 0.1946,  0.6094,  0.6868,  ...,  0.1193,  0.5682,  0.0223]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[-22.4501, -27.3229,  18.0588,  -3.1475,  28.2890, -20.9820, -10.6118,\n",
      "            9.8211],\n",
      "         [ 38.5803, -23.1331, -50.0699,  -4.1678,   0.3091, -13.0990,  14.2872,\n",
      "            6.4983],\n",
      "         [ -3.0318, -13.5131,  -8.3363,  11.1656,  11.2769, -26.1628,   2.5447,\n",
      "          -54.3154],\n",
      "         [-33.0204,  -9.0285,  -0.1662, -33.8208,   8.0944, -52.5760,  -5.8861,\n",
      "           -1.1306],\n",
      "         [ 19.0060, -47.6470,  -6.3343,  12.0157,  12.9937,  40.2882, -16.1914,\n",
      "          -15.2259],\n",
      "         [ 26.1028,  -3.8877,   1.2007,   3.0553, -28.3768, -19.7438, -30.3248,\n",
      "            9.8672],\n",
      "         [-16.4884,  -7.8283,  15.5849,  13.8714,  52.9685,   7.5987, -39.6278,\n",
      "          -17.3492],\n",
      "         [ 16.1978, -60.5894,  -7.3536,  12.8446, -31.8657,  -5.6797,  10.3218,\n",
      "          -44.2190],\n",
      "         [-23.4071,  23.1420,  31.2974, -42.3918, -17.0210,  25.7662,  11.9171,\n",
      "            8.4758],\n",
      "         [ 22.4303, -13.4624, -46.2667,  16.7822,   5.0198,   4.5309,  -1.7943,\n",
      "           41.0519],\n",
      "         [ 44.9506,  48.3630, -21.0771,  22.9051,  27.7502,  12.9804, -13.9673,\n",
      "            1.1788],\n",
      "         [  1.1000,   1.8526,  11.9124, -38.8140,  -4.9751,  31.8813,  21.1732,\n",
      "           53.6570],\n",
      "         [ 14.9640,  11.9888, -22.8297,  11.7125,  14.9182,  20.6487,  45.2928,\n",
      "           12.2411],\n",
      "         [-36.0800,  10.5580,  -2.3176,  -5.2460,  45.7455,  36.9101,  18.1074,\n",
      "          -19.8549]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[-0.1361, -0.4593,  0.0626,  ...,  0.1966,  0.3759, -0.1751],\n",
      "        [-0.1023,  0.7092,  0.3071,  ..., -0.4829,  0.6575,  0.3038],\n",
      "        [-0.1923,  0.3770,  0.7561,  ..., -0.0575,  0.0547,  0.4176],\n",
      "        ...,\n",
      "        [-0.5696, -0.0350,  0.2166,  ...,  0.6467,  0.1629, -0.4448],\n",
      "        [ 0.1893, -0.2550, -0.1053,  ...,  0.3244, -0.2293, -0.1896],\n",
      "        [-0.1983,  0.1304,  0.0536,  ..., -0.0269, -0.8210, -0.2949]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[ -2.8245, -19.3185,   2.3212,  -1.8781, -16.4185,   2.0075,  -2.9680,\n",
      "            3.8750],\n",
      "         [ -4.5777,   6.5667,   1.5540,   8.4353,  -8.1722,  19.7426, -18.6973,\n",
      "            5.0651],\n",
      "         [ 10.2007, -10.8011,   3.8341, -22.0723,  -8.7058,  12.5418,   6.2976,\n",
      "           14.3730],\n",
      "         [  0.8441,   6.1074, -15.6725,  10.5162,   1.6616,  11.9172,  23.6711,\n",
      "            8.4231],\n",
      "         [ -1.1185,  -5.8320,   3.8162,  25.7105,  17.7161, -26.0258,  -6.9344,\n",
      "            3.3028],\n",
      "         [-11.8890,   9.9096,   3.6713,  -9.7422,   7.6373,  22.3500, -11.5154,\n",
      "            6.8264],\n",
      "         [  6.9690,   4.9395,  -7.7246,   2.8783,  -9.1791,  10.7859,  -2.3303,\n",
      "            8.3253],\n",
      "         [ -9.4525,  14.4608, -17.9508, -15.3439,  27.7428,  12.3375,  -9.4515,\n",
      "           -9.7450],\n",
      "         [ 14.7615, -12.0356,   9.0065,  -4.3188,  -7.2354,  -2.2005,   0.6563,\n",
      "            0.4317],\n",
      "         [  3.7407, -20.0668,   0.5562,  -0.4731,  -3.9559,  -5.6385,  11.1319,\n",
      "           -7.8144],\n",
      "         [ 10.8668,  -5.5544,  -3.0505, -13.0484, -27.6434, -19.9872,  -8.9813,\n",
      "            7.3561],\n",
      "         [ -2.5068, -17.7433,  -0.1859,   7.0612,  -5.7130,  -1.8236,  -6.2560,\n",
      "           19.7534],\n",
      "         [  6.8605,  -2.1595,   0.2390, -17.3764,  12.9972, -13.7033,  15.7731,\n",
      "            6.2578],\n",
      "         [ 12.9941,  -2.2566,  -7.8241,  -3.2683,  16.9574,   9.0451,  16.0126,\n",
      "            4.0334]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.2911, -0.2409, -0.1624,  ...,  0.0289, -0.0092,  0.3943],\n",
      "        [ 0.0595, -0.8552,  0.5471,  ..., -0.3919,  0.4455,  0.1162],\n",
      "        [ 0.1678, -0.1376,  0.5763,  ..., -0.1760, -0.3223,  0.0290],\n",
      "        ...,\n",
      "        [ 0.3151,  0.3135,  0.2657,  ..., -0.0132, -0.4725, -0.1974],\n",
      "        [ 0.0284,  0.0711, -0.0708,  ..., -0.1833, -0.3459,  0.2976],\n",
      "        [-0.7220, -0.2360,  0.8317,  ..., -0.6290, -0.3250, -0.5167]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[ -1.3460,   1.7150,   3.5728, -23.6455,  24.7428,  10.8035,   1.1225,\n",
      "           -8.5411],\n",
      "         [  4.5716,   4.5454, -15.0870, -14.3257,   8.9780,   6.4788, -17.3610,\n",
      "           -6.4680],\n",
      "         [ -3.6574,   9.3977, -20.5394,   1.6304,  19.2697,   2.0871,  -0.2653,\n",
      "           15.7168],\n",
      "         [  9.5934,   2.6889,   2.9716,  -7.6586,  22.5410, -29.9791,   5.5906,\n",
      "          -10.2080],\n",
      "         [ 11.1585, -24.9309,   0.4039,  15.7226, -26.2114,  -5.7943,  -0.2974,\n",
      "          -35.3251],\n",
      "         [ -3.0191,   6.3459, -12.7010,  -0.5350,  -3.5663,   4.6850,   5.6850,\n",
      "          -33.3299],\n",
      "         [ 12.3933,  22.5086, -10.6131,  -6.3604,   7.1079,  -2.5340,   4.7691,\n",
      "           18.7717],\n",
      "         [ -9.6514,  -6.2704,   3.2865,   6.6883,  -3.2346,  -4.6621, -16.2376,\n",
      "            3.4670],\n",
      "         [ -9.8759,  14.8953,   8.9358, -23.9886,  -2.1466,  17.5152,  10.7086,\n",
      "           -8.5941],\n",
      "         [-19.6388,  16.5672,   0.3054,   0.9374,  -8.5768,  11.6859,   2.1941,\n",
      "            8.1421],\n",
      "         [  6.8923,   5.1549,  -2.2078,  -0.7994,  11.8809, -16.6799, -23.6161,\n",
      "          -13.2867],\n",
      "         [  7.2577,   9.5131,  -3.9154, -30.2017,   2.3317,  -7.0700,  -7.2168,\n",
      "            8.3376],\n",
      "         [ -8.9161,  10.4959,   3.9047,   3.3850,  -5.8880,   2.6647,  -0.9360,\n",
      "          -10.3764],\n",
      "         [ -1.8360,   1.7330,  -1.7386,   5.6990,  10.3144,  -3.7174,   3.8668,\n",
      "           -9.8602]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.2966, -0.1448, -0.3446,  ...,  0.4417,  0.1506, -0.0739],\n",
      "        [-0.3592, -0.4842, -0.4484,  ...,  0.0289, -0.2527, -0.4913],\n",
      "        [ 0.0506,  0.7105, -0.1040,  ..., -0.0594,  0.0669, -0.0841],\n",
      "        ...,\n",
      "        [-0.3704, -0.2181, -0.2972,  ..., -0.0380,  0.0047, -0.2248],\n",
      "        [-0.1333,  0.0864,  0.6688,  ..., -0.4287,  0.5167,  0.4931],\n",
      "        [ 0.0198,  0.4049,  0.1957,  ...,  0.3113, -0.5699, -0.2217]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[ -3.0499, -11.0458, -14.9944,  17.0363,  41.7376,  11.3176,  -1.3310,\n",
      "          -15.0464],\n",
      "         [-15.5546,  26.8352, -36.6965,   7.0141,  -4.7385, -21.7792,  -9.6379,\n",
      "          -15.1696],\n",
      "         [ -3.2580,  20.5110,  17.9837,  -9.0519,  36.5099,  12.9700,  -7.5444,\n",
      "            6.9670],\n",
      "         [ 37.3638,  15.9489, -56.6341,   7.7724, -13.2474,  -8.7239,   8.8976,\n",
      "          -14.6601],\n",
      "         [  9.3588,  33.6563,  19.9097,  51.4053,  -2.3290,  18.4385, -24.7270,\n",
      "           40.9971],\n",
      "         [-15.2055,   9.8950,  -3.1541, -32.0378,   1.8012, -16.8589, -14.5674,\n",
      "          -23.1274],\n",
      "         [ -1.5597, -19.9653, -31.9686,   8.1708,  46.4157, -13.1376,  -2.7174,\n",
      "          -15.8786],\n",
      "         [-27.4833,   1.6380, -22.6465,  -5.3716, -16.6121, -15.2430,  14.0288,\n",
      "           17.2731],\n",
      "         [  6.1677,  -5.9589, -14.0734,  29.5403, -19.8166,   6.5942, -14.5210,\n",
      "            3.5494],\n",
      "         [  7.9641,  13.2105, -31.7037,  -8.6301,   2.7114,   3.1792, -28.6711,\n",
      "           24.6685],\n",
      "         [ 13.1709,  15.1385,  -0.3628,  21.5902,   6.1698,  27.3343,  -2.7117,\n",
      "           58.8718],\n",
      "         [  1.8538,  -6.0530, -20.9460, -38.7223,   7.8577,  32.8527,  26.3000,\n",
      "           32.7008],\n",
      "         [ 17.0227,  21.0943, -26.4785,  22.3906, -17.3799,  -4.4780, -29.6840,\n",
      "           48.5376],\n",
      "         [ 25.7479,  17.4284,   7.0418, -34.3768, -17.1754, -10.8476,   9.0361,\n",
      "           -5.6344]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.3854, -0.2868,  0.3801,  ...,  0.3906, -0.5309, -0.0061],\n",
      "        [ 0.1154,  0.1106, -0.1334,  ...,  0.3087, -0.5137, -0.8137],\n",
      "        [ 0.0718,  0.0037, -0.2925,  ...,  0.5484,  0.2434, -0.1202],\n",
      "        ...,\n",
      "        [-0.0707, -0.4901, -0.0784,  ...,  0.6369,  0.3755, -0.1133],\n",
      "        [ 0.3665,  0.1309,  0.0140,  ..., -0.0668,  0.1593,  0.0999],\n",
      "        [ 0.1615, -0.2071,  0.3535,  ..., -0.6547,  0.3501, -0.0172]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[ 49.2709, -17.0438, -68.4289,  48.4324,  40.7911, -25.5071,  11.5904,\n",
      "          -17.8572],\n",
      "         [ 21.5483,  42.3596,  -1.3249, -11.3003, -14.5836, -29.1365, -55.9370,\n",
      "           12.4878],\n",
      "         [ 17.5898,  43.8666,  -2.2339,  10.7244, -43.6612, -84.5935, -28.7712,\n",
      "          -47.4674],\n",
      "         [  1.6950, -27.2862, -85.4637,  42.0055, -38.3069,  -5.7037,  71.6015,\n",
      "           -9.4518],\n",
      "         [-46.0693, -69.0685,  51.5323,  57.6580,  20.3704, -19.4374,  38.1079,\n",
      "           71.0064],\n",
      "         [ 36.3919,   7.0135,  20.0886,   4.7519,   7.5052,  -6.6046, -42.9866,\n",
      "           -1.8382],\n",
      "         [ -2.1379,  -1.9189, -58.5409,  -9.1001,  -2.8823, -32.7861, -12.9018,\n",
      "           20.1827],\n",
      "         [-55.6861,  -1.7671, -83.3662, -48.7596, -27.8083, -28.2353,   5.8040,\n",
      "          -20.9088],\n",
      "         [-43.1149,  -2.4540, -33.5232, -60.1323,   5.6673,   2.7005, -20.7756,\n",
      "           65.1560],\n",
      "         [-48.2457,  -0.8732,  32.8094,  32.3033,  32.7461, -67.4333,  58.8367,\n",
      "           19.1670],\n",
      "         [ 16.9744,  65.1635,   3.0583,  76.4530,  21.2473, -66.8835, -52.5194,\n",
      "           14.4477],\n",
      "         [ 29.0836,   0.2881, -18.9832,  26.5740, -58.9234, -13.7260,  22.3039,\n",
      "           77.4572],\n",
      "         [ 69.3995,  -5.0319, -23.2214,  10.3696,  -2.7153,   9.4230, -51.5181,\n",
      "            2.3377],\n",
      "         [ 32.8575, -18.5463, -48.5724,  18.6103,   6.6456, -11.6331, -28.0205,\n",
      "          -84.0507]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.1532,  0.4860,  0.0025,  ...,  0.1570,  0.0726,  0.7409],\n",
      "        [ 0.2568,  0.4020,  0.3738,  ..., -0.0224,  0.1368, -0.0671],\n",
      "        [ 0.7591, -0.1324,  0.1085,  ..., -0.7338,  0.1361, -0.3219],\n",
      "        ...,\n",
      "        [ 0.0362, -0.1090,  0.3151,  ...,  0.1330, -0.2717,  0.3521],\n",
      "        [-0.8323,  0.2063, -0.4029,  ..., -0.0535, -0.1900, -0.1749],\n",
      "        [ 0.5533,  0.4571, -0.4842,  ...,  0.2812,  0.1652,  0.1990]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[ 41.7128,  -1.8020,  46.9638, -34.6859,  30.7515, -36.3047, -33.1684,\n",
      "          -18.6547],\n",
      "         [ 17.0402,  23.3505,  61.0888,  31.3607,  35.5606,  14.7782,  71.6042,\n",
      "          -28.4471],\n",
      "         [ 28.8518, -11.1857,  11.5598,   8.7821,  -9.5450, -33.3165, -23.2813,\n",
      "            4.9364],\n",
      "         [ 59.0969,   7.6955,   1.7837, -20.7830, -37.6020,  -8.8648,  52.9432,\n",
      "          -10.8703],\n",
      "         [ 30.6446,  15.4712,  -3.7714,   8.5274,  79.8569, -24.7791,   6.6265,\n",
      "           52.6310],\n",
      "         [ 22.2230, -77.5014,  -3.6344,  12.5663, -94.1758,  45.2142,  -6.0012,\n",
      "          -59.7460],\n",
      "         [ -3.7547,  17.6825,  20.6222, -53.2682,  40.9621,  -6.0581,  86.3153,\n",
      "           21.9629],\n",
      "         [-43.2220, -83.8835,  22.1461,  31.5892,  45.7979,   8.1860,  24.9247,\n",
      "           12.1014],\n",
      "         [-16.8704, -41.6501, -39.7566, -73.4784, -73.7724,  21.6336,   5.5994,\n",
      "          102.6442],\n",
      "         [ -5.1647,  39.7760,  -0.5520, -79.8056,  62.4345, -18.3531,  45.1880,\n",
      "           26.4498],\n",
      "         [-56.5559,  23.0258, -77.8909, -24.7452,   9.4758, -35.1266,  -1.5957,\n",
      "          -13.4971],\n",
      "         [  0.3538, -30.4674, -41.4486, -61.9368, -21.6318,   8.8057,  38.6770,\n",
      "           41.6152],\n",
      "         [ 31.0154,  94.5392, -35.2061, -25.8464,  -9.0764, -24.0688, -87.6361,\n",
      "           -9.8529],\n",
      "         [ -5.2731, -10.8131,   8.4102,  29.5085,  -1.9948, -20.5480,  27.8493,\n",
      "          -56.6928]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=14336, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[-0.0611,  0.0013,  0.3942,  ..., -0.8139, -0.1475, -0.0068],\n",
      "        [-0.0261, -0.1718,  0.2946,  ..., -0.3245,  0.4191, -0.1427],\n",
      "        [ 0.2640,  0.3649, -0.2211,  ..., -0.5138, -0.2246, -0.1416],\n",
      "        ...,\n",
      "        [-0.0010, -0.0846,  0.4021,  ..., -0.5373,  0.2788, -0.0653],\n",
      "        [ 0.9216, -0.3845,  0.0590,  ..., -0.0301, -0.4022,  0.1321],\n",
      "        [-0.0553, -0.0863, -0.2114,  ..., -0.2012, -0.5234, -0.1739]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[ 36.1280,  50.2807,  13.5594, -17.2815,  56.6940, -10.9836,  -1.6003,\n",
      "           -6.2982],\n",
      "         [ -7.4413,  48.6571,  41.2510,  -7.0284, -11.3226,  -3.3533,  29.7689,\n",
      "           25.3066],\n",
      "         [-11.6659,   5.5951, -16.7391,   0.3989,  -7.0997,  37.9272,  24.1052,\n",
      "           13.1598],\n",
      "         [ 37.6245,  -3.0650,   7.8144,  13.6821, -27.4799, -31.9406,  -2.9661,\n",
      "           29.3657],\n",
      "         [-54.3899,  18.5298,  -6.7235,  -6.4019, -24.0725, -12.6018, -28.8824,\n",
      "            0.8255],\n",
      "         [ 28.7493, -30.2164,  14.0833,  -2.0964, -37.4078, -16.8082,  -0.8843,\n",
      "          -25.6480],\n",
      "         [ -3.9945,  24.2763,  -9.8342,  47.6653, -38.7077,  -8.5049, -55.4175,\n",
      "          -36.6162],\n",
      "         [ 24.5200,  25.6706, -25.0766,  27.4540, -11.2019, -12.3925,  59.4471,\n",
      "          -62.9737],\n",
      "         [-19.1175, -28.2284,  14.7157,  27.7789,   1.4729,  11.9622,  -7.7588,\n",
      "           -8.3619],\n",
      "         [ 43.5842, -12.1055, -12.0213,  -2.8695, -24.7396,   7.7548, -34.9058,\n",
      "          -25.3290],\n",
      "         [-48.8196,  -7.2444,  -6.1571,   9.4522, -35.4439,  16.1763, -25.3326,\n",
      "           22.6558],\n",
      "         [ 35.7209,  36.7782,  10.4946,   8.7562, -11.9729, -20.4604,   6.3342,\n",
      "          -10.2282],\n",
      "         [ 14.9744, -41.8067, -24.3625, -22.1070, -15.6258,  15.7339, -29.7501,\n",
      "          -26.5047],\n",
      "         [-16.4023,   2.3661, -11.7502,  13.6143,  36.8698, -42.7339, -19.5172,\n",
      "          -21.1052]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[-0.1553,  0.7724,  0.4169,  ...,  0.2344, -0.5325, -0.0287],\n",
      "        [ 0.2534,  0.2760,  0.2059,  ..., -0.1207, -0.1278, -0.0109],\n",
      "        [ 0.0183, -0.3972, -0.1721,  ..., -0.1118, -0.4905, -0.3288],\n",
      "        ...,\n",
      "        [ 0.2509, -0.2801, -0.0953,  ..., -0.2441,  0.9910, -0.2193],\n",
      "        [-0.3034, -0.3992, -0.1830,  ...,  0.2012, -0.0586,  0.1120],\n",
      "        [ 0.0165,  0.4702,  0.0232,  ..., -0.4571, -0.2617,  0.5024]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[  4.1111,   7.5593, -12.8927,   0.4066,  -1.0902,  26.0820,  56.6772,\n",
      "            4.6174],\n",
      "         [ 22.3319, -13.3785,  32.2212,  -6.3635,  11.8441,  39.2219,  -9.4770,\n",
      "           12.3792],\n",
      "         [ 18.1674,  -1.1608, -16.2080,   6.9063,  16.9507,  -4.8762, -11.0875,\n",
      "            6.6012],\n",
      "         [-10.5887,   6.8577,  42.3949,  29.3674,  38.1342,  22.9407,   0.3789,\n",
      "           31.1166],\n",
      "         [  1.3361,  40.8475,  -2.3337, -15.5710,  33.7696, -27.2532,  10.5171,\n",
      "          -16.5799],\n",
      "         [ 10.3316, -28.8649,  42.5629,   7.0652,  34.3032, -26.7956,  19.6565,\n",
      "           33.9064],\n",
      "         [ 50.2535,  20.9327,  28.7704,  11.1653,   0.0737, -23.5762,  24.4092,\n",
      "          -19.8552],\n",
      "         [-27.2578,  25.7148, -18.0401, -10.9950,  34.1392,  23.5305,  11.2015,\n",
      "          -44.1448],\n",
      "         [ 22.7442, -60.6398,   2.1320,  43.2606, -20.5297,  -4.7910,   2.6072,\n",
      "          -49.7170],\n",
      "         [ -3.6011, -26.1110,  53.6814, -27.1511, -28.4642,  13.7197,   4.0621,\n",
      "            4.6171],\n",
      "         [-19.3185,   9.7756,  -9.8101, -39.6937, -17.9217,  26.9503,  18.2977,\n",
      "            9.3003],\n",
      "         [ 11.0687, -20.6265,  -6.5123,  -5.4181,  27.3021,  21.2187,  -4.2505,\n",
      "          -46.2004],\n",
      "         [ 10.5844,   3.1474,  16.5854, -25.6278,   9.8496,  26.2954,   7.1115,\n",
      "          -14.0413],\n",
      "         [-10.4755,   0.7182,  68.9524, -18.6763,   9.9877,  -6.2650,   1.4716,\n",
      "           14.0017]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[-0.6205,  0.1046, -0.5619,  ..., -0.3707, -0.4951, -0.5001],\n",
      "        [-0.2319,  0.0470,  0.2959,  ...,  0.1238, -0.2355, -0.2033],\n",
      "        [ 0.3544, -0.1008,  0.4743,  ...,  0.4041,  0.2004,  0.1220],\n",
      "        ...,\n",
      "        [-0.3936, -0.0496,  0.0412,  ...,  0.2320, -0.2642,  0.8007],\n",
      "        [-0.5199,  0.8206,  0.0360,  ..., -0.1277, -0.5745,  0.3799],\n",
      "        [ 0.0418,  0.2138,  0.0707,  ..., -0.3063, -0.2589, -0.1840]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[  1.1283,   5.6767,   1.7487,   9.8339,   0.6320,  -3.3717,  -0.6115,\n",
      "           -1.3984],\n",
      "         [  1.8375,  -1.4782,  15.5446,   7.4671,   0.5632,  -3.2781,   4.7435,\n",
      "            9.1130],\n",
      "         [ -7.1745, -10.1224,  13.4609,   5.4612, -10.4199,  -1.4058,   6.8066,\n",
      "            7.9475],\n",
      "         [ -1.3665,  21.3803,   0.4680,  -6.9807,  -9.1768, -13.6028,  -5.3992,\n",
      "          -10.0041],\n",
      "         [ 13.3640,   6.9008,   1.0769,  -4.0246,  11.8544, -17.2815, -12.1383,\n",
      "            2.3660],\n",
      "         [ 16.0770,   1.5121,   1.4901,   6.9362, -17.6081,   6.1645,  -4.4194,\n",
      "          -19.4827],\n",
      "         [  9.8260,   6.2597, -15.6971, -35.2908,   7.9349,   2.2679,  28.9880,\n",
      "            7.7112],\n",
      "         [ -2.1497,  -3.7549,  -0.2056,  24.4809,  -0.8259,  12.0857,   0.3388,\n",
      "            2.7624],\n",
      "         [-13.7035,   6.4086,  -1.8943,   7.6697,  -0.5552, -21.3664,  12.1962,\n",
      "           -4.7370],\n",
      "         [  7.3274,   1.3227,  12.2460,  -4.3272,   0.7344, -22.8392,  -3.7470,\n",
      "           26.4460],\n",
      "         [ -5.4238,   6.5452,  -6.5667,   7.5498,  -8.7708,  -5.6010,   5.8604,\n",
      "            8.7913],\n",
      "         [ 15.1890,   2.6845,  -7.3364,  -8.6378, -11.1265,   9.0698,  -4.4141,\n",
      "           -0.2076],\n",
      "         [ 16.9142,  18.3892,  10.3502,  13.2076,   9.0782,  -9.2004, -24.3295,\n",
      "          -21.6608],\n",
      "         [-12.6921,  -2.8869,  15.4603,   1.9386,   1.6746,  13.4020,   4.1074,\n",
      "          -10.2600]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.0401, -0.0075, -0.2272,  ..., -0.0831,  0.2592, -0.3207],\n",
      "        [ 0.2864,  0.3313,  0.3252,  ..., -0.1433,  0.5486,  0.1250],\n",
      "        [-0.2108,  0.1835, -0.5909,  ..., -0.2565,  0.0731,  0.1586],\n",
      "        ...,\n",
      "        [-0.3664,  0.2786,  0.4180,  ...,  0.2505,  0.0152, -0.6039],\n",
      "        [ 0.0960, -0.1913, -0.1593,  ..., -0.2567,  0.0659, -0.2380],\n",
      "        [-0.1832, -0.3936, -0.2315,  ..., -0.0814,  0.5718, -0.3213]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[ 5.7604e+00,  6.0421e+00,  1.5953e+01,  8.5249e+00, -5.4069e+00,\n",
      "          -1.0446e+01, -2.1703e+01,  2.4736e+00],\n",
      "         [-1.5265e+01,  1.4943e+01,  4.8358e+00,  8.3198e+00, -2.3046e+00,\n",
      "          -7.9108e+00,  1.4094e+00, -1.0845e+01],\n",
      "         [ 3.0891e+00,  6.7180e+00, -1.3072e+00,  3.3779e+00, -1.5609e+01,\n",
      "          -1.7914e+01,  1.1857e+01,  2.5955e-03],\n",
      "         [ 6.4645e+00,  1.0557e+01,  1.0703e+01,  1.3310e+01,  1.5644e+01,\n",
      "          -1.2713e+00, -6.4603e+00,  6.4793e+00],\n",
      "         [ 1.3789e+01,  5.4732e+00, -1.5753e+01,  5.4589e+00, -8.8095e+00,\n",
      "           3.6675e-01, -1.6320e+01, -2.1051e+00],\n",
      "         [ 1.2185e+01, -1.3165e+01,  3.0591e-01, -4.8491e+00,  1.1101e+01,\n",
      "           1.0279e+00, -6.4230e+00, -1.4627e+01],\n",
      "         [-1.2903e+01, -7.3331e+00,  3.4535e+00, -2.4944e+00,  1.6907e+00,\n",
      "          -2.3630e+00, -8.0009e+00, -3.4692e+00],\n",
      "         [-5.9642e+00, -1.2371e+00,  8.2278e+00,  2.9423e+00, -9.4036e+00,\n",
      "          -9.3722e+00, -3.4045e+00, -6.9725e+00],\n",
      "         [-1.9701e+01,  9.9227e+00,  1.5211e+01, -6.6363e+00,  6.4740e+00,\n",
      "          -4.6812e+00, -1.8034e+01, -9.0740e+00],\n",
      "         [ 1.1838e+00, -1.6772e+01,  1.0108e+01, -3.1572e+00,  3.3830e+00,\n",
      "           2.2735e+00, -3.9899e+00,  1.2775e+01],\n",
      "         [-3.8176e+00,  5.0349e+00, -1.4785e+01, -1.0673e+01,  1.1042e+01,\n",
      "          -4.4612e+00,  1.8700e+00, -1.3026e+01],\n",
      "         [-1.3157e+00,  1.2427e+01, -4.1030e+00,  5.8820e+00, -4.8117e+00,\n",
      "          -1.6233e+01,  2.4296e+00,  3.3142e+00],\n",
      "         [ 1.2835e+00, -1.4579e+00,  5.6514e+00, -9.7445e+00, -2.1260e+00,\n",
      "          -1.8280e+00,  6.9997e+00, -1.1590e+01],\n",
      "         [ 8.7030e+00,  2.1391e+01, -2.0740e+00, -1.3062e+01, -8.7720e-01,\n",
      "           8.7198e+00, -1.2438e+01,  6.7924e+00]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[-0.2655,  0.6422, -0.1069,  ..., -0.1916, -0.2279, -0.0216],\n",
      "        [-0.0767,  0.0859,  0.2399,  ...,  0.0628, -0.3322,  0.3375],\n",
      "        [ 0.2140,  0.3524, -0.2868,  ...,  0.1459, -0.1872, -0.3841],\n",
      "        ...,\n",
      "        [-0.2570,  0.1623,  0.5165,  ..., -0.0178, -0.7567, -0.0918],\n",
      "        [-0.0375,  0.6943, -0.2998,  ..., -0.0383, -0.2844, -0.5676],\n",
      "        [-0.2180,  0.2637,  0.4054,  ..., -0.4969, -0.3998, -0.0192]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[  6.6296, -23.2273,  42.8386,  14.7541,  -0.3952,   9.7039, -29.9156,\n",
      "            1.0151],\n",
      "         [ 19.1914,   5.4152,  13.1213,   6.5108,   8.1204,  45.5748, -22.8715,\n",
      "          -40.1737],\n",
      "         [-46.5033,   7.2360,  23.1655, -12.5607,  -8.2659, -26.9174,  24.1337,\n",
      "           -4.9529],\n",
      "         [ 26.0601,  37.7830,   7.2140,  40.8027,   9.9832, -38.2956,   4.4834,\n",
      "            5.0484],\n",
      "         [  4.4102,  43.2637, -32.8028, -11.8922,   8.3428,  -6.4984, -14.2236,\n",
      "          -20.2966],\n",
      "         [ 48.8773, -11.5216,  23.2525,   6.0722, -38.3435, -18.7780, -39.8863,\n",
      "           -9.7618],\n",
      "         [-16.0007,   2.3292,   0.6935,  22.2507, -18.1748,  22.4726, -19.3624,\n",
      "            3.7114],\n",
      "         [-21.3131,  15.4331,  24.4728,  21.6096,  15.7052, -21.4290, -22.7454,\n",
      "          -11.7418],\n",
      "         [ 19.7400,   8.4505,   5.5181,   6.6360, -13.8490,  -8.3100, -32.4955,\n",
      "           -1.7455],\n",
      "         [ -8.7858,  -1.0518, -14.8751,  12.6295,  16.0045,  -6.5161, -17.7965,\n",
      "          -14.8717],\n",
      "         [ -2.7470,  11.5862, -46.0172,  24.8304,  45.0351,  -6.2067, -31.1785,\n",
      "            4.4873],\n",
      "         [ 41.5555, -47.9781,  -6.2621,  25.9745,   4.5975, -18.6273,   6.4516,\n",
      "            0.4815],\n",
      "         [  2.6163,   6.0095,  -7.4222,  -4.2363, -18.3984,   3.2214, -16.8195,\n",
      "          -12.9033],\n",
      "         [ 49.7855, -17.4668, -30.5602,  15.4858,  27.6644,  15.3445, -47.6588,\n",
      "          -25.2359]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.1916, -0.0903, -0.0468,  ...,  0.1898, -0.3409, -0.1346],\n",
      "        [ 0.1555,  0.2767,  0.2001,  ...,  0.2985, -0.0469,  0.1665],\n",
      "        [ 0.0132,  0.0799, -0.3635,  ...,  0.0834, -0.3414, -0.0452],\n",
      "        ...,\n",
      "        [ 1.0394,  0.1612,  0.1925,  ..., -0.1387, -0.3273, -0.0704],\n",
      "        [ 0.0702,  0.1096,  0.1310,  ..., -0.1614, -0.0764,  0.5704],\n",
      "        [-0.1088, -0.1751, -0.5602,  ..., -0.1243,  0.0992,  0.4635]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[ -22.2461,   38.6746,   32.8683,   -5.1348,   12.8369,   11.6102,\n",
      "            -4.1691,  -11.1906],\n",
      "         [ -79.6402,  -19.7120,  -46.4635,  -64.7173,  -51.8524,  -15.4721,\n",
      "            18.5111,   -0.7499],\n",
      "         [ -36.7991,   87.8162,    7.0315,  -15.3437,   62.5913,   -0.6096,\n",
      "            16.5359,  -11.6914],\n",
      "         [ -12.8502,   77.4502,  -98.0727,  -39.3479,  -13.5946,   60.4040,\n",
      "          -120.2639,   89.5285],\n",
      "         [  -4.3825,  -20.4574,   34.4158,   -2.2312,  -57.2334,    0.9315,\n",
      "           -63.8550,   -9.9784],\n",
      "         [  12.1512,  -22.3604,  -96.1322,  -25.7658,   20.1919,   37.5371,\n",
      "            77.7439,   -5.8033],\n",
      "         [  30.7642,  -68.3723,   33.1328,  -23.6016,  -57.3095, -120.2663,\n",
      "           -52.5547,  -22.0913],\n",
      "         [  79.5498,   -1.5338,   31.7853,   24.6306,    9.3764,    7.6555,\n",
      "            40.8314,   14.5604],\n",
      "         [ -11.7326,  -13.4949,  -20.0198,   65.4275,   19.3832,   16.5565,\n",
      "           -13.0388,   16.0331],\n",
      "         [ -32.9765,   11.1185,  -50.5557,    8.9553,   48.4843,   35.0773,\n",
      "             5.8735,  -50.3649],\n",
      "         [ -22.2723,  -11.0624,  -48.8286,  -24.1823,    6.8778,    7.3992,\n",
      "           -33.0184,   58.7538],\n",
      "         [ -68.9390,   20.6606,   10.0524,   -6.3824,  -41.1781,   56.7616,\n",
      "           -11.7918,  -36.9297],\n",
      "         [  23.1890,   33.0102,   -1.5172,   26.4130,   34.6247,   17.6875,\n",
      "             9.7313,  -33.6675],\n",
      "         [  27.5479, -123.0397,  -28.0459,  -64.8916,   16.8577,    1.6617,\n",
      "            47.4501,    2.1438]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[-0.0428, -0.0826,  0.5020,  ..., -0.5360, -0.5200,  0.2879],\n",
      "        [-0.1307, -0.6808, -0.0169,  ..., -0.3879, -0.0895,  0.1338],\n",
      "        [-0.2985, -0.4657, -0.5772,  ..., -0.3988, -0.3975, -0.3315],\n",
      "        ...,\n",
      "        [ 0.3254, -0.9032, -0.3102,  ..., -0.2375,  0.1309, -0.2419],\n",
      "        [-0.1529,  0.4674, -0.2916,  ...,  0.1529,  0.2918, -0.1806],\n",
      "        [-0.2172, -0.1589,  0.2730,  ..., -0.0228,  0.0127,  0.3220]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[  10.8525,  -16.7154,  -33.0241,   38.4234,   22.4413,  -58.2645,\n",
      "             6.9279,  -40.1795],\n",
      "         [   9.7862,    5.6854,  -50.8371,    6.8000,   97.9877,  -21.8743,\n",
      "            -9.8532,  -49.3920],\n",
      "         [  19.4840,   25.9107,    9.3780,  -46.5282,  -68.3678,  -28.5500,\n",
      "           -20.2933,  -40.4351],\n",
      "         [  54.2042,    1.3444,   15.8575,  -62.6299,  -82.6269,   36.4136,\n",
      "           -54.0219,   21.8648],\n",
      "         [ -34.5529,   24.3497,   49.2177,   30.8712,    9.5257,    0.8030,\n",
      "           -29.7544,  -37.2272],\n",
      "         [  43.8508,   78.4208,   22.1200,    1.3223,   45.0065,   13.2978,\n",
      "            11.3072,  -23.4167],\n",
      "         [  28.2016,   43.0282,  -28.4143,  -24.8485,    9.4779,   32.9192,\n",
      "            30.7148,  -32.9346],\n",
      "         [ -13.3540,  -25.1631,   51.0978,  -13.4777,  -18.1095,  -36.6445,\n",
      "            45.9952,   -1.8079],\n",
      "         [  54.1848,  -53.0899,  -19.7857,    5.5051,  -11.3353,  -20.2549,\n",
      "            -5.1021,  -60.6918],\n",
      "         [ -49.5203,  -32.4874,   -9.6119,    8.1965,  -31.4573,    0.3686,\n",
      "           -14.4215,  -52.6112],\n",
      "         [  33.4752,   -4.4365, -101.3927,   11.7883,    4.2273,   -3.8136,\n",
      "            -8.5804,  -27.3140],\n",
      "         [   1.3366,  -15.5584,  -39.9907,   22.3422,   26.1721,  -17.0587,\n",
      "            31.4372,   17.1298],\n",
      "         [  40.6688,  -49.3706,    2.1279,  -38.6199,  -20.1088,  -86.7930,\n",
      "           -15.4247,   17.4232],\n",
      "         [ -76.9896,   15.6005,  -75.8516,   -1.2785,  103.7494,  -11.9386,\n",
      "            49.6093,  -15.5020]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=14336, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.0239,  0.0174, -0.2806,  ..., -0.5949,  0.4200,  0.1206],\n",
      "        [-0.4819, -0.0982,  0.3582,  ..., -0.4114,  0.5497,  0.2409],\n",
      "        [-0.0496, -0.1725,  0.7104,  ...,  0.8999,  0.2259,  0.0033],\n",
      "        ...,\n",
      "        [-0.3421,  0.1452,  0.1653,  ...,  0.0640, -0.2050,  0.2506],\n",
      "        [ 0.4658, -0.0356, -0.3816,  ..., -0.3039,  0.0552, -0.1047],\n",
      "        [-0.1532, -0.0300,  0.9123,  ..., -0.5097, -0.0978, -0.1439]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[  1.7507, -21.9698,   9.3781, -18.8283, -22.2364, -29.8832, -25.0404,\n",
      "          -49.6495],\n",
      "         [ -4.2563, -16.0146, -15.1392,  -5.7495,  -0.6646, -16.7727,   0.6483,\n",
      "          -25.1917],\n",
      "         [-57.2707,   2.9769, -32.6325,  -4.4877,  13.5191,  -6.9154,   8.2171,\n",
      "           45.7505],\n",
      "         [ -4.1278, -33.9976,  17.7322, -12.5251,  12.6857,  24.9077,  32.6919,\n",
      "           22.8989],\n",
      "         [ -8.6306, -18.3175,   4.9793,  -0.2991,  -9.6779,  -2.6711,  32.5670,\n",
      "           -6.0535],\n",
      "         [ -8.6270,  14.0724,  -4.2888, -11.7612,  21.0341, -41.8592, -41.9408,\n",
      "           -1.0146],\n",
      "         [-43.2679,   8.2766,  22.9434,   5.9916,  14.7674, -42.5835, -22.6669,\n",
      "           40.0902],\n",
      "         [-32.2805,  39.4643,   4.7878, -19.3433, -52.0041,  28.1329,  26.7126,\n",
      "           -0.6658],\n",
      "         [ -9.2178,  15.7741,  30.6534, -22.1684,  -3.0246,   2.2434,  13.4374,\n",
      "           19.9779],\n",
      "         [ 32.9060, -11.4106,   9.1190,  -9.3773, -64.4782,  -6.3816,   3.6818,\n",
      "           35.8941],\n",
      "         [-12.7259, -30.5426,  -0.7205,   2.5638, -43.5753,  10.8367, -21.8137,\n",
      "          -22.3185],\n",
      "         [-42.1339,  18.3335,  -5.5760,  24.8333,   8.3370,  38.5658, -41.0631,\n",
      "          -22.5366],\n",
      "         [  2.7510, -16.1227,  27.6558, -17.7812,  -6.9243,  26.8403, -20.1665,\n",
      "           12.0057],\n",
      "         [ -9.0664,   8.0260, -22.9219, -17.8329,   6.1048,  44.9433, -34.7846,\n",
      "           -4.2407]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 3.2180e-01,  6.9030e-02, -4.3029e-01,  ...,  8.7168e-02,\n",
      "          2.3183e-01, -1.3346e-01],\n",
      "        [-6.1111e-01,  2.4784e-01,  3.0996e-01,  ..., -5.9007e-01,\n",
      "          5.1940e-01,  1.0698e-01],\n",
      "        [ 2.1416e-01, -8.6610e-02,  5.4570e-01,  ..., -1.6651e-03,\n",
      "         -8.6704e-04,  1.9752e-01],\n",
      "        ...,\n",
      "        [ 4.1074e-02,  3.0544e-01, -2.5737e-01,  ..., -2.1863e-01,\n",
      "         -7.6478e-02,  1.2559e-01],\n",
      "        [ 1.3958e-01,  1.9317e-01, -4.1856e-01,  ..., -2.4281e-01,\n",
      "          3.5436e-01, -8.2668e-02],\n",
      "        [ 9.4657e-02, -2.0321e-01,  3.1325e-01,  ..., -4.4076e-01,\n",
      "         -2.5017e-01, -9.4519e-01]], device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[-12.7961, -21.1463,   3.6246,  -7.9334, -26.4449,  22.3612,  22.0290,\n",
      "          -18.4813],\n",
      "         [ 33.6916,   5.0976,   0.9614,  39.1986, -47.7950,  -1.7266,   7.9943,\n",
      "          -23.6607],\n",
      "         [-19.0653,   3.4249,  21.7780, -16.1694,   8.6064,  -9.0164,   0.9945,\n",
      "          -18.1060],\n",
      "         [  1.3903, -15.8970, -40.3915,  -4.2639, -22.2893,  31.6117, -13.5412,\n",
      "          -29.3983],\n",
      "         [ -9.1107,  29.4889,  34.5664, -49.2575,  22.7885,  14.5267,   0.8432,\n",
      "            0.1841],\n",
      "         [  4.9206,   3.0785,  -5.7364,   6.5930,  -7.7110, -10.0248,  22.0880,\n",
      "           -1.2896],\n",
      "         [ -8.8757,   8.1557,  18.4276,  13.5160,  18.8860,   7.1419,  11.2324,\n",
      "            7.1092],\n",
      "         [  4.3972, -47.2457,   9.6439,  19.2390,  29.2140,  20.5425, -11.3205,\n",
      "           29.2173],\n",
      "         [ 14.3676, -13.6955,   7.6219,  35.0310,  -9.7942, -13.1738,  28.0350,\n",
      "           12.3895],\n",
      "         [ -9.2245,   1.0869, -28.1781,  24.3085,  19.0733,  10.1482,  -4.2639,\n",
      "          -27.4377],\n",
      "         [-36.9533,  -0.4047,  19.9517,   3.9606,   5.0969,  21.5055,  14.7668,\n",
      "            5.7994],\n",
      "         [ 36.1350,  -1.2643,  -9.4419,  -0.7005,  -2.7997,  44.5865,  26.3509,\n",
      "           -1.0370],\n",
      "         [ 22.5633,   6.0964,   1.5892, -44.4572, -16.1950,  22.1878,  20.9074,\n",
      "           -2.5348],\n",
      "         [-37.2182,   7.7638,  18.2671,  25.8753, -11.6498,  11.5329,  48.4012,\n",
      "          -32.1807]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[-0.2647, -0.5366,  0.2374,  ..., -0.2755, -0.5683,  0.2356],\n",
      "        [-0.0460,  0.0389,  1.2530,  ..., -0.1607,  0.1455, -0.0456],\n",
      "        [ 0.5171,  0.1360,  0.1721,  ...,  0.6276, -0.6601,  0.7579],\n",
      "        ...,\n",
      "        [-0.2620, -0.1211, -0.4051,  ...,  0.1716, -0.0377,  0.3038],\n",
      "        [-0.2574, -0.8329,  0.3635,  ..., -0.2136,  0.3680, -0.0366],\n",
      "        [-0.0918, -0.7331,  0.7411,  ...,  0.3442, -0.2746, -0.3742]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[-1.0400e+00,  1.2421e+01, -2.4140e+00, -2.5863e+00, -7.2900e+00,\n",
      "           1.0150e+01, -9.6440e+00, -2.7876e-01],\n",
      "         [ 2.9410e+00, -3.6058e+00,  1.0253e+01, -6.7921e+00, -1.4069e+01,\n",
      "          -2.0836e+01,  1.5989e+01, -7.0005e+00],\n",
      "         [ 1.6735e+01, -6.7784e+00, -1.1706e+01, -4.2833e-03, -1.2590e-01,\n",
      "          -2.6583e+00,  5.7976e+00,  1.7978e+01],\n",
      "         [-3.5326e+00,  3.3321e+00, -1.1533e+01,  7.6985e-01,  1.1777e+01,\n",
      "          -1.0290e+01, -1.6470e+01, -1.2396e+00],\n",
      "         [ 5.1698e+00,  1.7435e+00,  4.7551e+00, -3.0145e+00, -9.3017e+00,\n",
      "           1.7549e+01, -1.5614e+00, -8.4640e+00],\n",
      "         [-1.9805e+00,  2.6749e+00,  2.0843e+00, -5.5684e+00, -7.4638e+00,\n",
      "           3.6167e+00, -1.6407e+01, -1.1246e+01],\n",
      "         [-6.5509e+00, -7.4512e+00, -9.4152e+00,  1.2551e+01,  5.8405e+00,\n",
      "          -5.6845e+00,  1.5396e+01,  4.1311e+00],\n",
      "         [ 7.6411e+00,  4.9648e+00,  1.0316e+01,  8.4115e+00,  1.5533e+01,\n",
      "           7.5689e-01, -3.1303e+00, -7.0724e+00],\n",
      "         [-3.2458e+00, -2.8645e+01, -1.6632e+01,  8.6706e+00, -5.2512e+00,\n",
      "          -2.0734e+01, -9.5953e+00, -1.4105e+01],\n",
      "         [ 2.3264e+01, -2.4700e+00,  1.6067e-01,  7.8092e-01,  3.8814e+00,\n",
      "           2.2431e+01, -2.3213e+00,  1.1712e+01],\n",
      "         [-8.9717e+00, -4.8518e+00,  1.3524e+01,  7.7511e-01,  3.4916e+00,\n",
      "          -1.6619e+01,  5.9870e+00, -1.0245e+01],\n",
      "         [ 1.4616e+01,  1.2363e+01,  3.7454e+00,  5.4961e+00, -2.7912e+00,\n",
      "          -7.5177e-01, -9.8988e+00,  8.3361e+00],\n",
      "         [-1.8614e+01,  2.1245e+01, -1.5802e+01,  1.8696e+01, -1.3425e+01,\n",
      "          -1.1901e+01, -1.7001e+01, -4.1459e+00],\n",
      "         [-2.2269e+01, -5.1950e-01, -4.1335e+00, -8.0797e+00,  1.0728e+01,\n",
      "           1.2894e+01,  6.2491e+00,  6.6177e+00]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.5787, -0.1381, -0.1485,  ...,  0.1974,  0.0998,  0.3835],\n",
      "        [ 0.1542,  0.0608, -0.4864,  ..., -0.0338, -0.2055, -0.2454],\n",
      "        [ 0.0123,  0.3011,  0.2139,  ..., -0.0772, -0.4481,  0.2513],\n",
      "        ...,\n",
      "        [-0.1902,  0.4852,  0.0360,  ..., -0.3941,  0.3615, -0.2342],\n",
      "        [-0.7427,  0.2721, -0.6525,  ..., -0.0212,  0.2776,  0.1126],\n",
      "        [ 0.0840, -0.1566, -0.3541,  ...,  0.1131,  0.0417, -0.5419]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[  3.9715,  14.5949,  26.1766,   0.1225,  36.5979, -13.2982,  -9.8904,\n",
      "          -13.5788],\n",
      "         [ -7.5837,   0.8805,   7.1018,  -5.2202,   0.4989,  18.5169,  -2.9579,\n",
      "          -16.1191],\n",
      "         [ -1.8179,  -6.5425, -13.3471,  -7.5110,   3.3995,  14.0736,  -0.3040,\n",
      "          -12.3375],\n",
      "         [ -4.7210,  12.5602,   3.6924,   0.0493,   9.2182,   9.2067,  -3.0407,\n",
      "           -8.0485],\n",
      "         [ -7.2825, -12.8600,  -5.1180,  -5.6537, -11.7059,  12.7941,   1.6539,\n",
      "            0.0895],\n",
      "         [  4.3233,  -2.0894, -13.4478,   0.4596,  -3.4281,  -3.9500,   4.0239,\n",
      "            9.0973],\n",
      "         [  8.5366,  13.4198,  -4.4217,  -4.9960,   0.4376,  10.3254, -14.2706,\n",
      "           -2.7286],\n",
      "         [ -8.7089,   3.2830,  -9.5855, -18.6783,   6.5606,  12.3650,  17.9651,\n",
      "            7.2947],\n",
      "         [ 11.5544,  14.3645, -17.2118,   9.9877,  -6.1625,  -9.5870, -14.0026,\n",
      "            4.1747],\n",
      "         [-16.0214,   4.9477,  -8.8766,  -4.9696,   3.1745, -14.2008,   2.1023,\n",
      "           12.1313],\n",
      "         [ 10.5308,  15.1401,  -2.0986,  15.7250,  15.0680,  -7.2151,   5.8090,\n",
      "            1.2829],\n",
      "         [ -3.7003,  -5.7431,   4.2917, -17.2427,  -3.4322,  18.2853,  -1.3908,\n",
      "          -35.1271],\n",
      "         [  5.6062,  -2.4498,  -7.7876,  26.4595,   9.6641,  14.3838,  -1.0851,\n",
      "            8.2755],\n",
      "         [-11.0273,   5.4261,   6.5827,   9.4493,  16.4441,  -0.8692,   8.6260,\n",
      "          -18.5438]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.0420,  0.0640, -0.5282,  ...,  0.1402,  0.1332, -0.3463],\n",
      "        [-0.0403, -0.4280, -0.1560,  ..., -0.7508,  0.0401, -0.1545],\n",
      "        [-0.4209, -0.0183, -0.5806,  ..., -0.5649,  0.6145,  0.1938],\n",
      "        ...,\n",
      "        [-0.1234,  0.9359, -0.0887,  ...,  0.2370,  0.1782, -0.3420],\n",
      "        [ 0.2091,  0.2402, -0.1642,  ..., -0.3937, -0.3478, -0.3676],\n",
      "        [-0.3382,  0.4126, -0.0105,  ...,  0.5571,  0.2980,  0.0019]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[ 20.3770,  -8.9982,   5.7981, -54.4718,  10.3389,  25.6232,  -7.3619,\n",
      "           66.8954],\n",
      "         [-24.4952,  -8.0455, -25.7765,   9.3390, -10.6859,  13.9143,  24.6822,\n",
      "           -5.3635],\n",
      "         [ 14.3492,  -0.5480,   2.7146,  -3.5396,  -0.9122,   8.7759,  14.1261,\n",
      "           -8.9949],\n",
      "         [ 20.3872, -28.4469, -23.1507, -17.4206,  55.3954,   7.6063,  -6.7282,\n",
      "          -17.2995],\n",
      "         [ -7.9051,  -3.5794, -25.6732,  10.3576,  45.4144,   5.9895,  -3.6282,\n",
      "            7.9876],\n",
      "         [-10.6041,  -1.0423,   0.9219,  -7.5330, -52.7524,  35.2117,  43.2977,\n",
      "            9.6016],\n",
      "         [  4.7211,  23.0743,  -6.7613,   0.6553,  -3.8241, -59.9163, -24.1517,\n",
      "          -34.1698],\n",
      "         [  6.1564,  -6.8222,   8.5098,  23.4575,  -7.7107, -16.5264,  25.6527,\n",
      "           39.3804],\n",
      "         [ -4.6398,  -0.6583,  -5.4959, -16.6883,  -7.8943, -49.6436,  -8.7360,\n",
      "           14.4800],\n",
      "         [-10.0968,   9.6176, -21.2868, -13.9476, -55.4949,  43.7071, -28.6881,\n",
      "           11.1749],\n",
      "         [-14.0790,  24.8613,  14.2013, -15.2231,  -5.6982,   7.0661, -25.7879,\n",
      "          -22.6069],\n",
      "         [ 42.0498,   9.3817,  16.2842,   2.3952,  11.5551,  13.7041,  -0.6050,\n",
      "          -21.5755],\n",
      "         [ 24.2474, -27.4941,  -0.7662, -30.9570,  20.5891,   9.1767, -34.8202,\n",
      "           47.1419],\n",
      "         [-30.3167,   9.5995,  31.5491,  24.5011,  16.4449,  -1.1711,   2.1619,\n",
      "          -41.6707]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 1.2009e-01, -3.4810e-01,  2.2750e-01,  ...,  1.3859e-01,\n",
      "          5.2063e-01,  8.9554e-02],\n",
      "        [ 2.4253e-01,  2.6600e-01,  1.6356e-01,  ..., -6.8705e-02,\n",
      "         -8.3676e-02, -4.6986e-01],\n",
      "        [ 7.7957e-03, -1.6626e-01,  1.9100e-01,  ...,  2.0954e-01,\n",
      "         -5.8224e-02, -4.9827e-01],\n",
      "        ...,\n",
      "        [ 3.4260e-02,  3.7502e-04,  3.7257e-01,  ..., -5.1754e-01,\n",
      "          1.8014e-01,  4.8472e-01],\n",
      "        [ 3.9467e-01, -1.8822e-01,  1.1926e-01,  ..., -1.5807e-02,\n",
      "          2.3451e-01, -6.6330e-01],\n",
      "        [-4.4355e-01,  8.4144e-02, -4.9701e-01,  ..., -7.0415e-01,\n",
      "          4.3683e-01, -4.0986e-01]], device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[ -72.7959,  -84.8928,  -19.6075,    3.9463,  -80.1613,    1.4237,\n",
      "            55.4662,  -14.6598],\n",
      "         [ -61.7736,   32.3916,  -24.6856,   -4.6624,   11.6660,  -44.8509,\n",
      "            12.0158,  -23.9518],\n",
      "         [  38.5322,  -33.4644,  -75.5678,  -58.5582,   19.0756,   95.8303,\n",
      "            15.0848,   38.0064],\n",
      "         [ -18.8772, -105.6819,  -54.1393,  -31.0526,   -8.9837,   14.3598,\n",
      "            11.0269,  -24.9514],\n",
      "         [ -44.9042,  -71.9770,   57.0487,   21.7912,   35.8665,  -10.6950,\n",
      "           -69.6322,  -15.4334],\n",
      "         [  39.3751,  -14.9937,   -1.5589,  -13.3156,    2.1873,   40.8476,\n",
      "            46.1684,   33.9289],\n",
      "         [ -16.0536,  -13.3304,    7.1574,   -0.7537,  -56.1024,   31.6835,\n",
      "           -24.7281,  -87.7227],\n",
      "         [  21.3458,   32.0870,   -1.9651,    6.5925,   13.0070,  -48.6499,\n",
      "           -28.7940,    0.6593],\n",
      "         [ -29.5455,   87.6284,    1.9369,  -59.3251,  -33.7346,   61.9328,\n",
      "             9.3004,   20.8871],\n",
      "         [  20.1102,   15.7589,   59.3472,  -43.7652,   13.6183,  -66.0193,\n",
      "            16.8595,  -18.6881],\n",
      "         [ -31.1002,  -29.2981,    8.7929,  -78.2669,  -47.1873,   30.9346,\n",
      "            31.2069,  -35.5339],\n",
      "         [  43.1337,   54.7514,   -4.6119,   60.5397,   45.5312,  -42.1900,\n",
      "            72.5112,  -31.3131],\n",
      "         [  12.6225,    5.7110,   10.5778,   23.6800,   20.8503,  -24.5680,\n",
      "            19.0195,  -37.6107],\n",
      "         [  39.4776,   45.9197,   13.3386,   26.6516,  -35.4757,  -35.4802,\n",
      "           -24.7624,   -3.5904]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.8459,  0.0117, -0.6438,  ..., -0.4948, -0.2318, -0.2396],\n",
      "        [-0.2867, -0.0234,  0.2782,  ..., -0.1150,  0.1881,  0.0828],\n",
      "        [-0.2392,  0.2224,  0.2540,  ..., -0.0800, -0.1246, -0.5785],\n",
      "        ...,\n",
      "        [ 0.6276, -0.3937,  0.0856,  ...,  0.1160,  0.5973, -0.4421],\n",
      "        [-0.3831,  0.2661,  0.3804,  ..., -0.0152,  0.1801,  0.3438],\n",
      "        [-0.3112,  0.2653,  0.6427,  ...,  0.0237,  0.4074,  0.2181]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[  57.3357,   54.8512,  -31.0937,   -5.1960,   26.5318,   89.3239,\n",
      "            31.4868,   29.4847],\n",
      "         [  71.4110,  133.8667,  -57.2498,  -10.8180,  -52.9530,    5.0562,\n",
      "            50.6049,  -48.4184],\n",
      "         [ -24.5095,   60.9629,    6.3342,  -90.7579,   88.2586,  -34.7577,\n",
      "           -22.6620,  -17.4950],\n",
      "         [ -13.7795,   74.8057,   31.3115,  -29.0692,   43.2364,   24.3576,\n",
      "            10.2096,   37.4950],\n",
      "         [  20.2144,   30.4241,  -24.7200,   16.7293,  -21.9045,   22.5784,\n",
      "            33.2252,   -3.2795],\n",
      "         [-114.6826,   63.9650,  -31.2435,  -14.3650,   -2.9276,   18.1958,\n",
      "            -5.0110, -101.8272],\n",
      "         [  14.3691,  -18.6506,  -55.8027,  -92.3274,  -72.5252,   -4.4159,\n",
      "           -35.1242,  -24.0912],\n",
      "         [ -42.7037,  -33.8623,   40.6124,  -72.1612,   30.5697,  -46.3852,\n",
      "           -60.8559,  -30.0667],\n",
      "         [ -80.2971,   11.6004,   53.0544,   -5.4879,  -50.3188,  -46.5933,\n",
      "           -68.5643,   17.0646],\n",
      "         [ -40.8100,  -21.0393,  -11.7948,  -25.9618,   -3.1574,  -15.0476,\n",
      "            59.1318,   -2.2869],\n",
      "         [ -21.9398,  -16.8071,  -38.9892,   19.9090,   97.6719,  -27.7573,\n",
      "             8.7950,  -61.6845],\n",
      "         [ -74.9170,   30.4311,   18.7298,   62.4195,   58.3498,  -11.2379,\n",
      "           -61.1848,   24.9304],\n",
      "         [  54.6634,  -38.4511,   -2.4238,  -26.2694,  -32.8875,  -18.3659,\n",
      "           -11.8718,  -10.6290],\n",
      "         [  23.3141,   -5.4333,   43.8522,   19.5616,   10.2221,  -22.8521,\n",
      "             7.8790,  -34.5917]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=14336, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.2124, -0.0543, -0.1024,  ...,  0.2956, -0.1132, -0.0289],\n",
      "        [-0.8758,  0.0811, -0.2252,  ...,  0.4002, -0.2779, -0.5668],\n",
      "        [ 0.3961,  0.2414,  0.4788,  ...,  0.7060,  0.5068,  0.1532],\n",
      "        ...,\n",
      "        [ 0.1488, -0.3396, -0.2425,  ..., -0.4696,  0.4370,  0.2169],\n",
      "        [ 0.6468,  0.0137,  0.1838,  ..., -0.1301, -0.3638, -0.6547],\n",
      "        [-0.4598, -0.2089, -0.2916,  ..., -0.0870, -0.4668,  0.4432]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[-12.2559,   4.0979,  32.1519,   7.7786,  36.6216, -16.2874,  25.7354,\n",
      "           22.9132],\n",
      "         [ 17.4805, -36.6661,  17.4447, -13.5896,  23.9004, -12.2365, -41.5423,\n",
      "          -55.6121],\n",
      "         [ 28.4131,   2.4870,   3.1700, -10.6597,  19.6015, -15.3854,   2.6701,\n",
      "          -23.2200],\n",
      "         [  9.3064,   4.7387, -24.6498, -18.7472,   0.7887, -12.3505,  -7.6589,\n",
      "            2.2178],\n",
      "         [-35.4859,  -1.7514, -34.4050,  24.6426,  -4.9182, -54.4548,   5.6655,\n",
      "          -48.7335],\n",
      "         [ 16.9996,  32.1180,   6.8267,   5.9696, -13.6710,  29.9175,  19.2748,\n",
      "          -23.1563],\n",
      "         [ 12.3833,  -3.1952,  32.8878,  -8.4998,   6.2080,   9.8128, -39.7077,\n",
      "           35.8824],\n",
      "         [ 16.0926, -46.7237, -24.2937,  26.3002,  -0.5651, -21.7000, -14.0411,\n",
      "           29.9730],\n",
      "         [ 20.5260,  -3.8029,  23.3856,  25.7752, -21.7597, -23.0428,  -5.8726,\n",
      "          -18.8836],\n",
      "         [-23.2375,   4.5891,  -1.6435,  31.3652,  30.6726,  41.5871,  15.3598,\n",
      "          -17.0705],\n",
      "         [ -8.4065,  37.6809, -12.7757,  -1.2867,   4.3099,  -1.4572,  11.6578,\n",
      "          -52.7144],\n",
      "         [-11.0882, -32.7010,   3.9241,  26.3104,   3.8968,  11.8351, -41.5983,\n",
      "           -2.5303],\n",
      "         [ 40.1469,   9.5263,  -6.4535,   5.6226,   2.6964, -48.1762,  -9.4002,\n",
      "           -9.4321],\n",
      "         [  9.1729,  10.9389, -16.0400, -52.3333, -11.3851, -14.8701,  34.2992,\n",
      "            7.3554]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.2507,  0.2641,  0.1122,  ..., -0.0244, -0.2442, -0.1297],\n",
      "        [-0.0205,  0.3868, -0.0126,  ..., -0.1835, -0.0464, -0.2130],\n",
      "        [-0.4565, -0.4559,  0.0553,  ..., -0.4800,  0.0869,  0.0496],\n",
      "        ...,\n",
      "        [ 0.0923,  0.8126,  0.1134,  ...,  0.1031,  0.2880, -0.0635],\n",
      "        [ 0.4470,  0.4016, -0.0239,  ...,  0.2171, -0.2058, -0.7313],\n",
      "        [ 0.3358, -0.2782,  0.2605,  ...,  0.1693, -0.0381, -0.6493]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[  7.0591, -24.8305,  15.3529,  -5.1918, -19.0430,   3.3320,  34.7101,\n",
      "           -5.9203],\n",
      "         [  5.2043,  11.3021,  12.8066,  13.4870,  -8.6434, -32.6399, -16.1679,\n",
      "           -6.3472],\n",
      "         [ 11.5813,  -2.7159,  12.7979,   2.4005, -29.1528,   9.9622, -39.8908,\n",
      "          -16.8087],\n",
      "         [  8.9395,  20.4302,  18.4148,   3.0572,  -7.2959,  31.6257, -17.7879,\n",
      "          -11.5642],\n",
      "         [ 27.3194,  13.9888,   8.4280, -22.7596, -16.8484,  -5.6392,  42.2809,\n",
      "          -53.0397],\n",
      "         [-22.2954,  43.2847, -22.8547,  -9.5314,   2.4475,  31.6174,  28.0740,\n",
      "           34.5407],\n",
      "         [ -4.1633, -29.0802, -23.8581, -32.9834,  24.4398,  13.2704,  33.6883,\n",
      "           28.2482],\n",
      "         [  2.1425, -24.2169,  32.1284, -30.3300,  14.0898, -33.5403,  16.6251,\n",
      "           77.1333],\n",
      "         [  5.1400, -10.8881,  10.3583,  36.1582,  11.9727,  -9.0122,   8.3241,\n",
      "          -46.0667],\n",
      "         [  4.9944,  -3.1651, -10.8261, -23.2848, -15.4319,  36.1650, -29.5412,\n",
      "           26.4873],\n",
      "         [-14.7323, -10.6602,  -6.5088,  13.4003,  13.8499,  -5.1710,  -6.4988,\n",
      "           33.6042],\n",
      "         [-24.6226,  14.7334, -25.9486,  -6.9132,  -2.5914, -39.5062, -16.3523,\n",
      "          -17.3867],\n",
      "         [  0.5190,   9.9464,   5.4334,  14.5531,  22.7702,  13.6816,  -8.1756,\n",
      "          -10.7198],\n",
      "         [-11.6653,  15.4899, -10.0858,  36.9280,  12.7023,  12.6528,  34.0104,\n",
      "          -15.2130]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[-0.4555, -0.3244, -0.1471,  ...,  0.3184,  0.0148, -0.2724],\n",
      "        [-0.0852,  0.3382, -0.0426,  ...,  0.6460, -0.6127,  0.1431],\n",
      "        [ 0.2307,  0.4425,  0.2972,  ...,  0.0142, -0.0157,  0.0100],\n",
      "        ...,\n",
      "        [-0.1701,  0.6581,  0.1866,  ..., -0.0402,  0.5724, -0.0454],\n",
      "        [ 0.3917,  0.1188, -0.2115,  ...,  0.5044, -0.2375,  0.2873],\n",
      "        [-0.5148,  0.4462,  0.0318,  ..., -0.2094, -0.1168, -0.2928]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[  2.0665,   3.7345,  -6.8132,   5.5144,   2.7021,  23.6406,   5.0814,\n",
      "            4.8425],\n",
      "         [-28.9930,   5.6190,  -3.2786, -16.8291,   1.4150,  -0.2042, -13.2597,\n",
      "           -0.7979],\n",
      "         [-14.9311,  16.0813,  -1.3838,  29.9757,   9.0545, -19.7069,   6.7296,\n",
      "          -11.0313],\n",
      "         [ 10.2104,  14.8869,  26.5014,   6.9115,   7.9442,  -1.1806,  18.6444,\n",
      "           -6.3282],\n",
      "         [  7.4680,   1.4269,   0.2018,  -4.0511,  -4.6944,   7.5486,  11.1490,\n",
      "           10.5538],\n",
      "         [  6.9350,  12.1069, -13.2241,  -5.7977,   4.3730,  -9.6964,   5.3521,\n",
      "            5.6555],\n",
      "         [  1.4210,  18.5612,   3.2406,  -0.3067,  -6.4898,  17.4749,   0.4054,\n",
      "            3.8373],\n",
      "         [ -6.1552,  -6.6596,  -9.4637,  24.5901,   4.6341,   3.4574,  -7.8194,\n",
      "           22.8796],\n",
      "         [  8.2247,   8.8822,   0.2057,   3.0478,   3.7631,  -5.7156,  -0.0374,\n",
      "           20.4624],\n",
      "         [  1.0510,   4.2395,   1.4856,  -0.4836,   4.8290, -14.8825,  -2.2055,\n",
      "           14.6185],\n",
      "         [  0.1920,   1.2500,  -7.1813,  10.9379,   7.3020,  -0.0447,   4.7375,\n",
      "           12.7109],\n",
      "         [ -8.9051,  -0.5043,   3.1604,  -5.2776,  -3.2308,  -8.4238,   0.4015,\n",
      "           10.4465],\n",
      "         [  7.8401,  -6.0339, -17.6679,  35.2461,  16.5379,   1.2966,  -0.8151,\n",
      "          -24.1276],\n",
      "         [ 14.0912,  -3.6958,   2.0015,   1.3026, -24.5008,  -8.0914,  -2.9048,\n",
      "           -0.4656]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[-2.5789e-01, -3.5800e-01, -2.5945e-01,  ...,  1.8306e-01,\n",
      "          3.1280e-01,  4.8750e-04],\n",
      "        [ 5.5629e-02,  3.7779e-01, -1.3234e-02,  ..., -1.1595e-01,\n",
      "          2.8502e-01, -2.0690e-01],\n",
      "        [-1.1743e-02, -3.8983e-01, -2.4650e-01,  ..., -9.7387e-02,\n",
      "          1.8369e-01, -7.7005e-02],\n",
      "        ...,\n",
      "        [ 7.5385e-02,  1.1306e-01,  2.1147e-02,  ..., -2.8864e-01,\n",
      "          5.9041e-01, -5.4927e-02],\n",
      "        [ 1.0928e-01,  8.2086e-02, -5.8503e-01,  ..., -2.6634e-01,\n",
      "         -5.2533e-01,  2.2963e-01],\n",
      "        [-3.0016e-01,  3.1678e-01, -1.6171e-01,  ...,  4.7523e-01,\n",
      "          5.6695e-02,  2.9270e-01]], device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[ 20.6212,   1.5970,  12.7588,  -0.2501, -28.7474,   1.9747,  22.0280,\n",
      "           -3.0097],\n",
      "         [ -2.9451,  -4.7694,   4.9574, -14.7371,  -9.9060,  -6.9685,  24.5339,\n",
      "           -9.4290],\n",
      "         [  5.6077, -13.4063, -12.2247,  -2.0198,   1.4970,  -5.1591,  -0.2173,\n",
      "            3.5798],\n",
      "         [-18.0178,  -5.1859,   4.4692,   1.6982,  -5.0935,   5.1923, -19.3491,\n",
      "            5.1903],\n",
      "         [ -7.0420,  -6.2736,   9.9450,   9.2954,   6.1234, -16.3988,   1.0776,\n",
      "          -12.7993],\n",
      "         [ -5.1275, -10.5232,  12.8862, -22.0639, -19.3626,   5.1116,   8.9309,\n",
      "           -8.1356],\n",
      "         [  6.5112, -11.6723,   3.4256,  -0.6982,  28.0872,  -0.7969,   1.0336,\n",
      "            5.1300],\n",
      "         [  9.6006,  16.5690,   2.0238,  -5.3517,   6.6008,   5.2917,  -0.9113,\n",
      "          -12.4349],\n",
      "         [  9.7471,  -6.6465,   0.2954,   7.9791,   6.1355, -13.3811,  -9.8928,\n",
      "          -12.7091],\n",
      "         [ 12.6145,  -9.9622,   3.1394,  -5.1122,  -8.7965,  -6.9575,  -9.7065,\n",
      "           27.2599],\n",
      "         [-17.8434,  -7.3427,  -1.0945,   5.8728,  -1.6347,  21.1829,   5.5071,\n",
      "           -7.2492],\n",
      "         [ -1.0538,   8.8054,  -0.8323,  -8.1403,   0.3192, -19.6289,   0.4018,\n",
      "           -8.6845],\n",
      "         [ -6.3384,  -3.4978,   3.4283, -12.2326, -19.1830,  -5.6544,  11.2609,\n",
      "            0.9246],\n",
      "         [ 19.9237, -11.5962,   2.9415,  -5.1198, -19.6285,  13.1045,  13.6143,\n",
      "           -1.3333]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[-0.2530,  0.8215,  0.2086,  ..., -0.2673,  0.0073,  0.0292],\n",
      "        [ 0.0810, -0.8273, -0.3094,  ...,  0.1119, -0.0476,  0.3544],\n",
      "        [ 0.4604, -0.2439,  0.0793,  ..., -0.1641,  0.0388, -0.2121],\n",
      "        ...,\n",
      "        [-0.2325,  0.0265, -0.2798,  ...,  0.8082, -0.6147,  0.1143],\n",
      "        [ 0.1207,  0.0544, -0.1547,  ...,  0.6506,  0.4993,  0.1481],\n",
      "        [-0.6249, -0.7237,  0.1376,  ..., -0.5426, -0.1784,  0.4858]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[-46.9076,  -7.1730,  -8.3175,  24.9404,  16.0228,  24.8425, -33.1436,\n",
      "            7.2366],\n",
      "         [ -6.2313,  33.3742, -65.2453,  -7.0682,  26.3452,   5.9299,  -7.6523,\n",
      "           -9.0343],\n",
      "         [-21.1172, -16.5734,  18.9161,  15.7798,  15.7211,  14.3896,  38.3355,\n",
      "           27.7951],\n",
      "         [-20.2505,  -1.4674,  11.9400, -12.6088,  -8.5094,  57.7007, -27.7079,\n",
      "           13.6227],\n",
      "         [-31.2425,  25.3565, -17.6787, -29.7145,  -1.0799,  -3.9946,  -0.2208,\n",
      "           -5.9014],\n",
      "         [ 46.1436, -22.9724,   8.2502,  10.7578,  14.4421,   1.9159,  -2.0460,\n",
      "           22.6028],\n",
      "         [ -7.2346,  -6.2273, -31.9593, -21.8639, -17.5459,  39.0236,  -1.7841,\n",
      "            8.8057],\n",
      "         [  7.6970,  44.8885,  65.2739, -13.4550,  23.1183,  -1.5473, -18.1864,\n",
      "           -5.8081],\n",
      "         [-23.9755,  36.2818, -35.9049,  21.6695, -23.6341,   7.2188, -10.0258,\n",
      "           19.6299],\n",
      "         [ 35.9122, -13.8387,  -8.8169,  47.9500,  -5.0388,  33.5255,  17.7008,\n",
      "          -10.9920],\n",
      "         [ 64.0261,  10.0981,  43.0754,  15.7076,  13.4089,   2.9631, -16.0100,\n",
      "           -6.9526],\n",
      "         [ 18.1451,   8.3530, -27.1491, -28.2861, -15.7988,  24.7545,   1.9738,\n",
      "          -10.2424],\n",
      "         [-32.3655,   0.7445,  -2.7462, -10.7130,  -7.9385, -43.5141, -29.1661,\n",
      "          -15.5016],\n",
      "         [ 34.9050,   7.9519,  16.9329, -18.6947,  -4.5632,  12.6680, -20.3116,\n",
      "            9.2432]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[-0.3732, -0.0393,  0.0851,  ..., -0.3806, -0.2785,  0.1899],\n",
      "        [-0.2383,  0.3211, -0.6300,  ..., -0.2220,  0.5363, -0.0791],\n",
      "        [ 0.1853,  0.4891,  0.3613,  ...,  0.0276, -0.1509,  0.0501],\n",
      "        ...,\n",
      "        [ 0.1606, -0.3195,  0.1155,  ..., -0.2033, -0.4936,  0.1981],\n",
      "        [ 0.2346, -0.1995, -0.0818,  ...,  0.4195, -0.2728,  0.0581],\n",
      "        [ 0.5953,  0.3670, -0.4896,  ...,  0.0423, -0.3460,  0.2113]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[-4.3892e+01,  8.7249e+01, -3.6195e-02,  2.5418e+01, -1.7082e+01,\n",
      "           3.5087e+01, -5.0461e+00, -5.9970e+00],\n",
      "         [-2.8489e+00,  4.6791e+01,  6.2107e+01,  2.6921e+01,  3.7696e+01,\n",
      "           6.9244e+01, -1.9016e+01, -3.1027e+01],\n",
      "         [ 6.1148e+01,  3.5038e+01,  6.6763e+01, -1.3164e+01, -1.9251e+01,\n",
      "          -6.3177e+00, -3.4003e+01,  2.5352e+01],\n",
      "         [ 5.9765e+01, -3.3292e+01,  3.4780e+01,  5.8620e+01, -1.6083e+01,\n",
      "          -1.1070e+01, -1.5062e+01, -1.2211e+02],\n",
      "         [-3.7126e+01, -1.8450e+01, -2.5458e+00, -8.5653e-01,  4.0771e+01,\n",
      "           3.3705e+01, -2.6275e+01,  3.8122e+01],\n",
      "         [-1.6601e+01,  1.1282e+02, -1.8612e+01,  1.1476e+01, -1.6345e+01,\n",
      "          -5.1443e+01,  3.0321e+01, -3.5984e+00],\n",
      "         [ 6.7171e+00,  5.1870e+01, -4.6742e+01, -7.9383e+01, -1.2117e+00,\n",
      "           2.1140e+01,  6.1192e+01, -4.3249e+01],\n",
      "         [-3.6556e+01, -4.4533e+00,  5.3540e+00,  1.5991e+01, -2.1156e+01,\n",
      "          -1.0157e+02, -1.1297e+02, -7.2144e+01],\n",
      "         [ 6.0010e+01, -2.3485e+01, -4.4575e+01,  3.3816e+01, -5.3124e+01,\n",
      "           1.9312e+01,  6.6105e+01,  4.4396e+01],\n",
      "         [-6.3623e+00,  3.5198e+01, -9.7430e+01, -3.8611e+01, -1.2325e+02,\n",
      "           3.7210e+01,  3.5662e+01, -4.7224e+01],\n",
      "         [ 5.9247e+00,  1.9384e+01, -1.9001e+01,  2.3237e+00,  3.5409e+01,\n",
      "          -5.0366e+01,  2.1093e+01,  7.7045e+01],\n",
      "         [ 1.9507e+01,  9.0057e+01, -3.5495e+01, -6.9565e+01, -1.4022e+01,\n",
      "          -7.6445e+01,  5.8354e+01, -4.3732e+01],\n",
      "         [-5.0622e+01,  9.0021e+00, -4.6760e-01, -1.0938e+01, -2.4016e+01,\n",
      "           2.9702e+01, -1.4205e+01,  1.4340e+01],\n",
      "         [ 2.7066e+01, -4.0645e+00,  1.9502e+01, -5.6234e+01,  3.8299e+01,\n",
      "           4.4200e+01, -7.1602e+01, -5.9302e+01]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[-0.0580, -0.1678,  0.3538,  ..., -0.2379, -0.3047, -0.2538],\n",
      "        [ 0.4457, -0.2262, -0.0920,  ...,  0.2826,  0.1027, -0.0616],\n",
      "        [-0.1183,  0.4861,  0.1279,  ..., -0.2198,  0.1179, -0.3166],\n",
      "        ...,\n",
      "        [ 0.3079,  0.3129, -0.0936,  ...,  0.0050, -0.2380,  0.3389],\n",
      "        [-0.0478,  0.5921, -0.1118,  ..., -0.3755, -0.0006, -0.3817],\n",
      "        [ 0.4081, -0.3375,  0.0495,  ...,  0.4664, -0.1916, -0.3719]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[  63.6786,  -24.7159,  -16.8329,   36.3642,   14.5584,   -2.9739,\n",
      "           -33.6236,    8.5603],\n",
      "         [   2.1905,   39.1195,   68.2836,  -69.1905,   80.3381,   58.0840,\n",
      "           -78.4241,    2.8802],\n",
      "         [ -28.3861,    2.3621,   58.7178,   -6.8491,   44.8454,  -50.6690,\n",
      "             9.0299,   99.7188],\n",
      "         [ -88.7763,  -35.5398,  -86.9704,  -22.8262,   12.3655,   10.6522,\n",
      "            24.5408,   -9.2171],\n",
      "         [ -19.8735,   57.3545,   24.5847,   59.7099,  -14.8657,   22.1967,\n",
      "            12.3009,   17.1188],\n",
      "         [  39.0194,   28.9404,    1.4595,   77.0251,  -53.8673,  -63.5940,\n",
      "           -51.8121,   -9.4483],\n",
      "         [ -15.6136,   42.4014,  -44.8579,  -49.2313,    5.5597,   38.7514,\n",
      "           -23.0390,    6.8331],\n",
      "         [ -53.2820,   29.7248,   33.8283,   -5.9623,  -57.3982,  -24.1137,\n",
      "           -20.9845,  -28.1584],\n",
      "         [ -31.1403,   45.2596,  -37.9227,   11.2509,   -3.8738,   61.3285,\n",
      "           -30.2582,  -48.6149],\n",
      "         [  12.0097,  -22.2346,   -2.1604,   -0.7416,  -18.4267,   -0.8436,\n",
      "           -17.8090,   10.8194],\n",
      "         [ -25.0080,    0.9660,  -14.8478,   -4.7550,   95.8057,   33.6285,\n",
      "          -114.7319,   55.1256],\n",
      "         [ -19.3011,   -1.4192,   -7.0354,  -18.3838,   23.0182,  -29.1372,\n",
      "           -24.3059,   -9.1841],\n",
      "         [ -72.7703,  -77.9086,   33.9858,   29.8116,   20.2630,    9.0107,\n",
      "           -74.5470,  -13.6509],\n",
      "         [  33.3640,   24.3505,  -17.2297,  -12.9183,   58.0583,   29.6266,\n",
      "            45.1809,  -41.1923]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=14336, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[-0.1101, -0.0103, -0.1666,  ..., -0.2168, -0.9022, -0.0801],\n",
      "        [-0.3043,  0.5973,  0.1950,  ..., -0.3463,  0.4623,  0.0351],\n",
      "        [-0.3786,  0.2376,  0.2504,  ..., -0.0537, -0.0314,  0.5365],\n",
      "        ...,\n",
      "        [-0.2367, -0.3782,  0.1167,  ...,  0.2237,  0.2635, -0.3561],\n",
      "        [-0.1225, -0.3162, -0.2362,  ..., -0.4634,  0.0619, -0.6208],\n",
      "        [-0.9209,  0.5265, -0.2150,  ..., -0.4379,  0.3065,  0.0045]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[-16.2269,   4.1836, -36.5848,  -6.3187,  28.1105,  -2.0673,   9.0262,\n",
      "           26.3961],\n",
      "         [-25.4569, -31.1857,  55.5678,   5.2289, -25.7404,  31.6529,   3.6451,\n",
      "          -23.0944],\n",
      "         [ -2.8228, -36.5462,   6.6378,  -0.7403,  29.7562, -17.9216, -42.4223,\n",
      "            2.0689],\n",
      "         [ 15.2942, -33.3597,  -6.8756,   7.0824, -24.6392,  19.8367, -43.3321,\n",
      "           34.8439],\n",
      "         [  4.2841, -13.6907, -18.2735,  24.1110,   4.7914,   1.7504, -10.4433,\n",
      "           25.5395],\n",
      "         [ 11.0708,  -0.2152,  14.7614, -31.7237, -16.8248, -18.4586,  41.6333,\n",
      "           16.1637],\n",
      "         [ -7.8535,   5.5055,   5.1577,  -0.6594,   7.6310,  27.8610, -11.1507,\n",
      "            7.4675],\n",
      "         [-23.0841,  24.1032,   3.9136, -37.5149, -22.0360, -23.1494, -12.7694,\n",
      "           23.9220],\n",
      "         [-15.0655,  14.5194,  27.4383,  19.3689, -27.4208,  10.0164, -12.7237,\n",
      "           47.5671],\n",
      "         [-13.8272, -11.3077, -12.3304,   1.5074,  13.7464, -23.2704,  -2.4906,\n",
      "            2.3860],\n",
      "         [-14.0370,  15.8487,  33.9522, -22.6217, -42.0598, -18.0714, -19.5721,\n",
      "          -20.2790],\n",
      "         [ 62.0024, -40.1624,   2.9921,  21.8898, -14.9595,   1.9033, -36.7089,\n",
      "          -19.3654],\n",
      "         [ 13.6641,  59.1120, -21.2946,  -5.9594,  42.0943,   1.1718,  -5.1325,\n",
      "           17.2069],\n",
      "         [  2.3946,  -1.4621,  32.3101, -10.8865, -27.7590,  32.6615, -28.4061,\n",
      "           32.9080]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[-0.1977, -0.0356,  0.2764,  ...,  0.7259, -0.0196, -0.2098],\n",
      "        [ 0.1507,  0.5840, -0.2101,  ..., -0.2475,  0.4621, -0.4447],\n",
      "        [ 0.4203, -0.1761, -0.3439,  ...,  0.0786, -0.2163,  0.1709],\n",
      "        ...,\n",
      "        [-0.0560, -0.1693, -0.7435,  ...,  0.3006, -0.0613,  0.2474],\n",
      "        [-0.1642, -0.4667,  0.1984,  ..., -0.6828, -0.1671,  0.2206],\n",
      "        [-0.0993,  0.1835,  0.2819,  ...,  0.1659,  0.1799, -0.5296]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[  5.6593,  22.3485, -40.4483,  32.7914, -19.6113,  29.2208,   9.9664,\n",
      "           18.1104],\n",
      "         [-14.8175,  -7.8849,   4.4866,  16.1558,   3.6543, -17.3646,  -9.2790,\n",
      "           32.2451],\n",
      "         [  3.0996,  31.1740,  12.8371,  15.3726, -31.1154, -19.3004, -20.0391,\n",
      "           45.3238],\n",
      "         [ 11.6539,   2.4176,  38.3804,  28.8191,   1.9101,   9.3937,  24.3755,\n",
      "           55.3361],\n",
      "         [ -3.9580,  -1.3315,   2.1195,   1.1131,   2.3729,  25.4392,  15.4311,\n",
      "           77.9035],\n",
      "         [ -3.5893, -11.0007,  18.9847,  -6.4279,  36.0089,  16.6068,  -7.6233,\n",
      "           22.0556],\n",
      "         [  6.1897, -72.0441,  11.9776,  14.8291, -23.0119,  19.1445, -17.0443,\n",
      "           16.1539],\n",
      "         [  5.3508,  -7.2128,  25.7939,   8.8271,  44.8892, -32.8579, -14.2734,\n",
      "           12.2783],\n",
      "         [ 26.8203,  -5.5255, -11.7161, -35.3019,   5.4313, -33.8735,  -6.1452,\n",
      "           16.1787],\n",
      "         [ 13.4269,  -4.2278, -27.6543,   3.2741, -35.8339,   1.6303,   7.6864,\n",
      "          -21.4025],\n",
      "         [  1.2530,  12.8218,  26.5484, -15.4541,  13.9162,   7.5178, -17.6210,\n",
      "          -23.5464],\n",
      "         [ 22.7223, -23.8113,  12.5053,   7.2647,  -1.0749,  14.6601,  -4.1223,\n",
      "           -6.0153],\n",
      "         [ 17.1813, -12.9853, -21.6902,  -0.1626,  14.5084,  23.1044,  -3.5850,\n",
      "           -5.3460],\n",
      "         [-17.7307,   9.5815,   3.9241,  25.9300, -16.4764, -26.4148,   1.9210,\n",
      "            4.8479]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.1647,  0.0967, -0.1024,  ..., -0.1987, -0.0927,  0.4255],\n",
      "        [-0.0081,  0.4684, -0.1254,  ...,  0.7288, -0.4496, -0.1367],\n",
      "        [ 0.2820, -0.0827, -0.7146,  ...,  0.2651,  0.2322,  0.0753],\n",
      "        ...,\n",
      "        [ 0.4771, -0.1363, -0.5897,  ..., -0.9519, -0.2056, -0.1066],\n",
      "        [-0.1815,  0.6996,  0.4474,  ..., -0.3570, -0.1489,  0.1363],\n",
      "        [-0.1165,  0.5884,  0.4172,  ..., -0.2288, -0.0565, -0.1395]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[  6.8308,  -1.9674,  -4.6866,   4.2710, -18.9994,   1.2361,  -3.0229,\n",
      "           -2.7633],\n",
      "         [  6.8939,  27.3152,   5.5610,  10.9853,   2.9372,  -9.3662, -16.3912,\n",
      "            1.3786],\n",
      "         [  0.4856,   0.9907,  15.1514,   7.4002,   4.7458,  -4.5640,   2.9446,\n",
      "            1.6334],\n",
      "         [-10.2621,  13.4635,   0.1381, -17.8071, -22.1530, -13.2129, -11.0993,\n",
      "           -3.1961],\n",
      "         [ -4.1803,  -8.7695,  12.2544,   6.2459,   5.1452,   3.3681,  14.2367,\n",
      "           12.0111],\n",
      "         [ 18.6207,  -5.6965, -22.4059, -17.1052, -12.8141,   3.9352,  11.3662,\n",
      "            0.1529],\n",
      "         [  1.1833,   7.2196,   9.1459,   1.5373,  -1.0390,  11.6973,   5.2121,\n",
      "          -12.3446],\n",
      "         [  2.6546,   1.5439,   8.1559,   3.6458,  -8.3022, -10.2723,  -6.0108,\n",
      "            5.3088],\n",
      "         [-11.3821,  20.7886,  -0.3017,   8.7650,  -1.7612,   7.0750,  -5.3229,\n",
      "            4.6073],\n",
      "         [-26.7649,   4.7422,  10.3020, -14.6453,   5.9717,  -0.6778,  -7.3747,\n",
      "           -7.8706],\n",
      "         [  8.1726,  21.5526,   3.0939,   1.0873,  -8.6513,   4.9744,  -9.8057,\n",
      "            6.4331],\n",
      "         [ 11.6540, -10.1509,   4.8782,   9.6499,  -8.5379,  -3.5484,   1.1188,\n",
      "            3.1225],\n",
      "         [ -9.8994,   2.7712,  15.0037,  -6.4969,   8.2789, -20.8721,   6.8488,\n",
      "           -3.8407],\n",
      "         [ 25.0447,   5.5056,  -6.2545,   3.7252,  -5.7226,  11.3749,  -2.7621,\n",
      "          -14.9370]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[-0.2319,  1.0090, -0.3425,  ..., -0.6794, -0.4885,  0.0534],\n",
      "        [-0.0942,  0.0763, -0.6367,  ...,  0.3719, -0.2607,  0.3653],\n",
      "        [ 0.0609, -0.4805,  0.4455,  ..., -0.0239,  0.1493,  0.1158],\n",
      "        ...,\n",
      "        [ 0.0197, -0.1207,  0.7357,  ...,  0.0043, -0.0869, -0.1180],\n",
      "        [ 0.1569,  0.6542,  0.2602,  ...,  0.6014,  0.5149, -0.2910],\n",
      "        [ 0.2995, -0.3207,  0.4304,  ...,  0.4353,  0.0699, -0.3157]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[  4.5275, -16.0443,  -0.6848,  -9.1742, -13.9116, -35.3606,  17.4733,\n",
      "            6.4488],\n",
      "         [ -3.9407,  -4.9818,   4.2149,   0.1825,   2.5497,  10.9974,  13.5283,\n",
      "            4.8217],\n",
      "         [  3.3581,   5.3910,   8.8838,  -3.2363,  -6.8682,  -1.0233, -16.6671,\n",
      "            7.5892],\n",
      "         [-21.5365,  -1.8170,  -6.3616, -12.7977,   2.9694, -14.5633,  -2.7414,\n",
      "          -15.4377],\n",
      "         [ -0.8540,   2.6176,  -7.3760,   2.2903,   8.8125,   2.6613, -20.8254,\n",
      "          -11.0262],\n",
      "         [ 18.7514,  -0.1765,   7.8107,  -8.5405,   0.7102,  10.9536,   2.9120,\n",
      "            3.6793],\n",
      "         [-14.0587,  11.3985,  -2.1591, -16.5422,   3.8347,  -6.6420,  -0.8401,\n",
      "           -5.7913],\n",
      "         [  8.9461,   5.2016,   3.4293, -10.3141, -29.6696,   9.4330,  21.6047,\n",
      "           18.8536],\n",
      "         [  5.0001,   7.0623,  20.5550,   4.4642,  -9.6698,  21.8627,   1.6922,\n",
      "           -0.1770],\n",
      "         [  5.2981, -10.4313,  20.3489,  -2.6638, -19.0836,  -9.1753,  -5.2220,\n",
      "           -6.3438],\n",
      "         [  7.4383,  24.6067,   4.8288,  -7.1378,  -3.3313,   7.0543,  12.6684,\n",
      "           22.0940],\n",
      "         [ -9.6800,  -5.2464, -12.7951,   8.6097, -18.3126, -15.5766, -14.8229,\n",
      "            1.3731],\n",
      "         [-11.8195, -11.5509,  -8.7666,  -1.9646,  -0.2926,  -4.0984,   9.7729,\n",
      "            6.6529],\n",
      "         [  5.2075, -12.6135, -16.1271,   5.0237,  -8.9131,  -9.1115,  -1.5616,\n",
      "           13.3984]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.0719,  0.0532, -0.2931,  ...,  0.0925, -0.5644, -0.2524],\n",
      "        [ 0.1342,  0.5329, -0.7083,  ..., -0.0514,  0.0573,  0.5372],\n",
      "        [ 0.3264, -0.1046, -0.1170,  ...,  0.1742, -0.2188,  0.3609],\n",
      "        ...,\n",
      "        [-0.4023,  0.3446,  0.0990,  ..., -0.2946, -0.1135,  0.2851],\n",
      "        [-0.4690, -0.4264, -0.0275,  ...,  0.3257,  0.9516, -0.1015],\n",
      "        [-0.3381, -0.2958, -0.2279,  ..., -0.2252, -0.1319,  0.2423]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[ 30.9491,  15.5888,  19.4182,  45.0472,  39.8852,   9.7080, -10.3467,\n",
      "          -37.3402],\n",
      "         [  3.7110,  26.9577,  12.7982, -34.4027, -18.7293, -46.0956, -30.2006,\n",
      "            2.4499],\n",
      "         [-24.9350,  23.7419, -19.4107,  11.0986,  13.2757,  -3.6253,  -3.1377,\n",
      "           -5.2466],\n",
      "         [-18.7373,   7.4327,  48.0600,   0.4280,  -9.6878,   9.3367,   9.0096,\n",
      "          -22.1390],\n",
      "         [-15.4962,  20.2101,   3.8427,  -4.0944,   4.3232,  14.8638,  17.3980,\n",
      "          -16.2918],\n",
      "         [-33.0666,   3.8873, -28.1431,  -4.3159, -40.0558,  15.8342,   7.8121,\n",
      "          -14.2300],\n",
      "         [ -4.7937,  30.9528,  45.5749,   4.0683,  36.1950,   4.2058, -26.2653,\n",
      "           15.8512],\n",
      "         [-17.4292,   3.7149,  -5.3925, -25.1160,  -1.2010, -47.9674, -13.4378,\n",
      "           -0.2115],\n",
      "         [ -2.0114,  16.6528, -37.2837,   9.0109, -37.6556,  -7.6967, -58.3188,\n",
      "           37.9813],\n",
      "         [ -3.3035,  19.8960,   9.0470, -18.1806,  -0.4154,  27.3371, -27.0587,\n",
      "           10.0181],\n",
      "         [ 11.5614,  65.0060,  14.9271, -26.6681, -12.3184, -17.9426,   0.3774,\n",
      "           -8.3765],\n",
      "         [ -1.5189,  11.4253,  14.9778,   8.5596,   3.3599,  28.3435, -18.9412,\n",
      "           28.9594],\n",
      "         [-50.9002,   2.5296,  13.7200,  25.5663,  12.0488, -40.7930,   2.2987,\n",
      "          -21.8291],\n",
      "         [-16.1447, -33.0456,  -7.2072,  16.2970, -33.4152,  -5.4427,  13.4290,\n",
      "          -10.3720]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[-0.4201, -0.6703,  0.1762,  ..., -0.0459,  0.5423,  0.4591],\n",
      "        [-0.0463,  0.6511, -0.5408,  ...,  0.1778,  0.4693,  0.3211],\n",
      "        [ 0.1700,  0.0214, -0.2667,  ...,  0.2946, -0.3365, -0.1040],\n",
      "        ...,\n",
      "        [-0.2162, -0.3765,  0.1035,  ...,  0.4702,  0.4078,  0.2189],\n",
      "        [ 0.0280, -0.5269, -0.0223,  ..., -0.2303, -0.1799, -0.0600],\n",
      "        [ 0.3309,  0.3112, -0.7186,  ...,  0.0907,  0.3979,  0.3649]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[  41.2656,   31.3470,  -29.8267,   -3.0254,   14.2773,  -67.6067,\n",
      "            42.6424,  -27.2349],\n",
      "         [   5.8889,   -0.1574,  -17.1881,  -19.1888,  -11.8240,    0.6862,\n",
      "           -33.3356,  -29.2824],\n",
      "         [  -4.0420,   -7.8042,   30.1692, -107.5337,   -4.5472,  -19.5547,\n",
      "            29.6288,   26.5331],\n",
      "         [  35.6008,  -64.3858,    8.9502,   17.1864,   72.4561,   -7.3575,\n",
      "             9.0832,   -7.8120],\n",
      "         [  23.8756,  -79.2004,    9.1281,    3.4510,   56.3925,  -70.3173,\n",
      "            76.5465,  -13.5883],\n",
      "         [  86.5266,   22.9641,   33.5718,    4.2181,  -31.4559,  -55.9128,\n",
      "            48.8847,   38.1660],\n",
      "         [   7.9413,  -61.5130,   43.7845,   51.9903,   72.9722,   35.1873,\n",
      "            27.6010,  -12.4078],\n",
      "         [   2.0052,  -18.6706,  -44.2946,   44.1406,   26.6972,  -10.4166,\n",
      "            15.7240,    7.5394],\n",
      "         [  38.4495,  -98.1862,   77.1438,  -25.1225,  -37.0133,  -72.6254,\n",
      "             3.4763,  -12.1135],\n",
      "         [ -63.4755,  -12.1733,    2.7174,   24.2021, -110.9021,   19.0119,\n",
      "            61.8811,    1.2202],\n",
      "         [ -20.1538,   15.2062,  -13.6601,   32.2463,    8.0047,  -48.5544,\n",
      "            61.5531,   18.6496],\n",
      "         [   5.8861,  -44.0094,   27.9055,   -5.5822,   -6.8992,  -50.0887,\n",
      "            -3.6588,   59.2262],\n",
      "         [ -74.8381,   39.8240,   22.2598,   24.9498,  -44.2384,   15.5296,\n",
      "           -10.6867,   34.4245],\n",
      "         [  11.0247,   31.3635,  -35.1339,   19.4689,    7.0092,  -10.8133,\n",
      "           -53.9779,   55.3279]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.4414, -0.2141,  0.8359,  ...,  0.2342,  0.2923,  0.2143],\n",
      "        [ 0.4774, -0.1101, -0.5014,  ...,  0.6249, -0.0247,  0.1232],\n",
      "        [-0.2167, -0.0553,  0.0072,  ...,  0.3961,  0.0446, -0.4479],\n",
      "        ...,\n",
      "        [ 0.2511,  0.0593,  0.4689,  ..., -0.7274, -0.1243,  0.2430],\n",
      "        [-0.0982, -0.7259, -0.8912,  ...,  0.3105, -0.4594, -0.1844],\n",
      "        [-0.1943,  0.7615, -0.2222,  ...,  0.8204,  0.3839,  0.0137]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[ 33.6291,   2.8696, -30.2309, 112.5943, -86.3070,  -8.0818, -44.4307,\n",
      "          -41.2465],\n",
      "         [ 49.9154,  15.2269,  11.3872, -73.2788,  -5.8402,  -4.0574,  -2.6444,\n",
      "           -3.8858],\n",
      "         [-45.8796, -15.7857,  15.5730,   7.4348, -53.0490,  48.3344,  75.6971,\n",
      "          -57.8126],\n",
      "         [-18.6961,  35.8498,  -8.1887,  20.4661, -26.7121,   7.5056, -40.7990,\n",
      "          -21.9797],\n",
      "         [-58.1278,   8.2310, -46.9777,  24.7984,  -5.2958, -54.7076, -21.7536,\n",
      "           25.4184],\n",
      "         [  8.5906, -66.5208, -10.3434,   9.4380, -27.3042, -44.9922,  42.7931,\n",
      "          -25.6572],\n",
      "         [ 46.7379,  52.3361,  43.0918,  29.2930,  42.6171, -23.7902,  78.7655,\n",
      "           -7.8731],\n",
      "         [  2.8959,  17.1984, -10.9210, -35.7664,  -9.6257,   8.5980, -62.9983,\n",
      "           48.7442],\n",
      "         [ 30.4174,  71.3930,  60.1738, -65.1331, 120.7151, -68.9394, -14.3164,\n",
      "          -36.9554],\n",
      "         [ -8.6882,   4.1606,  35.5089,  98.2199, -57.2247,  74.9563, -60.9723,\n",
      "           -9.2899],\n",
      "         [ -5.8044,  90.1155,  31.4377, -36.0035,  28.7671,  25.5434,  46.2606,\n",
      "          -73.6992],\n",
      "         [-20.0639,  37.9448,  16.2968, -81.9111,   6.8140,  30.3677,  72.5099,\n",
      "          -23.6482],\n",
      "         [-63.1033, -27.6900,  16.1397, -22.6142,  39.0010, -15.2600, -12.3335,\n",
      "           -5.9666],\n",
      "         [ 39.3055,  99.8330, 104.3544, 110.1430,  32.3835,  -3.7218,  74.4041,\n",
      "          -65.6615]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=14336, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[-0.3167, -0.0910, -0.2631,  ..., -0.1321, -0.2137,  0.3707],\n",
      "        [ 0.4042,  0.5468, -0.5032,  ...,  0.6196,  0.2896,  0.3668],\n",
      "        [-0.1097,  0.3229,  0.4608,  ...,  0.1971,  0.0564, -0.2504],\n",
      "        ...,\n",
      "        [ 0.2561,  0.7027, -0.0801,  ...,  0.2271, -0.1894, -0.0240],\n",
      "        [-0.3511,  0.2997, -0.3191,  ...,  0.0370,  0.3503,  0.4798],\n",
      "        [-0.0189,  0.6140, -0.1994,  ..., -0.6303,  0.0984,  0.2057]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[-3.5880e+01,  2.8869e+00,  1.8310e+01, -3.8883e+00, -3.3065e+01,\n",
      "          -2.5288e+01,  2.1808e+01, -2.9182e+01],\n",
      "         [-1.4214e+01, -9.9150e+00,  7.9727e+00,  1.9054e+01, -2.4394e+01,\n",
      "           1.4587e+00, -2.1708e+00, -3.9420e+01],\n",
      "         [ 1.4152e+01,  3.4444e+01, -1.6220e+01, -1.4264e+01,  2.8675e+01,\n",
      "           7.9122e+01, -5.6042e-01, -4.2336e+01],\n",
      "         [ 1.0388e+01, -7.1627e+00, -1.3520e+01,  3.3052e+01, -3.9989e+01,\n",
      "          -3.1965e+00,  5.1299e-02,  2.7755e+01],\n",
      "         [ 8.4252e+00, -1.0454e+01, -2.3854e+01,  2.0951e+01,  1.2403e+01,\n",
      "          -4.0700e+01,  7.1008e-01, -2.5685e+01],\n",
      "         [ 8.7071e+00, -1.6478e+01,  6.6598e+00, -3.1550e+01, -4.0003e+01,\n",
      "           8.8990e+00, -3.4832e+00, -2.1288e+01],\n",
      "         [ 9.2201e+00, -3.3292e+01,  3.0898e+01,  2.2143e+01,  1.6019e+01,\n",
      "          -1.9398e+01,  1.0870e+01, -6.4733e+01],\n",
      "         [-1.0093e+01, -1.5893e+01,  1.0459e+01, -1.6245e+01,  1.7187e+00,\n",
      "           3.9247e+01, -2.3323e+01, -1.7861e+01],\n",
      "         [ 1.6732e+00, -4.1658e+01,  3.0238e+00, -2.0713e+01,  7.5989e+00,\n",
      "          -2.1610e+01, -4.3872e+00,  9.9164e+00],\n",
      "         [ 1.3017e+01, -3.4399e+01,  4.9245e+00, -2.2099e-01, -1.2504e+01,\n",
      "          -3.5912e+00,  1.7680e+01, -1.4007e+01],\n",
      "         [ 1.7358e+01, -5.3071e+00,  1.8890e+01, -2.0122e+01, -4.5351e+01,\n",
      "          -1.8555e+01,  2.6811e+01,  2.9616e+01],\n",
      "         [ 1.3815e+01,  1.3748e+01, -4.8242e+01, -3.0314e+00, -2.9268e+00,\n",
      "          -2.7731e+01, -5.0791e+01,  2.3570e+01],\n",
      "         [ 1.9608e+01, -9.3489e+00,  1.7428e+01,  1.1448e+01, -2.7034e+01,\n",
      "           1.7805e+01,  1.7515e+01,  2.9203e+01],\n",
      "         [ 9.2492e+00, -1.2117e+01,  2.1236e+00, -9.6730e+00,  2.7442e-01,\n",
      "          -3.3388e+01, -9.5683e+00, -2.0620e+01]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[-0.0371, -0.0330, -0.6342,  ...,  0.4584, -0.0981, -0.1766],\n",
      "        [ 0.1855, -0.2792,  0.0159,  ..., -0.0599,  0.3687, -0.2213],\n",
      "        [ 0.0267, -0.8700, -0.0867,  ...,  0.0719,  0.8523,  0.1787],\n",
      "        ...,\n",
      "        [-0.1888,  0.3947,  0.4811,  ..., -0.4673,  0.0041,  0.1533],\n",
      "        [ 0.7006, -0.0296, -0.1958,  ...,  0.5949, -0.2128,  0.0438],\n",
      "        [-0.3817, -0.0339, -0.3983,  ...,  0.2338,  0.0837, -0.5103]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[ 11.6593,   8.9288,   3.6254,  39.2504, -41.3817,  16.1057,   7.7627,\n",
      "           -2.5662],\n",
      "         [ 14.4266,   7.0389,  18.1277, -15.7335,  53.5043,  33.3288,  26.5537,\n",
      "          -18.5881],\n",
      "         [ -7.1440,  22.2471,  22.9421,   5.5157,  19.7914, -23.0195, -21.5413,\n",
      "          -36.5980],\n",
      "         [-30.1183,  24.0343, -36.6196,  36.1745, -14.6492,  26.0250,  16.4061,\n",
      "           28.7848],\n",
      "         [-20.8329,  12.5442,  15.0574, -14.7426, -37.6037,  23.6976,   8.6965,\n",
      "           39.8418],\n",
      "         [ -6.1283,  11.9680,  29.6235,  -3.5560,  23.6006,  25.2134,   3.7983,\n",
      "          -15.4239],\n",
      "         [ 69.1080, -13.0695, -25.5737,   9.9018, -23.2278, -14.7226,   9.3879,\n",
      "          -12.9195],\n",
      "         [-30.4976, -11.4233,  14.5295,   8.6588,  -3.9884,  25.0364,  12.0217,\n",
      "          -26.7836],\n",
      "         [ 30.4940,   3.4664,  -0.1229,  10.0345, -19.5141, -16.7195, -23.7720,\n",
      "           -1.3443],\n",
      "         [  3.6672,   5.3778,  18.6631,  30.4669,  18.5533, -10.3886, -12.7338,\n",
      "          -34.4746],\n",
      "         [-17.7290,   9.8248,  10.9618, -19.0487,  -7.2642,   2.2752,   4.2743,\n",
      "           11.3142],\n",
      "         [-15.4379,   2.1324,  10.5086,  30.5893,  15.1172,  18.3771, -14.3258,\n",
      "          -47.0443],\n",
      "         [-16.5356,   2.0058, -32.3038, -23.7914,   9.3892,  15.3485,  34.8164,\n",
      "          -20.5012],\n",
      "         [ 40.9571, -45.7635, -33.3581,  -1.9308, -36.7997,   6.0294,  26.0585,\n",
      "           30.3087]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[-0.0193, -0.5585, -0.7825,  ..., -0.2367, -0.1424, -0.3801],\n",
      "        [-0.6404,  0.0958,  0.2934,  ..., -0.5932, -0.3560,  0.2881],\n",
      "        [-0.2824, -0.1600,  0.3475,  ...,  0.4026, -0.1576,  0.0582],\n",
      "        ...,\n",
      "        [ 0.8566,  0.4617,  0.4153,  ...,  0.4277, -0.1198, -0.2724],\n",
      "        [-0.2787,  0.1529,  0.4262,  ...,  0.3455, -0.4054, -0.1170],\n",
      "        [-0.3246,  0.2733,  0.2450,  ..., -0.2874,  0.2006, -0.3879]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[ 1.0038e+01, -3.2332e+01, -1.7638e+01, -4.2984e+00, -7.3619e+00,\n",
      "          -4.1528e+00, -1.0418e+01, -9.6483e+00],\n",
      "         [-1.5271e+00, -2.9253e+00,  1.4692e+01,  1.1771e-01, -2.8031e+01,\n",
      "          -1.4826e+01, -1.3591e+01, -1.3031e+01],\n",
      "         [ 5.0437e+00,  1.3284e+01, -1.9289e+01,  2.1704e+01,  1.2126e+01,\n",
      "          -1.2431e+01, -8.1869e+00,  1.3059e+01],\n",
      "         [ 4.7371e+00,  7.7641e-01, -4.7362e+00,  6.7955e+00, -1.1591e+01,\n",
      "          -1.5652e+01, -8.1214e+00,  5.4841e+00],\n",
      "         [-9.0737e+00,  2.6901e-02,  3.9408e+00,  7.3325e+00,  4.6150e+00,\n",
      "           5.0792e+00, -1.8730e+00, -1.8532e+00],\n",
      "         [-9.2086e+00, -5.4401e+00,  1.0150e+01,  2.2531e+01, -1.3314e+00,\n",
      "           1.6928e+01,  2.1968e+01,  9.0615e+00],\n",
      "         [-3.6905e+00,  6.3488e-01, -1.0051e+01,  2.6867e-02, -1.0225e+01,\n",
      "          -8.1241e+00,  8.2097e+00,  1.1292e+01],\n",
      "         [-9.3456e+00, -1.6803e+01,  1.4168e+00,  4.8563e+00,  7.9097e+00,\n",
      "           5.3296e+00, -1.2276e+01,  1.2155e+01],\n",
      "         [ 2.2350e+00,  4.6898e+00, -6.4375e-01, -8.4405e+00, -3.2951e+00,\n",
      "          -1.5166e+01,  1.7013e+01,  3.2372e+00],\n",
      "         [ 2.3573e+01,  1.2089e+01,  2.4974e+01,  1.6297e+01, -2.6454e+01,\n",
      "          -2.3577e+00,  3.3700e+00, -4.5178e+00],\n",
      "         [-2.2316e+01, -1.7893e+01,  1.3491e+01,  4.4925e+00,  1.0468e+01,\n",
      "           3.5651e+00,  4.1955e+00,  6.9463e-01],\n",
      "         [-5.5723e+00,  3.7885e+00,  2.0890e+00,  4.2359e+00, -2.7129e+00,\n",
      "          -9.6418e+00, -2.7016e+00,  3.6435e+00],\n",
      "         [ 6.7752e+00, -4.5826e-01,  6.2639e+00, -1.5613e+00,  1.2194e+00,\n",
      "           9.0978e-01, -1.6090e+01,  1.3233e+01],\n",
      "         [ 5.1954e+00,  6.5076e+00, -1.2036e+01,  1.6828e+00,  2.2344e+01,\n",
      "           4.4628e+00,  1.8202e+01,  5.5954e+00]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.3036, -0.2072, -0.5286,  ...,  0.6082, -0.0977,  0.1443],\n",
      "        [-0.1759, -0.9130, -0.3923,  ..., -0.4331, -0.1489, -0.0279],\n",
      "        [-0.3284, -0.3246,  0.1153,  ..., -0.4656, -0.7756,  0.0633],\n",
      "        ...,\n",
      "        [ 0.5818, -0.6512,  0.8411,  ...,  0.3370,  0.3920,  0.0410],\n",
      "        [-0.0583, -0.3745, -0.3929,  ...,  0.5654,  0.0419, -0.2443],\n",
      "        [-0.2045, -0.8261,  0.2323,  ...,  0.2101, -0.0643,  0.1402]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[  9.0183,  -3.8425, -24.9856,   6.1491,   4.0109,  -0.5442,   2.2822,\n",
      "            9.9381],\n",
      "         [ -0.3425,  -2.1864,  16.7043,  -0.8859,  -2.4357,  -0.9658,   9.0205,\n",
      "            6.2157],\n",
      "         [ -4.1617,   8.2645,  10.7086,   2.7379, -11.0518,  14.5088, -10.7278,\n",
      "            5.0654],\n",
      "         [-10.4226,   5.4194, -10.2048,   0.3411,  13.5282,  -3.4265,  17.8178,\n",
      "            2.0184],\n",
      "         [ 10.2986,  12.9430,   0.4946, -17.5078,  25.0058,  -1.6879,   0.4631,\n",
      "            8.4654],\n",
      "         [ 15.7828,  -5.8515,   3.9460,  -9.4826, -21.0313,   6.3830, -27.5985,\n",
      "          -10.2773],\n",
      "         [ -9.9086,   8.0776,   8.6040,  -0.5781,  -5.7493,  24.1766,   6.4687,\n",
      "           -2.8624],\n",
      "         [-10.8227,   4.7199,   5.4647,   6.2973,  19.8951,   4.7926,   3.5148,\n",
      "          -24.3180],\n",
      "         [ 13.6621,   0.5511, -21.8225,  -0.7619,  -1.4758,   3.1455, -12.5940,\n",
      "           -5.4574],\n",
      "         [-13.5535, -12.8134,   1.8447,  -5.8307,   2.2835,   7.4545,  -0.2731,\n",
      "            7.2432],\n",
      "         [  5.6242,  15.1219,   8.2191,   0.7624, -15.5118, -20.7673,   8.5829,\n",
      "           16.2278],\n",
      "         [ -1.9164,   6.7009,   2.0732,  13.8826,  19.4654,   9.3155,  13.3071,\n",
      "          -24.9876],\n",
      "         [  3.6507,  12.3846,   0.0608,   9.1340,  -2.8567,  -2.2726, -11.7694,\n",
      "            1.4422],\n",
      "         [  1.0569,  -6.0100,  -6.3688,  -9.5505,   1.6665,  -0.8703,   0.2263,\n",
      "           -7.4544]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[-0.1062, -0.1811, -0.0881,  ...,  0.0470,  0.2911, -0.4089],\n",
      "        [ 0.0780,  0.5004, -0.2434,  ..., -0.0879, -0.4484, -0.3502],\n",
      "        [ 0.0170,  0.7216,  0.1011,  ..., -0.2740,  0.2301,  0.3982],\n",
      "        ...,\n",
      "        [-0.1240,  0.3144,  0.2404,  ...,  0.1181, -0.0933,  0.3647],\n",
      "        [-0.3933,  0.1235,  0.0391,  ..., -0.5412,  0.0354, -0.2053],\n",
      "        [ 0.4219,  0.0431,  0.1485,  ...,  0.0669, -0.0575, -0.0973]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[  5.1592,  -4.4380,   2.2379, -13.7379,  11.8210,  49.5815, -10.5696,\n",
      "          -18.9677],\n",
      "         [ 10.4734, -18.6355, -11.2793, -70.1925,  14.1774,  18.0449, -12.8933,\n",
      "            9.9578],\n",
      "         [  1.1992,  -9.6218,  -4.6899, -17.8628, -24.1892,  25.6073,  57.8676,\n",
      "           37.2204],\n",
      "         [ 11.2338, -55.4052,   2.4113,   9.7077, -38.4089, -24.7928,  37.7823,\n",
      "          -21.4611],\n",
      "         [ 25.0939,   3.4585,   1.6369,  33.5431,   0.4215,  -4.2894,  31.6824,\n",
      "           -1.0565],\n",
      "         [-23.2655,   9.5321, -35.0608,  13.0882, -24.9097,  12.1278,  34.8868,\n",
      "           35.8758],\n",
      "         [ 20.4885,  -3.3121,  -7.7516,   9.1317,   1.8905,  -1.7448,  18.6168,\n",
      "          -17.1413],\n",
      "         [ 33.1241,   0.3499,  17.1610,  43.4151,   9.6192, -37.9151,  45.0076,\n",
      "           19.6507],\n",
      "         [ -7.0827,  21.8204,   0.3399, -54.9822, -17.1364,  19.7027,   4.3206,\n",
      "           33.2103],\n",
      "         [-15.4152,  20.1472,  16.5306, -32.8379,   7.6338,  17.2028, -13.9201,\n",
      "           38.4843],\n",
      "         [ 31.7410,  50.0213,  -6.9179, -20.8588,   8.7840, -25.2313,  -7.9564,\n",
      "          -30.1700],\n",
      "         [  0.8888,  -4.4710,  -3.6305,  18.1403,  31.5115, -27.8663, -39.9766,\n",
      "           -2.7964],\n",
      "         [-33.6426,  18.2326,  17.3002,  19.0120,  21.4273,  17.3290,  -5.2725,\n",
      "           28.6088],\n",
      "         [ 19.6796,  -1.8352, -18.2475,  -4.2762,  -8.3119,  17.0011,   2.2577,\n",
      "           10.1433]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.1309, -0.5593, -0.4700,  ...,  0.1698,  0.7746, -0.1465],\n",
      "        [-0.2304,  0.4733, -0.2889,  ..., -0.2660,  0.0502, -0.4352],\n",
      "        [ 0.0210,  0.2857,  0.0622,  ..., -0.8461, -0.4821, -0.0873],\n",
      "        ...,\n",
      "        [ 0.0830,  0.1699,  0.0748,  ...,  0.1366, -0.0514,  0.0548],\n",
      "        [ 0.0633,  0.4950, -0.7846,  ...,  0.0949, -0.7152, -0.3195],\n",
      "        [-0.0526, -0.4100,  0.0925,  ..., -0.6987,  0.1492,  0.1136]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[ -24.1988,   -9.0479,  -67.3016,   23.2815,  -61.7670,  -53.6395,\n",
      "            39.2362,   73.6442],\n",
      "         [  23.5038,   96.4368,   -3.5390,   19.9810,   17.2787,  -16.4216,\n",
      "           -14.0600,   47.0941],\n",
      "         [   6.9582,   -6.8247,   26.0530,  -73.0111,    1.5464,  -76.8314,\n",
      "           -13.6040,  -14.1836],\n",
      "         [  16.2499,  -11.0930,   32.1840,    3.3518,  -29.8367,  -52.3764,\n",
      "           -51.6314,   -2.0398],\n",
      "         [  15.0005,  -21.8318,   67.1487,   57.4821,  -12.7694,  -21.1505,\n",
      "            10.3010,   10.8144],\n",
      "         [   3.7504,   40.9652,   -8.6470,   32.9238,   -2.0554,   31.3371,\n",
      "            23.2844,    2.5794],\n",
      "         [  14.2536,   45.3318,    2.6951,   30.2622,   69.5629,  -34.6527,\n",
      "            14.0682,    5.8164],\n",
      "         [   1.5297,   73.5043,  -15.4603,    8.6044,  -25.3082,   45.2860,\n",
      "            -5.5318,   -7.1826],\n",
      "         [   0.2290,   48.2121,  -35.0062,  -64.8429,   76.1684,   34.9072,\n",
      "           -18.5823,  -18.4974],\n",
      "         [ -15.9985,   -0.1455,  -12.8200,   22.0254,   69.5535,  -70.8519,\n",
      "            13.6192,  -27.0508],\n",
      "         [ -35.0583,  -10.1963,   11.9310,  -24.3412, -126.9687,  -36.1684,\n",
      "            52.6440,   87.1661],\n",
      "         [  -3.1403,  -15.8240,  -37.3430,  -19.5647,   14.9362,   -1.8599,\n",
      "            -7.3048,  -17.3879],\n",
      "         [   2.3192,  -58.7519,  -25.8198,    0.6186,  -30.2245,   -4.4942,\n",
      "            45.4138,   29.4052],\n",
      "         [ -52.6606,   20.8394,    8.1251,   20.7220,   40.0161,   -2.4053,\n",
      "            -0.7167,  -20.3568]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[-0.6215, -0.4111,  0.2803,  ...,  0.2999,  0.0940,  0.3580],\n",
      "        [-0.4929, -0.4157,  0.0972,  ...,  0.5297, -0.0155, -0.2594],\n",
      "        [ 0.0999,  0.0697, -0.4502,  ...,  0.4325,  0.3812,  0.3383],\n",
      "        ...,\n",
      "        [-0.1169, -0.1228, -0.3227,  ..., -0.6284, -0.5385, -0.8325],\n",
      "        [-0.4655,  0.4229,  0.4480,  ...,  0.0938,  0.4551,  0.0963],\n",
      "        [-0.0502,  0.2031,  0.0515,  ..., -0.4691, -0.1015, -0.2028]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[ 4.8598e+01,  6.6584e+00, -1.7048e+01, -6.8645e-02,  9.3305e-01,\n",
      "           1.8774e+01, -1.8521e-01,  2.4189e+00],\n",
      "         [-6.0724e+01, -2.7375e+01, -5.4806e+01, -1.5357e+00, -2.3262e+01,\n",
      "          -8.1207e+01,  3.5671e+01,  3.1837e+01],\n",
      "         [-7.2985e+00,  9.0673e+00,  5.6592e+01,  1.2354e+01, -5.3041e+01,\n",
      "          -1.3623e+01,  6.3282e+00, -3.8483e+01],\n",
      "         [ 2.8875e+01,  2.6834e+01, -9.4050e+01, -3.2226e+01, -2.6745e+00,\n",
      "           1.0188e+00, -4.5911e+01,  5.9637e+00],\n",
      "         [-1.9955e+01, -5.1830e+01, -6.9874e+01,  8.6685e+00,  2.1038e+00,\n",
      "          -5.8942e+00, -2.3957e+01,  4.3516e+01],\n",
      "         [ 5.9669e+01,  1.6341e+01, -7.7468e+01, -4.9508e+00, -5.9340e+01,\n",
      "           4.3112e+01,  2.4361e+01,  6.6114e-01],\n",
      "         [-6.6513e-01,  4.4399e+01,  1.7114e+01,  5.3730e+01,  3.4404e+01,\n",
      "           2.5557e+01, -1.7483e+01,  5.7198e+01],\n",
      "         [ 3.9294e+01,  3.9919e+01, -2.5129e+01, -1.4169e+01, -2.1720e+00,\n",
      "           9.1496e+00,  2.0080e+01, -2.0821e+01],\n",
      "         [-5.0439e+01,  1.1233e+00, -1.6970e+01, -4.5010e+01, -3.1287e+00,\n",
      "          -3.1416e+01, -4.8516e+01,  1.4273e+01],\n",
      "         [-1.0778e+02,  1.0089e+02,  2.8652e+01, -8.4099e+01, -4.0641e+01,\n",
      "          -4.1087e+01,  3.9871e+01,  3.0989e+00],\n",
      "         [ 1.5681e+01, -1.7022e+01,  5.7048e+00, -6.0331e+00, -2.8736e+01,\n",
      "          -3.7682e+01, -4.7829e+01, -3.4692e+00],\n",
      "         [ 1.7960e+01,  7.3225e+01, -5.2903e+00,  2.0489e+00,  1.6194e+01,\n",
      "          -7.9716e+01, -4.0944e+01, -3.3630e+01],\n",
      "         [ 8.1659e+00, -7.9653e+00, -5.3540e+01,  5.3313e+00,  3.6492e+01,\n",
      "          -1.4924e+01,  4.3985e+01,  6.3457e+01],\n",
      "         [ 4.7044e+01, -4.0381e+01, -8.2119e+01, -2.1130e+01,  4.1243e+01,\n",
      "          -2.1919e+01,  1.0474e+01,  1.0538e+01]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=14336, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.2666,  0.0219,  0.0394,  ..., -0.5703, -0.2047, -0.6492],\n",
      "        [-0.1468, -0.3081, -0.0997,  ...,  0.6454,  0.0891, -0.1021],\n",
      "        [-0.1243,  0.1493,  1.1462,  ...,  0.1169,  0.2092, -0.1601],\n",
      "        ...,\n",
      "        [ 0.1338, -0.1952,  0.7284,  ...,  0.2326,  0.1685,  0.0895],\n",
      "        [-0.3036,  0.0280, -0.4363,  ..., -0.6369,  0.2223,  0.1688],\n",
      "        [-0.5115, -0.4810, -0.6732,  ..., -0.0703, -0.3908,  0.7750]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[ 21.9237, -16.4880,  16.1209, -16.0783,  -5.2465, -15.3104, -47.6219,\n",
      "            8.4039],\n",
      "         [ 21.0769,  -9.3068,   2.2732, -30.5317,   4.9832, -27.1161,   3.2218,\n",
      "           -8.5079],\n",
      "         [-32.7997,   7.2776,   0.8671,   0.1057,  -8.2543,  29.5591,  22.7903,\n",
      "           12.2019],\n",
      "         [-25.8735,  22.9918,   5.7754,  -1.1402,  -9.5964,  -0.7979,  14.5690,\n",
      "          -24.7853],\n",
      "         [-15.6958,  13.4669, -14.7465,  12.5151, -27.2694,  15.2506,   8.5227,\n",
      "            8.5851],\n",
      "         [-18.5242,   1.3472, -17.7039,  20.9648,  10.0311, -44.9385,   5.7649,\n",
      "           18.5575],\n",
      "         [ 12.2292,  23.9059,  23.3539, -67.8577,  -3.3317,   6.7427,  -1.2142,\n",
      "           -9.8080],\n",
      "         [-18.3159,  32.7364, -33.6719,  10.7489, -37.8205,  19.8664,  20.8467,\n",
      "          -16.7082],\n",
      "         [ 10.5199,  -5.3033, -23.4888, -19.9568,  -7.7368,  36.6475, -18.0255,\n",
      "           27.9027],\n",
      "         [  2.0216, -25.4509, -53.2069, -15.8867, -24.2491, -32.2174,  39.4964,\n",
      "          -54.1105],\n",
      "         [ 29.0289, -26.6555,  36.3648,  -2.0061, -13.8721,  13.4147,   2.7302,\n",
      "           11.5815],\n",
      "         [  7.6216,  28.2968,  -9.3357, -25.5034,  12.0334,  16.8679,  -5.8306,\n",
      "           25.6234],\n",
      "         [ 12.6792,  11.5378, -11.2524, -28.0441,  30.9553,   5.9349,   9.6373,\n",
      "          -17.5603],\n",
      "         [  0.4474,  11.0195,  11.1348, -56.1372,  -2.0899,  12.4314,  61.8297,\n",
      "           35.9876]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.5580, -0.1376,  0.2614,  ..., -0.0074,  0.5214,  0.1033],\n",
      "        [-0.0682,  0.0816, -0.1039,  ...,  0.2225,  0.1521, -0.0889],\n",
      "        [ 0.1712,  0.6522, -0.1394,  ...,  0.3476, -0.0666,  0.3444],\n",
      "        ...,\n",
      "        [ 0.4406, -0.4051,  0.4885,  ...,  0.0408,  0.4391, -0.3276],\n",
      "        [-0.3489,  0.6408,  0.1390,  ..., -0.1677, -0.0495,  0.1592],\n",
      "        [-0.1656,  0.2896, -0.4901,  ...,  0.1597, -0.2365, -0.3868]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[  7.9630,  24.4267, -11.8131, -10.7073,   3.3052, -62.2309,   2.0336,\n",
      "           12.4520],\n",
      "         [  8.6874,  -0.8809,   9.0434,  22.4412, -31.0199, -19.9432,  13.3857,\n",
      "           -6.0955],\n",
      "         [  8.8909,   4.3946, -23.0252, -26.2003,   0.4738,   0.8058, -35.1973,\n",
      "          -29.5101],\n",
      "         [ 29.9531,  34.6869,  -6.8360,  -0.9682,   6.4877, -14.3595, -34.2325,\n",
      "           20.4277],\n",
      "         [ 48.6637,  10.6989,  29.2767,   5.7239,  24.3377, -22.6566,  33.5802,\n",
      "          -42.3077],\n",
      "         [ 27.9455, -12.2990,  32.8937, -25.5940, -29.5368,  -0.2298, -45.3077,\n",
      "            4.1825],\n",
      "         [  2.3976,  15.1938,   9.5186,  20.0081,   8.5666,  18.0500,  15.0136,\n",
      "          -23.6501],\n",
      "         [ 41.2460,   8.4316,   6.4435, -13.9577,  38.9025,  14.1826,   3.0512,\n",
      "            9.8933],\n",
      "         [ -1.6759,  -3.5423, -29.1506,  -6.9859,  29.6013, -31.4949,   3.7972,\n",
      "           10.8129],\n",
      "         [ 27.4137, -13.8295,  12.3162,   6.4028,  -7.5372,   1.4741,  26.2682,\n",
      "          -35.5220],\n",
      "         [-17.4943,  -9.1549,  12.2019,  21.8165,  32.1273, -13.0280,  -9.5685,\n",
      "           44.0479],\n",
      "         [-13.1449,  27.1751,  20.4763,   3.7552,  28.6789,  -8.0385,   5.4309,\n",
      "            5.1961],\n",
      "         [  2.4402,  16.3713, -18.8435,  60.3748, -23.5772, -14.2895,  -1.7559,\n",
      "           35.2938],\n",
      "         [ -3.7283, -10.1804,  -1.4411, -11.0044,   0.9572,  -4.1067, -55.3594,\n",
      "          -19.2150]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.0313, -0.1002, -0.0065,  ...,  0.1008, -0.1459,  0.0408],\n",
      "        [-0.0628,  0.4387, -0.2704,  ..., -0.4338, -0.4721, -0.0050],\n",
      "        [ 0.3243, -0.5109,  0.2601,  ...,  0.1550, -0.0753, -0.1301],\n",
      "        ...,\n",
      "        [ 0.3575, -0.1564,  0.1536,  ..., -0.0594,  0.0595, -0.7558],\n",
      "        [ 0.4008, -0.7227, -0.2705,  ...,  1.0301,  0.1529, -0.3182],\n",
      "        [-0.4847, -0.1396,  0.5521,  ..., -0.1788, -0.0515,  0.2913]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[  8.3940,  18.0065,  -1.6954,   7.4253,  -2.5701,  -5.7252,  -2.8689,\n",
      "            8.6964],\n",
      "         [  4.5548, -14.0621,  -5.6301,   3.0636, -12.6034,  -3.6487, -12.6862,\n",
      "           -0.6524],\n",
      "         [ -6.9262,  -3.3091, -10.8158,  -4.4976,  -5.0845,   0.7158,   1.5868,\n",
      "            8.6680],\n",
      "         [ -7.0277,   3.3263,   2.0620,  -0.6699,  19.0240,  -9.3866,  -7.2888,\n",
      "           -5.2980],\n",
      "         [ 22.3497,   8.9239,   8.5088,  -6.2403,   3.2073,  21.7790,   6.0398,\n",
      "          -12.6778],\n",
      "         [  9.4491,  13.8966,   9.4412,   7.1438,  -4.6652,  -5.3268,  -1.6189,\n",
      "           -3.9937],\n",
      "         [-19.4521,   8.4481,  -3.8908, -14.0832,  -2.4261,   4.7777,  -7.3491,\n",
      "           -3.7222],\n",
      "         [  2.8315,  -9.4795,   1.6959,   7.8022,  14.4971, -27.0040, -11.7053,\n",
      "           -0.7944],\n",
      "         [ -2.5817,   7.7467,   5.5550,  -6.1387,   1.9735,   7.0835,  -4.1688,\n",
      "           -9.5716],\n",
      "         [ -8.5349,  -2.6387,  -7.7081,  -5.4475,  -3.4938,   7.2672, -15.1447,\n",
      "          -13.4503],\n",
      "         [ 15.4268, -15.9640,   3.5961,  -8.5687,  21.8079,  11.9358,  -6.1006,\n",
      "            2.4039],\n",
      "         [ 10.6863,  -2.6533, -18.8968,  -1.7700,   5.6344,  10.2336, -10.0613,\n",
      "           16.6696],\n",
      "         [ -0.3219,  15.9101,  -6.9055, -10.9946,   8.5540,   2.8275,  20.4790,\n",
      "           -5.3120],\n",
      "         [  2.8506,   5.2046,   0.8146,  -5.2791, -14.7122,   8.5422,  15.4014,\n",
      "           12.0714]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[-0.2552, -0.0803, -0.1532,  ...,  0.3221,  0.3703, -0.4525],\n",
      "        [-0.9270,  0.1221,  0.3557,  ...,  0.3623, -0.0834, -0.1477],\n",
      "        [-0.0719, -0.0625,  0.4913,  ...,  0.2794, -0.4108, -0.0889],\n",
      "        ...,\n",
      "        [ 0.3201,  0.1800, -0.2961,  ..., -0.2607, -0.2376,  0.1940],\n",
      "        [-0.1724, -0.2862, -0.0836,  ..., -0.2253, -0.1257,  0.1225],\n",
      "        [ 0.3108,  0.5071,  0.5087,  ...,  0.7350, -0.2696, -0.1460]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[  3.7732,  -3.5771,   0.8650,  27.2089,  13.9444,  -5.0433, -12.1613,\n",
      "            3.6456],\n",
      "         [ -3.2610,  -5.8144,  14.7635, -11.6817,  19.1263,  16.1071,  -9.5854,\n",
      "           -8.5029],\n",
      "         [ -6.1383,   9.5441,   9.0252,  15.8736,   3.6833, -36.6464, -10.8677,\n",
      "           -3.2993],\n",
      "         [ 13.0939,   6.8265,  -5.5909,  -0.6265,   2.7724,  12.5247, -12.1408,\n",
      "           -1.5526],\n",
      "         [ 10.1991,  -3.8320,  -1.2560,   0.6830,   3.6606,  24.7358,   6.7762,\n",
      "           -1.8303],\n",
      "         [ -0.4167,   3.0219,  18.3263,  12.6827,   8.9924,   6.7624,  -3.9687,\n",
      "           13.3696],\n",
      "         [-15.5436,   3.6360,   8.0400, -13.6117,  -4.7247,   4.8753,  -7.3368,\n",
      "          -13.4956],\n",
      "         [-33.0972,  -5.6364,   0.0906,  -9.6016,   0.2085,   4.7707,  -5.8271,\n",
      "           18.8538],\n",
      "         [ -8.5309,   6.9700, -23.1980,  15.2718, -10.3198, -26.3267,  -2.6232,\n",
      "           -0.6979],\n",
      "         [  6.1165,  10.1789,  -7.6407,  14.9356,  -1.4488,  -5.1236,  -8.4721,\n",
      "           -9.8445],\n",
      "         [ 23.8869,   4.9536,   0.0909,   0.1139,  -5.2444,   2.4640,   8.9572,\n",
      "           -5.8369],\n",
      "         [-24.7083,  20.2285, -18.5823,   9.2996, -12.9194,  -8.5943,   0.1144,\n",
      "          -16.9659],\n",
      "         [  0.0446,  -6.4911,  -5.4535,   3.6406, -16.1993,  10.0953, -15.8086,\n",
      "           13.9084],\n",
      "         [  4.4756, -11.5686,  -4.0951,   7.7103,  -1.0922, -15.5335,   5.3262,\n",
      "           28.0538]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.1240,  0.2670, -0.5397,  ...,  0.6702,  0.1022,  0.1242],\n",
      "        [-0.4531, -0.0087,  0.4043,  ..., -0.0728,  0.0227, -0.8649],\n",
      "        [ 0.1386,  0.5580, -0.6122,  ...,  0.0423, -0.3499, -0.2998],\n",
      "        ...,\n",
      "        [-0.1803, -0.4057,  0.5100,  ...,  0.5912,  0.6761,  0.0130],\n",
      "        [-0.5652,  0.1924,  0.3949,  ...,  0.1815, -0.0687, -0.0253],\n",
      "        [ 0.3501, -0.1992,  0.0200,  ...,  0.4166, -0.1787,  0.0946]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[-15.5066, -16.0538,  55.8926, -27.6788,  13.4234,  28.0261,  11.0487,\n",
      "           -7.2669],\n",
      "         [ 13.9191, -25.7434,  -3.2202,  30.7923,  -2.0166, -34.5260, -18.3216,\n",
      "          -17.3863],\n",
      "         [ 18.4772,  37.5481,  10.4758,  13.1629,  -7.0446,   9.8030,  23.4700,\n",
      "           -8.1732],\n",
      "         [ -6.6260, -30.0379, -10.4996,   3.4287,  -3.2371, -38.6504, -12.8838,\n",
      "          -58.1461],\n",
      "         [ -8.9091,  20.4691,  23.7064,  16.1629, -14.0358, -19.6090, -54.9789,\n",
      "           -5.2030],\n",
      "         [-13.2121,  14.4311,  28.5287,   7.0219, -15.0309,  17.8359,  35.8925,\n",
      "           38.9907],\n",
      "         [ 14.8853, -23.0500,   5.1312,   8.7120, -41.8580, -22.8643,  -4.5572,\n",
      "          -29.9207],\n",
      "         [-31.6757,  -7.9137,  65.6124,  -9.1086,   2.5457,   7.1243, -13.7989,\n",
      "           31.8567],\n",
      "         [-23.8504,  -4.4205,   1.0238, -11.9997, -10.6529, -17.9772,  27.9126,\n",
      "            3.8986],\n",
      "         [ 17.2949,   0.8430,   3.1350, -35.9356,  -4.2839,  11.4053,  16.4051,\n",
      "            8.7602],\n",
      "         [  5.4537, -25.9011,   6.6706, -22.7153,  25.8053,  19.2146,   0.6667,\n",
      "           33.6310],\n",
      "         [ 20.9734, -22.0162,  -9.9939,  -7.1744,  18.7786,   3.4453,  -4.8871,\n",
      "          -11.0454],\n",
      "         [-18.1411,  15.9126,   0.2998, -18.7358,  25.6993,  -7.7078, -10.4269,\n",
      "          -12.0657],\n",
      "         [-14.6842, -12.4380,  -2.8697,  37.1574,  17.4590,  21.3370,  -7.2400,\n",
      "           25.7671]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[-0.0415,  0.0723, -0.3512,  ..., -0.0844, -0.2275,  0.4281],\n",
      "        [ 0.1012, -0.5262, -0.4637,  ...,  0.5584, -0.5323,  0.2380],\n",
      "        [-0.1981, -0.0600,  0.3348,  ..., -0.0355,  0.3885,  0.0156],\n",
      "        ...,\n",
      "        [ 0.0208,  0.3471,  0.1114,  ..., -0.2404, -0.2058,  0.3206],\n",
      "        [-0.5874,  0.0560,  0.4071,  ...,  0.0322, -0.1915, -0.2292],\n",
      "        [-0.2520, -0.5504, -0.2261,  ...,  0.1929, -0.4724, -0.1374]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[ -60.6602,   25.8135,  -94.2114,   47.1415,  -31.6733,   10.9478,\n",
      "            82.2813,  -42.6940],\n",
      "         [ -43.5628,  -13.2748,   -1.4393,    8.0248,    7.4503,    9.5952,\n",
      "           -72.9113,  -13.0606],\n",
      "         [  -9.7915,  -29.2414,   72.9764,  -33.1114,   24.9406,   38.9839,\n",
      "           -58.0879,   27.9203],\n",
      "         [  36.4449,  -11.6240,   78.5990,  -31.1996,  -24.4041,   17.4884,\n",
      "           -33.3713,   60.5485],\n",
      "         [  12.6907,   37.8342,   62.8179,  -49.0090,  -36.0400,   -5.3279,\n",
      "           -18.7480,  -43.8835],\n",
      "         [  47.2261,   20.3890,   16.9595,   25.9735,  -54.1148,    2.6519,\n",
      "            -1.9879,  -15.6407],\n",
      "         [  38.4863,   38.8698,   -0.5773,  -35.9652,   19.8082,  -39.3982,\n",
      "            59.5513,  -19.8865],\n",
      "         [  33.2521,   36.1976,  -46.2948,  -56.7818,    5.7579,   29.2963,\n",
      "           -27.2788,  -18.1317],\n",
      "         [  17.4017,  -55.3138,  -83.5832,   -3.7239,    8.0098,  125.9016,\n",
      "            -9.5751,   47.0662],\n",
      "         [  29.2300,    6.8346,  -22.0443,  -17.3723,   16.4059,   -9.5190,\n",
      "            21.8125,  -28.9114],\n",
      "         [ -13.7913,  -20.3375,    0.8519,   24.1103,    1.4725, -148.2851,\n",
      "           -16.5251,   -9.9674],\n",
      "         [  44.2487,   45.6317,   -7.7740,   -5.5166,   67.0876,   26.8905,\n",
      "           -35.1612,  -20.0738],\n",
      "         [  60.7829,   -0.7688,    5.1741,   66.0564,  -21.0751,   12.8202,\n",
      "             7.7937,  -44.5393],\n",
      "         [  -8.7287,  -36.7194,   68.1022,    7.6826,  -11.4951,  -11.7255,\n",
      "            38.7762,  -29.0336]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[-0.2323,  0.1831,  0.1745,  ...,  0.3464, -0.2924,  0.5802],\n",
      "        [-0.2152, -0.6528,  0.1677,  ..., -0.0703,  0.3661,  0.0620],\n",
      "        [ 0.2356, -0.6458, -0.4169,  ..., -0.7492,  0.2562,  0.2049],\n",
      "        ...,\n",
      "        [-0.2970,  0.2864,  0.5264,  ..., -0.0021,  0.1239,  0.5890],\n",
      "        [-0.2051,  0.0203,  0.3761,  ...,  0.2263,  0.5829, -0.0685],\n",
      "        [-0.1111, -1.0016, -0.0787,  ..., -0.0229,  0.2358,  0.0874]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[ 16.9129,  42.1157,  -9.1177,  43.8100, -92.9501, -47.5779,  -7.9936,\n",
      "          -32.0901],\n",
      "         [  3.0377,  33.1487, 101.8767,   2.2817, -56.5142,  -2.6853,  48.0055,\n",
      "          -69.4504],\n",
      "         [-25.7313, -49.0023,  53.6090, -36.8438,   8.8195,  -3.4438,  62.4176,\n",
      "          108.0978],\n",
      "         [-41.6942, -44.2191, -49.8761,   8.3115,  14.4765, -25.8576, -35.4727,\n",
      "           38.7631],\n",
      "         [-13.1563, -42.1154,  69.2243,  90.1575, -26.5879,   7.6712,   5.4307,\n",
      "           19.7617],\n",
      "         [  1.3015,  30.8813, -10.8114,  98.4420, -21.4019, -17.3130,   8.9426,\n",
      "           78.2684],\n",
      "         [-34.1138, -11.0207, -27.3678,  56.7089,   0.4730,  -7.4884,   9.9288,\n",
      "           42.7061],\n",
      "         [  0.1752, -80.9487, -24.8102,  35.7760,  -4.7760,  73.1604,  -7.6279,\n",
      "          -12.0575],\n",
      "         [-12.5209,   1.0678,   2.2092,  58.8254, -66.4322,   7.4295,  46.1252,\n",
      "          -17.4495],\n",
      "         [ 53.4954, -21.5714,  73.6313,  45.2803, -81.2027,   5.4544,  98.9186,\n",
      "          -14.5103],\n",
      "         [-34.0170, -29.2316,  32.0543, -30.1418, -38.9377,  64.8540,  53.2533,\n",
      "           -3.9385],\n",
      "         [-13.6410, -26.9329, -19.5206,  13.1551,  -5.5941,  50.1454,  34.7345,\n",
      "           32.0062],\n",
      "         [ -9.0403,   5.7003, -45.5269,  49.4316,  28.7986,  44.4922, -35.4264,\n",
      "           53.0798],\n",
      "         [-59.0941,  -7.5926,  54.8515, -27.7066, -15.3178, -57.1563, -39.0752,\n",
      "          -50.1309]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=14336, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "self.nero_A.weight: Parameter containing:\n",
      "tensor([[ 0.2793,  0.9967, -0.4486,  ..., -0.3429, -0.2898, -0.4080],\n",
      "        [-0.0140,  0.0299,  0.0787,  ...,  0.0148, -0.1749, -0.1660],\n",
      "        [-0.6058,  0.2285,  0.2972,  ...,  0.7412, -0.1283,  0.0670],\n",
      "        ...,\n",
      "        [-0.1231, -0.0331, -0.2356,  ...,  0.2916,  0.2706, -0.0631],\n",
      "        [-0.5548, -0.7454, -0.0413,  ...,  0.2274,  0.0746, -0.3040],\n",
      "        [-0.5897, -0.1239,  0.2319,  ..., -0.2178,  0.4592,  0.1608]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "test_out: tensor([[[-28.8697, -10.4574,   2.3093,  -1.8311,   9.3099,  -7.1167, -19.2486,\n",
      "           26.6775],\n",
      "         [ 27.1916,  14.1628,  -5.2475,  -3.0975,   1.1492,  13.1013,  17.9771,\n",
      "          -18.3145],\n",
      "         [ 40.6785,  48.0508,  29.4221, -18.1169,  -2.5401,  10.3081, -35.2484,\n",
      "            5.8384],\n",
      "         [ 17.7205,  -2.7768,  47.3216,  45.2213,  58.9405,  31.1158,   8.4302,\n",
      "           27.2363],\n",
      "         [ 31.5211,  16.8995, -26.8126,   3.1452,   7.9122,   4.0181,  -1.1609,\n",
      "            2.0190],\n",
      "         [-21.3723,  -8.5716, -21.3095,  18.6012,  -1.1104,  -9.5319,  27.3022,\n",
      "            9.1784],\n",
      "         [  1.2773,  -5.4820, -20.8417,  -2.8764,  15.0265, -20.6107,  41.8680,\n",
      "           14.1221],\n",
      "         [-18.3217,  23.0762, -19.2099,  21.7306,  -3.5165, -24.7389, -43.2501,\n",
      "          -22.8690],\n",
      "         [ 15.8195,  28.2525, -12.9726,  20.6450,  -7.0034, -12.6675,   8.9835,\n",
      "           15.2488],\n",
      "         [ 28.5880, -28.5086, -24.0803,   3.7705,   8.3424, -37.4412, -16.4850,\n",
      "            3.5007],\n",
      "         [ 53.7599, -26.7461,   0.5176,   1.8785,  -6.9658,  68.4421,  10.8486,\n",
      "           -1.3280],\n",
      "         [ 22.3691,  19.4792,  19.6893,   6.5030,   0.3830,  -4.6451, -17.8718,\n",
      "           -6.7061],\n",
      "         [-18.9718,  36.6545,  19.7736, -12.2951, -13.0798,  27.8793,  18.3365,\n",
      "           -1.6959],\n",
      "         [ 10.6102,  29.4945, -46.7512,  -5.9171,   8.0367, -22.1314, -29.4521,\n",
      "          -30.5546]]], device='cuda:0')\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n"
     ]
    }
   ],
   "source": [
    "nero_model.train()\n",
    "nero_model.gradient_checkpointing_enable() # Fix error: 'LlamaDecoderLayer' object has no attribute '_gradient_checkpointing_func'\n",
    "device = next(nero_model.parameters()).device\n",
    "inputs = tokenizer(\"Preheat the oven to 350 degrees and place the cookie dough\", return_tensors='pt')\n",
    "nero_model_outs = nero_model(input_ids=inputs['input_ids'].to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "only Tensors of floating point and complex dtype can require gradients",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-26-2607209966.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnero_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munfreeze_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipython-input-22-1521194664.py\u001b[0m in \u001b[0;36munfreeze_all\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0munfreeze_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m             \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mnero_layer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnero_layers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: only Tensors of floating point and complex dtype can require gradients"
     ]
    }
   ],
   "source": [
    "nero_model.unfreeze_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_grad',\n",
       " '_grad_fn',\n",
       " '_post_accumulate_grad_hooks',\n",
       " 'grad',\n",
       " 'grad_fn',\n",
       " 'register_post_accumulate_grad_hook',\n",
       " 'requires_grad',\n",
       " 'requires_grad_',\n",
       " 'retain_grad',\n",
       " 'retains_grad']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in dir(nero_model.base_model.model.layers[0].self_attn.q_proj.lora_A.weight) if 'grad' in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['requires_grad_', 'zero_grad']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in dir(nero_model) if 'grad' in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=4096, out_features=8, bias=False)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nero_model.base_model.model.layers[0].self_attn.q_proj.lora_A.requires_grad_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_model.model.embed_tokens.weight --> True torch.float16\n",
      "\n",
      "base_model.model.layers.0.self_attn.q_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.0.self_attn.q_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.0.self_attn.q_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.0.self_attn.q_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.0.self_attn.q_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.0.self_attn.q_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.0.self_attn.q_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.0.self_attn.k_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.0.self_attn.k_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.0.self_attn.k_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.0.self_attn.k_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.0.self_attn.k_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.0.self_attn.k_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.0.self_attn.k_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.0.self_attn.v_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.0.self_attn.v_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.0.self_attn.v_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.0.self_attn.v_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.0.self_attn.v_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.0.self_attn.v_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.0.self_attn.v_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.0.self_attn.o_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.0.self_attn.o_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.0.self_attn.o_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.0.self_attn.o_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.0.self_attn.o_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.0.self_attn.o_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.0.self_attn.o_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.0.mlp.gate_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.0.mlp.gate_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.0.mlp.gate_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.0.mlp.gate_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.0.mlp.gate_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.0.mlp.gate_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.0.mlp.gate_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.0.mlp.up_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.0.mlp.up_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.0.mlp.up_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.0.mlp.up_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.0.mlp.up_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.0.mlp.up_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.0.mlp.up_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.0.mlp.down_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.0.mlp.down_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.0.mlp.down_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.0.mlp.down_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.0.mlp.down_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.0.mlp.down_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.0.mlp.down_proj.nero_B.bias --> True torch.float32\n",
      "base_model.model.layers.0.input_layernorm.weight --> True torch.float16\n",
      "base_model.model.layers.0.post_attention_layernorm.weight --> True torch.float16\n",
      "\n",
      "base_model.model.layers.1.self_attn.q_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.1.self_attn.q_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.1.self_attn.q_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.1.self_attn.q_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.1.self_attn.q_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.1.self_attn.q_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.1.self_attn.q_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.1.self_attn.k_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.1.self_attn.k_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.1.self_attn.k_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.1.self_attn.k_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.1.self_attn.k_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.1.self_attn.k_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.1.self_attn.k_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.1.self_attn.v_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.1.self_attn.v_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.1.self_attn.v_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.1.self_attn.v_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.1.self_attn.v_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.1.self_attn.v_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.1.self_attn.v_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.1.self_attn.o_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.1.self_attn.o_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.1.self_attn.o_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.1.self_attn.o_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.1.self_attn.o_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.1.self_attn.o_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.1.self_attn.o_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.1.mlp.gate_proj.base_layer.weight --> True torch.float16\n",
      "base_model.model.layers.1.mlp.gate_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.1.mlp.gate_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.1.mlp.gate_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.1.mlp.gate_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.1.mlp.gate_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.1.mlp.gate_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.1.mlp.up_proj.base_layer.weight --> True torch.float16\n",
      "base_model.model.layers.1.mlp.up_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.1.mlp.up_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.1.mlp.up_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.1.mlp.up_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.1.mlp.up_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.1.mlp.up_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.1.mlp.down_proj.base_layer.weight --> True torch.float16\n",
      "base_model.model.layers.1.mlp.down_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.1.mlp.down_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.1.mlp.down_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.1.mlp.down_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.1.mlp.down_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.1.mlp.down_proj.nero_B.bias --> True torch.float32\n",
      "base_model.model.layers.1.input_layernorm.weight --> True torch.float16\n",
      "base_model.model.layers.1.post_attention_layernorm.weight --> True torch.float16\n",
      "\n",
      "base_model.model.layers.2.self_attn.q_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.2.self_attn.q_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.2.self_attn.q_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.2.self_attn.q_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.2.self_attn.q_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.2.self_attn.q_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.2.self_attn.q_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.2.self_attn.k_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.2.self_attn.k_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.2.self_attn.k_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.2.self_attn.k_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.2.self_attn.k_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.2.self_attn.k_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.2.self_attn.k_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.2.self_attn.v_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.2.self_attn.v_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.2.self_attn.v_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.2.self_attn.v_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.2.self_attn.v_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.2.self_attn.v_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.2.self_attn.v_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.2.self_attn.o_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.2.self_attn.o_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.2.self_attn.o_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.2.self_attn.o_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.2.self_attn.o_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.2.self_attn.o_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.2.self_attn.o_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.2.mlp.gate_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.2.mlp.gate_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.2.mlp.gate_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.2.mlp.gate_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.2.mlp.gate_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.2.mlp.gate_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.2.mlp.gate_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.2.mlp.up_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.2.mlp.up_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.2.mlp.up_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.2.mlp.up_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.2.mlp.up_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.2.mlp.up_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.2.mlp.up_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.2.mlp.down_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.2.mlp.down_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.2.mlp.down_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.2.mlp.down_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.2.mlp.down_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.2.mlp.down_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.2.mlp.down_proj.nero_B.bias --> True torch.float32\n",
      "base_model.model.layers.2.input_layernorm.weight --> True torch.float16\n",
      "base_model.model.layers.2.post_attention_layernorm.weight --> True torch.float16\n",
      "\n",
      "base_model.model.layers.3.self_attn.q_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.3.self_attn.q_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.3.self_attn.q_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.3.self_attn.q_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.3.self_attn.q_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.3.self_attn.q_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.3.self_attn.q_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.3.self_attn.k_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.3.self_attn.k_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.3.self_attn.k_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.3.self_attn.k_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.3.self_attn.k_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.3.self_attn.k_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.3.self_attn.k_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.3.self_attn.v_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.3.self_attn.v_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.3.self_attn.v_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.3.self_attn.v_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.3.self_attn.v_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.3.self_attn.v_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.3.self_attn.v_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.3.self_attn.o_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.3.self_attn.o_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.3.self_attn.o_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.3.self_attn.o_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.3.self_attn.o_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.3.self_attn.o_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.3.self_attn.o_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.3.mlp.gate_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.3.mlp.gate_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.3.mlp.gate_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.3.mlp.gate_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.3.mlp.gate_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.3.mlp.gate_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.3.mlp.gate_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.3.mlp.up_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.3.mlp.up_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.3.mlp.up_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.3.mlp.up_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.3.mlp.up_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.3.mlp.up_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.3.mlp.up_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.3.mlp.down_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.3.mlp.down_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.3.mlp.down_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.3.mlp.down_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.3.mlp.down_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.3.mlp.down_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.3.mlp.down_proj.nero_B.bias --> True torch.float32\n",
      "base_model.model.layers.3.input_layernorm.weight --> True torch.float16\n",
      "base_model.model.layers.3.post_attention_layernorm.weight --> True torch.float16\n",
      "\n",
      "base_model.model.layers.4.self_attn.q_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.4.self_attn.q_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.4.self_attn.q_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.4.self_attn.q_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.4.self_attn.q_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.4.self_attn.q_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.4.self_attn.q_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.4.self_attn.k_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.4.self_attn.k_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.4.self_attn.k_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.4.self_attn.k_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.4.self_attn.k_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.4.self_attn.k_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.4.self_attn.k_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.4.self_attn.v_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.4.self_attn.v_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.4.self_attn.v_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.4.self_attn.v_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.4.self_attn.v_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.4.self_attn.v_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.4.self_attn.v_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.4.self_attn.o_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.4.self_attn.o_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.4.self_attn.o_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.4.self_attn.o_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.4.self_attn.o_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.4.self_attn.o_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.4.self_attn.o_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.4.mlp.gate_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.4.mlp.gate_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.4.mlp.gate_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.4.mlp.gate_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.4.mlp.gate_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.4.mlp.gate_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.4.mlp.gate_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.4.mlp.up_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.4.mlp.up_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.4.mlp.up_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.4.mlp.up_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.4.mlp.up_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.4.mlp.up_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.4.mlp.up_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.4.mlp.down_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.4.mlp.down_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.4.mlp.down_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.4.mlp.down_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.4.mlp.down_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.4.mlp.down_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.4.mlp.down_proj.nero_B.bias --> True torch.float32\n",
      "base_model.model.layers.4.input_layernorm.weight --> True torch.float16\n",
      "base_model.model.layers.4.post_attention_layernorm.weight --> True torch.float16\n",
      "\n",
      "base_model.model.layers.5.self_attn.q_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.5.self_attn.q_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.5.self_attn.q_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.5.self_attn.q_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.5.self_attn.q_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.5.self_attn.q_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.5.self_attn.q_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.5.self_attn.k_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.5.self_attn.k_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.5.self_attn.k_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.5.self_attn.k_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.5.self_attn.k_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.5.self_attn.k_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.5.self_attn.k_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.5.self_attn.v_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.5.self_attn.v_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.5.self_attn.v_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.5.self_attn.v_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.5.self_attn.v_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.5.self_attn.v_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.5.self_attn.v_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.5.self_attn.o_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.5.self_attn.o_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.5.self_attn.o_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.5.self_attn.o_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.5.self_attn.o_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.5.self_attn.o_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.5.self_attn.o_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.5.mlp.gate_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.5.mlp.gate_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.5.mlp.gate_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.5.mlp.gate_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.5.mlp.gate_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.5.mlp.gate_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.5.mlp.gate_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.5.mlp.up_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.5.mlp.up_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.5.mlp.up_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.5.mlp.up_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.5.mlp.up_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.5.mlp.up_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.5.mlp.up_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.5.mlp.down_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.5.mlp.down_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.5.mlp.down_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.5.mlp.down_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.5.mlp.down_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.5.mlp.down_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.5.mlp.down_proj.nero_B.bias --> True torch.float32\n",
      "base_model.model.layers.5.input_layernorm.weight --> True torch.float16\n",
      "base_model.model.layers.5.post_attention_layernorm.weight --> True torch.float16\n",
      "\n",
      "base_model.model.layers.6.self_attn.q_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.6.self_attn.q_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.6.self_attn.q_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.6.self_attn.q_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.6.self_attn.q_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.6.self_attn.q_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.6.self_attn.q_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.6.self_attn.k_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.6.self_attn.k_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.6.self_attn.k_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.6.self_attn.k_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.6.self_attn.k_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.6.self_attn.k_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.6.self_attn.k_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.6.self_attn.v_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.6.self_attn.v_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.6.self_attn.v_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.6.self_attn.v_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.6.self_attn.v_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.6.self_attn.v_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.6.self_attn.v_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.6.self_attn.o_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.6.self_attn.o_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.6.self_attn.o_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.6.self_attn.o_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.6.self_attn.o_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.6.self_attn.o_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.6.self_attn.o_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.6.mlp.gate_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.6.mlp.gate_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.6.mlp.gate_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.6.mlp.gate_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.6.mlp.gate_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.6.mlp.gate_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.6.mlp.gate_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.6.mlp.up_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.6.mlp.up_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.6.mlp.up_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.6.mlp.up_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.6.mlp.up_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.6.mlp.up_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.6.mlp.up_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.6.mlp.down_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.6.mlp.down_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.6.mlp.down_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.6.mlp.down_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.6.mlp.down_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.6.mlp.down_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.6.mlp.down_proj.nero_B.bias --> True torch.float32\n",
      "base_model.model.layers.6.input_layernorm.weight --> True torch.float16\n",
      "base_model.model.layers.6.post_attention_layernorm.weight --> True torch.float16\n",
      "\n",
      "base_model.model.layers.7.self_attn.q_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.7.self_attn.q_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.7.self_attn.q_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.7.self_attn.q_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.7.self_attn.q_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.7.self_attn.q_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.7.self_attn.q_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.7.self_attn.k_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.7.self_attn.k_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.7.self_attn.k_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.7.self_attn.k_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.7.self_attn.k_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.7.self_attn.k_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.7.self_attn.k_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.7.self_attn.v_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.7.self_attn.v_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.7.self_attn.v_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.7.self_attn.v_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.7.self_attn.v_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.7.self_attn.v_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.7.self_attn.v_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.7.self_attn.o_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.7.self_attn.o_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.7.self_attn.o_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.7.self_attn.o_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.7.self_attn.o_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.7.self_attn.o_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.7.self_attn.o_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.7.mlp.gate_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.7.mlp.gate_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.7.mlp.gate_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.7.mlp.gate_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.7.mlp.gate_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.7.mlp.gate_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.7.mlp.gate_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.7.mlp.up_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.7.mlp.up_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.7.mlp.up_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.7.mlp.up_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.7.mlp.up_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.7.mlp.up_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.7.mlp.up_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.7.mlp.down_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.7.mlp.down_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.7.mlp.down_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.7.mlp.down_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.7.mlp.down_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.7.mlp.down_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.7.mlp.down_proj.nero_B.bias --> True torch.float32\n",
      "base_model.model.layers.7.input_layernorm.weight --> True torch.float16\n",
      "base_model.model.layers.7.post_attention_layernorm.weight --> True torch.float16\n",
      "\n",
      "base_model.model.layers.8.self_attn.q_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.8.self_attn.q_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.8.self_attn.q_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.8.self_attn.q_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.8.self_attn.q_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.8.self_attn.q_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.8.self_attn.q_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.8.self_attn.k_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.8.self_attn.k_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.8.self_attn.k_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.8.self_attn.k_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.8.self_attn.k_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.8.self_attn.k_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.8.self_attn.k_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.8.self_attn.v_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.8.self_attn.v_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.8.self_attn.v_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.8.self_attn.v_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.8.self_attn.v_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.8.self_attn.v_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.8.self_attn.v_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.8.self_attn.o_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.8.self_attn.o_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.8.self_attn.o_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.8.self_attn.o_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.8.self_attn.o_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.8.self_attn.o_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.8.self_attn.o_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.8.mlp.gate_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.8.mlp.gate_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.8.mlp.gate_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.8.mlp.gate_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.8.mlp.gate_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.8.mlp.gate_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.8.mlp.gate_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.8.mlp.up_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.8.mlp.up_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.8.mlp.up_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.8.mlp.up_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.8.mlp.up_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.8.mlp.up_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.8.mlp.up_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.8.mlp.down_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.8.mlp.down_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.8.mlp.down_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.8.mlp.down_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.8.mlp.down_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.8.mlp.down_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.8.mlp.down_proj.nero_B.bias --> True torch.float32\n",
      "base_model.model.layers.8.input_layernorm.weight --> True torch.float16\n",
      "base_model.model.layers.8.post_attention_layernorm.weight --> True torch.float16\n",
      "\n",
      "base_model.model.layers.9.self_attn.q_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.9.self_attn.q_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.9.self_attn.q_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.9.self_attn.q_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.9.self_attn.q_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.9.self_attn.q_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.9.self_attn.q_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.9.self_attn.k_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.9.self_attn.k_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.9.self_attn.k_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.9.self_attn.k_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.9.self_attn.k_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.9.self_attn.k_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.9.self_attn.k_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.9.self_attn.v_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.9.self_attn.v_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.9.self_attn.v_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.9.self_attn.v_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.9.self_attn.v_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.9.self_attn.v_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.9.self_attn.v_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.9.self_attn.o_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.9.self_attn.o_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.9.self_attn.o_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.9.self_attn.o_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.9.self_attn.o_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.9.self_attn.o_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.9.self_attn.o_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.9.mlp.gate_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.9.mlp.gate_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.9.mlp.gate_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.9.mlp.gate_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.9.mlp.gate_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.9.mlp.gate_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.9.mlp.gate_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.9.mlp.up_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.9.mlp.up_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.9.mlp.up_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.9.mlp.up_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.9.mlp.up_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.9.mlp.up_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.9.mlp.up_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.9.mlp.down_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.9.mlp.down_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.9.mlp.down_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.9.mlp.down_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.9.mlp.down_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.9.mlp.down_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.9.mlp.down_proj.nero_B.bias --> True torch.float32\n",
      "base_model.model.layers.9.input_layernorm.weight --> True torch.float16\n",
      "base_model.model.layers.9.post_attention_layernorm.weight --> True torch.float16\n",
      "\n",
      "base_model.model.layers.10.self_attn.q_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.10.self_attn.q_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.10.self_attn.q_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.10.self_attn.q_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.10.self_attn.q_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.10.self_attn.q_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.10.self_attn.q_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.10.self_attn.k_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.10.self_attn.k_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.10.self_attn.k_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.10.self_attn.k_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.10.self_attn.k_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.10.self_attn.k_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.10.self_attn.k_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.10.self_attn.v_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.10.self_attn.v_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.10.self_attn.v_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.10.self_attn.v_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.10.self_attn.v_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.10.self_attn.v_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.10.self_attn.v_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.10.self_attn.o_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.10.self_attn.o_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.10.self_attn.o_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.10.self_attn.o_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.10.self_attn.o_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.10.self_attn.o_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.10.self_attn.o_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.10.mlp.gate_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.10.mlp.gate_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.10.mlp.gate_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.10.mlp.gate_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.10.mlp.gate_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.10.mlp.gate_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.10.mlp.gate_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.10.mlp.up_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.10.mlp.up_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.10.mlp.up_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.10.mlp.up_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.10.mlp.up_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.10.mlp.up_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.10.mlp.up_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.10.mlp.down_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.10.mlp.down_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.10.mlp.down_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.10.mlp.down_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.10.mlp.down_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.10.mlp.down_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.10.mlp.down_proj.nero_B.bias --> True torch.float32\n",
      "base_model.model.layers.10.input_layernorm.weight --> True torch.float16\n",
      "base_model.model.layers.10.post_attention_layernorm.weight --> True torch.float16\n",
      "\n",
      "base_model.model.layers.11.self_attn.q_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.11.self_attn.q_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.11.self_attn.q_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.11.self_attn.q_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.11.self_attn.q_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.11.self_attn.q_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.11.self_attn.q_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.11.self_attn.k_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.11.self_attn.k_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.11.self_attn.k_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.11.self_attn.k_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.11.self_attn.k_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.11.self_attn.k_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.11.self_attn.k_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.11.self_attn.v_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.11.self_attn.v_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.11.self_attn.v_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.11.self_attn.v_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.11.self_attn.v_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.11.self_attn.v_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.11.self_attn.v_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.11.self_attn.o_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.11.self_attn.o_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.11.self_attn.o_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.11.self_attn.o_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.11.self_attn.o_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.11.self_attn.o_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.11.self_attn.o_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.11.mlp.gate_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.11.mlp.gate_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.11.mlp.gate_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.11.mlp.gate_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.11.mlp.gate_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.11.mlp.gate_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.11.mlp.gate_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.11.mlp.up_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.11.mlp.up_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.11.mlp.up_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.11.mlp.up_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.11.mlp.up_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.11.mlp.up_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.11.mlp.up_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.11.mlp.down_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.11.mlp.down_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.11.mlp.down_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.11.mlp.down_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.11.mlp.down_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.11.mlp.down_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.11.mlp.down_proj.nero_B.bias --> True torch.float32\n",
      "base_model.model.layers.11.input_layernorm.weight --> True torch.float16\n",
      "base_model.model.layers.11.post_attention_layernorm.weight --> True torch.float16\n",
      "\n",
      "base_model.model.layers.12.self_attn.q_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.12.self_attn.q_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.12.self_attn.q_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.12.self_attn.q_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.12.self_attn.q_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.12.self_attn.q_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.12.self_attn.q_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.12.self_attn.k_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.12.self_attn.k_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.12.self_attn.k_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.12.self_attn.k_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.12.self_attn.k_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.12.self_attn.k_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.12.self_attn.k_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.12.self_attn.v_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.12.self_attn.v_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.12.self_attn.v_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.12.self_attn.v_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.12.self_attn.v_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.12.self_attn.v_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.12.self_attn.v_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.12.self_attn.o_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.12.self_attn.o_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.12.self_attn.o_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.12.self_attn.o_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.12.self_attn.o_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.12.self_attn.o_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.12.self_attn.o_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.12.mlp.gate_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.12.mlp.gate_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.12.mlp.gate_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.12.mlp.gate_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.12.mlp.gate_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.12.mlp.gate_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.12.mlp.gate_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.12.mlp.up_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.12.mlp.up_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.12.mlp.up_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.12.mlp.up_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.12.mlp.up_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.12.mlp.up_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.12.mlp.up_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.12.mlp.down_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.12.mlp.down_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.12.mlp.down_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.12.mlp.down_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.12.mlp.down_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.12.mlp.down_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.12.mlp.down_proj.nero_B.bias --> True torch.float32\n",
      "base_model.model.layers.12.input_layernorm.weight --> True torch.float16\n",
      "base_model.model.layers.12.post_attention_layernorm.weight --> True torch.float16\n",
      "\n",
      "base_model.model.layers.13.self_attn.q_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.13.self_attn.q_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.13.self_attn.q_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.13.self_attn.q_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.13.self_attn.q_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.13.self_attn.q_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.13.self_attn.q_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.13.self_attn.k_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.13.self_attn.k_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.13.self_attn.k_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.13.self_attn.k_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.13.self_attn.k_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.13.self_attn.k_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.13.self_attn.k_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.13.self_attn.v_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.13.self_attn.v_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.13.self_attn.v_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.13.self_attn.v_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.13.self_attn.v_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.13.self_attn.v_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.13.self_attn.v_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.13.self_attn.o_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.13.self_attn.o_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.13.self_attn.o_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.13.self_attn.o_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.13.self_attn.o_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.13.self_attn.o_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.13.self_attn.o_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.13.mlp.gate_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.13.mlp.gate_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.13.mlp.gate_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.13.mlp.gate_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.13.mlp.gate_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.13.mlp.gate_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.13.mlp.gate_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.13.mlp.up_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.13.mlp.up_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.13.mlp.up_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.13.mlp.up_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.13.mlp.up_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.13.mlp.up_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.13.mlp.up_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.13.mlp.down_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.13.mlp.down_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.13.mlp.down_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.13.mlp.down_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.13.mlp.down_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.13.mlp.down_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.13.mlp.down_proj.nero_B.bias --> True torch.float32\n",
      "base_model.model.layers.13.input_layernorm.weight --> True torch.float16\n",
      "base_model.model.layers.13.post_attention_layernorm.weight --> True torch.float16\n",
      "\n",
      "base_model.model.layers.14.self_attn.q_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.14.self_attn.q_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.14.self_attn.q_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.14.self_attn.q_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.14.self_attn.q_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.14.self_attn.q_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.14.self_attn.q_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.14.self_attn.k_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.14.self_attn.k_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.14.self_attn.k_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.14.self_attn.k_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.14.self_attn.k_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.14.self_attn.k_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.14.self_attn.k_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.14.self_attn.v_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.14.self_attn.v_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.14.self_attn.v_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.14.self_attn.v_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.14.self_attn.v_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.14.self_attn.v_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.14.self_attn.v_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.14.self_attn.o_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.14.self_attn.o_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.14.self_attn.o_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.14.self_attn.o_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.14.self_attn.o_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.14.self_attn.o_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.14.self_attn.o_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.14.mlp.gate_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.14.mlp.gate_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.14.mlp.gate_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.14.mlp.gate_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.14.mlp.gate_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.14.mlp.gate_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.14.mlp.gate_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.14.mlp.up_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.14.mlp.up_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.14.mlp.up_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.14.mlp.up_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.14.mlp.up_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.14.mlp.up_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.14.mlp.up_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.14.mlp.down_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.14.mlp.down_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.14.mlp.down_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.14.mlp.down_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.14.mlp.down_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.14.mlp.down_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.14.mlp.down_proj.nero_B.bias --> True torch.float32\n",
      "base_model.model.layers.14.input_layernorm.weight --> True torch.float16\n",
      "base_model.model.layers.14.post_attention_layernorm.weight --> True torch.float16\n",
      "\n",
      "base_model.model.layers.15.self_attn.q_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.15.self_attn.q_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.15.self_attn.q_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.15.self_attn.q_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.15.self_attn.q_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.15.self_attn.q_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.15.self_attn.q_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.15.self_attn.k_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.15.self_attn.k_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.15.self_attn.k_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.15.self_attn.k_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.15.self_attn.k_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.15.self_attn.k_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.15.self_attn.k_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.15.self_attn.v_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.15.self_attn.v_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.15.self_attn.v_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.15.self_attn.v_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.15.self_attn.v_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.15.self_attn.v_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.15.self_attn.v_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.15.self_attn.o_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.15.self_attn.o_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.15.self_attn.o_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.15.self_attn.o_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.15.self_attn.o_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.15.self_attn.o_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.15.self_attn.o_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.15.mlp.gate_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.15.mlp.gate_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.15.mlp.gate_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.15.mlp.gate_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.15.mlp.gate_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.15.mlp.gate_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.15.mlp.gate_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.15.mlp.up_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.15.mlp.up_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.15.mlp.up_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.15.mlp.up_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.15.mlp.up_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.15.mlp.up_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.15.mlp.up_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.15.mlp.down_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.15.mlp.down_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.15.mlp.down_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.15.mlp.down_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.15.mlp.down_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.15.mlp.down_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.15.mlp.down_proj.nero_B.bias --> True torch.float32\n",
      "base_model.model.layers.15.input_layernorm.weight --> True torch.float16\n",
      "base_model.model.layers.15.post_attention_layernorm.weight --> True torch.float16\n",
      "\n",
      "base_model.model.layers.16.self_attn.q_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.16.self_attn.q_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.16.self_attn.q_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.16.self_attn.q_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.16.self_attn.q_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.16.self_attn.q_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.16.self_attn.q_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.16.self_attn.k_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.16.self_attn.k_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.16.self_attn.k_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.16.self_attn.k_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.16.self_attn.k_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.16.self_attn.k_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.16.self_attn.k_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.16.self_attn.v_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.16.self_attn.v_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.16.self_attn.v_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.16.self_attn.v_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.16.self_attn.v_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.16.self_attn.v_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.16.self_attn.v_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.16.self_attn.o_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.16.self_attn.o_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.16.self_attn.o_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.16.self_attn.o_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.16.self_attn.o_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.16.self_attn.o_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.16.self_attn.o_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.16.mlp.gate_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.16.mlp.gate_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.16.mlp.gate_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.16.mlp.gate_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.16.mlp.gate_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.16.mlp.gate_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.16.mlp.gate_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.16.mlp.up_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.16.mlp.up_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.16.mlp.up_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.16.mlp.up_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.16.mlp.up_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.16.mlp.up_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.16.mlp.up_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.16.mlp.down_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.16.mlp.down_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.16.mlp.down_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.16.mlp.down_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.16.mlp.down_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.16.mlp.down_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.16.mlp.down_proj.nero_B.bias --> True torch.float32\n",
      "base_model.model.layers.16.input_layernorm.weight --> True torch.float16\n",
      "base_model.model.layers.16.post_attention_layernorm.weight --> True torch.float16\n",
      "\n",
      "base_model.model.layers.17.self_attn.q_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.17.self_attn.q_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.17.self_attn.q_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.17.self_attn.q_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.17.self_attn.q_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.17.self_attn.q_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.17.self_attn.q_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.17.self_attn.k_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.17.self_attn.k_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.17.self_attn.k_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.17.self_attn.k_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.17.self_attn.k_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.17.self_attn.k_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.17.self_attn.k_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.17.self_attn.v_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.17.self_attn.v_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.17.self_attn.v_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.17.self_attn.v_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.17.self_attn.v_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.17.self_attn.v_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.17.self_attn.v_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.17.self_attn.o_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.17.self_attn.o_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.17.self_attn.o_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.17.self_attn.o_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.17.self_attn.o_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.17.self_attn.o_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.17.self_attn.o_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.17.mlp.gate_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.17.mlp.gate_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.17.mlp.gate_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.17.mlp.gate_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.17.mlp.gate_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.17.mlp.gate_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.17.mlp.gate_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.17.mlp.up_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.17.mlp.up_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.17.mlp.up_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.17.mlp.up_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.17.mlp.up_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.17.mlp.up_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.17.mlp.up_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.17.mlp.down_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.17.mlp.down_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.17.mlp.down_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.17.mlp.down_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.17.mlp.down_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.17.mlp.down_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.17.mlp.down_proj.nero_B.bias --> True torch.float32\n",
      "base_model.model.layers.17.input_layernorm.weight --> True torch.float16\n",
      "base_model.model.layers.17.post_attention_layernorm.weight --> True torch.float16\n",
      "\n",
      "base_model.model.layers.18.self_attn.q_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.18.self_attn.q_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.18.self_attn.q_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.18.self_attn.q_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.18.self_attn.q_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.18.self_attn.q_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.18.self_attn.q_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.18.self_attn.k_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.18.self_attn.k_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.18.self_attn.k_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.18.self_attn.k_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.18.self_attn.k_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.18.self_attn.k_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.18.self_attn.k_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.18.self_attn.v_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.18.self_attn.v_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.18.self_attn.v_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.18.self_attn.v_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.18.self_attn.v_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.18.self_attn.v_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.18.self_attn.v_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.18.self_attn.o_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.18.self_attn.o_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.18.self_attn.o_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.18.self_attn.o_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.18.self_attn.o_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.18.self_attn.o_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.18.self_attn.o_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.18.mlp.gate_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.18.mlp.gate_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.18.mlp.gate_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.18.mlp.gate_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.18.mlp.gate_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.18.mlp.gate_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.18.mlp.gate_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.18.mlp.up_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.18.mlp.up_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.18.mlp.up_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.18.mlp.up_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.18.mlp.up_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.18.mlp.up_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.18.mlp.up_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.18.mlp.down_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.18.mlp.down_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.18.mlp.down_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.18.mlp.down_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.18.mlp.down_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.18.mlp.down_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.18.mlp.down_proj.nero_B.bias --> True torch.float32\n",
      "base_model.model.layers.18.input_layernorm.weight --> True torch.float16\n",
      "base_model.model.layers.18.post_attention_layernorm.weight --> True torch.float16\n",
      "\n",
      "base_model.model.layers.19.self_attn.q_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.19.self_attn.q_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.19.self_attn.q_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.19.self_attn.q_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.19.self_attn.q_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.19.self_attn.q_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.19.self_attn.q_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.19.self_attn.k_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.19.self_attn.k_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.19.self_attn.k_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.19.self_attn.k_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.19.self_attn.k_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.19.self_attn.k_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.19.self_attn.k_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.19.self_attn.v_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.19.self_attn.v_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.19.self_attn.v_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.19.self_attn.v_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.19.self_attn.v_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.19.self_attn.v_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.19.self_attn.v_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.19.self_attn.o_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.19.self_attn.o_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.19.self_attn.o_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.19.self_attn.o_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.19.self_attn.o_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.19.self_attn.o_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.19.self_attn.o_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.19.mlp.gate_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.19.mlp.gate_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.19.mlp.gate_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.19.mlp.gate_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.19.mlp.gate_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.19.mlp.gate_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.19.mlp.gate_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.19.mlp.up_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.19.mlp.up_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.19.mlp.up_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.19.mlp.up_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.19.mlp.up_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.19.mlp.up_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.19.mlp.up_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.19.mlp.down_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.19.mlp.down_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.19.mlp.down_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.19.mlp.down_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.19.mlp.down_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.19.mlp.down_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.19.mlp.down_proj.nero_B.bias --> True torch.float32\n",
      "base_model.model.layers.19.input_layernorm.weight --> True torch.float16\n",
      "base_model.model.layers.19.post_attention_layernorm.weight --> True torch.float16\n",
      "\n",
      "base_model.model.layers.20.self_attn.q_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.20.self_attn.q_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.20.self_attn.q_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.20.self_attn.q_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.20.self_attn.q_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.20.self_attn.q_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.20.self_attn.q_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.20.self_attn.k_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.20.self_attn.k_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.20.self_attn.k_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.20.self_attn.k_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.20.self_attn.k_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.20.self_attn.k_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.20.self_attn.k_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.20.self_attn.v_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.20.self_attn.v_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.20.self_attn.v_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.20.self_attn.v_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.20.self_attn.v_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.20.self_attn.v_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.20.self_attn.v_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.20.self_attn.o_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.20.self_attn.o_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.20.self_attn.o_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.20.self_attn.o_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.20.self_attn.o_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.20.self_attn.o_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.20.self_attn.o_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.20.mlp.gate_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.20.mlp.gate_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.20.mlp.gate_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.20.mlp.gate_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.20.mlp.gate_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.20.mlp.gate_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.20.mlp.gate_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.20.mlp.up_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.20.mlp.up_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.20.mlp.up_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.20.mlp.up_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.20.mlp.up_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.20.mlp.up_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.20.mlp.up_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.20.mlp.down_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.20.mlp.down_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.20.mlp.down_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.20.mlp.down_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.20.mlp.down_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.20.mlp.down_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.20.mlp.down_proj.nero_B.bias --> True torch.float32\n",
      "base_model.model.layers.20.input_layernorm.weight --> True torch.float16\n",
      "base_model.model.layers.20.post_attention_layernorm.weight --> True torch.float16\n",
      "\n",
      "base_model.model.layers.21.self_attn.q_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.21.self_attn.q_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.21.self_attn.q_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.21.self_attn.q_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.21.self_attn.q_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.21.self_attn.q_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.21.self_attn.q_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.21.self_attn.k_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.21.self_attn.k_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.21.self_attn.k_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.21.self_attn.k_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.21.self_attn.k_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.21.self_attn.k_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.21.self_attn.k_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.21.self_attn.v_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.21.self_attn.v_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.21.self_attn.v_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.21.self_attn.v_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.21.self_attn.v_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.21.self_attn.v_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.21.self_attn.v_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.21.self_attn.o_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.21.self_attn.o_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.21.self_attn.o_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.21.self_attn.o_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.21.self_attn.o_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.21.self_attn.o_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.21.self_attn.o_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.21.mlp.gate_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.21.mlp.gate_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.21.mlp.gate_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.21.mlp.gate_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.21.mlp.gate_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.21.mlp.gate_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.21.mlp.gate_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.21.mlp.up_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.21.mlp.up_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.21.mlp.up_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.21.mlp.up_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.21.mlp.up_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.21.mlp.up_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.21.mlp.up_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.21.mlp.down_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.21.mlp.down_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.21.mlp.down_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.21.mlp.down_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.21.mlp.down_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.21.mlp.down_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.21.mlp.down_proj.nero_B.bias --> True torch.float32\n",
      "base_model.model.layers.21.input_layernorm.weight --> True torch.float16\n",
      "base_model.model.layers.21.post_attention_layernorm.weight --> True torch.float16\n",
      "\n",
      "base_model.model.layers.22.self_attn.q_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.22.self_attn.q_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.22.self_attn.q_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.22.self_attn.q_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.22.self_attn.q_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.22.self_attn.q_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.22.self_attn.q_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.22.self_attn.k_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.22.self_attn.k_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.22.self_attn.k_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.22.self_attn.k_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.22.self_attn.k_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.22.self_attn.k_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.22.self_attn.k_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.22.self_attn.v_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.22.self_attn.v_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.22.self_attn.v_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.22.self_attn.v_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.22.self_attn.v_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.22.self_attn.v_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.22.self_attn.v_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.22.self_attn.o_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.22.self_attn.o_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.22.self_attn.o_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.22.self_attn.o_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.22.self_attn.o_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.22.self_attn.o_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.22.self_attn.o_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.22.mlp.gate_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.22.mlp.gate_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.22.mlp.gate_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.22.mlp.gate_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.22.mlp.gate_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.22.mlp.gate_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.22.mlp.gate_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.22.mlp.up_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.22.mlp.up_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.22.mlp.up_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.22.mlp.up_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.22.mlp.up_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.22.mlp.up_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.22.mlp.up_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.22.mlp.down_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.22.mlp.down_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.22.mlp.down_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.22.mlp.down_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.22.mlp.down_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.22.mlp.down_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.22.mlp.down_proj.nero_B.bias --> True torch.float32\n",
      "base_model.model.layers.22.input_layernorm.weight --> True torch.float16\n",
      "base_model.model.layers.22.post_attention_layernorm.weight --> True torch.float16\n",
      "\n",
      "base_model.model.layers.23.self_attn.q_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.23.self_attn.q_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.23.self_attn.q_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.23.self_attn.q_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.23.self_attn.q_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.23.self_attn.q_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.23.self_attn.q_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.23.self_attn.k_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.23.self_attn.k_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.23.self_attn.k_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.23.self_attn.k_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.23.self_attn.k_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.23.self_attn.k_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.23.self_attn.k_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.23.self_attn.v_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.23.self_attn.v_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.23.self_attn.v_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.23.self_attn.v_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.23.self_attn.v_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.23.self_attn.v_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.23.self_attn.v_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.23.self_attn.o_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.23.self_attn.o_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.23.self_attn.o_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.23.self_attn.o_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.23.self_attn.o_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.23.self_attn.o_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.23.self_attn.o_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.23.mlp.gate_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.23.mlp.gate_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.23.mlp.gate_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.23.mlp.gate_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.23.mlp.gate_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.23.mlp.gate_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.23.mlp.gate_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.23.mlp.up_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.23.mlp.up_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.23.mlp.up_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.23.mlp.up_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.23.mlp.up_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.23.mlp.up_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.23.mlp.up_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.23.mlp.down_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.23.mlp.down_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.23.mlp.down_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.23.mlp.down_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.23.mlp.down_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.23.mlp.down_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.23.mlp.down_proj.nero_B.bias --> True torch.float32\n",
      "base_model.model.layers.23.input_layernorm.weight --> True torch.float16\n",
      "base_model.model.layers.23.post_attention_layernorm.weight --> True torch.float16\n",
      "\n",
      "base_model.model.layers.24.self_attn.q_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.24.self_attn.q_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.24.self_attn.q_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.24.self_attn.q_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.24.self_attn.q_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.24.self_attn.q_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.24.self_attn.q_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.24.self_attn.k_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.24.self_attn.k_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.24.self_attn.k_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.24.self_attn.k_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.24.self_attn.k_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.24.self_attn.k_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.24.self_attn.k_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.24.self_attn.v_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.24.self_attn.v_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.24.self_attn.v_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.24.self_attn.v_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.24.self_attn.v_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.24.self_attn.v_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.24.self_attn.v_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.24.self_attn.o_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.24.self_attn.o_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.24.self_attn.o_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.24.self_attn.o_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.24.self_attn.o_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.24.self_attn.o_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.24.self_attn.o_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.24.mlp.gate_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.24.mlp.gate_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.24.mlp.gate_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.24.mlp.gate_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.24.mlp.gate_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.24.mlp.gate_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.24.mlp.gate_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.24.mlp.up_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.24.mlp.up_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.24.mlp.up_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.24.mlp.up_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.24.mlp.up_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.24.mlp.up_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.24.mlp.up_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.24.mlp.down_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.24.mlp.down_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.24.mlp.down_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.24.mlp.down_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.24.mlp.down_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.24.mlp.down_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.24.mlp.down_proj.nero_B.bias --> True torch.float32\n",
      "base_model.model.layers.24.input_layernorm.weight --> True torch.float16\n",
      "base_model.model.layers.24.post_attention_layernorm.weight --> True torch.float16\n",
      "\n",
      "base_model.model.layers.25.self_attn.q_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.25.self_attn.q_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.25.self_attn.q_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.25.self_attn.q_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.25.self_attn.q_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.25.self_attn.q_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.25.self_attn.q_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.25.self_attn.k_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.25.self_attn.k_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.25.self_attn.k_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.25.self_attn.k_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.25.self_attn.k_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.25.self_attn.k_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.25.self_attn.k_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.25.self_attn.v_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.25.self_attn.v_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.25.self_attn.v_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.25.self_attn.v_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.25.self_attn.v_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.25.self_attn.v_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.25.self_attn.v_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.25.self_attn.o_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.25.self_attn.o_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.25.self_attn.o_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.25.self_attn.o_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.25.self_attn.o_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.25.self_attn.o_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.25.self_attn.o_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.25.mlp.gate_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.25.mlp.gate_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.25.mlp.gate_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.25.mlp.gate_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.25.mlp.gate_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.25.mlp.gate_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.25.mlp.gate_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.25.mlp.up_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.25.mlp.up_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.25.mlp.up_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.25.mlp.up_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.25.mlp.up_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.25.mlp.up_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.25.mlp.up_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.25.mlp.down_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.25.mlp.down_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.25.mlp.down_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.25.mlp.down_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.25.mlp.down_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.25.mlp.down_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.25.mlp.down_proj.nero_B.bias --> True torch.float32\n",
      "base_model.model.layers.25.input_layernorm.weight --> True torch.float16\n",
      "base_model.model.layers.25.post_attention_layernorm.weight --> True torch.float16\n",
      "\n",
      "base_model.model.layers.26.self_attn.q_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.26.self_attn.q_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.26.self_attn.q_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.26.self_attn.q_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.26.self_attn.q_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.26.self_attn.q_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.26.self_attn.q_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.26.self_attn.k_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.26.self_attn.k_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.26.self_attn.k_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.26.self_attn.k_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.26.self_attn.k_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.26.self_attn.k_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.26.self_attn.k_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.26.self_attn.v_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.26.self_attn.v_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.26.self_attn.v_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.26.self_attn.v_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.26.self_attn.v_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.26.self_attn.v_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.26.self_attn.v_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.26.self_attn.o_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.26.self_attn.o_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.26.self_attn.o_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.26.self_attn.o_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.26.self_attn.o_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.26.self_attn.o_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.26.self_attn.o_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.26.mlp.gate_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.26.mlp.gate_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.26.mlp.gate_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.26.mlp.gate_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.26.mlp.gate_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.26.mlp.gate_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.26.mlp.gate_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.26.mlp.up_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.26.mlp.up_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.26.mlp.up_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.26.mlp.up_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.26.mlp.up_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.26.mlp.up_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.26.mlp.up_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.26.mlp.down_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.26.mlp.down_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.26.mlp.down_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.26.mlp.down_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.26.mlp.down_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.26.mlp.down_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.26.mlp.down_proj.nero_B.bias --> True torch.float32\n",
      "base_model.model.layers.26.input_layernorm.weight --> True torch.float16\n",
      "base_model.model.layers.26.post_attention_layernorm.weight --> True torch.float16\n",
      "\n",
      "base_model.model.layers.27.self_attn.q_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.27.self_attn.q_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.27.self_attn.q_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.27.self_attn.q_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.27.self_attn.q_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.27.self_attn.q_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.27.self_attn.q_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.27.self_attn.k_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.27.self_attn.k_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.27.self_attn.k_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.27.self_attn.k_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.27.self_attn.k_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.27.self_attn.k_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.27.self_attn.k_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.27.self_attn.v_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.27.self_attn.v_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.27.self_attn.v_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.27.self_attn.v_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.27.self_attn.v_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.27.self_attn.v_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.27.self_attn.v_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.27.self_attn.o_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.27.self_attn.o_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.27.self_attn.o_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.27.self_attn.o_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.27.self_attn.o_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.27.self_attn.o_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.27.self_attn.o_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.27.mlp.gate_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.27.mlp.gate_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.27.mlp.gate_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.27.mlp.gate_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.27.mlp.gate_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.27.mlp.gate_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.27.mlp.gate_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.27.mlp.up_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.27.mlp.up_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.27.mlp.up_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.27.mlp.up_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.27.mlp.up_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.27.mlp.up_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.27.mlp.up_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.27.mlp.down_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.27.mlp.down_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.27.mlp.down_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.27.mlp.down_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.27.mlp.down_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.27.mlp.down_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.27.mlp.down_proj.nero_B.bias --> True torch.float32\n",
      "base_model.model.layers.27.input_layernorm.weight --> True torch.float16\n",
      "base_model.model.layers.27.post_attention_layernorm.weight --> True torch.float16\n",
      "\n",
      "base_model.model.layers.28.self_attn.q_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.28.self_attn.q_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.28.self_attn.q_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.28.self_attn.q_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.28.self_attn.q_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.28.self_attn.q_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.28.self_attn.q_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.28.self_attn.k_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.28.self_attn.k_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.28.self_attn.k_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.28.self_attn.k_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.28.self_attn.k_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.28.self_attn.k_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.28.self_attn.k_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.28.self_attn.v_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.28.self_attn.v_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.28.self_attn.v_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.28.self_attn.v_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.28.self_attn.v_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.28.self_attn.v_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.28.self_attn.v_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.28.self_attn.o_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.28.self_attn.o_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.28.self_attn.o_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.28.self_attn.o_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.28.self_attn.o_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.28.self_attn.o_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.28.self_attn.o_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.28.mlp.gate_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.28.mlp.gate_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.28.mlp.gate_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.28.mlp.gate_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.28.mlp.gate_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.28.mlp.gate_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.28.mlp.gate_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.28.mlp.up_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.28.mlp.up_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.28.mlp.up_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.28.mlp.up_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.28.mlp.up_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.28.mlp.up_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.28.mlp.up_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.28.mlp.down_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.28.mlp.down_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.28.mlp.down_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.28.mlp.down_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.28.mlp.down_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.28.mlp.down_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.28.mlp.down_proj.nero_B.bias --> True torch.float32\n",
      "base_model.model.layers.28.input_layernorm.weight --> True torch.float16\n",
      "base_model.model.layers.28.post_attention_layernorm.weight --> True torch.float16\n",
      "\n",
      "base_model.model.layers.29.self_attn.q_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.29.self_attn.q_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.29.self_attn.q_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.29.self_attn.q_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.29.self_attn.q_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.29.self_attn.q_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.29.self_attn.q_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.29.self_attn.k_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.29.self_attn.k_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.29.self_attn.k_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.29.self_attn.k_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.29.self_attn.k_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.29.self_attn.k_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.29.self_attn.k_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.29.self_attn.v_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.29.self_attn.v_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.29.self_attn.v_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.29.self_attn.v_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.29.self_attn.v_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.29.self_attn.v_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.29.self_attn.v_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.29.self_attn.o_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.29.self_attn.o_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.29.self_attn.o_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.29.self_attn.o_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.29.self_attn.o_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.29.self_attn.o_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.29.self_attn.o_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.29.mlp.gate_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.29.mlp.gate_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.29.mlp.gate_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.29.mlp.gate_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.29.mlp.gate_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.29.mlp.gate_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.29.mlp.gate_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.29.mlp.up_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.29.mlp.up_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.29.mlp.up_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.29.mlp.up_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.29.mlp.up_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.29.mlp.up_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.29.mlp.up_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.29.mlp.down_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.29.mlp.down_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.29.mlp.down_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.29.mlp.down_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.29.mlp.down_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.29.mlp.down_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.29.mlp.down_proj.nero_B.bias --> True torch.float32\n",
      "base_model.model.layers.29.input_layernorm.weight --> True torch.float16\n",
      "base_model.model.layers.29.post_attention_layernorm.weight --> True torch.float16\n",
      "\n",
      "base_model.model.layers.30.self_attn.q_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.30.self_attn.q_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.30.self_attn.q_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.30.self_attn.q_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.30.self_attn.q_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.30.self_attn.q_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.30.self_attn.q_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.30.self_attn.k_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.30.self_attn.k_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.30.self_attn.k_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.30.self_attn.k_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.30.self_attn.k_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.30.self_attn.k_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.30.self_attn.k_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.30.self_attn.v_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.30.self_attn.v_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.30.self_attn.v_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.30.self_attn.v_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.30.self_attn.v_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.30.self_attn.v_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.30.self_attn.v_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.30.self_attn.o_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.30.self_attn.o_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.30.self_attn.o_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.30.self_attn.o_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.30.self_attn.o_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.30.self_attn.o_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.30.self_attn.o_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.30.mlp.gate_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.30.mlp.gate_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.30.mlp.gate_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.30.mlp.gate_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.30.mlp.gate_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.30.mlp.gate_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.30.mlp.gate_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.30.mlp.up_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.30.mlp.up_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.30.mlp.up_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.30.mlp.up_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.30.mlp.up_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.30.mlp.up_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.30.mlp.up_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.30.mlp.down_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.30.mlp.down_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.30.mlp.down_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.30.mlp.down_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.30.mlp.down_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.30.mlp.down_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.30.mlp.down_proj.nero_B.bias --> True torch.float32\n",
      "base_model.model.layers.30.input_layernorm.weight --> True torch.float16\n",
      "base_model.model.layers.30.post_attention_layernorm.weight --> True torch.float16\n",
      "\n",
      "base_model.model.layers.31.self_attn.q_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.31.self_attn.q_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.31.self_attn.q_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.31.self_attn.q_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.31.self_attn.q_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.31.self_attn.q_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.31.self_attn.q_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.31.self_attn.k_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.31.self_attn.k_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.31.self_attn.k_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.31.self_attn.k_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.31.self_attn.k_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.31.self_attn.k_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.31.self_attn.k_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.31.self_attn.v_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.31.self_attn.v_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.31.self_attn.v_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.31.self_attn.v_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.31.self_attn.v_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.31.self_attn.v_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.31.self_attn.v_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.31.self_attn.o_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.31.self_attn.o_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.31.self_attn.o_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.31.self_attn.o_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.31.self_attn.o_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.31.self_attn.o_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.31.self_attn.o_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.31.mlp.gate_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.31.mlp.gate_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.31.mlp.gate_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.31.mlp.gate_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.31.mlp.gate_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.31.mlp.gate_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.31.mlp.gate_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.31.mlp.up_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.31.mlp.up_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.31.mlp.up_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.31.mlp.up_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.31.mlp.up_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.31.mlp.up_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.31.mlp.up_proj.nero_B.bias --> True torch.float32\n",
      "\n",
      "base_model.model.layers.31.mlp.down_proj.base_layer.weight --> False torch.uint8\n",
      "base_model.model.layers.31.mlp.down_proj.lora_A.weight --> True torch.float32\n",
      "base_model.model.layers.31.mlp.down_proj.lora_B.weight --> True torch.float32\n",
      "base_model.model.layers.31.mlp.down_proj.nero_A.weight --> True torch.float32\n",
      "base_model.model.layers.31.mlp.down_proj.nero_A.bias --> True torch.float32\n",
      "base_model.model.layers.31.mlp.down_proj.nero_B.weight --> True torch.float32\n",
      "base_model.model.layers.31.mlp.down_proj.nero_B.bias --> True torch.float32\n",
      "base_model.model.layers.31.input_layernorm.weight --> True torch.float16\n",
      "base_model.model.layers.31.post_attention_layernorm.weight --> True torch.float16\n",
      "base_model.model.norm.weight --> True torch.float16\n",
      "base_model.lm_head.weight --> True torch.float16\n"
     ]
    }
   ],
   "source": [
    "for n, p in nero_model.named_parameters():\n",
    "    if 'base_layer.weight' in n: \n",
    "        print()\n",
    "    print(n, \"-->\", p.requires_grad, p.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6283761152\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import torch\n",
    "\n",
    "# base_model1.to('cpu')\n",
    "# lora_model.to('cpu')\n",
    "# del base_model1\n",
    "# del nero_model\n",
    "\n",
    "print(torch.cuda.memory_allocated())\n",
    "\n",
    "if 'nero_model' in globals():\n",
    "    nero_model.to('cpu')\n",
    "    del nero_model\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "print(torch.cuda.memory_allocated())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "nero_model.base_model.model.layers[0].self_attn.q_proj.nero_A: Parameter containing:\n",
      "tensor([[-4.4971e-01,  3.1203e-01,  5.2366e-01,  ...,  2.6862e-01,\n",
      "          2.4798e-01,  6.7461e-04],\n",
      "        [-4.1525e-02,  4.5143e-01, -5.7140e-01,  ..., -6.3062e-02,\n",
      "         -1.2641e-01,  2.3381e-01],\n",
      "        [-6.1668e-02, -2.4167e-01, -8.9052e-02,  ..., -1.3829e-01,\n",
      "         -1.7905e-01,  1.7789e-02],\n",
      "        ...,\n",
      "        [ 1.9156e-02, -1.1599e+00,  3.7303e-01,  ...,  4.3789e-01,\n",
      "          7.5028e-02, -4.8528e-01],\n",
      "        [ 1.6513e-01,  7.7233e-01,  5.8815e-01,  ...,  2.0706e-01,\n",
      "         -2.5718e-01, -5.1134e-01],\n",
      "        [ 2.2792e-01, -2.5864e-01, -2.1519e-01,  ...,  2.5236e-01,\n",
      "         -1.1390e-01, -8.2920e-01]], device='cuda:0', requires_grad=True)\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(8, 4096).to('cuda')\n",
    "print(x.requires_grad)\n",
    "print('nero_A:', nero_model.base_model.model.layers[0].self_attn.q_proj.nero_A.weight)\n",
    "y = nero_model.base_model.model.layers[0].self_attn.q_proj.nero_A(x)\n",
    "print(y.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check LoRA parameters (unloaded):\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'check_lora_parameters' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-13-613842266.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Check LoRA parameters (unloaded):\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcheck_lora_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnero_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlora_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_configs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'L2T1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lora_dir'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'adapter_model.safetensors'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'check_lora_parameters' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Check LoRA parameters (unloaded):\")\n",
    "check_lora_parameters(nero_model)\n",
    "print()\n",
    "\n",
    "lora_path = os.path.join(model_configs['L2T1']['lora_dir'], 'adapter_model.safetensors')\n",
    "nero_model.load_lora_weights(lora_path)\n",
    "print()\n",
    "\n",
    "print(\"Check LoRA parameters (loaded):\")\n",
    "check_lora_parameters(nero_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_text(nero_model, tokenizer, prompt=\"Preheat the oven to 350 degrees and place the cookie dough\", skip_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-40.7062,  -6.6492,  -3.7754,  13.8341,  20.6145,  53.7147, -21.1631,\n",
       "         -40.2303],\n",
       "        [ -6.0338,  12.2223,   1.5039,  18.9884,  22.6390, -32.5255,  -3.8959,\n",
       "          38.7502],\n",
       "        [ 17.4199,  18.8145, -19.4615, -15.9465, -22.6114, -15.0024,  29.2715,\n",
       "         -41.9063],\n",
       "        [-18.6150, -13.4174,  -6.4494,  22.2234,   8.2466, -11.7426,   2.5520,\n",
       "         -19.9913],\n",
       "        [ -9.3683,   8.1962,  16.1248, -23.4653,  25.8517, -39.0575, -30.0681,\n",
       "           4.5514],\n",
       "        [ 38.9216, -17.0592, -25.0972,  12.2915,  -6.2447,   2.4214, -18.8855,\n",
       "          52.9850],\n",
       "        [  2.4511,  -6.4056, -43.2899, -56.0964, -24.5220, -17.7764,  32.7902,\n",
       "         -22.3956],\n",
       "        [ 12.9756,   8.9490,   7.6858,  -6.9334,  -5.3790,  11.6487,  26.5811,\n",
       "          -5.7308]], device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nero_model.base_model.model.layers[0].self_attn.q_proj.nero_A(torch.randn(8, 4096).to('cuda'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_model.eval()\n",
    "# lora_model.gradient_checkpointing_enable() # Fix error: 'LlamaDecoderLayer' object has no attribute '_gradient_checkpointing_func'\n",
    "device = next(lora_model.parameters()).device\n",
    "inputs = tokenizer(\"Preheat the oven to 350 degrees and place the cookie dough\", return_tensors='pt')\n",
    "lora_model_outs = lora_model(input_ids=inputs['input_ids'].to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=14336, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear(in_features=14336, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=14336, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=14336, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=14336, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=14336, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=14336, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=14336, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=14336, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=14336, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=14336, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=14336, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=14336, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=14336, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=14336, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=14336, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=14336, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=14336, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=14336, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=14336, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=14336, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=14336, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=14336, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=14336, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=14336, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=14336, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=14336, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=14336, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=14336, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=14336, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=14336, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=14336, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=1024, bias=False)\n",
      "  (nero_A): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=1024, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=4096, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=14336, bias=False)\n",
      "  (nero_A): Linear(in_features=14336, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=14336, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n",
      "[NeroLayer] Forward pass executed for NeroLayer(\n",
      "  (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "  (dropout): Identity()\n",
      "  (lora_A): Linear(in_features=14336, out_features=8, bias=False)\n",
      "  (lora_B): Linear(in_features=8, out_features=4096, bias=False)\n",
      "  (nero_A): Linear(in_features=4096, out_features=8, bias=True)\n",
      "  (nero_B): Linear(in_features=8, out_features=4096, bias=True)\n",
      ")\n",
      "base_out.requires_grad: False\n",
      "base_out.grad_fn: None\n",
      "lora_out.requires_grad: False\n",
      "lora_out.grad_fn: None\n",
      "nero_out.requires_grad: False\n",
      "nero_out.grad_fn: None\n"
     ]
    }
   ],
   "source": [
    "nero_model.train()\n",
    "nero_model.gradient_checkpointing_enable() # Fix error: 'LlamaDecoderLayer' object has no attribute '_gradient_checkpointing_func'\n",
    "device = next(nero_model.parameters()).device\n",
    "inputs = tokenizer(\"Preheat the oven to 350 degrees and place the cookie dough\", return_tensors='pt')\n",
    "nero_model_outs = nero_model(input_ids=inputs['input_ids'].to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.4004, 0.0000, 0.1152,  ..., 0.0000, 0.0000, 0.4817],\n",
       "         [0.4004, 0.0000, 0.1152,  ..., 0.0000, 0.0000, 0.4817],\n",
       "         [0.4004, 0.0000, 0.1152,  ..., 0.0000, 0.0000, 0.4817],\n",
       "         ...,\n",
       "         [0.4004, 0.0000, 0.1152,  ..., 0.0000, 0.0000, 0.4817],\n",
       "         [0.4004, 0.0000, 0.1152,  ..., 0.0000, 0.0000, 0.4817],\n",
       "         [0.4004, 0.0000, 0.1152,  ..., 0.0000, 0.0000, 0.4817]]],\n",
       "       device='cuda:0', dtype=torch.float16)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nero_model_outs[1]['layers__DOT__0__DOT__self_attn__DOT__q_proj']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0049, device='cuda:0', dtype=torch.float16)\n"
     ]
    }
   ],
   "source": [
    "def loss_func_v1(nero_outs, lora_outs):\n",
    "    assert nero_outs.keys() == lora_outs.keys() # TODO: Print warning message\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for layer_name in lora_outs.keys():\n",
    "        # Normalized MSE loss\n",
    "        mse_loss = F.mse_loss(nero_outs[layer_name], lora_outs[layer_name], reduction='sum') / torch.sum(nero_outs[layer_name] ** 2)\n",
    "        total_loss += mse_loss\n",
    "\n",
    "    return total_loss / len(lora_outs)  # Averaging loss across layers\n",
    "\n",
    "loss = loss_func_v1(nero_model_outs[1], lora_model_outs[1])\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-15-2859123600.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    624\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             )\n\u001b[0;32m--> 626\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    627\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         )\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    824\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[0;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_func(pred_outs, gt_outs, lambda_reg, lora_A_list, lora_B_list):\n",
    "    total_loss = 0.0\n",
    "    num_layers = len(gt_outs)\n",
    "\n",
    "    for i in range(num_layers):\n",
    "        # Normalized MSE loss\n",
    "        mse_loss = F.mse_loss(pred_outs[i], gt_outs[i], reduction='sum') / torch.sum(pred_outs[i] ** 2)\n",
    "        \n",
    "        # L2 regularization for LoRA matrices\n",
    "        reg_loss = lambda_reg * (torch.norm(lora_A_list[i], p=2) ** 2 + torch.norm(lora_B_list[i], p=2) ** 2)\n",
    "\n",
    "        total_loss += mse_loss + reg_loss\n",
    "\n",
    "    return total_loss / num_layers  # Averaging loss across layers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
