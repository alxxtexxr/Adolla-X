{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kill all processess on GPU\n",
    "# !fuser -v /dev/nvidia* -k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from evaluate import evaluator\n",
    "from transformers import AutoModelForCausalLM, LlamaForQuestionAnswering, AutoTokenizer, pipeline\n",
    "from peft import LoraConfig, AutoPeftModelForCausalLM\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b492dc581f4047e597ff9fca0c6099ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 427 files:   0%|          | 0/427 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face LoRA ID: alxxtexxr/L3.1-8B-wikipedia-id-5K-LoRA-v20250628061607\n"
     ]
    }
   ],
   "source": [
    "# Project configs\n",
    "seed = 69\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "lang = 'id' # 'en' | 'id'\n",
    "task = 'wikipedia' # 'wikipedia' | 'gsm8k'\n",
    "\n",
    "# Data Configs\n",
    "max_seq_length = 1024\n",
    "# hf_data_id = 'wikimedia/wikipedia' # 'wikimedia/wikipedia' | 'openai/gsm8k'\n",
    "# hf_data_dir = f'20231101.{lang}' if task == 'wikipedia' else 'main' # wikipedia: '20231101.en' | '20231101.id' || gsm8k: 'main'\n",
    "test_size = 1000\n",
    "# hf_data_split = f'train[-{test_size}:]'\n",
    "\n",
    "# Model configs\n",
    "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
    "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
    "\n",
    "# LoRA configs\n",
    "hf_lora_id = 'alxxtexxr/L3.1-8B-wikipedia-id-5K-LoRA-v20250628061607'\n",
    "lora_dir = hf_lora_id.split('/')[-1]\n",
    "\n",
    "# Download the trained LoRA adapter to the local directory\n",
    "from huggingface_hub import snapshot_download\n",
    "snapshot_download(\n",
    "    repo_id=hf_lora_id, \n",
    "    local_dir=lora_dir, \n",
    "    # ignore_patterns='checkpoint-*/*',\n",
    ")\n",
    "\n",
    "print(\"Hugging Face LoRA ID:\", hf_lora_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LoraConfig(task_type='CAUSAL_LM',\n",
      "           peft_type=<PeftType.LORA: 'LORA'>,\n",
      "           auto_mapping=None,\n",
      "           base_model_name_or_path='unsloth/meta-llama-3.1-8b-unsloth-bnb-4bit',\n",
      "           revision=None,\n",
      "           inference_mode=True,\n",
      "           r=8,\n",
      "           target_modules={'down_proj',\n",
      "                           'gate_proj',\n",
      "                           'k_proj',\n",
      "                           'o_proj',\n",
      "                           'q_proj',\n",
      "                           'up_proj',\n",
      "                           'v_proj'},\n",
      "           exclude_modules=None,\n",
      "           lora_alpha=16,\n",
      "           lora_dropout=0,\n",
      "           fan_in_fan_out=False,\n",
      "           bias='none',\n",
      "           use_rslora=False,\n",
      "           modules_to_save=None,\n",
      "           init_lora_weights=True,\n",
      "           layers_to_transform=None,\n",
      "           layers_pattern=None,\n",
      "           rank_pattern={},\n",
      "           alpha_pattern={},\n",
      "           megatron_config=None,\n",
      "           megatron_core='megatron.core',\n",
      "           trainable_token_indices=None,\n",
      "           loftq_config={},\n",
      "           eva_config=None,\n",
      "           corda_config=None,\n",
      "           use_dora=False,\n",
      "           layer_replication=None,\n",
      "           runtime_config=LoraRuntimeConfig(ephemeral_gpu_offload=False),\n",
      "           lora_bias=False)\n"
     ]
    }
   ],
   "source": [
    "lora_config = LoraConfig.from_pretrained(lora_dir)\n",
    "pprint(lora_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘data’: File exists\n",
      "--2025-06-28 18:24:41--  https://raw.githubusercontent.com/Wikidepia/SQuAD-id/refs/heads/master/data/train-SQuAD-id.json\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 37852227 (36M) [text/plain]\n",
      "Saving to: ‘train-SQuAD-id.json.14’\n",
      "\n",
      "train-SQuAD-id.json 100%[===================>]  36.10M  83.4MB/s    in 0.4s    \n",
      "\n",
      "2025-06-28 18:24:42 (83.4 MB/s) - ‘train-SQuAD-id.json.14’ saved [37852227/37852227]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Download the Indonesian SQuAD dataset\n",
    "!mkdir data\n",
    "!cd data && wget https://raw.githubusercontent.com/Wikidepia/SQuAD-id/refs/heads/master/data/train-SQuAD-id.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and convert data to Huggingface format\n",
    "# Source: https://github.com/Wikidepia/indonesian_datasets/blob/master/question-answering/squad/convert_huggingface.py\n",
    "\n",
    "with open('data/train-SQuAD-id.json', 'r') as f:\n",
    "    content = json.load(f)\n",
    "\n",
    "hf_data = []\n",
    "for data in content[\"data\"]:\n",
    "    title = data[\"title\"]\n",
    "    for paragraph in data[\"paragraphs\"]:\n",
    "        context = paragraph[\"context\"]\n",
    "        for qa in paragraph[\"qas\"]:\n",
    "            fill = {\n",
    "                \"id\":  qa[\"id\"],\n",
    "                \"title\": title,\n",
    "                \"context\": context,\n",
    "                \"question\": qa[\"question\"],\n",
    "                \"answers\": {\"answer_start\": [], \"text\": []}\n",
    "            }\n",
    "            if qa[\"is_impossible\"]:\n",
    "                answers = qa[\"plausible_answers\"]\n",
    "            else:\n",
    "                answers = qa[\"answers\"]\n",
    "            for answer in answers:\n",
    "                fill[\"answers\"][\"answer_start\"].append(answer[\"answer_start\"])\n",
    "                fill[\"answers\"][\"text\"].append(answer[\"text\"])\n",
    "            hf_data.append(fill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['id', 'title', 'context', 'question', 'answers'],\n",
      "    num_rows: 1000\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Create Huggingface dataset\n",
    "data = Dataset.from_list(hf_data[:test_size])\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(lora_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForQuestionAnswering were not initialized from the model checkpoint at unsloth/meta-llama-3.1-8b-unsloth-bnb-4bit and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight', 'transformer.embed_tokens.weight', 'transformer.layers.0.input_layernorm.weight', 'transformer.layers.0.mlp.down_proj.weight', 'transformer.layers.0.mlp.gate_proj.weight', 'transformer.layers.0.mlp.up_proj.weight', 'transformer.layers.0.post_attention_layernorm.weight', 'transformer.layers.0.self_attn.k_proj.weight', 'transformer.layers.0.self_attn.o_proj.weight', 'transformer.layers.0.self_attn.q_proj.weight', 'transformer.layers.0.self_attn.v_proj.weight', 'transformer.layers.1.input_layernorm.weight', 'transformer.layers.1.mlp.down_proj.weight', 'transformer.layers.1.mlp.gate_proj.weight', 'transformer.layers.1.mlp.up_proj.weight', 'transformer.layers.1.post_attention_layernorm.weight', 'transformer.layers.1.self_attn.k_proj.weight', 'transformer.layers.1.self_attn.o_proj.weight', 'transformer.layers.1.self_attn.q_proj.weight', 'transformer.layers.1.self_attn.v_proj.weight', 'transformer.layers.10.input_layernorm.weight', 'transformer.layers.10.mlp.down_proj.weight', 'transformer.layers.10.mlp.gate_proj.weight', 'transformer.layers.10.mlp.up_proj.weight', 'transformer.layers.10.post_attention_layernorm.weight', 'transformer.layers.10.self_attn.k_proj.weight', 'transformer.layers.10.self_attn.o_proj.weight', 'transformer.layers.10.self_attn.q_proj.weight', 'transformer.layers.10.self_attn.v_proj.weight', 'transformer.layers.11.input_layernorm.weight', 'transformer.layers.11.mlp.down_proj.weight', 'transformer.layers.11.mlp.gate_proj.weight', 'transformer.layers.11.mlp.up_proj.weight', 'transformer.layers.11.post_attention_layernorm.weight', 'transformer.layers.11.self_attn.k_proj.weight', 'transformer.layers.11.self_attn.o_proj.weight', 'transformer.layers.11.self_attn.q_proj.weight', 'transformer.layers.11.self_attn.v_proj.weight', 'transformer.layers.12.input_layernorm.weight', 'transformer.layers.12.mlp.down_proj.weight', 'transformer.layers.12.mlp.gate_proj.weight', 'transformer.layers.12.mlp.up_proj.weight', 'transformer.layers.12.post_attention_layernorm.weight', 'transformer.layers.12.self_attn.k_proj.weight', 'transformer.layers.12.self_attn.o_proj.weight', 'transformer.layers.12.self_attn.q_proj.weight', 'transformer.layers.12.self_attn.v_proj.weight', 'transformer.layers.13.input_layernorm.weight', 'transformer.layers.13.mlp.down_proj.weight', 'transformer.layers.13.mlp.gate_proj.weight', 'transformer.layers.13.mlp.up_proj.weight', 'transformer.layers.13.post_attention_layernorm.weight', 'transformer.layers.13.self_attn.k_proj.weight', 'transformer.layers.13.self_attn.o_proj.weight', 'transformer.layers.13.self_attn.q_proj.weight', 'transformer.layers.13.self_attn.v_proj.weight', 'transformer.layers.14.input_layernorm.weight', 'transformer.layers.14.mlp.down_proj.weight', 'transformer.layers.14.mlp.gate_proj.weight', 'transformer.layers.14.mlp.up_proj.weight', 'transformer.layers.14.post_attention_layernorm.weight', 'transformer.layers.14.self_attn.k_proj.weight', 'transformer.layers.14.self_attn.o_proj.weight', 'transformer.layers.14.self_attn.q_proj.weight', 'transformer.layers.14.self_attn.v_proj.weight', 'transformer.layers.15.input_layernorm.weight', 'transformer.layers.15.mlp.down_proj.weight', 'transformer.layers.15.mlp.gate_proj.weight', 'transformer.layers.15.mlp.up_proj.weight', 'transformer.layers.15.post_attention_layernorm.weight', 'transformer.layers.15.self_attn.k_proj.weight', 'transformer.layers.15.self_attn.o_proj.weight', 'transformer.layers.15.self_attn.q_proj.weight', 'transformer.layers.15.self_attn.v_proj.weight', 'transformer.layers.16.input_layernorm.weight', 'transformer.layers.16.mlp.down_proj.weight', 'transformer.layers.16.mlp.gate_proj.weight', 'transformer.layers.16.mlp.up_proj.weight', 'transformer.layers.16.post_attention_layernorm.weight', 'transformer.layers.16.self_attn.k_proj.weight', 'transformer.layers.16.self_attn.o_proj.weight', 'transformer.layers.16.self_attn.q_proj.weight', 'transformer.layers.16.self_attn.v_proj.weight', 'transformer.layers.17.input_layernorm.weight', 'transformer.layers.17.mlp.down_proj.weight', 'transformer.layers.17.mlp.gate_proj.weight', 'transformer.layers.17.mlp.up_proj.weight', 'transformer.layers.17.post_attention_layernorm.weight', 'transformer.layers.17.self_attn.k_proj.weight', 'transformer.layers.17.self_attn.o_proj.weight', 'transformer.layers.17.self_attn.q_proj.weight', 'transformer.layers.17.self_attn.v_proj.weight', 'transformer.layers.18.input_layernorm.weight', 'transformer.layers.18.mlp.down_proj.weight', 'transformer.layers.18.mlp.gate_proj.weight', 'transformer.layers.18.mlp.up_proj.weight', 'transformer.layers.18.post_attention_layernorm.weight', 'transformer.layers.18.self_attn.k_proj.weight', 'transformer.layers.18.self_attn.o_proj.weight', 'transformer.layers.18.self_attn.q_proj.weight', 'transformer.layers.18.self_attn.v_proj.weight', 'transformer.layers.19.input_layernorm.weight', 'transformer.layers.19.mlp.down_proj.weight', 'transformer.layers.19.mlp.gate_proj.weight', 'transformer.layers.19.mlp.up_proj.weight', 'transformer.layers.19.post_attention_layernorm.weight', 'transformer.layers.19.self_attn.k_proj.weight', 'transformer.layers.19.self_attn.o_proj.weight', 'transformer.layers.19.self_attn.q_proj.weight', 'transformer.layers.19.self_attn.v_proj.weight', 'transformer.layers.2.input_layernorm.weight', 'transformer.layers.2.mlp.down_proj.weight', 'transformer.layers.2.mlp.gate_proj.weight', 'transformer.layers.2.mlp.up_proj.weight', 'transformer.layers.2.post_attention_layernorm.weight', 'transformer.layers.2.self_attn.k_proj.weight', 'transformer.layers.2.self_attn.o_proj.weight', 'transformer.layers.2.self_attn.q_proj.weight', 'transformer.layers.2.self_attn.v_proj.weight', 'transformer.layers.20.input_layernorm.weight', 'transformer.layers.20.mlp.down_proj.weight', 'transformer.layers.20.mlp.gate_proj.weight', 'transformer.layers.20.mlp.up_proj.weight', 'transformer.layers.20.post_attention_layernorm.weight', 'transformer.layers.20.self_attn.k_proj.weight', 'transformer.layers.20.self_attn.o_proj.weight', 'transformer.layers.20.self_attn.q_proj.weight', 'transformer.layers.20.self_attn.v_proj.weight', 'transformer.layers.21.input_layernorm.weight', 'transformer.layers.21.mlp.down_proj.weight', 'transformer.layers.21.mlp.gate_proj.weight', 'transformer.layers.21.mlp.up_proj.weight', 'transformer.layers.21.post_attention_layernorm.weight', 'transformer.layers.21.self_attn.k_proj.weight', 'transformer.layers.21.self_attn.o_proj.weight', 'transformer.layers.21.self_attn.q_proj.weight', 'transformer.layers.21.self_attn.v_proj.weight', 'transformer.layers.22.input_layernorm.weight', 'transformer.layers.22.mlp.down_proj.weight', 'transformer.layers.22.mlp.gate_proj.weight', 'transformer.layers.22.mlp.up_proj.weight', 'transformer.layers.22.post_attention_layernorm.weight', 'transformer.layers.22.self_attn.k_proj.weight', 'transformer.layers.22.self_attn.o_proj.weight', 'transformer.layers.22.self_attn.q_proj.weight', 'transformer.layers.22.self_attn.v_proj.weight', 'transformer.layers.23.input_layernorm.weight', 'transformer.layers.23.mlp.down_proj.weight', 'transformer.layers.23.mlp.gate_proj.weight', 'transformer.layers.23.mlp.up_proj.weight', 'transformer.layers.23.post_attention_layernorm.weight', 'transformer.layers.23.self_attn.k_proj.weight', 'transformer.layers.23.self_attn.o_proj.weight', 'transformer.layers.23.self_attn.q_proj.weight', 'transformer.layers.23.self_attn.v_proj.weight', 'transformer.layers.24.input_layernorm.weight', 'transformer.layers.24.mlp.down_proj.weight', 'transformer.layers.24.mlp.gate_proj.weight', 'transformer.layers.24.mlp.up_proj.weight', 'transformer.layers.24.post_attention_layernorm.weight', 'transformer.layers.24.self_attn.k_proj.weight', 'transformer.layers.24.self_attn.o_proj.weight', 'transformer.layers.24.self_attn.q_proj.weight', 'transformer.layers.24.self_attn.v_proj.weight', 'transformer.layers.25.input_layernorm.weight', 'transformer.layers.25.mlp.down_proj.weight', 'transformer.layers.25.mlp.gate_proj.weight', 'transformer.layers.25.mlp.up_proj.weight', 'transformer.layers.25.post_attention_layernorm.weight', 'transformer.layers.25.self_attn.k_proj.weight', 'transformer.layers.25.self_attn.o_proj.weight', 'transformer.layers.25.self_attn.q_proj.weight', 'transformer.layers.25.self_attn.v_proj.weight', 'transformer.layers.26.input_layernorm.weight', 'transformer.layers.26.mlp.down_proj.weight', 'transformer.layers.26.mlp.gate_proj.weight', 'transformer.layers.26.mlp.up_proj.weight', 'transformer.layers.26.post_attention_layernorm.weight', 'transformer.layers.26.self_attn.k_proj.weight', 'transformer.layers.26.self_attn.o_proj.weight', 'transformer.layers.26.self_attn.q_proj.weight', 'transformer.layers.26.self_attn.v_proj.weight', 'transformer.layers.27.input_layernorm.weight', 'transformer.layers.27.mlp.down_proj.weight', 'transformer.layers.27.mlp.gate_proj.weight', 'transformer.layers.27.mlp.up_proj.weight', 'transformer.layers.27.post_attention_layernorm.weight', 'transformer.layers.27.self_attn.k_proj.weight', 'transformer.layers.27.self_attn.o_proj.weight', 'transformer.layers.27.self_attn.q_proj.weight', 'transformer.layers.27.self_attn.v_proj.weight', 'transformer.layers.28.input_layernorm.weight', 'transformer.layers.28.mlp.down_proj.weight', 'transformer.layers.28.mlp.gate_proj.weight', 'transformer.layers.28.mlp.up_proj.weight', 'transformer.layers.28.post_attention_layernorm.weight', 'transformer.layers.28.self_attn.k_proj.weight', 'transformer.layers.28.self_attn.o_proj.weight', 'transformer.layers.28.self_attn.q_proj.weight', 'transformer.layers.28.self_attn.v_proj.weight', 'transformer.layers.29.input_layernorm.weight', 'transformer.layers.29.mlp.down_proj.weight', 'transformer.layers.29.mlp.gate_proj.weight', 'transformer.layers.29.mlp.up_proj.weight', 'transformer.layers.29.post_attention_layernorm.weight', 'transformer.layers.29.self_attn.k_proj.weight', 'transformer.layers.29.self_attn.o_proj.weight', 'transformer.layers.29.self_attn.q_proj.weight', 'transformer.layers.29.self_attn.v_proj.weight', 'transformer.layers.3.input_layernorm.weight', 'transformer.layers.3.mlp.down_proj.weight', 'transformer.layers.3.mlp.gate_proj.weight', 'transformer.layers.3.mlp.up_proj.weight', 'transformer.layers.3.post_attention_layernorm.weight', 'transformer.layers.3.self_attn.k_proj.weight', 'transformer.layers.3.self_attn.o_proj.weight', 'transformer.layers.3.self_attn.q_proj.weight', 'transformer.layers.3.self_attn.v_proj.weight', 'transformer.layers.30.input_layernorm.weight', 'transformer.layers.30.mlp.down_proj.weight', 'transformer.layers.30.mlp.gate_proj.weight', 'transformer.layers.30.mlp.up_proj.weight', 'transformer.layers.30.post_attention_layernorm.weight', 'transformer.layers.30.self_attn.k_proj.weight', 'transformer.layers.30.self_attn.o_proj.weight', 'transformer.layers.30.self_attn.q_proj.weight', 'transformer.layers.30.self_attn.v_proj.weight', 'transformer.layers.31.input_layernorm.weight', 'transformer.layers.31.mlp.down_proj.weight', 'transformer.layers.31.mlp.gate_proj.weight', 'transformer.layers.31.mlp.up_proj.weight', 'transformer.layers.31.post_attention_layernorm.weight', 'transformer.layers.31.self_attn.k_proj.weight', 'transformer.layers.31.self_attn.o_proj.weight', 'transformer.layers.31.self_attn.q_proj.weight', 'transformer.layers.31.self_attn.v_proj.weight', 'transformer.layers.4.input_layernorm.weight', 'transformer.layers.4.mlp.down_proj.weight', 'transformer.layers.4.mlp.gate_proj.weight', 'transformer.layers.4.mlp.up_proj.weight', 'transformer.layers.4.post_attention_layernorm.weight', 'transformer.layers.4.self_attn.k_proj.weight', 'transformer.layers.4.self_attn.o_proj.weight', 'transformer.layers.4.self_attn.q_proj.weight', 'transformer.layers.4.self_attn.v_proj.weight', 'transformer.layers.5.input_layernorm.weight', 'transformer.layers.5.mlp.down_proj.weight', 'transformer.layers.5.mlp.gate_proj.weight', 'transformer.layers.5.mlp.up_proj.weight', 'transformer.layers.5.post_attention_layernorm.weight', 'transformer.layers.5.self_attn.k_proj.weight', 'transformer.layers.5.self_attn.o_proj.weight', 'transformer.layers.5.self_attn.q_proj.weight', 'transformer.layers.5.self_attn.v_proj.weight', 'transformer.layers.6.input_layernorm.weight', 'transformer.layers.6.mlp.down_proj.weight', 'transformer.layers.6.mlp.gate_proj.weight', 'transformer.layers.6.mlp.up_proj.weight', 'transformer.layers.6.post_attention_layernorm.weight', 'transformer.layers.6.self_attn.k_proj.weight', 'transformer.layers.6.self_attn.o_proj.weight', 'transformer.layers.6.self_attn.q_proj.weight', 'transformer.layers.6.self_attn.v_proj.weight', 'transformer.layers.7.input_layernorm.weight', 'transformer.layers.7.mlp.down_proj.weight', 'transformer.layers.7.mlp.gate_proj.weight', 'transformer.layers.7.mlp.up_proj.weight', 'transformer.layers.7.post_attention_layernorm.weight', 'transformer.layers.7.self_attn.k_proj.weight', 'transformer.layers.7.self_attn.o_proj.weight', 'transformer.layers.7.self_attn.q_proj.weight', 'transformer.layers.7.self_attn.v_proj.weight', 'transformer.layers.8.input_layernorm.weight', 'transformer.layers.8.mlp.down_proj.weight', 'transformer.layers.8.mlp.gate_proj.weight', 'transformer.layers.8.mlp.up_proj.weight', 'transformer.layers.8.post_attention_layernorm.weight', 'transformer.layers.8.self_attn.k_proj.weight', 'transformer.layers.8.self_attn.o_proj.weight', 'transformer.layers.8.self_attn.q_proj.weight', 'transformer.layers.8.self_attn.v_proj.weight', 'transformer.layers.9.input_layernorm.weight', 'transformer.layers.9.mlp.down_proj.weight', 'transformer.layers.9.mlp.gate_proj.weight', 'transformer.layers.9.mlp.up_proj.weight', 'transformer.layers.9.post_attention_layernorm.weight', 'transformer.layers.9.self_attn.k_proj.weight', 'transformer.layers.9.self_attn.o_proj.weight', 'transformer.layers.9.self_attn.q_proj.weight', 'transformer.layers.9.self_attn.v_proj.weight', 'transformer.norm.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LlamaForQuestionAnswering(\n",
       "  (transformer): LlamaModel(\n",
       "    (embed_tokens): Embedding(128256, 4096, padding_idx=128004)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (qa_outputs): Linear4bit(in_features=4096, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the base model\n",
    "base_model = LlamaForQuestionAnswering.from_pretrained(lora_config.base_model_name_or_path, device_map='auto')\n",
    "# base_model = base_model.to(device)\n",
    "base_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline('question-answering', model=base_model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_evaluator = evaluator('question-answering')\n",
    "eval_results = task_evaluator.compute(\n",
    "    model_or_pipeline=pipe,\n",
    "    data=data,\n",
    "    metric='squad',\n",
    "    strategy='bootstrap',\n",
    "    n_resamples=30,\n",
    "    squad_v2_format=False,  # Whether the dataset follows the format of squad_v2 dataset, \n",
    "                            # where a question may have no answer in the context\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
